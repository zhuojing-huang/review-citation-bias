id,summary,strengths,weaknesses,questions,limitations,flag_for_ethics_review,rating,confidence,Reviewer_Confidence,code_of_conduct,contribution,presentation,soundness,cdate,ddate,details,domain,forum,invitations,license,mdate,nonreaders,number,odate,pdate,readers,replyto,signatures,tcdate,tmdate,writers,response,binary_label,suggested_years,paper_info
bGgptw4vRO,"The paper presents a method that solves a specific type of problem of combinatorial optimization (hypergraph minimum vertex cover) through spiking neural networks. The method, tested on small versions of the problem, enables a neuromorphic hardware system made by Intel to arrive at a result in cases where previous methods did not, and with less energy consumption than certain other methods if they are ran on CPU.","The work advances the field of neural networks beyond machine learning, i.e. in combinatorial optimization.

Moreover, it concerns spiking neural networks, a field that has been attracting growing interest.

Furthermore, the method is actually tested in neuromorphic hardware, contrary to many papers in the field that only include theoretical implications for neuromorphic hardware.

Moreover, the work presents new partial evidence that neuromorphic algorithms and neuromorphic hardware may have advantages over more conventional approaches, a promise of this research field that has been long looking for fulfillment.","On the other hand, the paper has several weaknesses.

1. The paper does not make clear how significant the type of problem addressed here (HMVC) is, and why it is significant.

2. A figure illustrating an example toy problem of HMVC as well as its solution in the QUBO-based SNN and in the newly proposed method would be very helfpul in clarifying the paper's contribution.

3. The literature review around neuromorphic hardware is rather narrow, and largely focuses on Loihi alone. For example, even narrowly focusing on hardware for Ising models, here is a review of various implementations that could be cited: https://www.nature.com/articles/s42254-022-00440-8

4. Section 2 cites works where SNNs have performed well, but only does this for tasks outside of machine learning. For machine learning there is only a pointer to a survey, which is related to Loihi again, and again focuses largely beyond machine learning. This should be mitigated, especially because in reality, machine learning is arguably the more popular application of SNNs, and spiking machine learning models have in fact outperformed non-spiking ones concretely and under fair hardware conditions in certain cases. Here are the two examples that I am aware of: https://arxiv.org/abs/2009.06808 (under certain temporal dynamics SNNs were shown to be theoretically optimal and practically surpassed ANNs in accuracy) and https://openreview.net/forum?id=iMH1e5k7n3LI (spikes improved inference speed without accuracy drops, and even on GPUs).

5. Most importantly, I believe that the paper's contribution to the broader field of Neural Networks might not be significant, for the following reasons.

- 5a. The work is specifically related to SNNs alone, and specifically related to their use for combinatorial optimization and even more narrowly, specifically HMVC. That is a rather niche scenario.
- 5b. The results are on rather small scale demonstrations.
- 5c. It is unclear that there is any advantage from the neuromorphic aspect. Specifically, the presented heuristic-based algorithm (or a suitable adaptation) has not been tested on CPU. It seems that in the same way that previous SNN approaches were comparable to QUBO and could thus be run on CPU, there must be an analog of the new method that can also be tested on CPU, and might be more energy efficient than Loihi. After all, QUBO on CPU is more efficient than QUBO on Loihi, as the paper shows. Similarly, is QUBO on CPU the baseline to beat to claim a neuromorphic advantage, or should it be eg a microcontroller or an FPGA?

6. The authors mention that they could not change the random seed to obtain statistics. For a stochastic algorithm like the one presented, this seems rather important. Could this be mitigated, eg by running the algorithm on CPU and obtaining some statistics there?","Could the authors address the above points?

Is there an intuitive explanation why QUBO on Loihi is less efficient than on CPU, and does this explanation not apply to the authors' new approach?

Why can't the random seed be changed?","Some of the limitations mentioned in this review are mentioned in the paper, but not all.",['No ethics review needed.'],8,4,,Yes,3,2,3,1720990861135,,,NeurIPS.cc/2024/Conference,4A5IQEjG8c,"['NeurIPS.cc/2024/Conference/Submission565/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878650786,[],4,,,['everyone'],4A5IQEjG8c,['NeurIPS.cc/2024/Conference/Submission565/Reviewer_Que6'],1720990861135,1730878650786,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission565/Reviewer_Que6']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. A review of various implementations of neuromorphic hardware for Ising models, which can be found at https://www.nature.com/articles/s42254-022-00440-8.
2. Two examples of spiking machine learning models that have outperformed non-spiking ones:
   - https://arxiv.org/abs/2009.06808 (under certain temporal dynamics SNNs were shown to be theoretically optimal and practically surpassed ANNs in accuracy)
   - https://openreview.net/forum?id=iMH1e5k7n3LI (spikes improved inference speed without accuracy drops, and even on GPUs)",1,2020,A review of various implementations of neuromorphic hardware for Ising models 
bGgptw4vRO,"The paper presents a method that solves a specific type of problem of combinatorial optimization (hypergraph minimum vertex cover) through spiking neural networks. The method, tested on small versions of the problem, enables a neuromorphic hardware system made by Intel to arrive at a result in cases where previous methods did not, and with less energy consumption than certain other methods if they are ran on CPU.","The work advances the field of neural networks beyond machine learning, i.e. in combinatorial optimization.

Moreover, it concerns spiking neural networks, a field that has been attracting growing interest.

Furthermore, the method is actually tested in neuromorphic hardware, contrary to many papers in the field that only include theoretical implications for neuromorphic hardware.

Moreover, the work presents new partial evidence that neuromorphic algorithms and neuromorphic hardware may have advantages over more conventional approaches, a promise of this research field that has been long looking for fulfillment.","On the other hand, the paper has several weaknesses.

1. The paper does not make clear how significant the type of problem addressed here (HMVC) is, and why it is significant.

2. A figure illustrating an example toy problem of HMVC as well as its solution in the QUBO-based SNN and in the newly proposed method would be very helfpul in clarifying the paper's contribution.

3. The literature review around neuromorphic hardware is rather narrow, and largely focuses on Loihi alone. For example, even narrowly focusing on hardware for Ising models, here is a review of various implementations that could be cited: https://www.nature.com/articles/s42254-022-00440-8

4. Section 2 cites works where SNNs have performed well, but only does this for tasks outside of machine learning. For machine learning there is only a pointer to a survey, which is related to Loihi again, and again focuses largely beyond machine learning. This should be mitigated, especially because in reality, machine learning is arguably the more popular application of SNNs, and spiking machine learning models have in fact outperformed non-spiking ones concretely and under fair hardware conditions in certain cases. Here are the two examples that I am aware of: https://arxiv.org/abs/2009.06808 (under certain temporal dynamics SNNs were shown to be theoretically optimal and practically surpassed ANNs in accuracy) and https://openreview.net/forum?id=iMH1e5k7n3LI (spikes improved inference speed without accuracy drops, and even on GPUs).

5. Most importantly, I believe that the paper's contribution to the broader field of Neural Networks might not be significant, for the following reasons.

- 5a. The work is specifically related to SNNs alone, and specifically related to their use for combinatorial optimization and even more narrowly, specifically HMVC. That is a rather niche scenario.
- 5b. The results are on rather small scale demonstrations.
- 5c. It is unclear that there is any advantage from the neuromorphic aspect. Specifically, the presented heuristic-based algorithm (or a suitable adaptation) has not been tested on CPU. It seems that in the same way that previous SNN approaches were comparable to QUBO and could thus be run on CPU, there must be an analog of the new method that can also be tested on CPU, and might be more energy efficient than Loihi. After all, QUBO on CPU is more efficient than QUBO on Loihi, as the paper shows. Similarly, is QUBO on CPU the baseline to beat to claim a neuromorphic advantage, or should it be eg a microcontroller or an FPGA?

6. The authors mention that they could not change the random seed to obtain statistics. For a stochastic algorithm like the one presented, this seems rather important. Could this be mitigated, eg by running the algorithm on CPU and obtaining some statistics there?","Could the authors address the above points?

Is there an intuitive explanation why QUBO on Loihi is less efficient than on CPU, and does this explanation not apply to the authors' new approach?

Why can't the random seed be changed?","Some of the limitations mentioned in this review are mentioned in the paper, but not all.",['No ethics review needed.'],8,4,,Yes,3,2,3,1720990861135,,,NeurIPS.cc/2024/Conference,4A5IQEjG8c,"['NeurIPS.cc/2024/Conference/Submission565/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878650786,[],4,,,['everyone'],4A5IQEjG8c,['NeurIPS.cc/2024/Conference/Submission565/Reviewer_Que6'],1720990861135,1730878650786,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission565/Reviewer_Que6']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. A review of various implementations of neuromorphic hardware for Ising models, which can be found at https://www.nature.com/articles/s42254-022-00440-8.
2. Two examples of spiking machine learning models that have outperformed non-spiking ones:
   - https://arxiv.org/abs/2009.06808 (under certain temporal dynamics SNNs were shown to be theoretically optimal and practically surpassed ANNs in accuracy)
   - https://openreview.net/forum?id=iMH1e5k7n3LI (spikes improved inference speed without accuracy drops, and even on GPUs)",1,2020,Spiking Neural Networks Strategically Exploit Spatiotemporal Sparsity
SBlyRnJ2Ir,"The paper presents a novel approach to the problem of OOD generalization and detection. The authors introduce the AHA (Adaptive Human-Assisted OOD learning) framework, which aims to enhance both out-of-distribution (OOD) generalization and detection by strategically leveraging human-assisted labeling within a maximum disambiguation region. The paper reports significant improvements over state-of-the-art methods with only a few hundred human annotations, demonstrating the efficacy of the proposed framework.","- The AHA framework is a creative solution that addresses the challenges of OOD generalization and detection, which are critical for real-world applications of machine learning models.
- The authors provide extensive experimental results that validate the effectiveness of their approach, showing robust performance across various datasets.
- The incorporation of human feedback in a strategic manner is a strength, as it capitalizes on the limited labeling budget to maximize model performance.
- The paper's contributions are articulated, with the novel labeling strategy and the integration of human assistance being the highlights.
- The transformation of the problem into a noisy binary search is an intelligent methodological choice that allows for the efficient identification of the maximum ambiguity threshold.","- While the paper demonstrates strong results, it is not clear how the AHA framework scales with larger and more complex datasets.
- The reliance on human annotations could be a limitation in scenarios where such resources are not readily available or are cost-prohibitive.
- The paper could benefit from a discussion on how the findings generalize beyond the tested datasets and scenarios.
- The computational complexity of the AHA algorithm and its runtime performance on large datasets are not discussed.
- The paper could address potential biases introduced by human labeling, especially in the context of OOD detection.","- How does the AHA framework perform as the size and complexity of the dataset increase?
- What are the specific steps taken to mitigate potential biases in human labeling?
- Can the authors provide more details on the computational efficiency of the AHA algorithm, especially for large-scale applications?
- How does the framework handle a class imbalance in the context of OOD detection?
- Are there any specific domains or applications where the AHA framework is expected to be more or less effective, and why?
- Could the proposed method benefit the OOD detection with unreliable sources [R1] and inspire unsupervised OOD detection [R2]?

----
[R1] Out-of-distribution detection learning with unreliable out-of-distribution sources. NeurIPS 2023.   
[R2] Out-of-distribution detection with an adaptive likelihood ratio on informative hierarchical vae. NeurIPS 2022.",NA.,['No ethics review needed.'],7,4,,Yes,3,3,3,1718246471823,,,NeurIPS.cc/2024/Conference,49hXkwpWKA,"['NeurIPS.cc/2024/Conference/Submission7984/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879208542,[],1,,,['everyone'],49hXkwpWKA,['NeurIPS.cc/2024/Conference/Submission7984/Reviewer_CyPp'],1718246471823,1730879208542,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7984/Reviewer_CyPp']","Yes, this peer review explicitly suggests the authors of the paper to consider citing two specific literature references:

1. ""Out-of-distribution detection learning with unreliable out-of-distribution sources. NeurIPS 2023"" (referred to as [R1])
2. ""Out-of-distribution detection with an adaptive likelihood ratio on informative hierarchical vae. NeurIPS 2022"" (referred to as [R2])

The reviewer mentions that the proposed method could benefit OOD detection with unreliable sources ([R1]) and inspire unsupervised OOD detection ([R2]), implying that the authors should consider citing these references to further enhance their work.",1,"2023, 2022",Out-of-distribution detection learning with unreliable out-of-distribution sources 
SBlyRnJ2Ir,"The paper presents a novel approach to the problem of OOD generalization and detection. The authors introduce the AHA (Adaptive Human-Assisted OOD learning) framework, which aims to enhance both out-of-distribution (OOD) generalization and detection by strategically leveraging human-assisted labeling within a maximum disambiguation region. The paper reports significant improvements over state-of-the-art methods with only a few hundred human annotations, demonstrating the efficacy of the proposed framework.","- The AHA framework is a creative solution that addresses the challenges of OOD generalization and detection, which are critical for real-world applications of machine learning models.
- The authors provide extensive experimental results that validate the effectiveness of their approach, showing robust performance across various datasets.
- The incorporation of human feedback in a strategic manner is a strength, as it capitalizes on the limited labeling budget to maximize model performance.
- The paper's contributions are articulated, with the novel labeling strategy and the integration of human assistance being the highlights.
- The transformation of the problem into a noisy binary search is an intelligent methodological choice that allows for the efficient identification of the maximum ambiguity threshold.","- While the paper demonstrates strong results, it is not clear how the AHA framework scales with larger and more complex datasets.
- The reliance on human annotations could be a limitation in scenarios where such resources are not readily available or are cost-prohibitive.
- The paper could benefit from a discussion on how the findings generalize beyond the tested datasets and scenarios.
- The computational complexity of the AHA algorithm and its runtime performance on large datasets are not discussed.
- The paper could address potential biases introduced by human labeling, especially in the context of OOD detection.","- How does the AHA framework perform as the size and complexity of the dataset increase?
- What are the specific steps taken to mitigate potential biases in human labeling?
- Can the authors provide more details on the computational efficiency of the AHA algorithm, especially for large-scale applications?
- How does the framework handle a class imbalance in the context of OOD detection?
- Are there any specific domains or applications where the AHA framework is expected to be more or less effective, and why?
- Could the proposed method benefit the OOD detection with unreliable sources [R1] and inspire unsupervised OOD detection [R2]?

----
[R1] Out-of-distribution detection learning with unreliable out-of-distribution sources. NeurIPS 2023.   
[R2] Out-of-distribution detection with an adaptive likelihood ratio on informative hierarchical vae. NeurIPS 2022.",NA.,['No ethics review needed.'],7,4,,Yes,3,3,3,1718246471823,,,NeurIPS.cc/2024/Conference,49hXkwpWKA,"['NeurIPS.cc/2024/Conference/Submission7984/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879208542,[],1,,,['everyone'],49hXkwpWKA,['NeurIPS.cc/2024/Conference/Submission7984/Reviewer_CyPp'],1718246471823,1730879208542,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7984/Reviewer_CyPp']","Yes, this peer review explicitly suggests the authors of the paper to consider citing two specific literature references:

1. ""Out-of-distribution detection learning with unreliable out-of-distribution sources. NeurIPS 2023"" (referred to as [R1])
2. ""Out-of-distribution detection with an adaptive likelihood ratio on informative hierarchical vae. NeurIPS 2022"" (referred to as [R2])

The reviewer mentions that the proposed method could benefit OOD detection with unreliable sources ([R1]) and inspire unsupervised OOD detection ([R2]), implying that the authors should consider citing these references to further enhance their work.",1,"2023, 2022",Out-of-distribution detection with an adaptive likelihood ratio on informative hierarchical vae
WUHaywGFBj,"The paper presents a LLM-enhanced evolutionary algorithm to solve diverse combinatorial optimization problems. The method is evaludated on various COPs and heuristics, however, the advantage of proposed method compared to recent ML4CO methods that does not use LLM requires more specification.","1. The paper proposed a LLM-enhanced hyper-heuristic model to solve various combinatorial optimization problems.
2. Extensive experiments show the efficacy of the proposed method on five different COPs and multiple heuristics.","1. Some details of model is not fully specified from the text, including the meaning, output of ""short-term reflection"" and ""long-term reflection"". It is unclear how the process is done and how this process completes the ""reflection""？
2. Though the proposed method has demonstrated the advances compared with heuristics, on specific problems (take TSP as example), there might be some recent models undiscussed in this paper that does not use heuristic but still achieve competitive results, such as [1,2] that conducts TSP experiments on 1000 and 10000. 
3. The paper does not specify the costs of using LLM APIs, which could be real challenges when readers want to follow and reproduce the results in this paper.

[1] Qiu R, Sun Z, Yang Y. Dimes: A differentiable meta solver for combinatorial optimization problems[J]. Advances in Neural Information Processing Systems, 2022, 35: 25531-25546.
[2] Li Y, Guo J, Wang R, et al. From distribution learning in training to gradient search in testing for combinatorial optimization[J]. Advances in Neural Information Processing Systems, 2024, 36","1. What result does figure 4(B) shows, the obejective value or the gap towards the optimal? Without specifying the evaluation metric, it is difficult to interpret the results.
2. How does the proposed method compared to recent ML4CO method on TSP [1,2], or probably other methods on VRP? From my experience, hyper-heuristic methods may not perform well as these methods on solution quality or solving time. What is the advantage of LLM-enhanced heuristics in these COPs?","The paper discuss some limitations, but the method may be limited by cost of LLM inference and problem scale.",['No ethics review needed.'],5,3,,Yes,2,3,2,1720532547336,,,NeurIPS.cc/2024/Conference,483IPG0HWL,"['NeurIPS.cc/2024/Conference/Submission7440/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879162256,[],2,,,['everyone'],483IPG0HWL,['NeurIPS.cc/2024/Conference/Submission7440/Reviewer_qdUQ'],1720532547336,1730879162256,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7440/Reviewer_qdUQ']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. Qiu R, Sun Z, Yang Y. Dimes: A differentiable meta solver for combinatorial optimization problems[J]. Advances in Neural Information Processing Systems, 2022, 35: 25531-25546.
2. Li Y, Guo J, Wang R, et al. From distribution learning in training to gradient search in testing for combinatorial optimization[J]. Advances in Neural Information Processing Systems, 2024, 36

The reviewer mentions these papers as examples of recent ML4CO methods that do not use LLMs and achieve competitive results on specific problems, such as TSP. The reviewer suggests that the authors should compare their proposed method to these methods to demonstrate its advantage.",1,"2022, 2024",Dimes A differentiable meta solver for combinatorial optimization problems 
WUHaywGFBj,"The paper presents a LLM-enhanced evolutionary algorithm to solve diverse combinatorial optimization problems. The method is evaludated on various COPs and heuristics, however, the advantage of proposed method compared to recent ML4CO methods that does not use LLM requires more specification.","1. The paper proposed a LLM-enhanced hyper-heuristic model to solve various combinatorial optimization problems.
2. Extensive experiments show the efficacy of the proposed method on five different COPs and multiple heuristics.","1. Some details of model is not fully specified from the text, including the meaning, output of ""short-term reflection"" and ""long-term reflection"". It is unclear how the process is done and how this process completes the ""reflection""？
2. Though the proposed method has demonstrated the advances compared with heuristics, on specific problems (take TSP as example), there might be some recent models undiscussed in this paper that does not use heuristic but still achieve competitive results, such as [1,2] that conducts TSP experiments on 1000 and 10000. 
3. The paper does not specify the costs of using LLM APIs, which could be real challenges when readers want to follow and reproduce the results in this paper.

[1] Qiu R, Sun Z, Yang Y. Dimes: A differentiable meta solver for combinatorial optimization problems[J]. Advances in Neural Information Processing Systems, 2022, 35: 25531-25546.
[2] Li Y, Guo J, Wang R, et al. From distribution learning in training to gradient search in testing for combinatorial optimization[J]. Advances in Neural Information Processing Systems, 2024, 36","1. What result does figure 4(B) shows, the obejective value or the gap towards the optimal? Without specifying the evaluation metric, it is difficult to interpret the results.
2. How does the proposed method compared to recent ML4CO method on TSP [1,2], or probably other methods on VRP? From my experience, hyper-heuristic methods may not perform well as these methods on solution quality or solving time. What is the advantage of LLM-enhanced heuristics in these COPs?","The paper discuss some limitations, but the method may be limited by cost of LLM inference and problem scale.",['No ethics review needed.'],5,3,,Yes,2,3,2,1720532547336,,,NeurIPS.cc/2024/Conference,483IPG0HWL,"['NeurIPS.cc/2024/Conference/Submission7440/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879162256,[],2,,,['everyone'],483IPG0HWL,['NeurIPS.cc/2024/Conference/Submission7440/Reviewer_qdUQ'],1720532547336,1730879162256,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7440/Reviewer_qdUQ']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. Qiu R, Sun Z, Yang Y. Dimes: A differentiable meta solver for combinatorial optimization problems[J]. Advances in Neural Information Processing Systems, 2022, 35: 25531-25546.
2. Li Y, Guo J, Wang R, et al. From distribution learning in training to gradient search in testing for combinatorial optimization[J]. Advances in Neural Information Processing Systems, 2024, 36

The reviewer mentions these papers as examples of recent ML4CO methods that do not use LLMs and achieve competitive results on specific problems, such as TSP. The reviewer suggests that the authors should compare their proposed method to these methods to demonstrate its advantage.",1,"2022, 2024",From distribution learning in training to gradient search in testing for combinatorial optimization
Ai100MdjVt,"The paper presents Rockafellian Relaxation (RR), a new method to address labeling errors in machine learning datasets. RR is a loss reweighting technique that enhances neural network robustness against labeling errors and adversarial attacks, working across various data domains and model architectures. The key contribution is an approach that mitigates label corruption and class imbalance without needing clean validation sets, offering a practical solution for training robust models.","- The paper introduces Rockafellian Relaxation (RR), a novel loss reweighting methodology that addresses learning with noisy label problems

- The authors provide a solid theoretical basis for RR, relating it to optimistic and robust distributional optimization formulations. RR is also designed to be architecture-independent, making it a versatile tool applicable across different neural network architectures.

- The method does not rely on having clean validation data, which is of advantage in many real-world applications.","- While not explicitly mentioned, the iterative nature of the RR algorithm could potentially be computationally intensive, especially for large datasets.

- The method assumes a specific model of label noise (e.g., uniform label noise), which may not hold in all real-world scenarios. 

- The paper could benefit from a more comprehensive comparison with other state-of-the-art methods for handling noisy labels, such as GCE [1], ELR[2], to better position RR in the existing literature.

[R1] Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels

[R2] Early-Learning Regularization Prevents Memorization of Noisy Labels","- Could the authors provide insights into the computational complexity of the RR algorithm, particularly in the context of large-scale datasets such as clothing1m?

- How does the performance of RR compare under different models of label noise, especially those that deviate from the assumed uniform label noise model such as asymmetric/instance-dependent label noise?

- How does RR perform relative to other state-of-the-art methods like Generalized Cross Entropy (GCE) and Early-Learning Regularization (ELR) in terms of handling noisy labels?

- How sensitive is the performance of RR to the choice of hyperparameters, and are there any techniques to optimize these selections effectively?",Authors have adequately addressed the limitations.,['No ethics review needed.'],5,4,,Yes,3,2,3,1721129571514,,,NeurIPS.cc/2024/Conference,47CdPNiWUB,"['NeurIPS.cc/2024/Conference/Submission7923/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879203051,[],3,,,['everyone'],47CdPNiWUB,['NeurIPS.cc/2024/Conference/Submission7923/Reviewer_UZpK'],1721129571514,1730879203051,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7923/Reviewer_UZpK']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. [R1] Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels
2. [R2] Early-Learning Regularization Prevents Memorization of Noisy Labels

The reviewer mentions that ""The paper could benefit from a more comprehensive comparison with other state-of-the-art methods for handling noisy labels, such as GCE [1], ELR[2], to better position RR in the existing literature."" This implies that the reviewer is encouraging the authors to cite and compare their work with these specific papers.",1,,Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels
Ai100MdjVt,"The paper presents Rockafellian Relaxation (RR), a new method to address labeling errors in machine learning datasets. RR is a loss reweighting technique that enhances neural network robustness against labeling errors and adversarial attacks, working across various data domains and model architectures. The key contribution is an approach that mitigates label corruption and class imbalance without needing clean validation sets, offering a practical solution for training robust models.","- The paper introduces Rockafellian Relaxation (RR), a novel loss reweighting methodology that addresses learning with noisy label problems

- The authors provide a solid theoretical basis for RR, relating it to optimistic and robust distributional optimization formulations. RR is also designed to be architecture-independent, making it a versatile tool applicable across different neural network architectures.

- The method does not rely on having clean validation data, which is of advantage in many real-world applications.","- While not explicitly mentioned, the iterative nature of the RR algorithm could potentially be computationally intensive, especially for large datasets.

- The method assumes a specific model of label noise (e.g., uniform label noise), which may not hold in all real-world scenarios. 

- The paper could benefit from a more comprehensive comparison with other state-of-the-art methods for handling noisy labels, such as GCE [1], ELR[2], to better position RR in the existing literature.

[R1] Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels

[R2] Early-Learning Regularization Prevents Memorization of Noisy Labels","- Could the authors provide insights into the computational complexity of the RR algorithm, particularly in the context of large-scale datasets such as clothing1m?

- How does the performance of RR compare under different models of label noise, especially those that deviate from the assumed uniform label noise model such as asymmetric/instance-dependent label noise?

- How does RR perform relative to other state-of-the-art methods like Generalized Cross Entropy (GCE) and Early-Learning Regularization (ELR) in terms of handling noisy labels?

- How sensitive is the performance of RR to the choice of hyperparameters, and are there any techniques to optimize these selections effectively?",Authors have adequately addressed the limitations.,['No ethics review needed.'],5,4,,Yes,3,2,3,1721129571514,,,NeurIPS.cc/2024/Conference,47CdPNiWUB,"['NeurIPS.cc/2024/Conference/Submission7923/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879203051,[],3,,,['everyone'],47CdPNiWUB,['NeurIPS.cc/2024/Conference/Submission7923/Reviewer_UZpK'],1721129571514,1730879203051,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7923/Reviewer_UZpK']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. [R1] Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels
2. [R2] Early-Learning Regularization Prevents Memorization of Noisy Labels

The reviewer mentions that ""The paper could benefit from a more comprehensive comparison with other state-of-the-art methods for handling noisy labels, such as GCE [1], ELR[2], to better position RR in the existing literature."" This implies that the reviewer is encouraging the authors to cite and compare their work with these specific papers.",1,,Early-Learning Regularization Prevents Memorization of Noisy Labels
W3BukVGX95,"This paper focused on improving the temporal consistency of video editing. They propose to leverage the inherent diffusion feature correspondence with a sliding-window based strategy. With this design, the tokens in noisy latents can be sampled based on the “one-to-many” correspondence. The experiments demonstrate superior performance than other methods.","+ The paper proposed a new diffusion feature correspondences guided video editing method. In addition, they introduce the token merging and sliding window for higher efficiency.

+ The method demonstrates superior performance than previous methods with extensive ablations to evaluate the effectiveness. 

+ The paper is well-written with clear motivations.","- The proposed method highly relies on the correspondences of diffusion features. However, such correspondences may be difficult to obtain for videos with large content motions. The reviewer suggests a more detailed discussion about how to ensure the accuracy of the correspondences, as well as what are the potential limitations of inaccurate correspondences. In addition, it would be better to quantitatively evaluate the correctness of the correspondences of diffusion features.

- The paper mainly discussed and compared their method with optical flow-guided video editing methods. However, such correspondence-based idea is also related to deformation field based methods such as CoDeF [1] or neural atlas based methods [2], where they can ensure the accuracy of pixel / point level accuracy by evaluating the video reconstruction accuracy. The authors are suggested to compare or discuss their method with such approaches.

- The related works seem to be a bit short and less extensive. There have been many video editing works that target at improving temporal / subject consistency, efficiency, long video editing, etc. The reviewer suggests to include a more extensive related works and discuss the differences of the proposed work with them. 

[1] Ouyang, Hao, et al. ""Codef: Content deformation fields for temporally consistent video processing."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.

[2] Chai, Wenhao, et al. ""Stablevideo: Text-driven consistency-aware diffusion video editing."" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.","o	The reviewer appreciates the qualitative examples of correspondences of diffusion features in appendix. Is there any quantitative metric to evaluate the correspondences of diffusion features?

o	How to define the temporal length for token merging? Does it remain the same for all experiment videos?",Yes.,['No ethics review needed.'],6,4,,Yes,3,3,3,1720857854900,,,NeurIPS.cc/2024/Conference,474M9aeI4U,"['NeurIPS.cc/2024/Conference/Submission142/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878626882,[],3,,,['everyone'],474M9aeI4U,['NeurIPS.cc/2024/Conference/Submission142/Reviewer_LETZ'],1720857854900,1730878626882,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission142/Reviewer_LETZ']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. Ouyang, Hao, et al. ""Codef: Content deformation fields for temporally consistent video processing."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.
2. Chai, Wenhao, et al. ""Stablevideo: Text-driven consistency-aware diffusion video editing."" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.

The reviewer suggests that the authors compare or discuss their method with these approaches, implying that they should be cited in the paper. Additionally, the reviewer mentions that the related works section seems to be a bit short and less extensive, suggesting that the authors should include a more extensive review of related literature, which may include citing other relevant papers.",1,"2024, 2023",Codef: Content deformation fields for temporally consistent video processing 
W3BukVGX95,"This paper focused on improving the temporal consistency of video editing. They propose to leverage the inherent diffusion feature correspondence with a sliding-window based strategy. With this design, the tokens in noisy latents can be sampled based on the “one-to-many” correspondence. The experiments demonstrate superior performance than other methods.","+ The paper proposed a new diffusion feature correspondences guided video editing method. In addition, they introduce the token merging and sliding window for higher efficiency.

+ The method demonstrates superior performance than previous methods with extensive ablations to evaluate the effectiveness. 

+ The paper is well-written with clear motivations.","- The proposed method highly relies on the correspondences of diffusion features. However, such correspondences may be difficult to obtain for videos with large content motions. The reviewer suggests a more detailed discussion about how to ensure the accuracy of the correspondences, as well as what are the potential limitations of inaccurate correspondences. In addition, it would be better to quantitatively evaluate the correctness of the correspondences of diffusion features.

- The paper mainly discussed and compared their method with optical flow-guided video editing methods. However, such correspondence-based idea is also related to deformation field based methods such as CoDeF [1] or neural atlas based methods [2], where they can ensure the accuracy of pixel / point level accuracy by evaluating the video reconstruction accuracy. The authors are suggested to compare or discuss their method with such approaches.

- The related works seem to be a bit short and less extensive. There have been many video editing works that target at improving temporal / subject consistency, efficiency, long video editing, etc. The reviewer suggests to include a more extensive related works and discuss the differences of the proposed work with them. 

[1] Ouyang, Hao, et al. ""Codef: Content deformation fields for temporally consistent video processing."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.

[2] Chai, Wenhao, et al. ""Stablevideo: Text-driven consistency-aware diffusion video editing."" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.","o	The reviewer appreciates the qualitative examples of correspondences of diffusion features in appendix. Is there any quantitative metric to evaluate the correspondences of diffusion features?

o	How to define the temporal length for token merging? Does it remain the same for all experiment videos?",Yes.,['No ethics review needed.'],6,4,,Yes,3,3,3,1720857854900,,,NeurIPS.cc/2024/Conference,474M9aeI4U,"['NeurIPS.cc/2024/Conference/Submission142/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878626882,[],3,,,['everyone'],474M9aeI4U,['NeurIPS.cc/2024/Conference/Submission142/Reviewer_LETZ'],1720857854900,1730878626882,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission142/Reviewer_LETZ']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. Ouyang, Hao, et al. ""Codef: Content deformation fields for temporally consistent video processing."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.
2. Chai, Wenhao, et al. ""Stablevideo: Text-driven consistency-aware diffusion video editing."" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.

The reviewer suggests that the authors compare or discuss their method with these approaches, implying that they should be cited in the paper. Additionally, the reviewer mentions that the related works section seems to be a bit short and less extensive, suggesting that the authors should include a more extensive review of related literature, which may include citing other relevant papers.",1,"2024, 2023",Stablevideo: Text-driven consistency-aware diffusion video editing
FJ45JlZcDc,"This paper introduces AsyncDiff, an acceleration framework for diffusion models that transforms the traditional sequential denoising process into an asynchronous process. The key insight is that hidden state features in consecutive sampling steps exhibit high similarity. Therefore, feeding the output of the preceding component at time step t-1 as an approximation of the original input to each U-Net component has a negligible impact on performance. This approach allows the parallel denoising processes of AsyncDiff to operate fully asynchronously. Experiments on various versions of Stable Diffusion demonstrate that AsyncDiff significantly speeds up the denoising process for text-to-image generation. Additionally, AsyncDiff is applicable to video generation models such as AnimateDiff and SVD, further showcasing its versatility.","1. The writing is overall clear and well-structured. The paper effectively explains the limitations of previous methods that use patch parallelism and introduces a novel approach to ""asynchronous"" denoising to address these issues.
2. The paper provides thorough comparisons with baseline methods, such as Distrifusion, demonstrating clear improvements in both generation quality and efficiency.
3. The versatility of AsyncDiff is evidenced by experiments conducted on different versions of Stable Diffusion as well as video generation models.
4. The authors address concerns regarding the overhead of communication costs across multiple GPUs, showing that these costs are significantly lower than the model execution time.","1. Although the main contribution relies on the observation that the hidden states of consecutive steps are similar, the analysis of this phenomenon lacks details. Several key aspects need clearer explanation:
(a) Can the similarity of the hidden states be quantitatively measured? For instance, does a low MSE between hidden states indicate that the two states are “similar”?
(b) Is this phenomenon specific to the U-Net architecture, or is it agnostic to the backbone of the denoising model (e.g., Diffusion Transformer)?
(c) Is it only applicable to DDIM sampling? Does the phenomenon also hold for other fast ODE solvers, such as the DPM solver [1]?

2. While the experiments were conducted using 50 DDIM steps, a comparison with the original model using a number of DDIM steps that achieve a similar speedup would strengthen the argument for AsyncDiff. For instance, in a setup where AsyncDiff achieves a 2.7x speedup, comparing the FID score with the original model using 50 / 2.7 = 19 DDIM steps would clearly demonstrate the necessity of parallelizing the diffusion model.

[1] DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps, Lu et al., NeurIPS 2022","Most questions are included in the “Weaknesses” section.

Would a similar asynchronous denoising approach be applicable in a conditional generation setup as well? For instance, achieving faster inference for diverse conditional image generation models, such as ControlNet [1] and Zero-1-to-3 [2], could be practically useful.

[1] Adding Conditional Control to Text-to-Image Diffusion Models, Zhang et al., ICCV 2023

[2] Zero-1-to-3: Zero-shot One Image to 3D Object, Liu et al., ICCV 2023","The authors discuss the limitations of AsyncDiff (communication cost, dependency on the base model) and the potential societal impacts.",['No ethics review needed.'],6,4,,Yes,3,4,3,1720514699312,,,NeurIPS.cc/2024/Conference,46jtDC6gXu,"['NeurIPS.cc/2024/Conference/Submission1625/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878715260,[],1,,,['everyone'],46jtDC6gXu,['NeurIPS.cc/2024/Conference/Submission1625/Reviewer_773c'],1720514699312,1730878715260,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission1625/Reviewer_773c']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two specific papers:

1. ""DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps"" by Lu et al., NeurIPS 2022, which is referenced as [1] in the review.
2. The reviewer also mentions two papers related to conditional generation setups:
   - ""Adding Conditional Control to Text-to-Image Diffusion Models"" by Zhang et al., ICCV 2023, referenced as [1].
   - ""Zero-1-to-3: Zero-shot One Image to 3D Object"" by Liu et al., ICCV 2023, referenced as [2].

These citations are suggested to provide context and support for the ideas and questions raised by the reviewer, particularly regarding the applicability of the asynchronous denoising approach to conditional generation setups.",1,"2022, 2023, 2023",DPM-Solver A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps 
FJ45JlZcDc,"This paper introduces AsyncDiff, an acceleration framework for diffusion models that transforms the traditional sequential denoising process into an asynchronous process. The key insight is that hidden state features in consecutive sampling steps exhibit high similarity. Therefore, feeding the output of the preceding component at time step t-1 as an approximation of the original input to each U-Net component has a negligible impact on performance. This approach allows the parallel denoising processes of AsyncDiff to operate fully asynchronously. Experiments on various versions of Stable Diffusion demonstrate that AsyncDiff significantly speeds up the denoising process for text-to-image generation. Additionally, AsyncDiff is applicable to video generation models such as AnimateDiff and SVD, further showcasing its versatility.","1. The writing is overall clear and well-structured. The paper effectively explains the limitations of previous methods that use patch parallelism and introduces a novel approach to ""asynchronous"" denoising to address these issues.
2. The paper provides thorough comparisons with baseline methods, such as Distrifusion, demonstrating clear improvements in both generation quality and efficiency.
3. The versatility of AsyncDiff is evidenced by experiments conducted on different versions of Stable Diffusion as well as video generation models.
4. The authors address concerns regarding the overhead of communication costs across multiple GPUs, showing that these costs are significantly lower than the model execution time.","1. Although the main contribution relies on the observation that the hidden states of consecutive steps are similar, the analysis of this phenomenon lacks details. Several key aspects need clearer explanation:
(a) Can the similarity of the hidden states be quantitatively measured? For instance, does a low MSE between hidden states indicate that the two states are “similar”?
(b) Is this phenomenon specific to the U-Net architecture, or is it agnostic to the backbone of the denoising model (e.g., Diffusion Transformer)?
(c) Is it only applicable to DDIM sampling? Does the phenomenon also hold for other fast ODE solvers, such as the DPM solver [1]?

2. While the experiments were conducted using 50 DDIM steps, a comparison with the original model using a number of DDIM steps that achieve a similar speedup would strengthen the argument for AsyncDiff. For instance, in a setup where AsyncDiff achieves a 2.7x speedup, comparing the FID score with the original model using 50 / 2.7 = 19 DDIM steps would clearly demonstrate the necessity of parallelizing the diffusion model.

[1] DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps, Lu et al., NeurIPS 2022","Most questions are included in the “Weaknesses” section.

Would a similar asynchronous denoising approach be applicable in a conditional generation setup as well? For instance, achieving faster inference for diverse conditional image generation models, such as ControlNet [1] and Zero-1-to-3 [2], could be practically useful.

[1] Adding Conditional Control to Text-to-Image Diffusion Models, Zhang et al., ICCV 2023

[2] Zero-1-to-3: Zero-shot One Image to 3D Object, Liu et al., ICCV 2023","The authors discuss the limitations of AsyncDiff (communication cost, dependency on the base model) and the potential societal impacts.",['No ethics review needed.'],6,4,,Yes,3,4,3,1720514699312,,,NeurIPS.cc/2024/Conference,46jtDC6gXu,"['NeurIPS.cc/2024/Conference/Submission1625/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878715260,[],1,,,['everyone'],46jtDC6gXu,['NeurIPS.cc/2024/Conference/Submission1625/Reviewer_773c'],1720514699312,1730878715260,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission1625/Reviewer_773c']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two specific papers:

1. ""DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps"" by Lu et al., NeurIPS 2022, which is referenced as [1] in the review.
2. The reviewer also mentions two papers related to conditional generation setups:
   - ""Adding Conditional Control to Text-to-Image Diffusion Models"" by Zhang et al., ICCV 2023, referenced as [1].
   - ""Zero-1-to-3: Zero-shot One Image to 3D Object"" by Liu et al., ICCV 2023, referenced as [2].

These citations are suggested to provide context and support for the ideas and questions raised by the reviewer, particularly regarding the applicability of the asynchronous denoising approach to conditional generation setups.",1,"2022, 2023, 2023",Adding Conditional Control to Text-to-Image Diffusion Models 
FJ45JlZcDc,"This paper introduces AsyncDiff, an acceleration framework for diffusion models that transforms the traditional sequential denoising process into an asynchronous process. The key insight is that hidden state features in consecutive sampling steps exhibit high similarity. Therefore, feeding the output of the preceding component at time step t-1 as an approximation of the original input to each U-Net component has a negligible impact on performance. This approach allows the parallel denoising processes of AsyncDiff to operate fully asynchronously. Experiments on various versions of Stable Diffusion demonstrate that AsyncDiff significantly speeds up the denoising process for text-to-image generation. Additionally, AsyncDiff is applicable to video generation models such as AnimateDiff and SVD, further showcasing its versatility.","1. The writing is overall clear and well-structured. The paper effectively explains the limitations of previous methods that use patch parallelism and introduces a novel approach to ""asynchronous"" denoising to address these issues.
2. The paper provides thorough comparisons with baseline methods, such as Distrifusion, demonstrating clear improvements in both generation quality and efficiency.
3. The versatility of AsyncDiff is evidenced by experiments conducted on different versions of Stable Diffusion as well as video generation models.
4. The authors address concerns regarding the overhead of communication costs across multiple GPUs, showing that these costs are significantly lower than the model execution time.","1. Although the main contribution relies on the observation that the hidden states of consecutive steps are similar, the analysis of this phenomenon lacks details. Several key aspects need clearer explanation:
(a) Can the similarity of the hidden states be quantitatively measured? For instance, does a low MSE between hidden states indicate that the two states are “similar”?
(b) Is this phenomenon specific to the U-Net architecture, or is it agnostic to the backbone of the denoising model (e.g., Diffusion Transformer)?
(c) Is it only applicable to DDIM sampling? Does the phenomenon also hold for other fast ODE solvers, such as the DPM solver [1]?

2. While the experiments were conducted using 50 DDIM steps, a comparison with the original model using a number of DDIM steps that achieve a similar speedup would strengthen the argument for AsyncDiff. For instance, in a setup where AsyncDiff achieves a 2.7x speedup, comparing the FID score with the original model using 50 / 2.7 = 19 DDIM steps would clearly demonstrate the necessity of parallelizing the diffusion model.

[1] DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps, Lu et al., NeurIPS 2022","Most questions are included in the “Weaknesses” section.

Would a similar asynchronous denoising approach be applicable in a conditional generation setup as well? For instance, achieving faster inference for diverse conditional image generation models, such as ControlNet [1] and Zero-1-to-3 [2], could be practically useful.

[1] Adding Conditional Control to Text-to-Image Diffusion Models, Zhang et al., ICCV 2023

[2] Zero-1-to-3: Zero-shot One Image to 3D Object, Liu et al., ICCV 2023","The authors discuss the limitations of AsyncDiff (communication cost, dependency on the base model) and the potential societal impacts.",['No ethics review needed.'],6,4,,Yes,3,4,3,1720514699312,,,NeurIPS.cc/2024/Conference,46jtDC6gXu,"['NeurIPS.cc/2024/Conference/Submission1625/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878715260,[],1,,,['everyone'],46jtDC6gXu,['NeurIPS.cc/2024/Conference/Submission1625/Reviewer_773c'],1720514699312,1730878715260,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission1625/Reviewer_773c']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two specific papers:

1. ""DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps"" by Lu et al., NeurIPS 2022, which is referenced as [1] in the review.
2. The reviewer also mentions two papers related to conditional generation setups:
   - ""Adding Conditional Control to Text-to-Image Diffusion Models"" by Zhang et al., ICCV 2023, referenced as [1].
   - ""Zero-1-to-3: Zero-shot One Image to 3D Object"" by Liu et al., ICCV 2023, referenced as [2].

These citations are suggested to provide context and support for the ideas and questions raised by the reviewer, particularly regarding the applicability of the asynchronous denoising approach to conditional generation setups.",1,"2022, 2023, 2023",Zero-1-to-3 Zero-shot One Image to 3D Object
T3kLInd7zz,"This paper proposes AsyncDiff, a plug-and-play acceleration scheme that enables model parallelism across multiple devices. The core method involves dividing the diffusion model into multiple components and executing the inference in parallel. This is facilitated by the high similarity between hidden states in consecutive diffusion steps. With AsyncDiff, it is claimed that off-the-shelf diffusion models can be effectively accelerated with negligible degradation. Therefore, the key contribution of this paper lies in providing a simple and effective method to accelerate the diffusion process through parallelism.","1.	The proposed method is well-motivated, and the effectiveness of AsyncDiff has been evaluated on multiple models, making the results compelling.
2.	This method should be useful for video generation, which can take minutes or hours to produce a single video. The paper also supports this with experiments conducted on Stable Video Diffusion.
3.	As shown in Table 5, it seems that the communication cost can be covered by the inference cost, which is a favorable feature for model acceleration.","1.	Some concepts, such as the “dependency chain” in ABS, are not well explained. It would be beneficial if the author could provide a minimal explanation for these concepts.
2.	The paper appears to share a related idea with Distrifusion [1]. Could the author provide a more detailed discussion about the key differences between them? For example, the main difference seems to be the splitting schemes, where Distrifusion splits the data, and this approach splits the model. What is the main advantage of AsyncDiff?
3.	Are there any failure cases for the proposed AsyncDiff? 
[1] DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models","Additional Questions:
1.	Is this method helpful for large batch sizes?
2.	Is this method applicable to more GPUs?",I do not find any potential negative societal impact of this work.,['No ethics review needed.'],7,4,,Yes,4,3,4,1720572696956,,,NeurIPS.cc/2024/Conference,46jtDC6gXu,"['NeurIPS.cc/2024/Conference/Submission1625/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878715125,[],2,,,['everyone'],46jtDC6gXu,['NeurIPS.cc/2024/Conference/Submission1625/Reviewer_7eQm'],1720572696956,1730878715125,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission1625/Reviewer_7eQm']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature, namely ""DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models"" (referred to as [1] in the review). The reviewer asks the authors to provide a more detailed discussion about the key differences between AsyncDiff and DistriFusion.",1,,DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models
4xUx13brNh,"The paper explores challenges RNNs face in learning long-term dependencies. While generally attributed to the exploding and vanishing gradients problem (EVGP), the authors reveal that as a network's memory increases, parameter changes cause an explosion of the second moment of hidden states and their gradients, making gradient-based learning highly ill-posed. They study different design choices in recurrent architectures such as element-wise recurrence, gating mechanisms and careful parameterization with respect to the curse of memory. They apply their theoretical findings to successful architectures such as state-space models (SSMs) and LSTMs, offering new insights into why some RNN architectures perform better in gradient-based learning.","- The paper addresses a fundamental problem, the curse of memory, and connects it through theoretical analysis and experimental validation to the success of recent architectures, which makes the insights incredibly valuable to the machine learning community
- I like how the authors connect the dots between multiple facets of model training, e.g. investigating the implications of RNN recurrence parametrization on adaptive LR optimizers, which are actually used in practice
- The paper is also well structured and generally well written.","- To add to EVGP mitigation techniques (l. 61 - 64): There also exist regularization techniques based on dynamical systems theory, see especially [1]
- There are quite some typos across the document, see the list below. I recommend running the paper through some sort of language checker to improve the manuscript from a readability and presentation side.
- The authors repeatedly call $\mathbb{E}[X^2]$ a variance (where $X$ here is a placeholder for any RV, i.e.  $h_t$ and $d_\theta h_t$ in the paper), which is technically not correct. It is the second moment. I’d consider fixing this or explaining why the missing term for the variance, $\mathbb{E}[X]^2$ (first moment squared), can be neglected.

Typos / text-bugs:
- l. 119: “[...] a low a pass filtered [...]
- l. 191: “[...] does not hurts [...]”
- l. 192 “Several RNN architectures implicitly alleviates [...]”
- l. 200 “While such models can can approximate any smooth mappings [...]” 
- l. 219 “anaylsis”
- l. 257 “Both network are trained [...]”
- word missing in l. 283 “[...] that characteristic of the curse of memory, [...]”?
- l. 298 consistently -> consistent

[1] Schmidt et al., Identifying nonlinear dynamical systems with multiple time scales and long-range dependencies (ICML 2021)","- in l. 180 you assume $\gamma$ is independent of $\lambda$ yet in the Diff. eq. in l. 182 you introduce the dependency again ($\gamma(\lambda)$)? Is this connected to what you write in the caption of Fig. 2 where you decouple $\gamma$ from $\lambda$ when differentiating? Can you explain the reason for this in more detail?
- in l. 289 you mention that you probe ADAM’s effective learning rate by providing a vector of ones to the optimizer - does that mean you simply read out ADAM’s (corrected) second-moment estimates and report $\frac{\eta}{\sqrt{v_n} + \epsilon}$, where $\eta$ is the global learning rate and $v_n$ the second moment estimates at iteration $n$? If so, at which iteration/epoch do you query the effective learning rate?","While an explicit section on limitations is missing, the authors mention their limitations and specific assumptions throughout the manuscript.",['No ethics review needed.'],7,4,,Yes,4,3,3,1720692008797,,,NeurIPS.cc/2024/Conference,46Jr4sgTWa,"['NeurIPS.cc/2024/Conference/Submission10135/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879364072,[],3,,,['everyone'],46Jr4sgTWa,['NeurIPS.cc/2024/Conference/Submission10135/Reviewer_Bgq8'],1720692008797,1730879364072,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10135/Reviewer_Bgq8']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

Schmidt et al., Identifying nonlinear dynamical systems with multiple time scales and long-range dependencies (ICML 2021)

This is mentioned in the ""weaknesses"" section of the review, where the reviewer suggests that the authors should consider adding regularization techniques based on dynamical systems theory, and provides the reference to the Schmidt et al. paper as an example.",1,2021,Identifying nonlinear dynamical systems with multiple time scales and long-range dependencies
gNI5au91E8,"This paper introduces a parameterisation that contains the ability to represent weight tying corresponding to arbitrary (?) group equivariances. In practice it can represent interpolations of weight tying, but it is argued that this is a feature (not a bug!) since strict equivariance is often too strong a constraint to place on a model for it to still fit the training data.

Strict equivariance is known to be represented by a permutation matrix (correct me if I'm wrong), which justifies the need to use doubly stochastic matrices to interpolate. This makes the edges of the parametisation strict equivariances. (For equivariances of discretised continuous signals this is not quite true, as the permutation in continuous space would need to be approximated by some interpolation in the discrete space)

This leads to a new parameterisation of a weight structure in a layer that can be trained in the usual way. The doubly-stochastic matrices can then be investigated to see if equivariance is actually learned.

The experiments implement the method, and run on benchmark datasets and synthetic datasets, showing good performance, and somewhat interpretable group structure appearing. It is unclear what the actual point of the experiments is, since there are many reasons to use equivariance, but the experiments are not phrased in terms of this (see discussion).","The problem of learning equivariances is very important, as it would remove a significant difficulty in designing networks with the correct inductive biases. The solution is flexible, as any (?) group structure can be represented by the parameterisation. There is also an elegant solution to the problem of needing a large number of parameters, that will work in practice for image data: Assuming translational equivariance, and only parameterising additional equivariances on the filters that are much smaller than the image.","Overall, the paper presents a well-reasoned method to an important problem, and I do believe that it meets the standard for publication at NeurIPS.

**Method & Presentation**
The method is well-justified. However, a final summary of what a forward pass through a layer looks like was not given, and would be really helpful. In addition, it would be helpful to have a clearer discussion of how many additional parameters are added (beyond lines 220 onwards), with the architectures that are discussed given as an explicit example.

Essentially, one thing which seems to be the case, but is not explicitly acknowledged, is that this method collapses to just a special parameterisation of weight matrices, where the weights have low-rank combined with doubly-stochastic structure. The low-rank-ness is shown in eq 6. While this is a simplistic way of looking at the method, it does give a helpful alternative view. Making this explicit would help the paper.

**What is the claim of the experiments?**
The experiments are the main weakness of the paper. Some qualitative results about the structure of the learned weights are given, which are helpful. But it is not clear what the quantitative claim of the experiments is. Equivariance can help in several ways, e.g. better out-of-distribution prediction, better prediction at low data, or smaller/compacter models. So is the claim that the equivariance inductive bias helps, and it can be discovered automatically? But in this case this is not disentangled from the model capacity. Perhaps a normal CNN would perform better if it were just made larger! This is additionally indicated that the baseline 70% accuracy on CIFAR 10 is low compared to what other non-group-equivariant methods can achieve. This unclarity also exists in the synthetic experiments, where the size of the dataset is not discussed. Low-data experiments could help here, since it's easier to make the model large enough that size doesn't help any longer, which isolates inductive bias only.

The CIFAR experiments show that making the model larger improves performance. How can we be sure that this is really the benefit of learning equivariances, rather than adding more capacity? Another experiment that is necessary here, is a comparison to a weight structure that does not have the doubly-stochastic constraint enforced on it. This would allow the effect of simply adding capacity to be tested.

Alternatively, a low-data experiment would allow the generalisation capabilities of the model to be tested (e.g. [Invariance Learning in Deep Neural Networks with Differentiable Laplace Approximations](fig 3 in https://proceedings.neurips.cc/paper_files/paper/2022/file/50d005f92a6c5c9646db4b761da676ba-Paper-Conference.pdf)). This could be done on MNIST variants, where currently the differences are so small, it is hard to draw conclusions.

This same issue pops up in the synthetic experiments. What is the dataset size? If the dataset is so large that all transformed signals are in the dataset, even a fully-connected network would learn the correct function. A low-data experiment is needed to really show that truly an equivariance has been learned that can help to _generalise_. Alternatively, you need to argue a benefit on the basis of parameter count.

In summary: The claims that the experiment section support are not clear. The field of equivariances is mature enough that the potential benefits have been clearly described, and these need to be clearly evaluated in experimental sections.

**Related Work**
The idea of relaxing equivariance by placing a distribution over transformations is older than the papers currently cited. E.g.:
- [Local Group Invariant Representations via Orbit Embeddings](http://proceedings.mlr.press/v54/raj17a/raj17a.pdf)

The discussion of ""symmetry discovery methods"" is unclear. What data do these methods need, or what kind of training signal do they use? What kind of predictive improvements do they obtain? Is the goal of these papers the same as those in the previous paragraph? Or, is the way that these methods learn group structure different from those in the previous section? If so, how?

Methods that learn a degree of equivariance on a layer-by-layer basis are relatively new, and it would be good to discuss this explicitly. E.g.:
- [Residual Pathway Priors for Soft Equivariance Constraints](https://proceedings.neurips.cc/paper/2021/file/fc394e9935fbd62c8aedc372464e1965-Paper.pdf) Finzi et al is not mentioned at all, but does allow partial equivariance in a layer-by-layer way.
- Reference [26] ""Learning layer-wise equivariances automatically using gradients"" is cited, but only in the context of arguing that overly constrained models suffer poor performance, but not in the context that this paper also discusses how to learn the right equivariance to use. This author has more papers on learning invariance/equivariances that may be relevant.

Overall, the literature review misses a lot of relevant work. The suggestions I gave are off the top of my head and I definitely missed some important papers too. However, it is the responsibility of the authors to put the time and effort into going beyond this to give a more thorough overview.

**Minor**
- _""Requiring no prior knowledge of the possible symmetries.""_ (line 52) It is true that earlier methods (with the exception of [31]) could only pick between groups that were completely specified a-priori. While this paper _in principle_ does provide a parameterisation that can _search_ over a much wider space, this space needs to be limited for scalability reasons, and it was not demonstrated that the method would work reliably without this ""prior"" being added!
- It would be really helpful to have a full discussion of the impact on the number of parameters, for these specific experiments.Needs a discussion of the total number of parameters
- Is there a typo in params in table 1? Under ""Params"" should ""103 + 265K"" be ""103K + 256K""?","- Can this parameterisation represent arbitrary group equivariances? Is the representation of every strict equivariance a permutation matrix? It would be helpful to be explicit about how general this really is.
- Am I right in understanding that this method ultimately just parameterises a low-rank weight matrix over different feature channels?
- Can the benefit that equivariance promises in the low-data regime still be provided by this method when the invariance is learned? Since effectively, you're just parameterising weights in a different way (low rank?). In rotationally equivariant settings in low-data, could these weights not just overfit, rather than learning to rotate filters? Would this not lose an important benefit of equivariance?
- How important is the doubly-stochastic nature of things? Could you just run an experiment without the Sinkhorn component at all?
- Can you give a very short (ideally 1 sentence, or a 2-3 sentences) summary of the quantitative claims that are made about the method, that are verified in the experiment section?","See above.

Overall, this is a really interesting idea. I do have some concerns about the evaluation. These concerns are large in the scheme of determining how well this method really works relative to clearly formulated claims, but small relative to typical approaches in the ML community.",['No ethics review needed.'],6,4,,Yes,3,2,2,1721597446035,,,NeurIPS.cc/2024/Conference,44WWOW4GPF,"['NeurIPS.cc/2024/Conference/Submission17698/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879928146,[],4,,,['everyone'],44WWOW4GPF,['NeurIPS.cc/2024/Conference/Submission17698/Reviewer_1myY'],1721597446035,1730879928146,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17698/Reviewer_1myY']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several papers that are relevant to the topic, including:

1. ""Local Group Invariant Representations via Orbit Embeddings"" (http://proceedings.mlr.press/v54/raj17a/raj17a.pdf)
2. ""Residual Pathway Priors for Soft Equivariance Constraints"" (https://proceedings.neurips.cc/paper/2021/file/fc394e9935fbd62c8aedc372464e1965-Paper.pdf)
3. ""Learning layer-wise equivariances automatically using gradients"" (Reference [26] in the paper)
4. Other papers by the same author as Reference [26] that discuss learning invariance/equivariances.

The reviewer also mentions that the literature review in the paper misses a lot of relevant work and suggests that the authors should put in more effort to provide a thorough overview of the existing literature.",1,2021,Local Group Invariant Representations via Orbit Embeddings
gNI5au91E8,"This paper introduces a parameterisation that contains the ability to represent weight tying corresponding to arbitrary (?) group equivariances. In practice it can represent interpolations of weight tying, but it is argued that this is a feature (not a bug!) since strict equivariance is often too strong a constraint to place on a model for it to still fit the training data.

Strict equivariance is known to be represented by a permutation matrix (correct me if I'm wrong), which justifies the need to use doubly stochastic matrices to interpolate. This makes the edges of the parametisation strict equivariances. (For equivariances of discretised continuous signals this is not quite true, as the permutation in continuous space would need to be approximated by some interpolation in the discrete space)

This leads to a new parameterisation of a weight structure in a layer that can be trained in the usual way. The doubly-stochastic matrices can then be investigated to see if equivariance is actually learned.

The experiments implement the method, and run on benchmark datasets and synthetic datasets, showing good performance, and somewhat interpretable group structure appearing. It is unclear what the actual point of the experiments is, since there are many reasons to use equivariance, but the experiments are not phrased in terms of this (see discussion).","The problem of learning equivariances is very important, as it would remove a significant difficulty in designing networks with the correct inductive biases. The solution is flexible, as any (?) group structure can be represented by the parameterisation. There is also an elegant solution to the problem of needing a large number of parameters, that will work in practice for image data: Assuming translational equivariance, and only parameterising additional equivariances on the filters that are much smaller than the image.","Overall, the paper presents a well-reasoned method to an important problem, and I do believe that it meets the standard for publication at NeurIPS.

**Method & Presentation**
The method is well-justified. However, a final summary of what a forward pass through a layer looks like was not given, and would be really helpful. In addition, it would be helpful to have a clearer discussion of how many additional parameters are added (beyond lines 220 onwards), with the architectures that are discussed given as an explicit example.

Essentially, one thing which seems to be the case, but is not explicitly acknowledged, is that this method collapses to just a special parameterisation of weight matrices, where the weights have low-rank combined with doubly-stochastic structure. The low-rank-ness is shown in eq 6. While this is a simplistic way of looking at the method, it does give a helpful alternative view. Making this explicit would help the paper.

**What is the claim of the experiments?**
The experiments are the main weakness of the paper. Some qualitative results about the structure of the learned weights are given, which are helpful. But it is not clear what the quantitative claim of the experiments is. Equivariance can help in several ways, e.g. better out-of-distribution prediction, better prediction at low data, or smaller/compacter models. So is the claim that the equivariance inductive bias helps, and it can be discovered automatically? But in this case this is not disentangled from the model capacity. Perhaps a normal CNN would perform better if it were just made larger! This is additionally indicated that the baseline 70% accuracy on CIFAR 10 is low compared to what other non-group-equivariant methods can achieve. This unclarity also exists in the synthetic experiments, where the size of the dataset is not discussed. Low-data experiments could help here, since it's easier to make the model large enough that size doesn't help any longer, which isolates inductive bias only.

The CIFAR experiments show that making the model larger improves performance. How can we be sure that this is really the benefit of learning equivariances, rather than adding more capacity? Another experiment that is necessary here, is a comparison to a weight structure that does not have the doubly-stochastic constraint enforced on it. This would allow the effect of simply adding capacity to be tested.

Alternatively, a low-data experiment would allow the generalisation capabilities of the model to be tested (e.g. [Invariance Learning in Deep Neural Networks with Differentiable Laplace Approximations](fig 3 in https://proceedings.neurips.cc/paper_files/paper/2022/file/50d005f92a6c5c9646db4b761da676ba-Paper-Conference.pdf)). This could be done on MNIST variants, where currently the differences are so small, it is hard to draw conclusions.

This same issue pops up in the synthetic experiments. What is the dataset size? If the dataset is so large that all transformed signals are in the dataset, even a fully-connected network would learn the correct function. A low-data experiment is needed to really show that truly an equivariance has been learned that can help to _generalise_. Alternatively, you need to argue a benefit on the basis of parameter count.

In summary: The claims that the experiment section support are not clear. The field of equivariances is mature enough that the potential benefits have been clearly described, and these need to be clearly evaluated in experimental sections.

**Related Work**
The idea of relaxing equivariance by placing a distribution over transformations is older than the papers currently cited. E.g.:
- [Local Group Invariant Representations via Orbit Embeddings](http://proceedings.mlr.press/v54/raj17a/raj17a.pdf)

The discussion of ""symmetry discovery methods"" is unclear. What data do these methods need, or what kind of training signal do they use? What kind of predictive improvements do they obtain? Is the goal of these papers the same as those in the previous paragraph? Or, is the way that these methods learn group structure different from those in the previous section? If so, how?

Methods that learn a degree of equivariance on a layer-by-layer basis are relatively new, and it would be good to discuss this explicitly. E.g.:
- [Residual Pathway Priors for Soft Equivariance Constraints](https://proceedings.neurips.cc/paper/2021/file/fc394e9935fbd62c8aedc372464e1965-Paper.pdf) Finzi et al is not mentioned at all, but does allow partial equivariance in a layer-by-layer way.
- Reference [26] ""Learning layer-wise equivariances automatically using gradients"" is cited, but only in the context of arguing that overly constrained models suffer poor performance, but not in the context that this paper also discusses how to learn the right equivariance to use. This author has more papers on learning invariance/equivariances that may be relevant.

Overall, the literature review misses a lot of relevant work. The suggestions I gave are off the top of my head and I definitely missed some important papers too. However, it is the responsibility of the authors to put the time and effort into going beyond this to give a more thorough overview.

**Minor**
- _""Requiring no prior knowledge of the possible symmetries.""_ (line 52) It is true that earlier methods (with the exception of [31]) could only pick between groups that were completely specified a-priori. While this paper _in principle_ does provide a parameterisation that can _search_ over a much wider space, this space needs to be limited for scalability reasons, and it was not demonstrated that the method would work reliably without this ""prior"" being added!
- It would be really helpful to have a full discussion of the impact on the number of parameters, for these specific experiments.Needs a discussion of the total number of parameters
- Is there a typo in params in table 1? Under ""Params"" should ""103 + 265K"" be ""103K + 256K""?","- Can this parameterisation represent arbitrary group equivariances? Is the representation of every strict equivariance a permutation matrix? It would be helpful to be explicit about how general this really is.
- Am I right in understanding that this method ultimately just parameterises a low-rank weight matrix over different feature channels?
- Can the benefit that equivariance promises in the low-data regime still be provided by this method when the invariance is learned? Since effectively, you're just parameterising weights in a different way (low rank?). In rotationally equivariant settings in low-data, could these weights not just overfit, rather than learning to rotate filters? Would this not lose an important benefit of equivariance?
- How important is the doubly-stochastic nature of things? Could you just run an experiment without the Sinkhorn component at all?
- Can you give a very short (ideally 1 sentence, or a 2-3 sentences) summary of the quantitative claims that are made about the method, that are verified in the experiment section?","See above.

Overall, this is a really interesting idea. I do have some concerns about the evaluation. These concerns are large in the scheme of determining how well this method really works relative to clearly formulated claims, but small relative to typical approaches in the ML community.",['No ethics review needed.'],6,4,,Yes,3,2,2,1721597446035,,,NeurIPS.cc/2024/Conference,44WWOW4GPF,"['NeurIPS.cc/2024/Conference/Submission17698/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879928146,[],4,,,['everyone'],44WWOW4GPF,['NeurIPS.cc/2024/Conference/Submission17698/Reviewer_1myY'],1721597446035,1730879928146,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17698/Reviewer_1myY']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several papers that are relevant to the topic, including:

1. ""Local Group Invariant Representations via Orbit Embeddings"" (http://proceedings.mlr.press/v54/raj17a/raj17a.pdf)
2. ""Residual Pathway Priors for Soft Equivariance Constraints"" (https://proceedings.neurips.cc/paper/2021/file/fc394e9935fbd62c8aedc372464e1965-Paper.pdf)
3. ""Learning layer-wise equivariances automatically using gradients"" (Reference [26] in the paper)
4. Other papers by the same author as Reference [26] that discuss learning invariance/equivariances.

The reviewer also mentions that the literature review in the paper misses a lot of relevant work and suggests that the authors should put in more effort to provide a thorough overview of the existing literature.",1,2021,Residual Pathway Priors for Soft Equivariance Constraints
gNI5au91E8,"This paper introduces a parameterisation that contains the ability to represent weight tying corresponding to arbitrary (?) group equivariances. In practice it can represent interpolations of weight tying, but it is argued that this is a feature (not a bug!) since strict equivariance is often too strong a constraint to place on a model for it to still fit the training data.

Strict equivariance is known to be represented by a permutation matrix (correct me if I'm wrong), which justifies the need to use doubly stochastic matrices to interpolate. This makes the edges of the parametisation strict equivariances. (For equivariances of discretised continuous signals this is not quite true, as the permutation in continuous space would need to be approximated by some interpolation in the discrete space)

This leads to a new parameterisation of a weight structure in a layer that can be trained in the usual way. The doubly-stochastic matrices can then be investigated to see if equivariance is actually learned.

The experiments implement the method, and run on benchmark datasets and synthetic datasets, showing good performance, and somewhat interpretable group structure appearing. It is unclear what the actual point of the experiments is, since there are many reasons to use equivariance, but the experiments are not phrased in terms of this (see discussion).","The problem of learning equivariances is very important, as it would remove a significant difficulty in designing networks with the correct inductive biases. The solution is flexible, as any (?) group structure can be represented by the parameterisation. There is also an elegant solution to the problem of needing a large number of parameters, that will work in practice for image data: Assuming translational equivariance, and only parameterising additional equivariances on the filters that are much smaller than the image.","Overall, the paper presents a well-reasoned method to an important problem, and I do believe that it meets the standard for publication at NeurIPS.

**Method & Presentation**
The method is well-justified. However, a final summary of what a forward pass through a layer looks like was not given, and would be really helpful. In addition, it would be helpful to have a clearer discussion of how many additional parameters are added (beyond lines 220 onwards), with the architectures that are discussed given as an explicit example.

Essentially, one thing which seems to be the case, but is not explicitly acknowledged, is that this method collapses to just a special parameterisation of weight matrices, where the weights have low-rank combined with doubly-stochastic structure. The low-rank-ness is shown in eq 6. While this is a simplistic way of looking at the method, it does give a helpful alternative view. Making this explicit would help the paper.

**What is the claim of the experiments?**
The experiments are the main weakness of the paper. Some qualitative results about the structure of the learned weights are given, which are helpful. But it is not clear what the quantitative claim of the experiments is. Equivariance can help in several ways, e.g. better out-of-distribution prediction, better prediction at low data, or smaller/compacter models. So is the claim that the equivariance inductive bias helps, and it can be discovered automatically? But in this case this is not disentangled from the model capacity. Perhaps a normal CNN would perform better if it were just made larger! This is additionally indicated that the baseline 70% accuracy on CIFAR 10 is low compared to what other non-group-equivariant methods can achieve. This unclarity also exists in the synthetic experiments, where the size of the dataset is not discussed. Low-data experiments could help here, since it's easier to make the model large enough that size doesn't help any longer, which isolates inductive bias only.

The CIFAR experiments show that making the model larger improves performance. How can we be sure that this is really the benefit of learning equivariances, rather than adding more capacity? Another experiment that is necessary here, is a comparison to a weight structure that does not have the doubly-stochastic constraint enforced on it. This would allow the effect of simply adding capacity to be tested.

Alternatively, a low-data experiment would allow the generalisation capabilities of the model to be tested (e.g. [Invariance Learning in Deep Neural Networks with Differentiable Laplace Approximations](fig 3 in https://proceedings.neurips.cc/paper_files/paper/2022/file/50d005f92a6c5c9646db4b761da676ba-Paper-Conference.pdf)). This could be done on MNIST variants, where currently the differences are so small, it is hard to draw conclusions.

This same issue pops up in the synthetic experiments. What is the dataset size? If the dataset is so large that all transformed signals are in the dataset, even a fully-connected network would learn the correct function. A low-data experiment is needed to really show that truly an equivariance has been learned that can help to _generalise_. Alternatively, you need to argue a benefit on the basis of parameter count.

In summary: The claims that the experiment section support are not clear. The field of equivariances is mature enough that the potential benefits have been clearly described, and these need to be clearly evaluated in experimental sections.

**Related Work**
The idea of relaxing equivariance by placing a distribution over transformations is older than the papers currently cited. E.g.:
- [Local Group Invariant Representations via Orbit Embeddings](http://proceedings.mlr.press/v54/raj17a/raj17a.pdf)

The discussion of ""symmetry discovery methods"" is unclear. What data do these methods need, or what kind of training signal do they use? What kind of predictive improvements do they obtain? Is the goal of these papers the same as those in the previous paragraph? Or, is the way that these methods learn group structure different from those in the previous section? If so, how?

Methods that learn a degree of equivariance on a layer-by-layer basis are relatively new, and it would be good to discuss this explicitly. E.g.:
- [Residual Pathway Priors for Soft Equivariance Constraints](https://proceedings.neurips.cc/paper/2021/file/fc394e9935fbd62c8aedc372464e1965-Paper.pdf) Finzi et al is not mentioned at all, but does allow partial equivariance in a layer-by-layer way.
- Reference [26] ""Learning layer-wise equivariances automatically using gradients"" is cited, but only in the context of arguing that overly constrained models suffer poor performance, but not in the context that this paper also discusses how to learn the right equivariance to use. This author has more papers on learning invariance/equivariances that may be relevant.

Overall, the literature review misses a lot of relevant work. The suggestions I gave are off the top of my head and I definitely missed some important papers too. However, it is the responsibility of the authors to put the time and effort into going beyond this to give a more thorough overview.

**Minor**
- _""Requiring no prior knowledge of the possible symmetries.""_ (line 52) It is true that earlier methods (with the exception of [31]) could only pick between groups that were completely specified a-priori. While this paper _in principle_ does provide a parameterisation that can _search_ over a much wider space, this space needs to be limited for scalability reasons, and it was not demonstrated that the method would work reliably without this ""prior"" being added!
- It would be really helpful to have a full discussion of the impact on the number of parameters, for these specific experiments.Needs a discussion of the total number of parameters
- Is there a typo in params in table 1? Under ""Params"" should ""103 + 265K"" be ""103K + 256K""?","- Can this parameterisation represent arbitrary group equivariances? Is the representation of every strict equivariance a permutation matrix? It would be helpful to be explicit about how general this really is.
- Am I right in understanding that this method ultimately just parameterises a low-rank weight matrix over different feature channels?
- Can the benefit that equivariance promises in the low-data regime still be provided by this method when the invariance is learned? Since effectively, you're just parameterising weights in a different way (low rank?). In rotationally equivariant settings in low-data, could these weights not just overfit, rather than learning to rotate filters? Would this not lose an important benefit of equivariance?
- How important is the doubly-stochastic nature of things? Could you just run an experiment without the Sinkhorn component at all?
- Can you give a very short (ideally 1 sentence, or a 2-3 sentences) summary of the quantitative claims that are made about the method, that are verified in the experiment section?","See above.

Overall, this is a really interesting idea. I do have some concerns about the evaluation. These concerns are large in the scheme of determining how well this method really works relative to clearly formulated claims, but small relative to typical approaches in the ML community.",['No ethics review needed.'],6,4,,Yes,3,2,2,1721597446035,,,NeurIPS.cc/2024/Conference,44WWOW4GPF,"['NeurIPS.cc/2024/Conference/Submission17698/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879928146,[],4,,,['everyone'],44WWOW4GPF,['NeurIPS.cc/2024/Conference/Submission17698/Reviewer_1myY'],1721597446035,1730879928146,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17698/Reviewer_1myY']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several papers that are relevant to the topic, including:

1. ""Local Group Invariant Representations via Orbit Embeddings"" (http://proceedings.mlr.press/v54/raj17a/raj17a.pdf)
2. ""Residual Pathway Priors for Soft Equivariance Constraints"" (https://proceedings.neurips.cc/paper/2021/file/fc394e9935fbd62c8aedc372464e1965-Paper.pdf)
3. ""Learning layer-wise equivariances automatically using gradients"" (Reference [26] in the paper)
4. Other papers by the same author as Reference [26] that discuss learning invariance/equivariances.

The reviewer also mentions that the literature review in the paper misses a lot of relevant work and suggests that the authors should put in more effort to provide a thorough overview of the existing literature.",1,2021,Learning layer-wise equivariances automatically using gradients
r12Qc0iC5i,"In this paper, the authors introduce a novel Bi-Level Active Finetuning Framework (BiLAF) designed to address the limitations of existing active learning methods in the context of the pretraining-finetuning paradigm. The framework aims to optimize sample selection for finetuning models within a limited annotation budget. The authors propose an innovative unsupervised denoising technique to eliminate noisy samples and use a newly designed boundary score metric for iterative boundary sample selection. Extensive experiments demonstrate that BiLAF outperforms existing methods across various datasets and tasks.","- The bi-level framework that combines core sample selection with boundary sample selection effectively addresses limitations in existing active learning methods.
- The novel unsupervised denoising technique effectively eliminates noisy samples, improving the reliability of sample selection.
-  Extensive experiments on multiple datasets and tasks consistently show BiLAF outperforms state-of-the-art methods.
- The paper is well-organized with a clear explanation of the motivation, proposed method, and experimental results.","Activate Finetuning is advantageous for model fine-tuning in scenarios with limited data, and the motivation behind the proposed BiLAF is clear. However, I have concerns regarding the generalizability of this method to different data sizes. As shown in Table I, there is a significant performance drop in the CIFAR10 dataset under the 0.5% setting. This decline might be attributed to the small size of CIFAR10 images and the low 0.5% ratio, making it challenging to select and denoise boundary samples. It raises the question of whether BiLAF requires a certain threshold of fine-tuning data to be effective, which warrants further investigation by the authors. Additionally, the CVPR 2024 paper (see reference below) reports on the performance of CIFAR10 under 0.1% and 0.2% settings, which is highly relevant. I believe that Activate Finetuning would be more meaningful in scenarios with extremely limited data (e.g., few-shot fine-tuning), where changing the random seed can lead to significant accuracy fluctuations. Therefore, I recommend the authors include experiments and analyses on such scenarios. Furthermore, comparative experiments with other settings in the paper should be included to substantiate the method's effectiveness.
Moreover, when the amount of fine-tuning data increases, BiLAF's performance becomes comparable to the baseline ActiveFT. Hence, it would be insightful for the authors to discuss whether BiLAF remains effective with larger amounts of fine-tuning data, such as 20% of the ImageNet 1k dataset. This additional discussion would enhance the paper's comprehensiveness.

Xu, Wenshuai, et al. ""ActiveDC: Distribution Calibration for Active Finetuning."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.",Same as weakness.,"As described in the Weakness section, there might be some critical aspects that are not verified enough. The authors are encouraged to show additional results to support their claims.",['No ethics review needed.'],5,4,,Yes,3,3,3,1720688064479,,,NeurIPS.cc/2024/Conference,444LAH3MhG,"['NeurIPS.cc/2024/Conference/Submission376/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878640051,[],3,,,['everyone'],444LAH3MhG,['NeurIPS.cc/2024/Conference/Submission376/Reviewer_8trC'],1720688064479,1730878640051,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission376/Reviewer_8trC']","Yes, the peer review explicitly mentions a specific literature, ""Xu, Wenshuai, et al. 'ActiveDC: Distribution Calibration for Active Finetuning.' Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024"", and even refers to it as a relevant reference, implying that the authors should consider citing it.",1,2024,ActiveDC Distribution Calibration for Active Finetuning
OcqloO7fsf,"This paper introduces a novel approach to retrieving cell values and database schema within the table question answering domain. The method operates as follows:
1) It expands the initial question by identifying potential queries for column retrieval or cell value retrieval.
2) For each query generated in the first step, the method identifies the top-K columns using their embeddings.
3) Within a given encoding budget for cell retrieval, it proposes embedding the most frequent B distinct values for each column and retrieves them based on their similarity to each query.
Additionally, the authors have developed two new datasets for large-scale table question answering. Their approach demonstrates improved cost efficiency and effectiveness on these large-scale datasets compared to previous methods.","1) The proposed approach significantly outperforms the baseline models, particularly in retrieving cell values, showing a substantial improvement in recall metric.

2) Unlike previous works in the table question answering domain, which focused on small-scale tables that do not accurately represent real-world databases, this approach tackles a more challenging setting. It addresses scenarios where tables can contain millions of rows and numerous columns. The authors also developed two new datasets specifically designed for large-scale table question answering.

3) The paper includes well-conducted ablation studies and experiments that compare their method against their baseline methods. These studies demonstrate the effectiveness of each component of their approach.","1) My primary concern pertains to the comprehensiveness of the baselines used. While the paper correctly mentions that the table schema is predominantly considered in the text-to-SQL domain, cell values also play a crucial role in SQL generation. Notably, papers like CodeS [1] have proposed using BM25 retrieval to find cell values, which would serve as an excellent baseline for comparison. Additionally, schema linking—the process of identifying the correct rows and columns—is well-explored. Approaches proposed in studies like TaBERT [2] could also be utilized as baselines.

2) Given an encoding budget, the strategy of retaining only the most frequent distinct cell values seems problematic, especially for queries that require data from columns containing names, addresses, etc. Heuristic-based methods, such as those using syntactic similarity with edit distance, can effectively filter most of the cell values and might be more appropriate.

[1]: CodeS: Towards Building Open-source Language Models for Text-to-SQL
[2]: TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data",Not applicable,Not applicable,['No ethics review needed.'],4,4,,Yes,2,3,3,1720320690343,,,NeurIPS.cc/2024/Conference,41lovPOCo5,"['NeurIPS.cc/2024/Conference/Submission13056/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879604348,[],3,,,['everyone'],41lovPOCo5,['NeurIPS.cc/2024/Conference/Submission13056/Reviewer_yX7T'],1720320690343,1730879604348,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission13056/Reviewer_yX7T']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. CodeS: Towards Building Open-source Language Models for Text-to-SQL
2. TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data

The reviewer mentions that these papers propose methods (BM25 retrieval and schema linking) that could be used as baselines for comparison, implying that the authors should consider citing and incorporating these works into their research.",1,,CodeS Towards Building Open-source Language Models for Text-to-SQL
OcqloO7fsf,"This paper introduces a novel approach to retrieving cell values and database schema within the table question answering domain. The method operates as follows:
1) It expands the initial question by identifying potential queries for column retrieval or cell value retrieval.
2) For each query generated in the first step, the method identifies the top-K columns using their embeddings.
3) Within a given encoding budget for cell retrieval, it proposes embedding the most frequent B distinct values for each column and retrieves them based on their similarity to each query.
Additionally, the authors have developed two new datasets for large-scale table question answering. Their approach demonstrates improved cost efficiency and effectiveness on these large-scale datasets compared to previous methods.","1) The proposed approach significantly outperforms the baseline models, particularly in retrieving cell values, showing a substantial improvement in recall metric.

2) Unlike previous works in the table question answering domain, which focused on small-scale tables that do not accurately represent real-world databases, this approach tackles a more challenging setting. It addresses scenarios where tables can contain millions of rows and numerous columns. The authors also developed two new datasets specifically designed for large-scale table question answering.

3) The paper includes well-conducted ablation studies and experiments that compare their method against their baseline methods. These studies demonstrate the effectiveness of each component of their approach.","1) My primary concern pertains to the comprehensiveness of the baselines used. While the paper correctly mentions that the table schema is predominantly considered in the text-to-SQL domain, cell values also play a crucial role in SQL generation. Notably, papers like CodeS [1] have proposed using BM25 retrieval to find cell values, which would serve as an excellent baseline for comparison. Additionally, schema linking—the process of identifying the correct rows and columns—is well-explored. Approaches proposed in studies like TaBERT [2] could also be utilized as baselines.

2) Given an encoding budget, the strategy of retaining only the most frequent distinct cell values seems problematic, especially for queries that require data from columns containing names, addresses, etc. Heuristic-based methods, such as those using syntactic similarity with edit distance, can effectively filter most of the cell values and might be more appropriate.

[1]: CodeS: Towards Building Open-source Language Models for Text-to-SQL
[2]: TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data",Not applicable,Not applicable,['No ethics review needed.'],4,4,,Yes,2,3,3,1720320690343,,,NeurIPS.cc/2024/Conference,41lovPOCo5,"['NeurIPS.cc/2024/Conference/Submission13056/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879604348,[],3,,,['everyone'],41lovPOCo5,['NeurIPS.cc/2024/Conference/Submission13056/Reviewer_yX7T'],1720320690343,1730879604348,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission13056/Reviewer_yX7T']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. CodeS: Towards Building Open-source Language Models for Text-to-SQL
2. TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data

The reviewer mentions that these papers propose methods (BM25 retrieval and schema linking) that could be used as baselines for comparison, implying that the authors should consider citing and incorporating these works into their research.",1,,TaBERT Pretraining for Joint Understanding of Textual and Tabular Data
sWYKW0OssF,"This paper presents Equivariant Neural Diffusion (END), a novel diffusion model for 3D molecule generation. The major novelty of END over previous molecule diffusion models lies in adopting a learnable forward process based on neural flow diffusion models. Experiments show that END can achieve good performance on benchmark datasets.","- Successfully incorporate neural flow diffusion models into the equivariant 3D molecule generation framework and demonstrate its usefulness in experiments.
- Generally good, clear and well-organized writing.","- The novelty contribution of the proposed END method is not high, as END is largely a combination of EDM [1] and neural flow diffusion models. Particularly, the paper does not give a clear discussion or analysis about why adopting learnable forward diffusion process is useful and beneficial to 3D molecule generation, or what molecular structures can be additionally captured by END through learnable forward diffusion process compared with previous diffusion models.
- There already exist some SDE based 3D molecule generation methods like EDM-BRIDGE [2] and EEGSDE [3]. Authors are encouraged to highlight the key difference in the diffusion process between END and these methods.
- Compared with GEOLDM, END does not show better performance (Table 1 and 2), which weakens the claim about the advantages of using learnable forward process. Since the main evaluation metrics proposed by EDM [1] in 3D molecule generation are saturating in recent literatures, authors are encouraged to adopt metrics proposed by HierDiff [4] to better evaluate the quality of generated 3D molecules.

[1] Equivariant Diffusion for Molecule Generation in 3D. ICML 2022.  
[2] Diffusion-based Molecule Generation with Informative Prior Bridges. NeurIPS 2022.  
[3] Equivariant Energy-Guided SDE for Inverse Molecular Design. ICLR 2023.  
[4] Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D. ICML 2023.

-------------------Post Rebuttal---------------------

I appreciate authors' efforts in addressing my concerns and questions in rebuttal. After reading over authors' rebuttal responses and pdf, I think all my concerns have been addressed so I increased my score. I hope authors will carefully add all rebuttal updates (discussion, analysis and experiment results) to the revised version of paper in the future.",See Weaknesses part.,Yes.,['No ethics review needed.'],6,3,,Yes,3,3,3,1720152391012,,,NeurIPS.cc/2024/Conference,40pE5pFhWl,"['NeurIPS.cc/2024/Conference/Submission18516/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879982724,[],1,,,['everyone'],40pE5pFhWl,['NeurIPS.cc/2024/Conference/Submission18516/Reviewer_5dRq'],1720152391012,1730879982724,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18516/Reviewer_5dRq']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. EDM [1] - Equivariant Diffusion for Molecule Generation in 3D. ICML 2022.
2. EDM-BRIDGE [2] - Diffusion-based Molecule Generation with Informative Prior Bridges. NeurIPS 2022.
3. EEGSDE [3] - Equivariant Energy-Guided SDE for Inverse Molecular Design. ICLR 2023.
4. HierDiff [4] - Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D. ICML 2023.

The reviewer encourages the authors to compare their work with these existing methods, particularly in terms of the diffusion process, and to adopt metrics proposed by HierDiff [4] to better evaluate the quality of generated 3D molecules.",1,"2022, 2022, 2023, 2023",Equivariant Diffusion for Molecule Generation in 3D 
sWYKW0OssF,"This paper presents Equivariant Neural Diffusion (END), a novel diffusion model for 3D molecule generation. The major novelty of END over previous molecule diffusion models lies in adopting a learnable forward process based on neural flow diffusion models. Experiments show that END can achieve good performance on benchmark datasets.","- Successfully incorporate neural flow diffusion models into the equivariant 3D molecule generation framework and demonstrate its usefulness in experiments.
- Generally good, clear and well-organized writing.","- The novelty contribution of the proposed END method is not high, as END is largely a combination of EDM [1] and neural flow diffusion models. Particularly, the paper does not give a clear discussion or analysis about why adopting learnable forward diffusion process is useful and beneficial to 3D molecule generation, or what molecular structures can be additionally captured by END through learnable forward diffusion process compared with previous diffusion models.
- There already exist some SDE based 3D molecule generation methods like EDM-BRIDGE [2] and EEGSDE [3]. Authors are encouraged to highlight the key difference in the diffusion process between END and these methods.
- Compared with GEOLDM, END does not show better performance (Table 1 and 2), which weakens the claim about the advantages of using learnable forward process. Since the main evaluation metrics proposed by EDM [1] in 3D molecule generation are saturating in recent literatures, authors are encouraged to adopt metrics proposed by HierDiff [4] to better evaluate the quality of generated 3D molecules.

[1] Equivariant Diffusion for Molecule Generation in 3D. ICML 2022.  
[2] Diffusion-based Molecule Generation with Informative Prior Bridges. NeurIPS 2022.  
[3] Equivariant Energy-Guided SDE for Inverse Molecular Design. ICLR 2023.  
[4] Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D. ICML 2023.

-------------------Post Rebuttal---------------------

I appreciate authors' efforts in addressing my concerns and questions in rebuttal. After reading over authors' rebuttal responses and pdf, I think all my concerns have been addressed so I increased my score. I hope authors will carefully add all rebuttal updates (discussion, analysis and experiment results) to the revised version of paper in the future.",See Weaknesses part.,Yes.,['No ethics review needed.'],6,3,,Yes,3,3,3,1720152391012,,,NeurIPS.cc/2024/Conference,40pE5pFhWl,"['NeurIPS.cc/2024/Conference/Submission18516/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879982724,[],1,,,['everyone'],40pE5pFhWl,['NeurIPS.cc/2024/Conference/Submission18516/Reviewer_5dRq'],1720152391012,1730879982724,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18516/Reviewer_5dRq']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. EDM [1] - Equivariant Diffusion for Molecule Generation in 3D. ICML 2022.
2. EDM-BRIDGE [2] - Diffusion-based Molecule Generation with Informative Prior Bridges. NeurIPS 2022.
3. EEGSDE [3] - Equivariant Energy-Guided SDE for Inverse Molecular Design. ICLR 2023.
4. HierDiff [4] - Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D. ICML 2023.

The reviewer encourages the authors to compare their work with these existing methods, particularly in terms of the diffusion process, and to adopt metrics proposed by HierDiff [4] to better evaluate the quality of generated 3D molecules.",1,"2022, 2022, 2023, 2023",Diffusion-based Molecule Generation with Informative Prior Bridges 
sWYKW0OssF,"This paper presents Equivariant Neural Diffusion (END), a novel diffusion model for 3D molecule generation. The major novelty of END over previous molecule diffusion models lies in adopting a learnable forward process based on neural flow diffusion models. Experiments show that END can achieve good performance on benchmark datasets.","- Successfully incorporate neural flow diffusion models into the equivariant 3D molecule generation framework and demonstrate its usefulness in experiments.
- Generally good, clear and well-organized writing.","- The novelty contribution of the proposed END method is not high, as END is largely a combination of EDM [1] and neural flow diffusion models. Particularly, the paper does not give a clear discussion or analysis about why adopting learnable forward diffusion process is useful and beneficial to 3D molecule generation, or what molecular structures can be additionally captured by END through learnable forward diffusion process compared with previous diffusion models.
- There already exist some SDE based 3D molecule generation methods like EDM-BRIDGE [2] and EEGSDE [3]. Authors are encouraged to highlight the key difference in the diffusion process between END and these methods.
- Compared with GEOLDM, END does not show better performance (Table 1 and 2), which weakens the claim about the advantages of using learnable forward process. Since the main evaluation metrics proposed by EDM [1] in 3D molecule generation are saturating in recent literatures, authors are encouraged to adopt metrics proposed by HierDiff [4] to better evaluate the quality of generated 3D molecules.

[1] Equivariant Diffusion for Molecule Generation in 3D. ICML 2022.  
[2] Diffusion-based Molecule Generation with Informative Prior Bridges. NeurIPS 2022.  
[3] Equivariant Energy-Guided SDE for Inverse Molecular Design. ICLR 2023.  
[4] Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D. ICML 2023.

-------------------Post Rebuttal---------------------

I appreciate authors' efforts in addressing my concerns and questions in rebuttal. After reading over authors' rebuttal responses and pdf, I think all my concerns have been addressed so I increased my score. I hope authors will carefully add all rebuttal updates (discussion, analysis and experiment results) to the revised version of paper in the future.",See Weaknesses part.,Yes.,['No ethics review needed.'],6,3,,Yes,3,3,3,1720152391012,,,NeurIPS.cc/2024/Conference,40pE5pFhWl,"['NeurIPS.cc/2024/Conference/Submission18516/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879982724,[],1,,,['everyone'],40pE5pFhWl,['NeurIPS.cc/2024/Conference/Submission18516/Reviewer_5dRq'],1720152391012,1730879982724,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18516/Reviewer_5dRq']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. EDM [1] - Equivariant Diffusion for Molecule Generation in 3D. ICML 2022.
2. EDM-BRIDGE [2] - Diffusion-based Molecule Generation with Informative Prior Bridges. NeurIPS 2022.
3. EEGSDE [3] - Equivariant Energy-Guided SDE for Inverse Molecular Design. ICLR 2023.
4. HierDiff [4] - Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D. ICML 2023.

The reviewer encourages the authors to compare their work with these existing methods, particularly in terms of the diffusion process, and to adopt metrics proposed by HierDiff [4] to better evaluate the quality of generated 3D molecules.",1,"2022, 2022, 2023, 2023",Equivariant Energy-Guided SDE for Inverse Molecular Design 
sWYKW0OssF,"This paper presents Equivariant Neural Diffusion (END), a novel diffusion model for 3D molecule generation. The major novelty of END over previous molecule diffusion models lies in adopting a learnable forward process based on neural flow diffusion models. Experiments show that END can achieve good performance on benchmark datasets.","- Successfully incorporate neural flow diffusion models into the equivariant 3D molecule generation framework and demonstrate its usefulness in experiments.
- Generally good, clear and well-organized writing.","- The novelty contribution of the proposed END method is not high, as END is largely a combination of EDM [1] and neural flow diffusion models. Particularly, the paper does not give a clear discussion or analysis about why adopting learnable forward diffusion process is useful and beneficial to 3D molecule generation, or what molecular structures can be additionally captured by END through learnable forward diffusion process compared with previous diffusion models.
- There already exist some SDE based 3D molecule generation methods like EDM-BRIDGE [2] and EEGSDE [3]. Authors are encouraged to highlight the key difference in the diffusion process between END and these methods.
- Compared with GEOLDM, END does not show better performance (Table 1 and 2), which weakens the claim about the advantages of using learnable forward process. Since the main evaluation metrics proposed by EDM [1] in 3D molecule generation are saturating in recent literatures, authors are encouraged to adopt metrics proposed by HierDiff [4] to better evaluate the quality of generated 3D molecules.

[1] Equivariant Diffusion for Molecule Generation in 3D. ICML 2022.  
[2] Diffusion-based Molecule Generation with Informative Prior Bridges. NeurIPS 2022.  
[3] Equivariant Energy-Guided SDE for Inverse Molecular Design. ICLR 2023.  
[4] Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D. ICML 2023.

-------------------Post Rebuttal---------------------

I appreciate authors' efforts in addressing my concerns and questions in rebuttal. After reading over authors' rebuttal responses and pdf, I think all my concerns have been addressed so I increased my score. I hope authors will carefully add all rebuttal updates (discussion, analysis and experiment results) to the revised version of paper in the future.",See Weaknesses part.,Yes.,['No ethics review needed.'],6,3,,Yes,3,3,3,1720152391012,,,NeurIPS.cc/2024/Conference,40pE5pFhWl,"['NeurIPS.cc/2024/Conference/Submission18516/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879982724,[],1,,,['everyone'],40pE5pFhWl,['NeurIPS.cc/2024/Conference/Submission18516/Reviewer_5dRq'],1720152391012,1730879982724,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18516/Reviewer_5dRq']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. EDM [1] - Equivariant Diffusion for Molecule Generation in 3D. ICML 2022.
2. EDM-BRIDGE [2] - Diffusion-based Molecule Generation with Informative Prior Bridges. NeurIPS 2022.
3. EEGSDE [3] - Equivariant Energy-Guided SDE for Inverse Molecular Design. ICLR 2023.
4. HierDiff [4] - Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D. ICML 2023.

The reviewer encourages the authors to compare their work with these existing methods, particularly in terms of the diffusion process, and to adopt metrics proposed by HierDiff [4] to better evaluate the quality of generated 3D molecules.",1,"2022, 2022, 2023, 2023",Coarse-to-Fine a Hierarchical Diffusion Model for Molecule Generation in 3D
4k2P2x5Af3,"The authors propose a local feature matching method that leverages homography to accelerate the transformer-based feature matching pipeline. Additionally, they employ unidirectional cross-attention in the refinement stage to further reduce computational overhead. Experimental results demonstrate the efficiency and effectiveness of this approach.","1. The paper is well-written and easy to understand.
2. Integrating homography as theoretical guidance into the transformer pipeline is a commendable approach, enhancing the transformer-based pipeline with theoretical support.
3. Experimental results demonstrate that the proposed method achieves much smaller time usage, validating its efficiency in practice.","1. Though the time usage is decrease, the accuracy is also decrease from Tab.1&2&3.
2. The paper lacks significant citations in feature matching methods, such as Efficient LoFTR[1], RoMa[2]. Some of these works also focus on improving efficiency in feature matching and should be referenced to provide a comprehensive background. Including these methods in the experiments would offer a more thorough comparison of the proposed approach's performance.
3. Though the authors acknowledge that some other methods (e.g., [14, 38]) are better in certain aspects (line356-357), it would be beneficial to include a comparative analysis with these methods. This would provide a clearer understanding of the strengths and weaknesses of the proposed approach.

[1]. Wang, Yifan, et al. ""Efficient LoFTR: Semi-dense local feature matching with sparse-like speed."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.
[2] Edstedt, Johan, et al. ""RoMa: Robust dense feature matching."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.",No question to the authors.,The authors have addressed the limitations in their paper.,['No ethics review needed.'],5,3,,Yes,3,3,3,1720591562526,,,NeurIPS.cc/2024/Conference,3xHCaDdYcc,"['NeurIPS.cc/2024/Conference/Submission12798/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879581750,[],2,,,['everyone'],3xHCaDdYcc,['NeurIPS.cc/2024/Conference/Submission12798/Reviewer_7KzZ'],1720591562526,1730879581750,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission12798/Reviewer_7KzZ']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, such as Efficient LoFTR [1] and RoMa [2], which are related to feature matching methods and focus on improving efficiency. The reviewer mentions that including these methods in the experiments would offer a more thorough comparison of the proposed approach's performance.",1,,Efficient LoFTR 
4k2P2x5Af3,"The authors propose a local feature matching method that leverages homography to accelerate the transformer-based feature matching pipeline. Additionally, they employ unidirectional cross-attention in the refinement stage to further reduce computational overhead. Experimental results demonstrate the efficiency and effectiveness of this approach.","1. The paper is well-written and easy to understand.
2. Integrating homography as theoretical guidance into the transformer pipeline is a commendable approach, enhancing the transformer-based pipeline with theoretical support.
3. Experimental results demonstrate that the proposed method achieves much smaller time usage, validating its efficiency in practice.","1. Though the time usage is decrease, the accuracy is also decrease from Tab.1&2&3.
2. The paper lacks significant citations in feature matching methods, such as Efficient LoFTR[1], RoMa[2]. Some of these works also focus on improving efficiency in feature matching and should be referenced to provide a comprehensive background. Including these methods in the experiments would offer a more thorough comparison of the proposed approach's performance.
3. Though the authors acknowledge that some other methods (e.g., [14, 38]) are better in certain aspects (line356-357), it would be beneficial to include a comparative analysis with these methods. This would provide a clearer understanding of the strengths and weaknesses of the proposed approach.

[1]. Wang, Yifan, et al. ""Efficient LoFTR: Semi-dense local feature matching with sparse-like speed."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.
[2] Edstedt, Johan, et al. ""RoMa: Robust dense feature matching."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.",No question to the authors.,The authors have addressed the limitations in their paper.,['No ethics review needed.'],5,3,,Yes,3,3,3,1720591562526,,,NeurIPS.cc/2024/Conference,3xHCaDdYcc,"['NeurIPS.cc/2024/Conference/Submission12798/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879581750,[],2,,,['everyone'],3xHCaDdYcc,['NeurIPS.cc/2024/Conference/Submission12798/Reviewer_7KzZ'],1720591562526,1730879581750,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission12798/Reviewer_7KzZ']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, such as Efficient LoFTR [1] and RoMa [2], which are related to feature matching methods and focus on improving efficiency. The reviewer mentions that including these methods in the experiments would offer a more thorough comparison of the proposed approach's performance.",1,,RoMa
r2s6HrID68,"Off-policy actor-critic Deep RL has unstable and seemingly oscillatory learning dynamics, which are poorly understood. This paper looks closely at the trajectories taken by policy networks during training. An SVD analysis, performed over sequences of policy parameter snapshots, reveals near-monotonic parameter evolution along directions corresponding to the few dominant singular values, and--- indeed---oscillatory behaviour along the minor directions.
The authors propose an intuitive and mathematically sound way to remedy this pathology by only permitting the parameters to move in subspace spanned by a small number of the top directions, while retaining the policy performance. Additionally, by taking larger steps in the first two major directions, they are able to train more performant policies.","**Significance**

The paper addresses an important problem. Deep RL researchers have long observed poor training dynamics in off-policy learning. These include divergence, performance collapses, and oscillatory behaviour (i.e. policies forgetting what was learnt, then recovering). The reasons behind these are poorly understood. While the paper does not quite advance our understanding of the problem, it does potentially identify some mechanistic signatures of the problem (oscillatory weight dynamics) and proposes a treatment for this symptom (suppressing movement in oscillation-afflicted subspaces). I think the proposed PPTB fix is unlikely to be a complete solution, mainly because the critic's behaviour is not yet studied, but it can be a stepping stone towards better behaved learning dynamics. 

**Clarity**

The paper is very clearly written, and I enjoyed reading it. Policy churn and oscillatory dynamics potentially stem from the combined actor-critic training dynamics, but the authors focus exclusively on the policy here. This is good, as it has kept the study focused and revealed interesting phenomena. 

**Originality**

I am unaware of prior work which empirically inspects the policy learning dynamics by actually plotting out the weights' evolution, as the authors have done.

**Quality**

The idea of using temporal SVD upon the policy weights is quite sensible, and a treatment for the problem immediately pops out of the same tool; this fix also appears to be easily implementable in code, and seems to grant substantial performance boosts.","1. **Limited analysis.** The analysis is focused on TD3 and RAD (based on SAC here, which itself is quite close to TD3). I think this is insufficient. Seasoned RL practitioners will note that DDPG exhibits markedly more policy oscillations/collapses/recoveries than TD3: the introduction of the Clipped Double Q trick already substantially mitigates those effects. In this empirical study, I worry that by not including DDPG --- the simplest possible baseline --- the authors are not observing the problematic dynamics in their full glory, and perhaps not testing the full potential of PPTB. Right now, there is a risk that your observed phenomena are quirks of TD3-lineage methods.

2. **Related work.** The observation that gradient descent moves the parameters along a few dominant directions, chiefly in a low-dimensional subspace, is not new. There is a body of deep learning literature around this phenomenon, which the authors don't cite right now. Here is one such paper, and there are more:
 - ""Gradient descent happens in a tiny subspace"" G Gur-Ari, DA Roberts, E Dyer 

3. **Potentially limited significance.** Following from the above point: the existence of dominant directions is unsurprising. The existence of oscillatory detours in the minor directions *could* be a novel finding regarding actor-critic RL, but we don't know that yet. To strengthen the paper, here's a test: do you also observe the same harmonics in basic supervised learning? (e.g. when training the actor network with an MSE behaviour cloning loss). I think this is a particularly important thing to investigate, because I'm concerned that it could change the story of your paper.

4. **Lack of training curve comparisons.** For a method that expressly tries to curb oscillations, it is important that we see how the actual training curves look, instead of just a table with scores.

5. **Limited evaluations.** 6 is not enough; it's common to report a minimum of 10 independent trials. Also: you have `Humanoid-v4` experiments in the paper, but don't report scores with PPTB on that env.","- Line `434`: you say that you choose the boosting coefficient $p_b$ from a set of values. Do you mean that you search from this set for a good hyperpameter value, or do you randomly sample from this set at each training iteration?","The limitations section is well written, but one thing that isn't mentioned is that the method can struggle to scale up to larger network sizes (beyond the smallish networks used in this paper).

Overall, I find this paper exciting, and I'm willing to substantially improve my rating if the authors address all the listed weaknesses (most crucially, number `3`).",['No ethics review needed.'],4,4,,Yes,3,3,4,1720837036827,,,NeurIPS.cc/2024/Conference,3vHfwL2stG,"['NeurIPS.cc/2024/Conference/Submission10552/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879397271,[],3,,,['everyone'],3vHfwL2stG,['NeurIPS.cc/2024/Conference/Submission10552/Reviewer_8fBA'],1720837036827,1730879397271,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10552/Reviewer_8fBA']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature. The reviewer mentions a paper titled ""Gradient descent happens in a tiny subspace"" by G Gur-Ari, DA Roberts, E Dyer, indicating that the authors should be aware of this existing body of deep learning literature regarding the phenomenon of gradient descent moving parameters along a few dominant directions.",1,,Gradient descent happens in a tiny subspace
2lG2eMp5pB,"This paper investigates the evolution of parameters over time during policy optimization with TD3 and RAD. By analysing the SVD of a matrix containing parameters over time, the authors find that there are a few directions in which the parameters move consistently and many with more oscillations. Using this insight, an algorithm is proposed which boosts updates in the top estimated directions and reduces updates in the uninmportant ones. Evaluations on standard deep RL benchmark tasks demonstrate the utility of the approach.","This paper uncovers some nice insights into the training process of deep RL agents. 
As far as I know, I have not seen the SVD used to study parameter evolution over time, and I find it is an interesting application of that tool. The proposed algorithm is conceptually simple and easy to implement, making it easy to add to a variety of existing algorithms.
In terms of impact, the identified phenomena may extend past RL and could be true of deep neural network training more generally, potentially giving widespread impact. 

The paper is well-organized, with the different sections flowing nicely into each other. Generally, the paper was easy to follow and experiments chosen appropriately to make the intended arugments.","My main concern is about the evaluation of the algorithms. 
For example, reporting the max return in the evaluation of algorithm or using the standard deviation across runs, whereas the standard error or boostrapped confidence intervals would be more appropriate. (see Questions)

Also, the following design choice is confusing to me:
- Fig. 1 caption. ""Only	upper 80% values according to $\nabla^{apc}_j$ are taken to plot...for meaningful analysis"" 
	Could you elaborate why this decision was made? Does it have to do with many of the values being close to zero?

The improvement in the performance is generally fairly modest. I think this is fine given that main contribution to me is identifying behaviours in the parameter evolution. I think expanding a bit more on the analysis could be interesting. 

In terms of clarity, some details could be expanded upon more in the main text. See Questions section.","_Clarification questions_


- Line 157: What is $\alpha_k$? Is it Singular Value Information Amount? 


- Fig 2 b) 4th and 5th figure from left. Interesting findings. So basically, the detour ratio is smaller for the 
Again, I wonder if that has more to do with noise or curvature.
Perhaps there is less noise in these directions, 

	- In the 3rd fig from the left, it's hard to see much since the black curve masks everything else. Consider using different colors or some transparency. It would be nice to see how the paths get increasingly noisy.

- Policy Path Trimming: To clarify the algorithm, does it project the current parameters into the space identified by the top singular vectors? 
	The description of the algorithm could be improved in Sec. 4.1. where it is introduced. While the intuition is described, the exact mechanism that is implemented is not explained.

- Similarly, in section 4.2, the Policy Path Boosting could be described a bit more clearly. Eq. 2 in particular is a bit confusing since  
$\hat{u}_{n,*}$ is updated but then only 

$\hat{u}_{n,i}$ $(i=1,2)$ are actually used. 

The phrase in line 241 ""PPB modifies $\theta_n$ by increasing $u_{n,1}, u_{n,2}$ along the temporal direction..."" sounds  overly complicated. Perhaps rephrasing it to something like ""PPB moves the parameter further in the direction of previous updates along the first two main directions $u_{n,1}$ and $u_{n,2}$"" could be simpler. 

_Suggestions and broader questions_
- By constraining the parameter evolution path to focus on the previous main directions, would the effect of ""primacy bias"" or related phenomena be even stronger? Could we be losing out on performance due to prematurely committing to certain update directions? 

- Line 270. The evaluation metric ""SCORE"" should no longer be used since the maximum over runs introduces overestimation bias and leads to less reliable estimatse. See [1] for better evaluation practices and [2] for arguments against using the max. 

- I wonder if the detours are mainly due to noise or curvature of the objective. One way to test this would be to increase or decrease the minibatch size, which can control the variance of the updates. Then, by inspecting the effect on the detour ratio or cumulative parameter movement, we could guess the relative impact of noise and curvature. 

- Fig.1 is a CDF plot. I think a histogram or a box plot might be easier to interpret than CDF plots since you need to look at differences in a CDF plot to identify where most of the probability mass is.

- An ablation study for the two components of the algorithm would be a valuable addition. It is not clear if both pieces are necessary right now or how important they are.

- I would also be curious to know what would happen if we took the estimated space 

- Here is a paper that could be interested to read [3] where the authors show that, even if you constrain neural network parameters to a random subspace, as long as the dimension of that subspace is not too small, you can recover the same performance as the original network. 
The idea of Policy Path Trimming could be interpreted as a more intelligent approach which estimates the constrained subspace instead of choosing a random one. 

- Another line of research (e.g. see [4]) has observed that the Hessian contains only a few large eigenvalues in neural network training, which may be related to the ideas discussed in the paper since there would be some interplay between the curvature of the loss surface and directions of updates over time. 

- In the matrix of parameters over time, consider using $t \in {1,...,T}$ to index the rows instead of $n$ so it's a little easier for the reader to remember which dimension corresponds to what. Alternatively, if $t$ is reserved for environment timesptes, $\tau$ could be used as a substitute. 



[1] ""Deep Reinforcement Learning at the Edge of the Statistical Precipice"" Agarwal et al.

[2] ""Deep Reinforcement Learning that Matters"" Henderson et al. 

[3] ""Measuring the Intrinsic Dimension of Objective Landscapes"" Li et al. 

[4] ""An Investigation into Neural Net Optimization via Hessian Eigenvalue Density"" Ghorbani et al.",These are discussed.,['No ethics review needed.'],6,4,,Yes,3,4,2,1720992896805,,,NeurIPS.cc/2024/Conference,3vHfwL2stG,"['NeurIPS.cc/2024/Conference/Submission10552/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879397136,[],4,,,['everyone'],3vHfwL2stG,['NeurIPS.cc/2024/Conference/Submission10552/Reviewer_iaGj'],1720992896805,1730879397136,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10552/Reviewer_iaGj']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several papers that could be of interest to the authors, including:

1. ""Deep Reinforcement Learning at the Edge of the Statistical Precipice"" by Agarwal et al. ([1])
2. ""Deep Reinforcement Learning that Matters"" by Henderson et al. ([2])
3. ""Measuring the Intrinsic Dimension of Objective Landscapes"" by Li et al. ([3])
4. ""An Investigation into Neural Net Optimization via Hessian Eigenvalue Density"" by Ghorbani et al. ([4])

The reviewer suggests that these papers could provide useful context, insights, or related research that could strengthen the authors' work.",1,,Deep Reinforcement Learning at the Edge of the Statistical Precipice 
2lG2eMp5pB,"This paper investigates the evolution of parameters over time during policy optimization with TD3 and RAD. By analysing the SVD of a matrix containing parameters over time, the authors find that there are a few directions in which the parameters move consistently and many with more oscillations. Using this insight, an algorithm is proposed which boosts updates in the top estimated directions and reduces updates in the uninmportant ones. Evaluations on standard deep RL benchmark tasks demonstrate the utility of the approach.","This paper uncovers some nice insights into the training process of deep RL agents. 
As far as I know, I have not seen the SVD used to study parameter evolution over time, and I find it is an interesting application of that tool. The proposed algorithm is conceptually simple and easy to implement, making it easy to add to a variety of existing algorithms.
In terms of impact, the identified phenomena may extend past RL and could be true of deep neural network training more generally, potentially giving widespread impact. 

The paper is well-organized, with the different sections flowing nicely into each other. Generally, the paper was easy to follow and experiments chosen appropriately to make the intended arugments.","My main concern is about the evaluation of the algorithms. 
For example, reporting the max return in the evaluation of algorithm or using the standard deviation across runs, whereas the standard error or boostrapped confidence intervals would be more appropriate. (see Questions)

Also, the following design choice is confusing to me:
- Fig. 1 caption. ""Only	upper 80% values according to $\nabla^{apc}_j$ are taken to plot...for meaningful analysis"" 
	Could you elaborate why this decision was made? Does it have to do with many of the values being close to zero?

The improvement in the performance is generally fairly modest. I think this is fine given that main contribution to me is identifying behaviours in the parameter evolution. I think expanding a bit more on the analysis could be interesting. 

In terms of clarity, some details could be expanded upon more in the main text. See Questions section.","_Clarification questions_


- Line 157: What is $\alpha_k$? Is it Singular Value Information Amount? 


- Fig 2 b) 4th and 5th figure from left. Interesting findings. So basically, the detour ratio is smaller for the 
Again, I wonder if that has more to do with noise or curvature.
Perhaps there is less noise in these directions, 

	- In the 3rd fig from the left, it's hard to see much since the black curve masks everything else. Consider using different colors or some transparency. It would be nice to see how the paths get increasingly noisy.

- Policy Path Trimming: To clarify the algorithm, does it project the current parameters into the space identified by the top singular vectors? 
	The description of the algorithm could be improved in Sec. 4.1. where it is introduced. While the intuition is described, the exact mechanism that is implemented is not explained.

- Similarly, in section 4.2, the Policy Path Boosting could be described a bit more clearly. Eq. 2 in particular is a bit confusing since  
$\hat{u}_{n,*}$ is updated but then only 

$\hat{u}_{n,i}$ $(i=1,2)$ are actually used. 

The phrase in line 241 ""PPB modifies $\theta_n$ by increasing $u_{n,1}, u_{n,2}$ along the temporal direction..."" sounds  overly complicated. Perhaps rephrasing it to something like ""PPB moves the parameter further in the direction of previous updates along the first two main directions $u_{n,1}$ and $u_{n,2}$"" could be simpler. 

_Suggestions and broader questions_
- By constraining the parameter evolution path to focus on the previous main directions, would the effect of ""primacy bias"" or related phenomena be even stronger? Could we be losing out on performance due to prematurely committing to certain update directions? 

- Line 270. The evaluation metric ""SCORE"" should no longer be used since the maximum over runs introduces overestimation bias and leads to less reliable estimatse. See [1] for better evaluation practices and [2] for arguments against using the max. 

- I wonder if the detours are mainly due to noise or curvature of the objective. One way to test this would be to increase or decrease the minibatch size, which can control the variance of the updates. Then, by inspecting the effect on the detour ratio or cumulative parameter movement, we could guess the relative impact of noise and curvature. 

- Fig.1 is a CDF plot. I think a histogram or a box plot might be easier to interpret than CDF plots since you need to look at differences in a CDF plot to identify where most of the probability mass is.

- An ablation study for the two components of the algorithm would be a valuable addition. It is not clear if both pieces are necessary right now or how important they are.

- I would also be curious to know what would happen if we took the estimated space 

- Here is a paper that could be interested to read [3] where the authors show that, even if you constrain neural network parameters to a random subspace, as long as the dimension of that subspace is not too small, you can recover the same performance as the original network. 
The idea of Policy Path Trimming could be interpreted as a more intelligent approach which estimates the constrained subspace instead of choosing a random one. 

- Another line of research (e.g. see [4]) has observed that the Hessian contains only a few large eigenvalues in neural network training, which may be related to the ideas discussed in the paper since there would be some interplay between the curvature of the loss surface and directions of updates over time. 

- In the matrix of parameters over time, consider using $t \in {1,...,T}$ to index the rows instead of $n$ so it's a little easier for the reader to remember which dimension corresponds to what. Alternatively, if $t$ is reserved for environment timesptes, $\tau$ could be used as a substitute. 



[1] ""Deep Reinforcement Learning at the Edge of the Statistical Precipice"" Agarwal et al.

[2] ""Deep Reinforcement Learning that Matters"" Henderson et al. 

[3] ""Measuring the Intrinsic Dimension of Objective Landscapes"" Li et al. 

[4] ""An Investigation into Neural Net Optimization via Hessian Eigenvalue Density"" Ghorbani et al.",These are discussed.,['No ethics review needed.'],6,4,,Yes,3,4,2,1720992896805,,,NeurIPS.cc/2024/Conference,3vHfwL2stG,"['NeurIPS.cc/2024/Conference/Submission10552/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879397136,[],4,,,['everyone'],3vHfwL2stG,['NeurIPS.cc/2024/Conference/Submission10552/Reviewer_iaGj'],1720992896805,1730879397136,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10552/Reviewer_iaGj']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several papers that could be of interest to the authors, including:

1. ""Deep Reinforcement Learning at the Edge of the Statistical Precipice"" by Agarwal et al. ([1])
2. ""Deep Reinforcement Learning that Matters"" by Henderson et al. ([2])
3. ""Measuring the Intrinsic Dimension of Objective Landscapes"" by Li et al. ([3])
4. ""An Investigation into Neural Net Optimization via Hessian Eigenvalue Density"" by Ghorbani et al. ([4])

The reviewer suggests that these papers could provide useful context, insights, or related research that could strengthen the authors' work.",1,,Deep Reinforcement Learning that Matters 
2lG2eMp5pB,"This paper investigates the evolution of parameters over time during policy optimization with TD3 and RAD. By analysing the SVD of a matrix containing parameters over time, the authors find that there are a few directions in which the parameters move consistently and many with more oscillations. Using this insight, an algorithm is proposed which boosts updates in the top estimated directions and reduces updates in the uninmportant ones. Evaluations on standard deep RL benchmark tasks demonstrate the utility of the approach.","This paper uncovers some nice insights into the training process of deep RL agents. 
As far as I know, I have not seen the SVD used to study parameter evolution over time, and I find it is an interesting application of that tool. The proposed algorithm is conceptually simple and easy to implement, making it easy to add to a variety of existing algorithms.
In terms of impact, the identified phenomena may extend past RL and could be true of deep neural network training more generally, potentially giving widespread impact. 

The paper is well-organized, with the different sections flowing nicely into each other. Generally, the paper was easy to follow and experiments chosen appropriately to make the intended arugments.","My main concern is about the evaluation of the algorithms. 
For example, reporting the max return in the evaluation of algorithm or using the standard deviation across runs, whereas the standard error or boostrapped confidence intervals would be more appropriate. (see Questions)

Also, the following design choice is confusing to me:
- Fig. 1 caption. ""Only	upper 80% values according to $\nabla^{apc}_j$ are taken to plot...for meaningful analysis"" 
	Could you elaborate why this decision was made? Does it have to do with many of the values being close to zero?

The improvement in the performance is generally fairly modest. I think this is fine given that main contribution to me is identifying behaviours in the parameter evolution. I think expanding a bit more on the analysis could be interesting. 

In terms of clarity, some details could be expanded upon more in the main text. See Questions section.","_Clarification questions_


- Line 157: What is $\alpha_k$? Is it Singular Value Information Amount? 


- Fig 2 b) 4th and 5th figure from left. Interesting findings. So basically, the detour ratio is smaller for the 
Again, I wonder if that has more to do with noise or curvature.
Perhaps there is less noise in these directions, 

	- In the 3rd fig from the left, it's hard to see much since the black curve masks everything else. Consider using different colors or some transparency. It would be nice to see how the paths get increasingly noisy.

- Policy Path Trimming: To clarify the algorithm, does it project the current parameters into the space identified by the top singular vectors? 
	The description of the algorithm could be improved in Sec. 4.1. where it is introduced. While the intuition is described, the exact mechanism that is implemented is not explained.

- Similarly, in section 4.2, the Policy Path Boosting could be described a bit more clearly. Eq. 2 in particular is a bit confusing since  
$\hat{u}_{n,*}$ is updated but then only 

$\hat{u}_{n,i}$ $(i=1,2)$ are actually used. 

The phrase in line 241 ""PPB modifies $\theta_n$ by increasing $u_{n,1}, u_{n,2}$ along the temporal direction..."" sounds  overly complicated. Perhaps rephrasing it to something like ""PPB moves the parameter further in the direction of previous updates along the first two main directions $u_{n,1}$ and $u_{n,2}$"" could be simpler. 

_Suggestions and broader questions_
- By constraining the parameter evolution path to focus on the previous main directions, would the effect of ""primacy bias"" or related phenomena be even stronger? Could we be losing out on performance due to prematurely committing to certain update directions? 

- Line 270. The evaluation metric ""SCORE"" should no longer be used since the maximum over runs introduces overestimation bias and leads to less reliable estimatse. See [1] for better evaluation practices and [2] for arguments against using the max. 

- I wonder if the detours are mainly due to noise or curvature of the objective. One way to test this would be to increase or decrease the minibatch size, which can control the variance of the updates. Then, by inspecting the effect on the detour ratio or cumulative parameter movement, we could guess the relative impact of noise and curvature. 

- Fig.1 is a CDF plot. I think a histogram or a box plot might be easier to interpret than CDF plots since you need to look at differences in a CDF plot to identify where most of the probability mass is.

- An ablation study for the two components of the algorithm would be a valuable addition. It is not clear if both pieces are necessary right now or how important they are.

- I would also be curious to know what would happen if we took the estimated space 

- Here is a paper that could be interested to read [3] where the authors show that, even if you constrain neural network parameters to a random subspace, as long as the dimension of that subspace is not too small, you can recover the same performance as the original network. 
The idea of Policy Path Trimming could be interpreted as a more intelligent approach which estimates the constrained subspace instead of choosing a random one. 

- Another line of research (e.g. see [4]) has observed that the Hessian contains only a few large eigenvalues in neural network training, which may be related to the ideas discussed in the paper since there would be some interplay between the curvature of the loss surface and directions of updates over time. 

- In the matrix of parameters over time, consider using $t \in {1,...,T}$ to index the rows instead of $n$ so it's a little easier for the reader to remember which dimension corresponds to what. Alternatively, if $t$ is reserved for environment timesptes, $\tau$ could be used as a substitute. 



[1] ""Deep Reinforcement Learning at the Edge of the Statistical Precipice"" Agarwal et al.

[2] ""Deep Reinforcement Learning that Matters"" Henderson et al. 

[3] ""Measuring the Intrinsic Dimension of Objective Landscapes"" Li et al. 

[4] ""An Investigation into Neural Net Optimization via Hessian Eigenvalue Density"" Ghorbani et al.",These are discussed.,['No ethics review needed.'],6,4,,Yes,3,4,2,1720992896805,,,NeurIPS.cc/2024/Conference,3vHfwL2stG,"['NeurIPS.cc/2024/Conference/Submission10552/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879397136,[],4,,,['everyone'],3vHfwL2stG,['NeurIPS.cc/2024/Conference/Submission10552/Reviewer_iaGj'],1720992896805,1730879397136,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10552/Reviewer_iaGj']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several papers that could be of interest to the authors, including:

1. ""Deep Reinforcement Learning at the Edge of the Statistical Precipice"" by Agarwal et al. ([1])
2. ""Deep Reinforcement Learning that Matters"" by Henderson et al. ([2])
3. ""Measuring the Intrinsic Dimension of Objective Landscapes"" by Li et al. ([3])
4. ""An Investigation into Neural Net Optimization via Hessian Eigenvalue Density"" by Ghorbani et al. ([4])

The reviewer suggests that these papers could provide useful context, insights, or related research that could strengthen the authors' work.",1,,Measuring the Intrinsic Dimension of Objective Landscapes 
2lG2eMp5pB,"This paper investigates the evolution of parameters over time during policy optimization with TD3 and RAD. By analysing the SVD of a matrix containing parameters over time, the authors find that there are a few directions in which the parameters move consistently and many with more oscillations. Using this insight, an algorithm is proposed which boosts updates in the top estimated directions and reduces updates in the uninmportant ones. Evaluations on standard deep RL benchmark tasks demonstrate the utility of the approach.","This paper uncovers some nice insights into the training process of deep RL agents. 
As far as I know, I have not seen the SVD used to study parameter evolution over time, and I find it is an interesting application of that tool. The proposed algorithm is conceptually simple and easy to implement, making it easy to add to a variety of existing algorithms.
In terms of impact, the identified phenomena may extend past RL and could be true of deep neural network training more generally, potentially giving widespread impact. 

The paper is well-organized, with the different sections flowing nicely into each other. Generally, the paper was easy to follow and experiments chosen appropriately to make the intended arugments.","My main concern is about the evaluation of the algorithms. 
For example, reporting the max return in the evaluation of algorithm or using the standard deviation across runs, whereas the standard error or boostrapped confidence intervals would be more appropriate. (see Questions)

Also, the following design choice is confusing to me:
- Fig. 1 caption. ""Only	upper 80% values according to $\nabla^{apc}_j$ are taken to plot...for meaningful analysis"" 
	Could you elaborate why this decision was made? Does it have to do with many of the values being close to zero?

The improvement in the performance is generally fairly modest. I think this is fine given that main contribution to me is identifying behaviours in the parameter evolution. I think expanding a bit more on the analysis could be interesting. 

In terms of clarity, some details could be expanded upon more in the main text. See Questions section.","_Clarification questions_


- Line 157: What is $\alpha_k$? Is it Singular Value Information Amount? 


- Fig 2 b) 4th and 5th figure from left. Interesting findings. So basically, the detour ratio is smaller for the 
Again, I wonder if that has more to do with noise or curvature.
Perhaps there is less noise in these directions, 

	- In the 3rd fig from the left, it's hard to see much since the black curve masks everything else. Consider using different colors or some transparency. It would be nice to see how the paths get increasingly noisy.

- Policy Path Trimming: To clarify the algorithm, does it project the current parameters into the space identified by the top singular vectors? 
	The description of the algorithm could be improved in Sec. 4.1. where it is introduced. While the intuition is described, the exact mechanism that is implemented is not explained.

- Similarly, in section 4.2, the Policy Path Boosting could be described a bit more clearly. Eq. 2 in particular is a bit confusing since  
$\hat{u}_{n,*}$ is updated but then only 

$\hat{u}_{n,i}$ $(i=1,2)$ are actually used. 

The phrase in line 241 ""PPB modifies $\theta_n$ by increasing $u_{n,1}, u_{n,2}$ along the temporal direction..."" sounds  overly complicated. Perhaps rephrasing it to something like ""PPB moves the parameter further in the direction of previous updates along the first two main directions $u_{n,1}$ and $u_{n,2}$"" could be simpler. 

_Suggestions and broader questions_
- By constraining the parameter evolution path to focus on the previous main directions, would the effect of ""primacy bias"" or related phenomena be even stronger? Could we be losing out on performance due to prematurely committing to certain update directions? 

- Line 270. The evaluation metric ""SCORE"" should no longer be used since the maximum over runs introduces overestimation bias and leads to less reliable estimatse. See [1] for better evaluation practices and [2] for arguments against using the max. 

- I wonder if the detours are mainly due to noise or curvature of the objective. One way to test this would be to increase or decrease the minibatch size, which can control the variance of the updates. Then, by inspecting the effect on the detour ratio or cumulative parameter movement, we could guess the relative impact of noise and curvature. 

- Fig.1 is a CDF plot. I think a histogram or a box plot might be easier to interpret than CDF plots since you need to look at differences in a CDF plot to identify where most of the probability mass is.

- An ablation study for the two components of the algorithm would be a valuable addition. It is not clear if both pieces are necessary right now or how important they are.

- I would also be curious to know what would happen if we took the estimated space 

- Here is a paper that could be interested to read [3] where the authors show that, even if you constrain neural network parameters to a random subspace, as long as the dimension of that subspace is not too small, you can recover the same performance as the original network. 
The idea of Policy Path Trimming could be interpreted as a more intelligent approach which estimates the constrained subspace instead of choosing a random one. 

- Another line of research (e.g. see [4]) has observed that the Hessian contains only a few large eigenvalues in neural network training, which may be related to the ideas discussed in the paper since there would be some interplay between the curvature of the loss surface and directions of updates over time. 

- In the matrix of parameters over time, consider using $t \in {1,...,T}$ to index the rows instead of $n$ so it's a little easier for the reader to remember which dimension corresponds to what. Alternatively, if $t$ is reserved for environment timesptes, $\tau$ could be used as a substitute. 



[1] ""Deep Reinforcement Learning at the Edge of the Statistical Precipice"" Agarwal et al.

[2] ""Deep Reinforcement Learning that Matters"" Henderson et al. 

[3] ""Measuring the Intrinsic Dimension of Objective Landscapes"" Li et al. 

[4] ""An Investigation into Neural Net Optimization via Hessian Eigenvalue Density"" Ghorbani et al.",These are discussed.,['No ethics review needed.'],6,4,,Yes,3,4,2,1720992896805,,,NeurIPS.cc/2024/Conference,3vHfwL2stG,"['NeurIPS.cc/2024/Conference/Submission10552/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879397136,[],4,,,['everyone'],3vHfwL2stG,['NeurIPS.cc/2024/Conference/Submission10552/Reviewer_iaGj'],1720992896805,1730879397136,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10552/Reviewer_iaGj']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several papers that could be of interest to the authors, including:

1. ""Deep Reinforcement Learning at the Edge of the Statistical Precipice"" by Agarwal et al. ([1])
2. ""Deep Reinforcement Learning that Matters"" by Henderson et al. ([2])
3. ""Measuring the Intrinsic Dimension of Objective Landscapes"" by Li et al. ([3])
4. ""An Investigation into Neural Net Optimization via Hessian Eigenvalue Density"" by Ghorbani et al. ([4])

The reviewer suggests that these papers could provide useful context, insights, or related research that could strengthen the authors' work.",1,,An Investigation into Neural Net Optimization via Hessian Eigenvalue Density
eMchcAPipT,"The authors examine the trajectories of policy learning in continuous control reinforcement learning tasks. 

They begin by measuring how directly parameters go to their destination and observe large detours and differing update behaviour for different layers. They then examine the singular value decomposition of the different training checkpoints and observe some strong common update trends. 

They propose Policy Path Trimming and Boosting (PPTB), where policy boosting is boosting the gradients towards the strongest singular values, and trimming trims the updates from the smaller singular values.","* The paper describes their method and analysis well. I generally found it easy to read and understand what points they were trying to convey.
* The proposed method does seem to improve performance on the tasks presented.","* The environments and methods investigated, given the authors resutls are purely empirical, are not diverse enough to draw any real conclusions. The authors focus on continuous control environments without considering discrete environments such as Atari, or more diverse network architectures such as  recurrent networks or transformers, or different methods such as PPO or DQN. These results hold only for MLPs or CNNs trained on continuous control tasks, which just isn't a convincing enough setting to warrant acceptance.
* The proposed method does not seem particularly practical. Computing SVD is both time intensive and requires storing a wide range of previous parameters. It therefore requires a lot more compute, which is why such methods are typically not used. Compared to approximations such as momentum-based optimisation [1], which are also aimed at achieving more uniform convergence, this time among eigenvalues of the data matrix. Although their method improves performance, they have not convincingly demonstrated that the compute couldn't be better used elsewhere, for example by training a bigger network or by sweeping hyperparameters more effectively.



[1] Goh, ""Why Momentum Really Works"", Distill, 2017. http://doi.org/10.23915/distill.00006","* Can you comment more on the relationship between your work and other, less compute intensive methods, that aim to allow more uniform convergence among the different data eigenvalues such as momentum? Is there an explicit connection here? Have you thought about that?","* The authors, to their credit, provide an extensive discussion of the limitations of their work in Appendix A. I agree largely with the points in that section and enjoyed their contextualisation of their work there.",['No ethics review needed.'],6,3,,Yes,3,2,3,1721391207294,,,NeurIPS.cc/2024/Conference,3vHfwL2stG,"['NeurIPS.cc/2024/Conference/Submission10552/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879396986,[],5,,,['everyone'],3vHfwL2stG,['NeurIPS.cc/2024/Conference/Submission10552/Reviewer_dZpR'],1721391207294,1730879396986,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10552/Reviewer_dZpR']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

Goh, ""Why Momentum Really Works"", Distill, 2017. http://doi.org/10.23915/distill.00006

This is mentioned in the weaknesses section of the review, where the reviewer compares the proposed method with momentum-based optimization and suggests that the authors should comment on the relationship between their work and this less compute-intensive method.",1,2017,Why Momentum Really Works
185RnH3Vg1,"The paper provides an algorithm for differentially private RELU regression. They claim that their results outperform DPSGD. Additionally, for the case of a small privacy budget, they provide a tree aggregation protocol that balances privacy and utility. Finally, extensive experimental results are provided to support the claims.","1) A novel algorithm is provided for differentially private RELU regression which outperforms DPSGD.

2) Detailed theoretical analysis is provided for the proposed algorithms.

3) Sufficient experimental evaluation is provided for the proposed algorithms with experiments on both synthetic and real-world data",1) There are a lot of recent works on privacy-utility tradeoffs which seem relevant to this paper. A literature survey involving works in that area can be helpful for future readers to further extend this work.,"1) Can the authors propose ideas on how the proposed approach be extended to models with higher complexity such as deep neural networks?
2) The authors analyze the privacy-utility tradeoff in their work. They should also mention similar papers involving privacy-utility tradeoff algorithms such as

[a] Alireza Fallah, Ali Makhdoumi, Azarakhsh Malekian, and Asuman Ozdaglar Optimal and Differentially Private Data Acquisition: Central and Local Mechanisms Operations Research 2024 72:3, 1105-1123
[b] Ameya Anjarlekar, Rasoul Etesami, & R. Srikant. (2023). Striking a Balance: An Optimal Mechanism Design for Heterogenous Differentially Private Data Acquisition for Logistic Regression.
[c] Andrew Lowy, Zeman Li, Tianjian Huang, & Meisam Razaviyayn. (2024). Optimal Differentially Private Model Training with Public Data.

3) Typo on line 335",,['No ethics review needed.'],7,3,,Yes,4,3,3,1720322746104,,,NeurIPS.cc/2024/Conference,3uUIwMxYbR,"['NeurIPS.cc/2024/Conference/Submission8180/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879223641,[],2,,,['everyone'],3uUIwMxYbR,['NeurIPS.cc/2024/Conference/Submission8180/Reviewer_JyY5'],1720322746104,1730879223641,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8180/Reviewer_JyY5']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, particularly papers involving privacy-utility tradeoff algorithms, such as:

[a] Alireza Fallah, Ali Makhdoumi, Azarakhsh Malekian, and Asuman Ozdaglar ""Optimal and Differentially Private Data Acquisition: Central and Local Mechanisms""
[b] Ameya Anjarlekar, Rasoul Etesami, & R. Srikant. ""Striking a Balance: An Optimal Mechanism Design for Heterogenous Differentially Private Data Acquisition for Logistic Regression""
[c] Andrew Lowy, Zeman Li, Tianjian Huang, & Meisam Razaviyayn. ""Optimal Differentially Private Model Training with Public Data""

The reviewer mentions that including a literature survey involving these works can be helpful for future readers to further extend the work.",1,,Optimal and Differentially Private Data Acquisition Central and Local Mechanisms
185RnH3Vg1,"The paper provides an algorithm for differentially private RELU regression. They claim that their results outperform DPSGD. Additionally, for the case of a small privacy budget, they provide a tree aggregation protocol that balances privacy and utility. Finally, extensive experimental results are provided to support the claims.","1) A novel algorithm is provided for differentially private RELU regression which outperforms DPSGD.

2) Detailed theoretical analysis is provided for the proposed algorithms.

3) Sufficient experimental evaluation is provided for the proposed algorithms with experiments on both synthetic and real-world data",1) There are a lot of recent works on privacy-utility tradeoffs which seem relevant to this paper. A literature survey involving works in that area can be helpful for future readers to further extend this work.,"1) Can the authors propose ideas on how the proposed approach be extended to models with higher complexity such as deep neural networks?
2) The authors analyze the privacy-utility tradeoff in their work. They should also mention similar papers involving privacy-utility tradeoff algorithms such as

[a] Alireza Fallah, Ali Makhdoumi, Azarakhsh Malekian, and Asuman Ozdaglar Optimal and Differentially Private Data Acquisition: Central and Local Mechanisms Operations Research 2024 72:3, 1105-1123
[b] Ameya Anjarlekar, Rasoul Etesami, & R. Srikant. (2023). Striking a Balance: An Optimal Mechanism Design for Heterogenous Differentially Private Data Acquisition for Logistic Regression.
[c] Andrew Lowy, Zeman Li, Tianjian Huang, & Meisam Razaviyayn. (2024). Optimal Differentially Private Model Training with Public Data.

3) Typo on line 335",,['No ethics review needed.'],7,3,,Yes,4,3,3,1720322746104,,,NeurIPS.cc/2024/Conference,3uUIwMxYbR,"['NeurIPS.cc/2024/Conference/Submission8180/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879223641,[],2,,,['everyone'],3uUIwMxYbR,['NeurIPS.cc/2024/Conference/Submission8180/Reviewer_JyY5'],1720322746104,1730879223641,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8180/Reviewer_JyY5']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, particularly papers involving privacy-utility tradeoff algorithms, such as:

[a] Alireza Fallah, Ali Makhdoumi, Azarakhsh Malekian, and Asuman Ozdaglar ""Optimal and Differentially Private Data Acquisition: Central and Local Mechanisms""
[b] Ameya Anjarlekar, Rasoul Etesami, & R. Srikant. ""Striking a Balance: An Optimal Mechanism Design for Heterogenous Differentially Private Data Acquisition for Logistic Regression""
[c] Andrew Lowy, Zeman Li, Tianjian Huang, & Meisam Razaviyayn. ""Optimal Differentially Private Model Training with Public Data""

The reviewer mentions that including a literature survey involving these works can be helpful for future readers to further extend the work.",1,,Striking a Balance An Optimal Mechanism Design for Heterogenous Differentially Private Data Acquisition for Logistic Regression
185RnH3Vg1,"The paper provides an algorithm for differentially private RELU regression. They claim that their results outperform DPSGD. Additionally, for the case of a small privacy budget, they provide a tree aggregation protocol that balances privacy and utility. Finally, extensive experimental results are provided to support the claims.","1) A novel algorithm is provided for differentially private RELU regression which outperforms DPSGD.

2) Detailed theoretical analysis is provided for the proposed algorithms.

3) Sufficient experimental evaluation is provided for the proposed algorithms with experiments on both synthetic and real-world data",1) There are a lot of recent works on privacy-utility tradeoffs which seem relevant to this paper. A literature survey involving works in that area can be helpful for future readers to further extend this work.,"1) Can the authors propose ideas on how the proposed approach be extended to models with higher complexity such as deep neural networks?
2) The authors analyze the privacy-utility tradeoff in their work. They should also mention similar papers involving privacy-utility tradeoff algorithms such as

[a] Alireza Fallah, Ali Makhdoumi, Azarakhsh Malekian, and Asuman Ozdaglar Optimal and Differentially Private Data Acquisition: Central and Local Mechanisms Operations Research 2024 72:3, 1105-1123
[b] Ameya Anjarlekar, Rasoul Etesami, & R. Srikant. (2023). Striking a Balance: An Optimal Mechanism Design for Heterogenous Differentially Private Data Acquisition for Logistic Regression.
[c] Andrew Lowy, Zeman Li, Tianjian Huang, & Meisam Razaviyayn. (2024). Optimal Differentially Private Model Training with Public Data.

3) Typo on line 335",,['No ethics review needed.'],7,3,,Yes,4,3,3,1720322746104,,,NeurIPS.cc/2024/Conference,3uUIwMxYbR,"['NeurIPS.cc/2024/Conference/Submission8180/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879223641,[],2,,,['everyone'],3uUIwMxYbR,['NeurIPS.cc/2024/Conference/Submission8180/Reviewer_JyY5'],1720322746104,1730879223641,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8180/Reviewer_JyY5']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, particularly papers involving privacy-utility tradeoff algorithms, such as:

[a] Alireza Fallah, Ali Makhdoumi, Azarakhsh Malekian, and Asuman Ozdaglar ""Optimal and Differentially Private Data Acquisition: Central and Local Mechanisms""
[b] Ameya Anjarlekar, Rasoul Etesami, & R. Srikant. ""Striking a Balance: An Optimal Mechanism Design for Heterogenous Differentially Private Data Acquisition for Logistic Regression""
[c] Andrew Lowy, Zeman Li, Tianjian Huang, & Meisam Razaviyayn. ""Optimal Differentially Private Model Training with Public Data""

The reviewer mentions that including a literature survey involving these works can be helpful for future readers to further extend the work.",1,,Optimal Differentially Private Model Training with Public Data
LnPtcmj4xw,"This study introduces SA3DIP, a novel 3D instance segmentation model based on SAM. SA3DIP leverages texture priors from point cloud color channels to generate complementary primitives and incorporates 3D spatial priors when merging 2D masks by integrating a 3D detector. These enhancements enable SA3DIP to generate superior superpoints and mitigate the over-segmentation problem found in previous SAM-based 3D instance segmentation methods.","(1) Using SAM to extract 2D masks from RGB-D frames and merge them into a final 3D segmentation result is common in 3D OV segmentation methods. However, few previous methods are geometry-aware during the merging process, highlighting the significance of SA3DIP's incorporation of 3D priors.

(2) Constraints from 3D spatial priors substantially improve performance on both the ScanNetV2 and ScanNetV2-INS datasets.

(3) The low quality of ScanNetV2 ground-truth segmentation results has been a persistent problem. A 3D segmentation dataset with more accurate ground truth, like ScanNetV2-INS, is demanding.","(1) Using RGB values only as texture prior are not robust enough due to their susceptibility to variations caused by lighting conditions, shadows, reflections, and object materials.

(2) The ablation study shows that the performance gain from Complementary 3D superpoint primitives is not significant compared to other modules in SA3DIP.

(3) This paper reports only the class-agnostic instance segmentation results of SA3DIP. However, the previous benchmark method (SAI3D [1]) also uses semantic instance segmentation as a typical evaluation metric.

[1] Yin, Y., Liu, Y., Xiao, Y., Cohen-Or, D., Huang, J. and Chen, B., 2024. Sai3d: Segment any instance in 3d scenes. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 3292-3302).","More comprehensive experiments are needed to validate the effectiveness of the Complementary Primitives Generation module. Additionally, the authors should further discuss the motivations for using color value similarities as texture priors.",The authors adequately addressed the limitations in section 4.4.,['No ethics review needed.'],6,4,,Yes,2,3,3,1720623469172,,,NeurIPS.cc/2024/Conference,3uI4ceR4iz,"['NeurIPS.cc/2024/Conference/Submission17768/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879931972,[],3,,,['everyone'],3uI4ceR4iz,['NeurIPS.cc/2024/Conference/Submission17768/Reviewer_sUBY'],1720623469172,1730879931972,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17768/Reviewer_sUBY']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

Yin, Y., Liu, Y., Xiao, Y., Cohen-Or, D., Huang, J. and Chen, B., 2024. Sai3d: Segment any instance in 3d scenes. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 3292-3302).

This is referenced as [1] in the peer review.",1,2024,Sai3d Segment any instance in 3d scenes
XMZHkN7bNk,"This paper investigates the generalization capabilities of world models in RL, particularly with respect to latent representation errors, which arise when observations are encoded into a low-dimensional latent space. The authors provide a bound on latent representation error when using CNN encoder-decoder architectures. The world model is framed as a stochastic differential equation to characterize the impact of latent representation errors on generalization in terms of either zero or non-zero drift. The authors provide theoretical analysis which shows that these errors can result in implicit regularization in the zero drift case, and propose a Jacobian regularization scheme to tackle the unwanted bias term in the non-zero drift case. Finally, when performing model rollouts for learning a policy, the authors study the effect of these errors on the value function. Experiments on Mujoco tasks demonstrate that the proposed Jacobian regularization enhances robustness to noisy states, reduces the detrimental impact of latent representation errors, and improves convergence speed for longer horizon tasks.","- World models are a popular area of research in the RL community, but there is a lack of theoretical understanding. This paper takes one step towards theoretically analyzing the generalization capabilities of world models.
- The analysis of the effect of latent representation error is a novel theoretical contribution, to the best of my knowledge.
- The results in the paper seem mathematically sound and provide useful insights. The empirical results demonstrate that the Jacobian regularization, which naturally arises from the theoretical analysis, is helpful in improving robustness.
- As a very theory-heavy paper, the authors structured the writing such that it makes it easy to follow each individual result (though there is some room for improvement here, see weaknesses).","While the paper studies a previously unexplored problem, there are some questions about the significance of these findings and the use of drift and diffusion terms to represent the error. Other areas for improvement include explaining the insights from the theoretical analysis more clearly, describing the experimental settings in more detail, and supporting certain claims with more evidence.

- Studying the effect of latent representation error is certainly useful, however, with recent advances in representation learning approaches, one can learn reasonably good representations such that the reconstruction error is negligible. When it comes to model-based RL, a much bigger issue is the compounding model error, which is a result of error in the latent/state dynamics model predictions. A comment from the authors on this aspect would be helpful.
- The decomposition of latent error into drift and diffusion terms seems a bit contrived. It is not clear how the error can be expressed in this form, and what defines the scenarios of zero versus non-zero drift.
- The interpretation that propagation of latent error leads to the model exploring novel states seems somewhat questionable. My understanding is that the erroneous states improve robustness similar to noise injection, but will most likely not be valid states belonging to the state space of the MDP. Some reasonable evidence is required to support this statement.
- The paper presents several results and including some intuitive or low-level explanation for each of those results would greatly improve readability. Additionally, due to the large amount of mathematical notation used throughout the paper, it would be helpful to include a notation table in the appendix for easy reference.
- The experimental setting is not sufficiently clear, especially in the introduction when the authors refer to Table 1. With regards to the perturbations - are they applied to every state in the trajectory? For masking, is the same mask used for every state, or is the mask also sampled randomly? With regards to injecting encoder error - how to interpret the $\mu_t$ and $\sigma_t$ values?","- I am not sure I fully understand the relation of batch size with the latent representation error in Table 1. Since one would take the mean over the batch size, it should not affect the error magnitude. Is the variation in performance due to stochasticity of the SGD updates? If so, how does it relate to latent representation error? Also, as mentioned in weaknesses, the experimental setting should be clearly explained at this point in the paper.
- What do the drift and diffusion terms corresponding to the latent representation error signify?
- Theorem 3.7 suggests that the regularizing effect of the latent representation error can be attributed to the Hessian of the loss function, which encourages wider minima. As noted by the authors, this term is non-negative only if the loss function is convex. Could the authors comment on how to interpret this result for non-convex loss functions (which is usually the case in deep learning)?
- The analysis in this paper focuses on Dreamer style models which use an RNN to represent the latent dynamics. A parallel line of work, TD-MPC [1], uses an MLP model to predict the next state which is applied recursively. I am interested to know if the authors have any thoughts on the applicability of their analysis to such methods, and if there are any major differences.
- An alternate method to improve robustness to perturbations is by training the model/value function on different augmentations of the states [2]. I understand the limitations of time during the short rebuttal period, but an empirical comparison would significantly enhance the paper. I am also curious to know the authors’ thoughts on the pros/cons of using the Jacobian regularization term over such data augmentation methods.
- How much computational overhead is added by the calculation of the Jacobian regularization term?

[1] Hansen, N.A., Su, H. and Wang, X., 2022, June. Temporal Difference Learning for Model Predictive Control. In *International Conference on Machine Learning* (pp. 8387-8406). PMLR.

[2] Yarats, D., Kostrikov, I. and Fergus, R., 2021, May. Image augmentation is all you need: Regularizing deep reinforcement learning from pixels. In *International conference on learning representations*.","There is little discussion on the limitations of the analysis. Some points worth discussing could be the impact of various assumptions when deriving the results, the fact that the analysis is mostly focused on a specific setting - learning from pixels using a CNN encoder and an RNN latent dynamics model, and further investigation of the compounding model error problem.",['No ethics review needed.'],6,3,,Yes,2,2,3,1720090483674,,,NeurIPS.cc/2024/Conference,3sWghzJvGd,"['NeurIPS.cc/2024/Conference/Submission13788/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879660283,[],1,,,['everyone'],3sWghzJvGd,['NeurIPS.cc/2024/Conference/Submission13788/Reviewer_waKG'],1720090483674,1730879660283,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission13788/Reviewer_waKG']","Yes, the peer review explicitly suggests the authors of the paper to cite two specific literature references:

1. Hansen, N.A., Su, H. and Wang, X., 2022, June. Temporal Difference Learning for Model Predictive Control. In *International Conference on Machine Learning* (pp. 8387-8406). PMLR. (referred to as [1] in the review)
2. Yarats, D., Kostrikov, I. and Fergus, R., 2021, May. Image augmentation is all you need: Regularizing deep reinforcement learning from pixels. In *International conference on learning representations*. (referred to as [2] in the review)

The reviewer is interested in knowing the authors' thoughts on the applicability of their analysis to methods like TD-MPC ([1]) and comparing their Jacobian regularization approach with data augmentation methods like the one presented in [2].",1,"2022, 2021",Temporal Difference Learning for Model Predictive Control 
XMZHkN7bNk,"This paper investigates the generalization capabilities of world models in RL, particularly with respect to latent representation errors, which arise when observations are encoded into a low-dimensional latent space. The authors provide a bound on latent representation error when using CNN encoder-decoder architectures. The world model is framed as a stochastic differential equation to characterize the impact of latent representation errors on generalization in terms of either zero or non-zero drift. The authors provide theoretical analysis which shows that these errors can result in implicit regularization in the zero drift case, and propose a Jacobian regularization scheme to tackle the unwanted bias term in the non-zero drift case. Finally, when performing model rollouts for learning a policy, the authors study the effect of these errors on the value function. Experiments on Mujoco tasks demonstrate that the proposed Jacobian regularization enhances robustness to noisy states, reduces the detrimental impact of latent representation errors, and improves convergence speed for longer horizon tasks.","- World models are a popular area of research in the RL community, but there is a lack of theoretical understanding. This paper takes one step towards theoretically analyzing the generalization capabilities of world models.
- The analysis of the effect of latent representation error is a novel theoretical contribution, to the best of my knowledge.
- The results in the paper seem mathematically sound and provide useful insights. The empirical results demonstrate that the Jacobian regularization, which naturally arises from the theoretical analysis, is helpful in improving robustness.
- As a very theory-heavy paper, the authors structured the writing such that it makes it easy to follow each individual result (though there is some room for improvement here, see weaknesses).","While the paper studies a previously unexplored problem, there are some questions about the significance of these findings and the use of drift and diffusion terms to represent the error. Other areas for improvement include explaining the insights from the theoretical analysis more clearly, describing the experimental settings in more detail, and supporting certain claims with more evidence.

- Studying the effect of latent representation error is certainly useful, however, with recent advances in representation learning approaches, one can learn reasonably good representations such that the reconstruction error is negligible. When it comes to model-based RL, a much bigger issue is the compounding model error, which is a result of error in the latent/state dynamics model predictions. A comment from the authors on this aspect would be helpful.
- The decomposition of latent error into drift and diffusion terms seems a bit contrived. It is not clear how the error can be expressed in this form, and what defines the scenarios of zero versus non-zero drift.
- The interpretation that propagation of latent error leads to the model exploring novel states seems somewhat questionable. My understanding is that the erroneous states improve robustness similar to noise injection, but will most likely not be valid states belonging to the state space of the MDP. Some reasonable evidence is required to support this statement.
- The paper presents several results and including some intuitive or low-level explanation for each of those results would greatly improve readability. Additionally, due to the large amount of mathematical notation used throughout the paper, it would be helpful to include a notation table in the appendix for easy reference.
- The experimental setting is not sufficiently clear, especially in the introduction when the authors refer to Table 1. With regards to the perturbations - are they applied to every state in the trajectory? For masking, is the same mask used for every state, or is the mask also sampled randomly? With regards to injecting encoder error - how to interpret the $\mu_t$ and $\sigma_t$ values?","- I am not sure I fully understand the relation of batch size with the latent representation error in Table 1. Since one would take the mean over the batch size, it should not affect the error magnitude. Is the variation in performance due to stochasticity of the SGD updates? If so, how does it relate to latent representation error? Also, as mentioned in weaknesses, the experimental setting should be clearly explained at this point in the paper.
- What do the drift and diffusion terms corresponding to the latent representation error signify?
- Theorem 3.7 suggests that the regularizing effect of the latent representation error can be attributed to the Hessian of the loss function, which encourages wider minima. As noted by the authors, this term is non-negative only if the loss function is convex. Could the authors comment on how to interpret this result for non-convex loss functions (which is usually the case in deep learning)?
- The analysis in this paper focuses on Dreamer style models which use an RNN to represent the latent dynamics. A parallel line of work, TD-MPC [1], uses an MLP model to predict the next state which is applied recursively. I am interested to know if the authors have any thoughts on the applicability of their analysis to such methods, and if there are any major differences.
- An alternate method to improve robustness to perturbations is by training the model/value function on different augmentations of the states [2]. I understand the limitations of time during the short rebuttal period, but an empirical comparison would significantly enhance the paper. I am also curious to know the authors’ thoughts on the pros/cons of using the Jacobian regularization term over such data augmentation methods.
- How much computational overhead is added by the calculation of the Jacobian regularization term?

[1] Hansen, N.A., Su, H. and Wang, X., 2022, June. Temporal Difference Learning for Model Predictive Control. In *International Conference on Machine Learning* (pp. 8387-8406). PMLR.

[2] Yarats, D., Kostrikov, I. and Fergus, R., 2021, May. Image augmentation is all you need: Regularizing deep reinforcement learning from pixels. In *International conference on learning representations*.","There is little discussion on the limitations of the analysis. Some points worth discussing could be the impact of various assumptions when deriving the results, the fact that the analysis is mostly focused on a specific setting - learning from pixels using a CNN encoder and an RNN latent dynamics model, and further investigation of the compounding model error problem.",['No ethics review needed.'],6,3,,Yes,2,2,3,1720090483674,,,NeurIPS.cc/2024/Conference,3sWghzJvGd,"['NeurIPS.cc/2024/Conference/Submission13788/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879660283,[],1,,,['everyone'],3sWghzJvGd,['NeurIPS.cc/2024/Conference/Submission13788/Reviewer_waKG'],1720090483674,1730879660283,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission13788/Reviewer_waKG']","Yes, the peer review explicitly suggests the authors of the paper to cite two specific literature references:

1. Hansen, N.A., Su, H. and Wang, X., 2022, June. Temporal Difference Learning for Model Predictive Control. In *International Conference on Machine Learning* (pp. 8387-8406). PMLR. (referred to as [1] in the review)
2. Yarats, D., Kostrikov, I. and Fergus, R., 2021, May. Image augmentation is all you need: Regularizing deep reinforcement learning from pixels. In *International conference on learning representations*. (referred to as [2] in the review)

The reviewer is interested in knowing the authors' thoughts on the applicability of their analysis to methods like TD-MPC ([1]) and comparing their Jacobian regularization approach with data augmentation methods like the one presented in [2].",1,"2022, 2021",Image augmentation is all you need Regularizing deep reinforcement learning from pixels
QQoDJ7WbQY,"This paper proposes a novel framework for modeling and editing dynamic scenes. The authors used a two-pass Multi-Gaussian approach to represent the entire scene. First, they obtained relatively stable Core Gaussians through initialization, and then used the Core Gaussians to drive Sub-Gaussians to fit the entire scene. To better edit motion, the authors parameterized each Gaussian with triangle soup. Experimental results show that this method not only matches the rendering quality of SC-GS but also enables the editing of more extreme large motions.","This paper is clear and easy to follow. The dynamic reconstruction method based on Gaussian splatting inherently has advantages in motion editing, but this direction has not been well-explored by the community. Therefore, I am very grateful to the authors for focusing on improving the motion editing capabilities of dynamic scenes and achieving impressive editing results (as shown in Fig. 4). The triangle-soup-based motion editing proposed by the authors really makes sense. Additionally, the honest comparison of rendering metrics in both synthetic and real scenes is also appreciated.","1. I think the following papers should also be cited, because they have made significant contributions to the early dynamic scenes reconstruction based on Gaussian splatting.:
   - (CVPR 2024) Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis by Zhan Li et al.
   - (ICLR 2024) Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting by Zeyu Yang et al.
2. L136, The concept of anchor Gaussian originally comes from Scaffold-GS [1], not from Spec-Gaussian. It would be even better if Scaffold-GS could be cited.
3. It would be even better if Deformable-GS [2] were included in the comparison of quantitative metrics (such as Tabs. 1-2), as it is the first deformation-based dynamic Gaussian splatting method and serves as the baseline for SC-GS.
4. I think the ablation study is not thorough enough. Although the ablation on batch size is appreciated, I am unclear about the roles of other components of the method. Corresponding ablation studies are needed to make the paper more robust. For example, I am very interested in understanding the impact of the `Sub-Rot Network` mentioned in L218 on the rendering metrics.



[1] Tao Lu, Mulin Yu, Linning Xu, Yuanbo Xiangli, Limin Wang, Dahua Lin, and Bo Dai. 2023. Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering. arXiv preprint arXiv:2312.00109 (2023)

[2] Ziyi Yang, Xinyu Gao, Wen Zhou, Shaohui Jiao, Yuqing Zhang, and Xiaogang Jin. Deformable 3d gaussians for high-fidelity monocular dynamic scene reconstruction. arXiv preprint arXiv:2309.13101,2023.","A small tip: In Tab. 1, the authors used the metrics from the SC-GS paper. However, SC-GS did not use a consistent background; for example, the `Bounce` (and maybe `Trex`) scene used a white background. The authors clearly used a black background consistently. Although the reported metrics in the table show a slight decrease compared to SC-GS, I greatly appreciate the authors' honesty.",Please refer to the weakness part.,['No ethics review needed.'],7,5,,Yes,3,3,3,1719372886291,,,NeurIPS.cc/2024/Conference,3og0FT85B2,"['NeurIPS.cc/2024/Conference/Submission779/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878659778,[],3,,,['everyone'],3og0FT85B2,['NeurIPS.cc/2024/Conference/Submission779/Reviewer_hxyh'],1719372886291,1730878659778,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission779/Reviewer_hxyh']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. (CVPR 2024) Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis by Zhan Li et al.
2. (ICLR 2024) Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting by Zeyu Yang et al.
3. Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering by Tao Lu et al. (arXiv preprint arXiv:2312.00109, 2023)
4. Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene Reconstruction by Ziyi Yang et al. (arXiv preprint arXiv:2309.13101, 2023)

The reviewer suggests that citing these papers would be beneficial to provide a more comprehensive background and context for the proposed method, and to acknowledge the contributions of other researchers in the field.",1,"2024, 2024, 2023, 2023, 2023, 2023",Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis 
QQoDJ7WbQY,"This paper proposes a novel framework for modeling and editing dynamic scenes. The authors used a two-pass Multi-Gaussian approach to represent the entire scene. First, they obtained relatively stable Core Gaussians through initialization, and then used the Core Gaussians to drive Sub-Gaussians to fit the entire scene. To better edit motion, the authors parameterized each Gaussian with triangle soup. Experimental results show that this method not only matches the rendering quality of SC-GS but also enables the editing of more extreme large motions.","This paper is clear and easy to follow. The dynamic reconstruction method based on Gaussian splatting inherently has advantages in motion editing, but this direction has not been well-explored by the community. Therefore, I am very grateful to the authors for focusing on improving the motion editing capabilities of dynamic scenes and achieving impressive editing results (as shown in Fig. 4). The triangle-soup-based motion editing proposed by the authors really makes sense. Additionally, the honest comparison of rendering metrics in both synthetic and real scenes is also appreciated.","1. I think the following papers should also be cited, because they have made significant contributions to the early dynamic scenes reconstruction based on Gaussian splatting.:
   - (CVPR 2024) Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis by Zhan Li et al.
   - (ICLR 2024) Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting by Zeyu Yang et al.
2. L136, The concept of anchor Gaussian originally comes from Scaffold-GS [1], not from Spec-Gaussian. It would be even better if Scaffold-GS could be cited.
3. It would be even better if Deformable-GS [2] were included in the comparison of quantitative metrics (such as Tabs. 1-2), as it is the first deformation-based dynamic Gaussian splatting method and serves as the baseline for SC-GS.
4. I think the ablation study is not thorough enough. Although the ablation on batch size is appreciated, I am unclear about the roles of other components of the method. Corresponding ablation studies are needed to make the paper more robust. For example, I am very interested in understanding the impact of the `Sub-Rot Network` mentioned in L218 on the rendering metrics.



[1] Tao Lu, Mulin Yu, Linning Xu, Yuanbo Xiangli, Limin Wang, Dahua Lin, and Bo Dai. 2023. Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering. arXiv preprint arXiv:2312.00109 (2023)

[2] Ziyi Yang, Xinyu Gao, Wen Zhou, Shaohui Jiao, Yuqing Zhang, and Xiaogang Jin. Deformable 3d gaussians for high-fidelity monocular dynamic scene reconstruction. arXiv preprint arXiv:2309.13101,2023.","A small tip: In Tab. 1, the authors used the metrics from the SC-GS paper. However, SC-GS did not use a consistent background; for example, the `Bounce` (and maybe `Trex`) scene used a white background. The authors clearly used a black background consistently. Although the reported metrics in the table show a slight decrease compared to SC-GS, I greatly appreciate the authors' honesty.",Please refer to the weakness part.,['No ethics review needed.'],7,5,,Yes,3,3,3,1719372886291,,,NeurIPS.cc/2024/Conference,3og0FT85B2,"['NeurIPS.cc/2024/Conference/Submission779/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878659778,[],3,,,['everyone'],3og0FT85B2,['NeurIPS.cc/2024/Conference/Submission779/Reviewer_hxyh'],1719372886291,1730878659778,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission779/Reviewer_hxyh']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. (CVPR 2024) Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis by Zhan Li et al.
2. (ICLR 2024) Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting by Zeyu Yang et al.
3. Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering by Tao Lu et al. (arXiv preprint arXiv:2312.00109, 2023)
4. Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene Reconstruction by Ziyi Yang et al. (arXiv preprint arXiv:2309.13101, 2023)

The reviewer suggests that citing these papers would be beneficial to provide a more comprehensive background and context for the proposed method, and to acknowledge the contributions of other researchers in the field.",1,"2024, 2024, 2023, 2023, 2023, 2023",Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting 
QQoDJ7WbQY,"This paper proposes a novel framework for modeling and editing dynamic scenes. The authors used a two-pass Multi-Gaussian approach to represent the entire scene. First, they obtained relatively stable Core Gaussians through initialization, and then used the Core Gaussians to drive Sub-Gaussians to fit the entire scene. To better edit motion, the authors parameterized each Gaussian with triangle soup. Experimental results show that this method not only matches the rendering quality of SC-GS but also enables the editing of more extreme large motions.","This paper is clear and easy to follow. The dynamic reconstruction method based on Gaussian splatting inherently has advantages in motion editing, but this direction has not been well-explored by the community. Therefore, I am very grateful to the authors for focusing on improving the motion editing capabilities of dynamic scenes and achieving impressive editing results (as shown in Fig. 4). The triangle-soup-based motion editing proposed by the authors really makes sense. Additionally, the honest comparison of rendering metrics in both synthetic and real scenes is also appreciated.","1. I think the following papers should also be cited, because they have made significant contributions to the early dynamic scenes reconstruction based on Gaussian splatting.:
   - (CVPR 2024) Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis by Zhan Li et al.
   - (ICLR 2024) Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting by Zeyu Yang et al.
2. L136, The concept of anchor Gaussian originally comes from Scaffold-GS [1], not from Spec-Gaussian. It would be even better if Scaffold-GS could be cited.
3. It would be even better if Deformable-GS [2] were included in the comparison of quantitative metrics (such as Tabs. 1-2), as it is the first deformation-based dynamic Gaussian splatting method and serves as the baseline for SC-GS.
4. I think the ablation study is not thorough enough. Although the ablation on batch size is appreciated, I am unclear about the roles of other components of the method. Corresponding ablation studies are needed to make the paper more robust. For example, I am very interested in understanding the impact of the `Sub-Rot Network` mentioned in L218 on the rendering metrics.



[1] Tao Lu, Mulin Yu, Linning Xu, Yuanbo Xiangli, Limin Wang, Dahua Lin, and Bo Dai. 2023. Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering. arXiv preprint arXiv:2312.00109 (2023)

[2] Ziyi Yang, Xinyu Gao, Wen Zhou, Shaohui Jiao, Yuqing Zhang, and Xiaogang Jin. Deformable 3d gaussians for high-fidelity monocular dynamic scene reconstruction. arXiv preprint arXiv:2309.13101,2023.","A small tip: In Tab. 1, the authors used the metrics from the SC-GS paper. However, SC-GS did not use a consistent background; for example, the `Bounce` (and maybe `Trex`) scene used a white background. The authors clearly used a black background consistently. Although the reported metrics in the table show a slight decrease compared to SC-GS, I greatly appreciate the authors' honesty.",Please refer to the weakness part.,['No ethics review needed.'],7,5,,Yes,3,3,3,1719372886291,,,NeurIPS.cc/2024/Conference,3og0FT85B2,"['NeurIPS.cc/2024/Conference/Submission779/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878659778,[],3,,,['everyone'],3og0FT85B2,['NeurIPS.cc/2024/Conference/Submission779/Reviewer_hxyh'],1719372886291,1730878659778,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission779/Reviewer_hxyh']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. (CVPR 2024) Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis by Zhan Li et al.
2. (ICLR 2024) Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting by Zeyu Yang et al.
3. Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering by Tao Lu et al. (arXiv preprint arXiv:2312.00109, 2023)
4. Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene Reconstruction by Ziyi Yang et al. (arXiv preprint arXiv:2309.13101, 2023)

The reviewer suggests that citing these papers would be beneficial to provide a more comprehensive background and context for the proposed method, and to acknowledge the contributions of other researchers in the field.",1,"2024, 2024, 2023, 2023, 2023, 2023",Scaffold-GS Structured 3D Gaussians for View-Adaptive Rendering 
QQoDJ7WbQY,"This paper proposes a novel framework for modeling and editing dynamic scenes. The authors used a two-pass Multi-Gaussian approach to represent the entire scene. First, they obtained relatively stable Core Gaussians through initialization, and then used the Core Gaussians to drive Sub-Gaussians to fit the entire scene. To better edit motion, the authors parameterized each Gaussian with triangle soup. Experimental results show that this method not only matches the rendering quality of SC-GS but also enables the editing of more extreme large motions.","This paper is clear and easy to follow. The dynamic reconstruction method based on Gaussian splatting inherently has advantages in motion editing, but this direction has not been well-explored by the community. Therefore, I am very grateful to the authors for focusing on improving the motion editing capabilities of dynamic scenes and achieving impressive editing results (as shown in Fig. 4). The triangle-soup-based motion editing proposed by the authors really makes sense. Additionally, the honest comparison of rendering metrics in both synthetic and real scenes is also appreciated.","1. I think the following papers should also be cited, because they have made significant contributions to the early dynamic scenes reconstruction based on Gaussian splatting.:
   - (CVPR 2024) Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis by Zhan Li et al.
   - (ICLR 2024) Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting by Zeyu Yang et al.
2. L136, The concept of anchor Gaussian originally comes from Scaffold-GS [1], not from Spec-Gaussian. It would be even better if Scaffold-GS could be cited.
3. It would be even better if Deformable-GS [2] were included in the comparison of quantitative metrics (such as Tabs. 1-2), as it is the first deformation-based dynamic Gaussian splatting method and serves as the baseline for SC-GS.
4. I think the ablation study is not thorough enough. Although the ablation on batch size is appreciated, I am unclear about the roles of other components of the method. Corresponding ablation studies are needed to make the paper more robust. For example, I am very interested in understanding the impact of the `Sub-Rot Network` mentioned in L218 on the rendering metrics.



[1] Tao Lu, Mulin Yu, Linning Xu, Yuanbo Xiangli, Limin Wang, Dahua Lin, and Bo Dai. 2023. Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering. arXiv preprint arXiv:2312.00109 (2023)

[2] Ziyi Yang, Xinyu Gao, Wen Zhou, Shaohui Jiao, Yuqing Zhang, and Xiaogang Jin. Deformable 3d gaussians for high-fidelity monocular dynamic scene reconstruction. arXiv preprint arXiv:2309.13101,2023.","A small tip: In Tab. 1, the authors used the metrics from the SC-GS paper. However, SC-GS did not use a consistent background; for example, the `Bounce` (and maybe `Trex`) scene used a white background. The authors clearly used a black background consistently. Although the reported metrics in the table show a slight decrease compared to SC-GS, I greatly appreciate the authors' honesty.",Please refer to the weakness part.,['No ethics review needed.'],7,5,,Yes,3,3,3,1719372886291,,,NeurIPS.cc/2024/Conference,3og0FT85B2,"['NeurIPS.cc/2024/Conference/Submission779/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878659778,[],3,,,['everyone'],3og0FT85B2,['NeurIPS.cc/2024/Conference/Submission779/Reviewer_hxyh'],1719372886291,1730878659778,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission779/Reviewer_hxyh']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. (CVPR 2024) Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis by Zhan Li et al.
2. (ICLR 2024) Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting by Zeyu Yang et al.
3. Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering by Tao Lu et al. (arXiv preprint arXiv:2312.00109, 2023)
4. Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene Reconstruction by Ziyi Yang et al. (arXiv preprint arXiv:2309.13101, 2023)

The reviewer suggests that citing these papers would be beneficial to provide a more comprehensive background and context for the proposed method, and to acknowledge the contributions of other researchers in the field.",1,"2024, 2024, 2023, 2023, 2023, 2023",Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene Reconstruction
w0EKZ8Ed4J,"This paper proposes a method to recover face albedo by disentangling the input image into an albedo and shading maps (called ""light conditions""). The shading maps are generated by a network which are combined with the albedo texture (generated from AlbedoMM) that is rendered under a set of $n$ lighting conditions represented using spherical harmonics. The networks for predicting the shading maps, spherical harmonics and the texture are optimized through a photometric loss along with regularizations. In order to generate meaningful masks, a binarization constraint is added on the generated masks along with an area constraint. While the final renders are significantly better than prior work, two crucial comparisons are missing i.e against the Haar-wavelet basis (https://graphics.stanford.edu/papers/allfreqmat/) and the Albedo from AlbedoMM","1) From my perspective, the central contribution of this paper is a somewhat 'neural' spherical harmonics (SH) representation, where the 'neural' masks help model sharp illumination effects such as shadows which SH fails to capture. This is certainly an interesting direction to explore

2) The paper is well written

3) Quantitative and qualitative results are better than prior work (especially in albedo). However, some crucial comparisons are missing.","1) The authors have not compared against optimizing in haar-wavelets (https://graphics.stanford.edu/papers/allfreqmat/) which are designed specifically to model sharp illumination dependent effects. Without this comparison, it is hard to asses the improvements the proposed model offers over classical representations. I understand that such an optimization may be compute intensive, but it is necessary.

2) There are no results shown of the initial AlbedoMM texture the texture map is initialized from. AlbedoMM already gives a relatively uniform texture map that is free from lighting artifacts, it is unclear what additional benefits texture optimization yields.","How many bands of SH are optimized? Did you investigate optimizing higher number of bands instead of generating the masks (again, as done in: http://graphics.stanford.edu/papers/allfreq/allfreq.pdf",Yes.,['No ethics review needed.'],6,3,,Yes,3,3,2,1720735929898,,,NeurIPS.cc/2024/Conference,3lic0JgPRZ,"['NeurIPS.cc/2024/Conference/Submission2540/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878783943,[],2,,,['everyone'],3lic0JgPRZ,['NeurIPS.cc/2024/Conference/Submission2540/Reviewer_W5JR'],1720735929898,1730878783943,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2540/Reviewer_W5JR']","Yes, this peer review explicitly suggests the authors of the paper to cite and compare their work with two specific literature:

1. ""All-Frequency Rendering"" by Sloan et al. (https://graphics.stanford.edu/papers/allfreqmat/), which uses the Haar-wavelet basis to model sharp illumination effects.
2. ""All-Frequency Precomputed Radiance Transfer"" by Sloan et al. (http://graphics.stanford.edu/papers/allfreq/allfreq.pdf), which optimizes higher number of bands instead of generating masks.

The reviewer mentions that comparing with these works is necessary to assess the improvements the proposed model offers over classical representations.",1,,All-Frequency Rendering
w0EKZ8Ed4J,"This paper proposes a method to recover face albedo by disentangling the input image into an albedo and shading maps (called ""light conditions""). The shading maps are generated by a network which are combined with the albedo texture (generated from AlbedoMM) that is rendered under a set of $n$ lighting conditions represented using spherical harmonics. The networks for predicting the shading maps, spherical harmonics and the texture are optimized through a photometric loss along with regularizations. In order to generate meaningful masks, a binarization constraint is added on the generated masks along with an area constraint. While the final renders are significantly better than prior work, two crucial comparisons are missing i.e against the Haar-wavelet basis (https://graphics.stanford.edu/papers/allfreqmat/) and the Albedo from AlbedoMM","1) From my perspective, the central contribution of this paper is a somewhat 'neural' spherical harmonics (SH) representation, where the 'neural' masks help model sharp illumination effects such as shadows which SH fails to capture. This is certainly an interesting direction to explore

2) The paper is well written

3) Quantitative and qualitative results are better than prior work (especially in albedo). However, some crucial comparisons are missing.","1) The authors have not compared against optimizing in haar-wavelets (https://graphics.stanford.edu/papers/allfreqmat/) which are designed specifically to model sharp illumination dependent effects. Without this comparison, it is hard to asses the improvements the proposed model offers over classical representations. I understand that such an optimization may be compute intensive, but it is necessary.

2) There are no results shown of the initial AlbedoMM texture the texture map is initialized from. AlbedoMM already gives a relatively uniform texture map that is free from lighting artifacts, it is unclear what additional benefits texture optimization yields.","How many bands of SH are optimized? Did you investigate optimizing higher number of bands instead of generating the masks (again, as done in: http://graphics.stanford.edu/papers/allfreq/allfreq.pdf",Yes.,['No ethics review needed.'],6,3,,Yes,3,3,2,1720735929898,,,NeurIPS.cc/2024/Conference,3lic0JgPRZ,"['NeurIPS.cc/2024/Conference/Submission2540/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878783943,[],2,,,['everyone'],3lic0JgPRZ,['NeurIPS.cc/2024/Conference/Submission2540/Reviewer_W5JR'],1720735929898,1730878783943,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2540/Reviewer_W5JR']","Yes, this peer review explicitly suggests the authors of the paper to cite and compare their work with two specific literature:

1. ""All-Frequency Rendering"" by Sloan et al. (https://graphics.stanford.edu/papers/allfreqmat/), which uses the Haar-wavelet basis to model sharp illumination effects.
2. ""All-Frequency Precomputed Radiance Transfer"" by Sloan et al. (http://graphics.stanford.edu/papers/allfreq/allfreq.pdf), which optimizes higher number of bands instead of generating masks.

The reviewer mentions that comparing with these works is necessary to assess the improvements the proposed model offers over classical representations.",1,,All-Frequency Precomputed Radiance Transfer
t0m25FL1fY,"This work tackles the problem of external shadows in single image face reconstruction. Specifically, when the input image contains foreign shadows, this often affects the quality of the estimated facial texture, as the external shadows often become baked into the texture or leave behind undesirable artifacts in the shadow region. The paper proposes a comprehensive solution to this problem, including a way to decouple the face image into the result of multiple lights as well as an Adaptive Condition Estimation (ACE) strategy to select which lights are present in the image. The paper further proposes multiple human face priors, such as a global prior to ensure the face texture hue is consistent with the initialization from a 3DMM model and a local prior to ensure that the smoothness of the face texture is similar to the initialization. Experiments demonstrate that the method is able to improve rendering performance on in-the-wild face images by rendering both source images with external shadows and target images without external shadows. The major improvements on target images without external shadows shows that the method is able to produce accurate facial textures that are minimally impacted by the presence of these shadows. Qualitative ablations are also provided to further aid in evaluating the method.","The improvement in rendering performance on target images (w/o external shadows) clearly shows that the method is able to minimize the impact of external shadows from the source image. The qualitative results further support this conclusion, as the facial textures do not contain external shadow artifacts. 

Qualitative ablations are available to help assess the impact of each technical contribution in this work. 

This work is sufficiently novel since it enables more accurate face reconstruction under the condition of external occlusions from the source image, which is a heavily understudied problem. It also goes beyond traditional work in this area since it considers the scenario that there could be more than one light in the image and proposes a method to estimate the set of lights illuminating the face.","For the ablation studies, it would be much more convincing to have tables with quantitative results demonstrating the margin of improvement of each component. Simply picking a few favorable qualitative examples is easy and not convincing. 

In almost all examples in this work, the foreign (external) shadows involved are caused by hats. What about other types of foreign shadows caused by tree leaves, pens, paper, hands, etc? How are the resulting face textures in these situations? It would be nice to compare with the baselines on some images with more diverse foreign shadows. If it is difficult to find such images in the wild, you can find a small test set of 100 or so images from the paper ""Portrait Shadow Manipulation (SIGGRAPH 2020)"" with diverse foreign shadow shapes. 

Some important citations are missing from this work, especially in the face relighting and portrait shadow removal domains. There are several face relighting methods that involve intrinsic decomposition of faces and illumination modeling, some of which involve ray tracing to handle self shadows: 

1. SfSNet : Learning Shape, Reflectance and Illuminance of Faces in the Wild (CVPR 2018)
2. Face Relighting with Geometrically Consistent Shadows (CVPR 2022)
3. Learning Physics-guided Face Relighting under Directional Light (CVPR 2020)

In addition, the shadow removal domain is highly relevant to this work since a simple solution to this problem would be to perform a preprocessing step to remove the foreign (external) shadows from the image first using a portrait shadow removal method before performing face reconstruction. These methods should be cited and discussed in the paper and the authors should verify that their method outperforms this simple baseline: 

1. Portrait Shadow Manipulation (SIGGRAPH 2020)
2. Unsupervised Portrait Shadow Removal via Generative Priors (MM 2021)
3. Blind Removal of Facial Foreign Shadows (BMVC 2022)","Please see the experiments I suggested above, especially with regard to quantitative evaluations for ablations, evaluations on images with more diverse foreign (external) shadows, and comparing with the simple baseline of running a foreign shadow removal method on the images beforehand. I will be carefully reviewing the rebuttal as well as the opinions of the other reviewers to decide if I would like to change my rating. Please also factor in missing citations, as the two areas I mentioned are very relevant to this work.","The authors have at least made an attempt to include a limitations section, although more analysis on failure cases would be helpful. For example, does the method fail when the external shadow covers most of the face? There is no section on potential negative societal impact, although there are certainly some potential concerns with face reconstruction methods, as with any face modeling work. The potential to edit the face and produce fake content is always present.",['No ethics review needed.'],6,4,,Yes,3,2,3,1720767574204,,,NeurIPS.cc/2024/Conference,3lic0JgPRZ,"['NeurIPS.cc/2024/Conference/Submission2540/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878783769,[],3,,,['everyone'],3lic0JgPRZ,['NeurIPS.cc/2024/Conference/Submission2540/Reviewer_SyuP'],1720767574204,1730878783769,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2540/Reviewer_SyuP']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature in the face relighting and portrait shadow removal domains. The reviewer mentions several papers that are relevant to the work and should be cited and discussed, including:

1. SfSNet : Learning Shape, Reflectance and Illuminance of Faces in the Wild (CVPR 2018)
2. Face Relighting with Geometrically Consistent Shadows (CVPR 2022)
3. Learning Physics-guided Face Relighting under Directional Light (CVPR 2020)
4. Portrait Shadow Manipulation (SIGGRAPH 2020)
5. Unsupervised Portrait Shadow Removal via Generative Priors (MM 2021)
6. Blind Removal of Facial Foreign Shadows (BMVC 2022)

The reviewer also suggests that the authors should verify that their method outperforms the simple baseline of running a foreign shadow removal method on the images beforehand, using methods such as those mentioned above.",1,"2018, 2022, 2020, 2020, 2021, 2022","Learning Shape, Reflectance and Illuminance of Faces in the Wild "
t0m25FL1fY,"This work tackles the problem of external shadows in single image face reconstruction. Specifically, when the input image contains foreign shadows, this often affects the quality of the estimated facial texture, as the external shadows often become baked into the texture or leave behind undesirable artifacts in the shadow region. The paper proposes a comprehensive solution to this problem, including a way to decouple the face image into the result of multiple lights as well as an Adaptive Condition Estimation (ACE) strategy to select which lights are present in the image. The paper further proposes multiple human face priors, such as a global prior to ensure the face texture hue is consistent with the initialization from a 3DMM model and a local prior to ensure that the smoothness of the face texture is similar to the initialization. Experiments demonstrate that the method is able to improve rendering performance on in-the-wild face images by rendering both source images with external shadows and target images without external shadows. The major improvements on target images without external shadows shows that the method is able to produce accurate facial textures that are minimally impacted by the presence of these shadows. Qualitative ablations are also provided to further aid in evaluating the method.","The improvement in rendering performance on target images (w/o external shadows) clearly shows that the method is able to minimize the impact of external shadows from the source image. The qualitative results further support this conclusion, as the facial textures do not contain external shadow artifacts. 

Qualitative ablations are available to help assess the impact of each technical contribution in this work. 

This work is sufficiently novel since it enables more accurate face reconstruction under the condition of external occlusions from the source image, which is a heavily understudied problem. It also goes beyond traditional work in this area since it considers the scenario that there could be more than one light in the image and proposes a method to estimate the set of lights illuminating the face.","For the ablation studies, it would be much more convincing to have tables with quantitative results demonstrating the margin of improvement of each component. Simply picking a few favorable qualitative examples is easy and not convincing. 

In almost all examples in this work, the foreign (external) shadows involved are caused by hats. What about other types of foreign shadows caused by tree leaves, pens, paper, hands, etc? How are the resulting face textures in these situations? It would be nice to compare with the baselines on some images with more diverse foreign shadows. If it is difficult to find such images in the wild, you can find a small test set of 100 or so images from the paper ""Portrait Shadow Manipulation (SIGGRAPH 2020)"" with diverse foreign shadow shapes. 

Some important citations are missing from this work, especially in the face relighting and portrait shadow removal domains. There are several face relighting methods that involve intrinsic decomposition of faces and illumination modeling, some of which involve ray tracing to handle self shadows: 

1. SfSNet : Learning Shape, Reflectance and Illuminance of Faces in the Wild (CVPR 2018)
2. Face Relighting with Geometrically Consistent Shadows (CVPR 2022)
3. Learning Physics-guided Face Relighting under Directional Light (CVPR 2020)

In addition, the shadow removal domain is highly relevant to this work since a simple solution to this problem would be to perform a preprocessing step to remove the foreign (external) shadows from the image first using a portrait shadow removal method before performing face reconstruction. These methods should be cited and discussed in the paper and the authors should verify that their method outperforms this simple baseline: 

1. Portrait Shadow Manipulation (SIGGRAPH 2020)
2. Unsupervised Portrait Shadow Removal via Generative Priors (MM 2021)
3. Blind Removal of Facial Foreign Shadows (BMVC 2022)","Please see the experiments I suggested above, especially with regard to quantitative evaluations for ablations, evaluations on images with more diverse foreign (external) shadows, and comparing with the simple baseline of running a foreign shadow removal method on the images beforehand. I will be carefully reviewing the rebuttal as well as the opinions of the other reviewers to decide if I would like to change my rating. Please also factor in missing citations, as the two areas I mentioned are very relevant to this work.","The authors have at least made an attempt to include a limitations section, although more analysis on failure cases would be helpful. For example, does the method fail when the external shadow covers most of the face? There is no section on potential negative societal impact, although there are certainly some potential concerns with face reconstruction methods, as with any face modeling work. The potential to edit the face and produce fake content is always present.",['No ethics review needed.'],6,4,,Yes,3,2,3,1720767574204,,,NeurIPS.cc/2024/Conference,3lic0JgPRZ,"['NeurIPS.cc/2024/Conference/Submission2540/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878783769,[],3,,,['everyone'],3lic0JgPRZ,['NeurIPS.cc/2024/Conference/Submission2540/Reviewer_SyuP'],1720767574204,1730878783769,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2540/Reviewer_SyuP']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature in the face relighting and portrait shadow removal domains. The reviewer mentions several papers that are relevant to the work and should be cited and discussed, including:

1. SfSNet : Learning Shape, Reflectance and Illuminance of Faces in the Wild (CVPR 2018)
2. Face Relighting with Geometrically Consistent Shadows (CVPR 2022)
3. Learning Physics-guided Face Relighting under Directional Light (CVPR 2020)
4. Portrait Shadow Manipulation (SIGGRAPH 2020)
5. Unsupervised Portrait Shadow Removal via Generative Priors (MM 2021)
6. Blind Removal of Facial Foreign Shadows (BMVC 2022)

The reviewer also suggests that the authors should verify that their method outperforms the simple baseline of running a foreign shadow removal method on the images beforehand, using methods such as those mentioned above.",1,"2018, 2022, 2020, 2020, 2021, 2022",Face Relighting with Geometrically Consistent Shadows 
t0m25FL1fY,"This work tackles the problem of external shadows in single image face reconstruction. Specifically, when the input image contains foreign shadows, this often affects the quality of the estimated facial texture, as the external shadows often become baked into the texture or leave behind undesirable artifacts in the shadow region. The paper proposes a comprehensive solution to this problem, including a way to decouple the face image into the result of multiple lights as well as an Adaptive Condition Estimation (ACE) strategy to select which lights are present in the image. The paper further proposes multiple human face priors, such as a global prior to ensure the face texture hue is consistent with the initialization from a 3DMM model and a local prior to ensure that the smoothness of the face texture is similar to the initialization. Experiments demonstrate that the method is able to improve rendering performance on in-the-wild face images by rendering both source images with external shadows and target images without external shadows. The major improvements on target images without external shadows shows that the method is able to produce accurate facial textures that are minimally impacted by the presence of these shadows. Qualitative ablations are also provided to further aid in evaluating the method.","The improvement in rendering performance on target images (w/o external shadows) clearly shows that the method is able to minimize the impact of external shadows from the source image. The qualitative results further support this conclusion, as the facial textures do not contain external shadow artifacts. 

Qualitative ablations are available to help assess the impact of each technical contribution in this work. 

This work is sufficiently novel since it enables more accurate face reconstruction under the condition of external occlusions from the source image, which is a heavily understudied problem. It also goes beyond traditional work in this area since it considers the scenario that there could be more than one light in the image and proposes a method to estimate the set of lights illuminating the face.","For the ablation studies, it would be much more convincing to have tables with quantitative results demonstrating the margin of improvement of each component. Simply picking a few favorable qualitative examples is easy and not convincing. 

In almost all examples in this work, the foreign (external) shadows involved are caused by hats. What about other types of foreign shadows caused by tree leaves, pens, paper, hands, etc? How are the resulting face textures in these situations? It would be nice to compare with the baselines on some images with more diverse foreign shadows. If it is difficult to find such images in the wild, you can find a small test set of 100 or so images from the paper ""Portrait Shadow Manipulation (SIGGRAPH 2020)"" with diverse foreign shadow shapes. 

Some important citations are missing from this work, especially in the face relighting and portrait shadow removal domains. There are several face relighting methods that involve intrinsic decomposition of faces and illumination modeling, some of which involve ray tracing to handle self shadows: 

1. SfSNet : Learning Shape, Reflectance and Illuminance of Faces in the Wild (CVPR 2018)
2. Face Relighting with Geometrically Consistent Shadows (CVPR 2022)
3. Learning Physics-guided Face Relighting under Directional Light (CVPR 2020)

In addition, the shadow removal domain is highly relevant to this work since a simple solution to this problem would be to perform a preprocessing step to remove the foreign (external) shadows from the image first using a portrait shadow removal method before performing face reconstruction. These methods should be cited and discussed in the paper and the authors should verify that their method outperforms this simple baseline: 

1. Portrait Shadow Manipulation (SIGGRAPH 2020)
2. Unsupervised Portrait Shadow Removal via Generative Priors (MM 2021)
3. Blind Removal of Facial Foreign Shadows (BMVC 2022)","Please see the experiments I suggested above, especially with regard to quantitative evaluations for ablations, evaluations on images with more diverse foreign (external) shadows, and comparing with the simple baseline of running a foreign shadow removal method on the images beforehand. I will be carefully reviewing the rebuttal as well as the opinions of the other reviewers to decide if I would like to change my rating. Please also factor in missing citations, as the two areas I mentioned are very relevant to this work.","The authors have at least made an attempt to include a limitations section, although more analysis on failure cases would be helpful. For example, does the method fail when the external shadow covers most of the face? There is no section on potential negative societal impact, although there are certainly some potential concerns with face reconstruction methods, as with any face modeling work. The potential to edit the face and produce fake content is always present.",['No ethics review needed.'],6,4,,Yes,3,2,3,1720767574204,,,NeurIPS.cc/2024/Conference,3lic0JgPRZ,"['NeurIPS.cc/2024/Conference/Submission2540/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878783769,[],3,,,['everyone'],3lic0JgPRZ,['NeurIPS.cc/2024/Conference/Submission2540/Reviewer_SyuP'],1720767574204,1730878783769,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2540/Reviewer_SyuP']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature in the face relighting and portrait shadow removal domains. The reviewer mentions several papers that are relevant to the work and should be cited and discussed, including:

1. SfSNet : Learning Shape, Reflectance and Illuminance of Faces in the Wild (CVPR 2018)
2. Face Relighting with Geometrically Consistent Shadows (CVPR 2022)
3. Learning Physics-guided Face Relighting under Directional Light (CVPR 2020)
4. Portrait Shadow Manipulation (SIGGRAPH 2020)
5. Unsupervised Portrait Shadow Removal via Generative Priors (MM 2021)
6. Blind Removal of Facial Foreign Shadows (BMVC 2022)

The reviewer also suggests that the authors should verify that their method outperforms the simple baseline of running a foreign shadow removal method on the images beforehand, using methods such as those mentioned above.",1,"2018, 2022, 2020, 2020, 2021, 2022",Learning Physics-guided Face Relighting under Directional Light 
t0m25FL1fY,"This work tackles the problem of external shadows in single image face reconstruction. Specifically, when the input image contains foreign shadows, this often affects the quality of the estimated facial texture, as the external shadows often become baked into the texture or leave behind undesirable artifacts in the shadow region. The paper proposes a comprehensive solution to this problem, including a way to decouple the face image into the result of multiple lights as well as an Adaptive Condition Estimation (ACE) strategy to select which lights are present in the image. The paper further proposes multiple human face priors, such as a global prior to ensure the face texture hue is consistent with the initialization from a 3DMM model and a local prior to ensure that the smoothness of the face texture is similar to the initialization. Experiments demonstrate that the method is able to improve rendering performance on in-the-wild face images by rendering both source images with external shadows and target images without external shadows. The major improvements on target images without external shadows shows that the method is able to produce accurate facial textures that are minimally impacted by the presence of these shadows. Qualitative ablations are also provided to further aid in evaluating the method.","The improvement in rendering performance on target images (w/o external shadows) clearly shows that the method is able to minimize the impact of external shadows from the source image. The qualitative results further support this conclusion, as the facial textures do not contain external shadow artifacts. 

Qualitative ablations are available to help assess the impact of each technical contribution in this work. 

This work is sufficiently novel since it enables more accurate face reconstruction under the condition of external occlusions from the source image, which is a heavily understudied problem. It also goes beyond traditional work in this area since it considers the scenario that there could be more than one light in the image and proposes a method to estimate the set of lights illuminating the face.","For the ablation studies, it would be much more convincing to have tables with quantitative results demonstrating the margin of improvement of each component. Simply picking a few favorable qualitative examples is easy and not convincing. 

In almost all examples in this work, the foreign (external) shadows involved are caused by hats. What about other types of foreign shadows caused by tree leaves, pens, paper, hands, etc? How are the resulting face textures in these situations? It would be nice to compare with the baselines on some images with more diverse foreign shadows. If it is difficult to find such images in the wild, you can find a small test set of 100 or so images from the paper ""Portrait Shadow Manipulation (SIGGRAPH 2020)"" with diverse foreign shadow shapes. 

Some important citations are missing from this work, especially in the face relighting and portrait shadow removal domains. There are several face relighting methods that involve intrinsic decomposition of faces and illumination modeling, some of which involve ray tracing to handle self shadows: 

1. SfSNet : Learning Shape, Reflectance and Illuminance of Faces in the Wild (CVPR 2018)
2. Face Relighting with Geometrically Consistent Shadows (CVPR 2022)
3. Learning Physics-guided Face Relighting under Directional Light (CVPR 2020)

In addition, the shadow removal domain is highly relevant to this work since a simple solution to this problem would be to perform a preprocessing step to remove the foreign (external) shadows from the image first using a portrait shadow removal method before performing face reconstruction. These methods should be cited and discussed in the paper and the authors should verify that their method outperforms this simple baseline: 

1. Portrait Shadow Manipulation (SIGGRAPH 2020)
2. Unsupervised Portrait Shadow Removal via Generative Priors (MM 2021)
3. Blind Removal of Facial Foreign Shadows (BMVC 2022)","Please see the experiments I suggested above, especially with regard to quantitative evaluations for ablations, evaluations on images with more diverse foreign (external) shadows, and comparing with the simple baseline of running a foreign shadow removal method on the images beforehand. I will be carefully reviewing the rebuttal as well as the opinions of the other reviewers to decide if I would like to change my rating. Please also factor in missing citations, as the two areas I mentioned are very relevant to this work.","The authors have at least made an attempt to include a limitations section, although more analysis on failure cases would be helpful. For example, does the method fail when the external shadow covers most of the face? There is no section on potential negative societal impact, although there are certainly some potential concerns with face reconstruction methods, as with any face modeling work. The potential to edit the face and produce fake content is always present.",['No ethics review needed.'],6,4,,Yes,3,2,3,1720767574204,,,NeurIPS.cc/2024/Conference,3lic0JgPRZ,"['NeurIPS.cc/2024/Conference/Submission2540/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878783769,[],3,,,['everyone'],3lic0JgPRZ,['NeurIPS.cc/2024/Conference/Submission2540/Reviewer_SyuP'],1720767574204,1730878783769,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2540/Reviewer_SyuP']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature in the face relighting and portrait shadow removal domains. The reviewer mentions several papers that are relevant to the work and should be cited and discussed, including:

1. SfSNet : Learning Shape, Reflectance and Illuminance of Faces in the Wild (CVPR 2018)
2. Face Relighting with Geometrically Consistent Shadows (CVPR 2022)
3. Learning Physics-guided Face Relighting under Directional Light (CVPR 2020)
4. Portrait Shadow Manipulation (SIGGRAPH 2020)
5. Unsupervised Portrait Shadow Removal via Generative Priors (MM 2021)
6. Blind Removal of Facial Foreign Shadows (BMVC 2022)

The reviewer also suggests that the authors should verify that their method outperforms the simple baseline of running a foreign shadow removal method on the images beforehand, using methods such as those mentioned above.",1,"2018, 2022, 2020, 2020, 2021, 2022",Portrait Shadow Manipulation 
t0m25FL1fY,"This work tackles the problem of external shadows in single image face reconstruction. Specifically, when the input image contains foreign shadows, this often affects the quality of the estimated facial texture, as the external shadows often become baked into the texture or leave behind undesirable artifacts in the shadow region. The paper proposes a comprehensive solution to this problem, including a way to decouple the face image into the result of multiple lights as well as an Adaptive Condition Estimation (ACE) strategy to select which lights are present in the image. The paper further proposes multiple human face priors, such as a global prior to ensure the face texture hue is consistent with the initialization from a 3DMM model and a local prior to ensure that the smoothness of the face texture is similar to the initialization. Experiments demonstrate that the method is able to improve rendering performance on in-the-wild face images by rendering both source images with external shadows and target images without external shadows. The major improvements on target images without external shadows shows that the method is able to produce accurate facial textures that are minimally impacted by the presence of these shadows. Qualitative ablations are also provided to further aid in evaluating the method.","The improvement in rendering performance on target images (w/o external shadows) clearly shows that the method is able to minimize the impact of external shadows from the source image. The qualitative results further support this conclusion, as the facial textures do not contain external shadow artifacts. 

Qualitative ablations are available to help assess the impact of each technical contribution in this work. 

This work is sufficiently novel since it enables more accurate face reconstruction under the condition of external occlusions from the source image, which is a heavily understudied problem. It also goes beyond traditional work in this area since it considers the scenario that there could be more than one light in the image and proposes a method to estimate the set of lights illuminating the face.","For the ablation studies, it would be much more convincing to have tables with quantitative results demonstrating the margin of improvement of each component. Simply picking a few favorable qualitative examples is easy and not convincing. 

In almost all examples in this work, the foreign (external) shadows involved are caused by hats. What about other types of foreign shadows caused by tree leaves, pens, paper, hands, etc? How are the resulting face textures in these situations? It would be nice to compare with the baselines on some images with more diverse foreign shadows. If it is difficult to find such images in the wild, you can find a small test set of 100 or so images from the paper ""Portrait Shadow Manipulation (SIGGRAPH 2020)"" with diverse foreign shadow shapes. 

Some important citations are missing from this work, especially in the face relighting and portrait shadow removal domains. There are several face relighting methods that involve intrinsic decomposition of faces and illumination modeling, some of which involve ray tracing to handle self shadows: 

1. SfSNet : Learning Shape, Reflectance and Illuminance of Faces in the Wild (CVPR 2018)
2. Face Relighting with Geometrically Consistent Shadows (CVPR 2022)
3. Learning Physics-guided Face Relighting under Directional Light (CVPR 2020)

In addition, the shadow removal domain is highly relevant to this work since a simple solution to this problem would be to perform a preprocessing step to remove the foreign (external) shadows from the image first using a portrait shadow removal method before performing face reconstruction. These methods should be cited and discussed in the paper and the authors should verify that their method outperforms this simple baseline: 

1. Portrait Shadow Manipulation (SIGGRAPH 2020)
2. Unsupervised Portrait Shadow Removal via Generative Priors (MM 2021)
3. Blind Removal of Facial Foreign Shadows (BMVC 2022)","Please see the experiments I suggested above, especially with regard to quantitative evaluations for ablations, evaluations on images with more diverse foreign (external) shadows, and comparing with the simple baseline of running a foreign shadow removal method on the images beforehand. I will be carefully reviewing the rebuttal as well as the opinions of the other reviewers to decide if I would like to change my rating. Please also factor in missing citations, as the two areas I mentioned are very relevant to this work.","The authors have at least made an attempt to include a limitations section, although more analysis on failure cases would be helpful. For example, does the method fail when the external shadow covers most of the face? There is no section on potential negative societal impact, although there are certainly some potential concerns with face reconstruction methods, as with any face modeling work. The potential to edit the face and produce fake content is always present.",['No ethics review needed.'],6,4,,Yes,3,2,3,1720767574204,,,NeurIPS.cc/2024/Conference,3lic0JgPRZ,"['NeurIPS.cc/2024/Conference/Submission2540/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878783769,[],3,,,['everyone'],3lic0JgPRZ,['NeurIPS.cc/2024/Conference/Submission2540/Reviewer_SyuP'],1720767574204,1730878783769,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2540/Reviewer_SyuP']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature in the face relighting and portrait shadow removal domains. The reviewer mentions several papers that are relevant to the work and should be cited and discussed, including:

1. SfSNet : Learning Shape, Reflectance and Illuminance of Faces in the Wild (CVPR 2018)
2. Face Relighting with Geometrically Consistent Shadows (CVPR 2022)
3. Learning Physics-guided Face Relighting under Directional Light (CVPR 2020)
4. Portrait Shadow Manipulation (SIGGRAPH 2020)
5. Unsupervised Portrait Shadow Removal via Generative Priors (MM 2021)
6. Blind Removal of Facial Foreign Shadows (BMVC 2022)

The reviewer also suggests that the authors should verify that their method outperforms the simple baseline of running a foreign shadow removal method on the images beforehand, using methods such as those mentioned above.",1,"2018, 2022, 2020, 2020, 2021, 2022",Unsupervised Portrait Shadow Removal via Generative Priors 
t0m25FL1fY,"This work tackles the problem of external shadows in single image face reconstruction. Specifically, when the input image contains foreign shadows, this often affects the quality of the estimated facial texture, as the external shadows often become baked into the texture or leave behind undesirable artifacts in the shadow region. The paper proposes a comprehensive solution to this problem, including a way to decouple the face image into the result of multiple lights as well as an Adaptive Condition Estimation (ACE) strategy to select which lights are present in the image. The paper further proposes multiple human face priors, such as a global prior to ensure the face texture hue is consistent with the initialization from a 3DMM model and a local prior to ensure that the smoothness of the face texture is similar to the initialization. Experiments demonstrate that the method is able to improve rendering performance on in-the-wild face images by rendering both source images with external shadows and target images without external shadows. The major improvements on target images without external shadows shows that the method is able to produce accurate facial textures that are minimally impacted by the presence of these shadows. Qualitative ablations are also provided to further aid in evaluating the method.","The improvement in rendering performance on target images (w/o external shadows) clearly shows that the method is able to minimize the impact of external shadows from the source image. The qualitative results further support this conclusion, as the facial textures do not contain external shadow artifacts. 

Qualitative ablations are available to help assess the impact of each technical contribution in this work. 

This work is sufficiently novel since it enables more accurate face reconstruction under the condition of external occlusions from the source image, which is a heavily understudied problem. It also goes beyond traditional work in this area since it considers the scenario that there could be more than one light in the image and proposes a method to estimate the set of lights illuminating the face.","For the ablation studies, it would be much more convincing to have tables with quantitative results demonstrating the margin of improvement of each component. Simply picking a few favorable qualitative examples is easy and not convincing. 

In almost all examples in this work, the foreign (external) shadows involved are caused by hats. What about other types of foreign shadows caused by tree leaves, pens, paper, hands, etc? How are the resulting face textures in these situations? It would be nice to compare with the baselines on some images with more diverse foreign shadows. If it is difficult to find such images in the wild, you can find a small test set of 100 or so images from the paper ""Portrait Shadow Manipulation (SIGGRAPH 2020)"" with diverse foreign shadow shapes. 

Some important citations are missing from this work, especially in the face relighting and portrait shadow removal domains. There are several face relighting methods that involve intrinsic decomposition of faces and illumination modeling, some of which involve ray tracing to handle self shadows: 

1. SfSNet : Learning Shape, Reflectance and Illuminance of Faces in the Wild (CVPR 2018)
2. Face Relighting with Geometrically Consistent Shadows (CVPR 2022)
3. Learning Physics-guided Face Relighting under Directional Light (CVPR 2020)

In addition, the shadow removal domain is highly relevant to this work since a simple solution to this problem would be to perform a preprocessing step to remove the foreign (external) shadows from the image first using a portrait shadow removal method before performing face reconstruction. These methods should be cited and discussed in the paper and the authors should verify that their method outperforms this simple baseline: 

1. Portrait Shadow Manipulation (SIGGRAPH 2020)
2. Unsupervised Portrait Shadow Removal via Generative Priors (MM 2021)
3. Blind Removal of Facial Foreign Shadows (BMVC 2022)","Please see the experiments I suggested above, especially with regard to quantitative evaluations for ablations, evaluations on images with more diverse foreign (external) shadows, and comparing with the simple baseline of running a foreign shadow removal method on the images beforehand. I will be carefully reviewing the rebuttal as well as the opinions of the other reviewers to decide if I would like to change my rating. Please also factor in missing citations, as the two areas I mentioned are very relevant to this work.","The authors have at least made an attempt to include a limitations section, although more analysis on failure cases would be helpful. For example, does the method fail when the external shadow covers most of the face? There is no section on potential negative societal impact, although there are certainly some potential concerns with face reconstruction methods, as with any face modeling work. The potential to edit the face and produce fake content is always present.",['No ethics review needed.'],6,4,,Yes,3,2,3,1720767574204,,,NeurIPS.cc/2024/Conference,3lic0JgPRZ,"['NeurIPS.cc/2024/Conference/Submission2540/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878783769,[],3,,,['everyone'],3lic0JgPRZ,['NeurIPS.cc/2024/Conference/Submission2540/Reviewer_SyuP'],1720767574204,1730878783769,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2540/Reviewer_SyuP']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature in the face relighting and portrait shadow removal domains. The reviewer mentions several papers that are relevant to the work and should be cited and discussed, including:

1. SfSNet : Learning Shape, Reflectance and Illuminance of Faces in the Wild (CVPR 2018)
2. Face Relighting with Geometrically Consistent Shadows (CVPR 2022)
3. Learning Physics-guided Face Relighting under Directional Light (CVPR 2020)
4. Portrait Shadow Manipulation (SIGGRAPH 2020)
5. Unsupervised Portrait Shadow Removal via Generative Priors (MM 2021)
6. Blind Removal of Facial Foreign Shadows (BMVC 2022)

The reviewer also suggests that the authors should verify that their method outperforms the simple baseline of running a foreign shadow removal method on the images beforehand, using methods such as those mentioned above.",1,"2018, 2022, 2020, 2020, 2021, 2022",Blind Removal of Facial Foreign Shadows
H4Ugo8C1QI,"The paper presents a method for reconstructing 3D face textures from monocular images in the presence of occlusions, both self-occlusions and occlusions by other scene elements such as hats. The paper identifies a key limitation in existing works -- they all get impacted by the lighting changes introduced by an occluder, as they assume globally consistent lighting. The paper proposes to model the scene using a combination of different lighting for the different regions of the face. The different regions are reconstructed without direct supervision. Additionally, a mask is used to separate out the occluder pixels. Modeling multiple light sources enables the method to model appearance effects due to occluders and thus enables higher quality reconstructions than the state of the art.","The paper is very well motivated. It identifies a key problem and motivates the solution very well. 
The method is novel and simple. 
The results are impressive and outperform the chosen baselines. The reconstructed masks fit very well to the shadow boundaries","The main weakness is the lack of discussion and comparisons with existing works, and the lack of stronger baselines. 

The paper does not mention existing research on dealing with occlusions. Here are a couple:
- Robust Model-based Face Reconstruction through Weakly-Supervised Outlier Segmentation [CVPR23]
- Occlusion-aware 3D Morphable Models and an Illumination Prior for Face Image Analysis [IJCV18]
Both these papers jointly perform 3D reconstruction and solve for occluders. They might not use texture optimization and instead perform per-vertex color optimization, but their techniques should be trivially extended for texture optimization. Comparisons to these baselines makes it impossible to evaluate this submission. 

In addition, there are other strong baselines that were not considered. Generative models, such as those introduced by ""Face De-occlusion using 3D Morphable Model and Generative Adversarial Network"" [ICCV19] can remove occlusions from portrait images. Can the output of those methods directly be used with NextFace for high-quality reconstructions? 

The other weakness relates to the exposition. The technical details of the paper were not easy to read. I did not understand how many number of masks are used, what 't' refers to in L128, how many such 't' are used. How are all the hyperparameters, such as 'n', n_L', m, epsilon, etc., chosen? I did not find a discussion. The paper is not reproducible in its current state.",Please refer to weaknesses.,Yes,['No ethics review needed.'],6,4,,Yes,2,2,3,1721020943856,,,NeurIPS.cc/2024/Conference,3lic0JgPRZ,"['NeurIPS.cc/2024/Conference/Submission2540/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878783628,[],4,,,['everyone'],3lic0JgPRZ,['NeurIPS.cc/2024/Conference/Submission2540/Reviewer_WqKW'],1721020943856,1730878783628,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2540/Reviewer_WqKW']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. ""Robust Model-based Face Reconstruction through Weakly-Supervised Outlier Segmentation"" [CVPR23]
2. ""Occlusion-aware 3D Morphable Models and an Illumination Prior for Face Image Analysis"" [IJCV18]
3. ""Face De-occlusion using 3D Morphable Model and Generative Adversarial Network"" [ICCV19]

The reviewer mentions that comparing the proposed method to these baselines is necessary to evaluate the submission, implying that the authors should cite and discuss these works in their paper.",1,,Robust Model-based Face Reconstruction through Weakly-Supervised Outlier Segmentation 
H4Ugo8C1QI,"The paper presents a method for reconstructing 3D face textures from monocular images in the presence of occlusions, both self-occlusions and occlusions by other scene elements such as hats. The paper identifies a key limitation in existing works -- they all get impacted by the lighting changes introduced by an occluder, as they assume globally consistent lighting. The paper proposes to model the scene using a combination of different lighting for the different regions of the face. The different regions are reconstructed without direct supervision. Additionally, a mask is used to separate out the occluder pixels. Modeling multiple light sources enables the method to model appearance effects due to occluders and thus enables higher quality reconstructions than the state of the art.","The paper is very well motivated. It identifies a key problem and motivates the solution very well. 
The method is novel and simple. 
The results are impressive and outperform the chosen baselines. The reconstructed masks fit very well to the shadow boundaries","The main weakness is the lack of discussion and comparisons with existing works, and the lack of stronger baselines. 

The paper does not mention existing research on dealing with occlusions. Here are a couple:
- Robust Model-based Face Reconstruction through Weakly-Supervised Outlier Segmentation [CVPR23]
- Occlusion-aware 3D Morphable Models and an Illumination Prior for Face Image Analysis [IJCV18]
Both these papers jointly perform 3D reconstruction and solve for occluders. They might not use texture optimization and instead perform per-vertex color optimization, but their techniques should be trivially extended for texture optimization. Comparisons to these baselines makes it impossible to evaluate this submission. 

In addition, there are other strong baselines that were not considered. Generative models, such as those introduced by ""Face De-occlusion using 3D Morphable Model and Generative Adversarial Network"" [ICCV19] can remove occlusions from portrait images. Can the output of those methods directly be used with NextFace for high-quality reconstructions? 

The other weakness relates to the exposition. The technical details of the paper were not easy to read. I did not understand how many number of masks are used, what 't' refers to in L128, how many such 't' are used. How are all the hyperparameters, such as 'n', n_L', m, epsilon, etc., chosen? I did not find a discussion. The paper is not reproducible in its current state.",Please refer to weaknesses.,Yes,['No ethics review needed.'],6,4,,Yes,2,2,3,1721020943856,,,NeurIPS.cc/2024/Conference,3lic0JgPRZ,"['NeurIPS.cc/2024/Conference/Submission2540/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878783628,[],4,,,['everyone'],3lic0JgPRZ,['NeurIPS.cc/2024/Conference/Submission2540/Reviewer_WqKW'],1721020943856,1730878783628,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2540/Reviewer_WqKW']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. ""Robust Model-based Face Reconstruction through Weakly-Supervised Outlier Segmentation"" [CVPR23]
2. ""Occlusion-aware 3D Morphable Models and an Illumination Prior for Face Image Analysis"" [IJCV18]
3. ""Face De-occlusion using 3D Morphable Model and Generative Adversarial Network"" [ICCV19]

The reviewer mentions that comparing the proposed method to these baselines is necessary to evaluate the submission, implying that the authors should cite and discuss these works in their paper.",1,,Occlusion-aware 3D Morphable Models and an Illumination Prior for Face Image Analysis 
H4Ugo8C1QI,"The paper presents a method for reconstructing 3D face textures from monocular images in the presence of occlusions, both self-occlusions and occlusions by other scene elements such as hats. The paper identifies a key limitation in existing works -- they all get impacted by the lighting changes introduced by an occluder, as they assume globally consistent lighting. The paper proposes to model the scene using a combination of different lighting for the different regions of the face. The different regions are reconstructed without direct supervision. Additionally, a mask is used to separate out the occluder pixels. Modeling multiple light sources enables the method to model appearance effects due to occluders and thus enables higher quality reconstructions than the state of the art.","The paper is very well motivated. It identifies a key problem and motivates the solution very well. 
The method is novel and simple. 
The results are impressive and outperform the chosen baselines. The reconstructed masks fit very well to the shadow boundaries","The main weakness is the lack of discussion and comparisons with existing works, and the lack of stronger baselines. 

The paper does not mention existing research on dealing with occlusions. Here are a couple:
- Robust Model-based Face Reconstruction through Weakly-Supervised Outlier Segmentation [CVPR23]
- Occlusion-aware 3D Morphable Models and an Illumination Prior for Face Image Analysis [IJCV18]
Both these papers jointly perform 3D reconstruction and solve for occluders. They might not use texture optimization and instead perform per-vertex color optimization, but their techniques should be trivially extended for texture optimization. Comparisons to these baselines makes it impossible to evaluate this submission. 

In addition, there are other strong baselines that were not considered. Generative models, such as those introduced by ""Face De-occlusion using 3D Morphable Model and Generative Adversarial Network"" [ICCV19] can remove occlusions from portrait images. Can the output of those methods directly be used with NextFace for high-quality reconstructions? 

The other weakness relates to the exposition. The technical details of the paper were not easy to read. I did not understand how many number of masks are used, what 't' refers to in L128, how many such 't' are used. How are all the hyperparameters, such as 'n', n_L', m, epsilon, etc., chosen? I did not find a discussion. The paper is not reproducible in its current state.",Please refer to weaknesses.,Yes,['No ethics review needed.'],6,4,,Yes,2,2,3,1721020943856,,,NeurIPS.cc/2024/Conference,3lic0JgPRZ,"['NeurIPS.cc/2024/Conference/Submission2540/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878783628,[],4,,,['everyone'],3lic0JgPRZ,['NeurIPS.cc/2024/Conference/Submission2540/Reviewer_WqKW'],1721020943856,1730878783628,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2540/Reviewer_WqKW']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. ""Robust Model-based Face Reconstruction through Weakly-Supervised Outlier Segmentation"" [CVPR23]
2. ""Occlusion-aware 3D Morphable Models and an Illumination Prior for Face Image Analysis"" [IJCV18]
3. ""Face De-occlusion using 3D Morphable Model and Generative Adversarial Network"" [ICCV19]

The reviewer mentions that comparing the proposed method to these baselines is necessary to evaluate the submission, implying that the authors should cite and discuss these works in their paper.",1,,Face De-occlusion using 3D Morphable Model and Generative Adversarial Network
kTWEZRNdSh,"The paper explores RL in Infinite-horizon Ergodic Average-reward constrained 
MDPs under general policy parametrization. In this setting, the authors propose 
a primal-dual based policy gradient algorithm that simultaneously optimizes the 
policy parameter and a constraint violation penalty term $\lambda$. They also 
equip their method with techniques to address challenges due to the 
average-reward MDP setup, constraints on the MDP and general policy 
parametrization. They prove global convergence of their resulting method in 
terms of the Lagrange function and from this derive bounds on the expected 
regret as well as constraint violation. Furthermore, when the policy class is expressive enough to approximately contain an optimal policy of the constrained MDP so that the un-expressivity parameter $\varepsilon_{bias}$ is zero or negligibly small, the authors prove that the 
expected average regret and constraint violation of their method decreases at a rate of $O(T^{-1/5})$.","1. The authors consider the task of reinforcement learning 
	in average-reward constrained MDPs and propose novel techniques to address 
	underlying challenges.
2. This is a complete piece of work that explores provably 
	efficient RL in average reward constrained MDPs. Their claims are backed by 
	theoretical analysis, and they highlight the strength as well as weaknesses 
	of their work.
3. This submission is clearly written. The authors highlight 
	the required assumptions and adequately discuss the nature of most relevant 
	parameters.
4. This work significantly contributes to existing theory 
	on reinforcement learning when it is more desirable to optimize the average 
	return, rather than the typical discounted return, and in addition to 
	return optimization, the policy is required to adequately adhere to 
	additional constraints on the MDP.",See questions.,"1. In Lines 243-246, the authors claim that there are scenarios under 
	which the un-expressivity parameter $\varepsilon_{bias}$ is zero or 
	negligible. I could reason about this claim when $\pi^{\*}$ is an optimal 
	policy in the unconstrained MDP, but unsure that the same holds when 
	$\pi^{*}$ is an optimal policy in the constrained MDP (see Line 240). Can 
	the authors kindly provide exact pointers in the referenced 
	papers that verify this claim, or a proof in the appendix?

2. In Lines 323 and 324, the authors claim that the primal-dual approach to policy optimization
	is known to give worse results than in the unconstrained version, even for 
	the discounted setting. Could this be related to the fact that the method is policy, rather than value based? In the offline setting, [1] takes a value-based primal-dual approach and their result implicitly highlights that the constrained setting may not be worse off than the unconstrained setting.

3. Can the authors kindly elaborate on the bias of single 
	trajectory-based estimations in this setting? Reference [13] in the paper seems to 
	achieve better performance even with this biased estimation strategy.

4.  How strong is Assumption 5?

[1] Hong, K., \& Tewari, A. (2024). A Primal-Dual Algorithm for Offline 
Constrained Reinforcement Learning with Low-Rank MDPs. arXiv preprint 
arXiv:2402.04493.

**Comments**
1. Line 265 makes reference to equation 21 twice rather than the 
	expressions after lines 263 and 264.
2. Expectation is sometimes expressed without the parenthesis. For 
	example, see Equations 20, 22, as well as Lines 265, 266 e.t.c.",None. This is a purely theory paper.,['No ethics review needed.'],7,3,,Yes,3,3,3,1720781955618,,,NeurIPS.cc/2024/Conference,3lQgEPRxeu,"['NeurIPS.cc/2024/Conference/Submission6623/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879094255,[],1,,,['everyone'],3lQgEPRxeu,['NeurIPS.cc/2024/Conference/Submission6623/Reviewer_UyCM'],1720781955618,1730879094255,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission6623/Reviewer_UyCM']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

Hong, K., & Tewari, A. (2024). A Primal-Dual Algorithm for Offline Constrained Reinforcement Learning with Low-Rank MDPs. arXiv preprint arXiv:2402.04493.

This is mentioned in question 2 of the peer review, where the reviewer is asking the authors to consider the difference between policy-based and value-based primal-dual approaches, and references the aforementioned paper as an example of a value-based approach.",1,"2024, 2024",A Primal-Dual Algorithm for Offline Constrained Reinforcement Learning with Low-Rank MDPs
bgKk789MDg,This paper tackles the infinite horizon average reward Constrained MDP setting and proposes an analysis of regret and constraint violation under a general policy parametrization. They devise a primal-dual policy gradient algorithm achieving global optimality while ensuring sublinear bounds on the regret and constraint violation.,"The paper is interesting and well-written and places itself well in the related literature by filling the gap about infinite horizon average reward constraint MDPs under general parametrized policies. 
They employ similar techniques that can be found in the related unconstrained setting but also highlight and overcome the challenges encountered while facing the constrained and average reward setting. In particular, they take inspiration from already existing techniques developed for the discounted setting and adapt them to cope with the average reward MDP.","From the theoretical perspective, I do not recognize specific weaknesses. 

However, I would like to highlight that the authors assume the knowledge of the mixing and hitting time of the MDP. I recognize that this is a standard assumption in this type of work, however, I wonder if they are necessary to achieve these results or if the authors are aware of similar techniques that can provide sublinear guarantees without this knowledge. Recently, the work of [1] highlighted some techniques that allow achieving global convergence results without this knowledge. Would it be possible to apply these techniques to this setting as well?

From the simulation perspective, I believe that some experimental results showing the validity of the presented approach may be beneficial for the presented work.



[1] Patel B. et al., Towards Global Optimality for Practical Average Reward Reinforcement Learning without Mixing Time Oracles, ICML 2024.",See the weakness section.,,['No ethics review needed.'],6,2,,Yes,3,3,3,1720789606644,,,NeurIPS.cc/2024/Conference,3lQgEPRxeu,"['NeurIPS.cc/2024/Conference/Submission6623/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879094117,[],2,,,['everyone'],3lQgEPRxeu,['NeurIPS.cc/2024/Conference/Submission6623/Reviewer_waAx'],1720789606644,1730879094117,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission6623/Reviewer_waAx']","Yes, the peer review explicitly suggests the authors of the paper to consider citing the work of Patel B. et al., ""Towards Global Optimality for Practical Average Reward Reinforcement Learning without Mixing Time Oracles"", ICML 2024, as it may be relevant to their research and could potentially provide an alternative approach to achieving sublinear guarantees without the need for knowledge of the mixing and hitting time of the MDP.",1,2024,Towards Global Optimality for Practical Average Reward Reinforcement Learning without Mixing Time Oracles
dZVNEgrxB1,"This work addresses the sensitivity of expectation propagation (EP) to the randomness of Monte Carlo (MC) estimates involved in its update steps. It tackles this issue by recasting the moment matching step in EP as natural gradient descent (NGD) in the mean space of an exponential family distribution. The author identifies that the instability of EP to MC noise is due to the nonlinearity of the mirror map defined by the log partition function of the exponential family. By cleverly moving the NGD from the mean space to the natural parameter space, this issue is bypassed.
The author also studies the influence of the stepsize on the accumulation of MC error, finding that decreasing the stepsize of the NGD updates helps to reduce the bias.","- This is a well-written work. It starts with a succinct overview of the expectation propagation (EP) algorithm and summarizes several variants of EP updates in a unified manner (in Algorithm 1). This review also makes the contribution of this work very clear. It provides a sufficient discussion on why EP is sensitive to stochasticity and clearly motivates the design of the methodology. I also appreciate the self-contained review of the exponential family, natural gradient descent, and detailed derivation of EP updates provided in the appendix. Although these materials are standard, they help to make the work more accessible to a general audience.

- The feasibility of performing unbiased NGD updates in the natural space of $\tilde p_i$ (Prop1) is a smart observation, and this simple modification makes the inner loop significantly more robust to the stochasticity in MC est. This simple modification (from mean space to natural parameter space) makes the inner loop significantly more robust to the stochasticity in Monte Carlo estimation. I'm indeed impressed that EP can work with single-sample estimation in the inner loop.

- I also appreciate the rigorous investigation of the effect of $\alpha$ and $\epsilon$ to the bias of estimated mean parmaeter.

- The empirical performance of proposed methods are superior; it outperforms the standard EP by a significant margin (as shown in Fig2).","The technical side of this work is very strong in my perspective, and I don't observe many weakness on this regard. 
However, I think the novelty of this NGD perspective is overclaimed. To my knowledge, the relationship between moment matching in the exponential family and NGD is very well known (e.g., [1][2][3]). Once it is identified that $\tidle p_i$ is in the exponential family, the derivation of NGD (in either mean space Prop1 or natural parameter space) becomes quite straightforward. I hope the authors can elaborate on this point, and include discussion on some relavant literature arolund prop 1.

I believe the real contribution of this work lies in the rigorous understanding of the influence of the stepsize on the accumulation of Monte Carlo (MC) error and the identification of the nonlinearity of the mirror map that leads to this error accumulation, which is already impactful to me.




- [1]: Conjugate-Computation Variational Inference : Converting Variational Inference in Non-Conjugate Models to Inferences in Conjugate Models, 2018
- [2]: MCMC-driven learning, 2024
- [3]: Distributed Bayesian Learning with Stochastic Natural Gradient Expectation Propagation and the Posterior Server","- How do you estimate the KL divergence in the experiments? Maybe I'm missing something, but the target posterior is only known up to a constant, so unbiased KL est is not feasible?

- I'm curious to see the relative performance of this work to NGVI [1] (specified in the Weakness section).",The limitation is well discussed.,['No ethics review needed.'],8,2,,Yes,3,3,3,1720849505685,,,NeurIPS.cc/2024/Conference,3kDWoqs2X2,"['NeurIPS.cc/2024/Conference/Submission10953/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879429403,[],2,,,['everyone'],3kDWoqs2X2,['NeurIPS.cc/2024/Conference/Submission10953/Reviewer_YMg2'],1720849505685,1730879429403,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10953/Reviewer_YMg2']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, namely:

* [1]: Conjugate-Computation Variational Inference : Converting Variational Inference in Non-Conjugate Models to Inferences in Conjugate Models, 2018
* [2]: MCMC-driven learning, 2024
* [3]: Distributed Bayesian Learning with Stochastic Natural Gradient Expectation Propagation and the Posterior Server

The reviewer mentions that the relationship between moment matching in the exponential family and NGD is well known and can be found in these references, and suggests that the authors should include a discussion on this point and cite the relevant literature around Prop 1.",1,"2018, 2024",Conjugate-Computation Variational Inference 
dZVNEgrxB1,"This work addresses the sensitivity of expectation propagation (EP) to the randomness of Monte Carlo (MC) estimates involved in its update steps. It tackles this issue by recasting the moment matching step in EP as natural gradient descent (NGD) in the mean space of an exponential family distribution. The author identifies that the instability of EP to MC noise is due to the nonlinearity of the mirror map defined by the log partition function of the exponential family. By cleverly moving the NGD from the mean space to the natural parameter space, this issue is bypassed.
The author also studies the influence of the stepsize on the accumulation of MC error, finding that decreasing the stepsize of the NGD updates helps to reduce the bias.","- This is a well-written work. It starts with a succinct overview of the expectation propagation (EP) algorithm and summarizes several variants of EP updates in a unified manner (in Algorithm 1). This review also makes the contribution of this work very clear. It provides a sufficient discussion on why EP is sensitive to stochasticity and clearly motivates the design of the methodology. I also appreciate the self-contained review of the exponential family, natural gradient descent, and detailed derivation of EP updates provided in the appendix. Although these materials are standard, they help to make the work more accessible to a general audience.

- The feasibility of performing unbiased NGD updates in the natural space of $\tilde p_i$ (Prop1) is a smart observation, and this simple modification makes the inner loop significantly more robust to the stochasticity in MC est. This simple modification (from mean space to natural parameter space) makes the inner loop significantly more robust to the stochasticity in Monte Carlo estimation. I'm indeed impressed that EP can work with single-sample estimation in the inner loop.

- I also appreciate the rigorous investigation of the effect of $\alpha$ and $\epsilon$ to the bias of estimated mean parmaeter.

- The empirical performance of proposed methods are superior; it outperforms the standard EP by a significant margin (as shown in Fig2).","The technical side of this work is very strong in my perspective, and I don't observe many weakness on this regard. 
However, I think the novelty of this NGD perspective is overclaimed. To my knowledge, the relationship between moment matching in the exponential family and NGD is very well known (e.g., [1][2][3]). Once it is identified that $\tidle p_i$ is in the exponential family, the derivation of NGD (in either mean space Prop1 or natural parameter space) becomes quite straightforward. I hope the authors can elaborate on this point, and include discussion on some relavant literature arolund prop 1.

I believe the real contribution of this work lies in the rigorous understanding of the influence of the stepsize on the accumulation of Monte Carlo (MC) error and the identification of the nonlinearity of the mirror map that leads to this error accumulation, which is already impactful to me.




- [1]: Conjugate-Computation Variational Inference : Converting Variational Inference in Non-Conjugate Models to Inferences in Conjugate Models, 2018
- [2]: MCMC-driven learning, 2024
- [3]: Distributed Bayesian Learning with Stochastic Natural Gradient Expectation Propagation and the Posterior Server","- How do you estimate the KL divergence in the experiments? Maybe I'm missing something, but the target posterior is only known up to a constant, so unbiased KL est is not feasible?

- I'm curious to see the relative performance of this work to NGVI [1] (specified in the Weakness section).",The limitation is well discussed.,['No ethics review needed.'],8,2,,Yes,3,3,3,1720849505685,,,NeurIPS.cc/2024/Conference,3kDWoqs2X2,"['NeurIPS.cc/2024/Conference/Submission10953/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879429403,[],2,,,['everyone'],3kDWoqs2X2,['NeurIPS.cc/2024/Conference/Submission10953/Reviewer_YMg2'],1720849505685,1730879429403,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10953/Reviewer_YMg2']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, namely:

* [1]: Conjugate-Computation Variational Inference : Converting Variational Inference in Non-Conjugate Models to Inferences in Conjugate Models, 2018
* [2]: MCMC-driven learning, 2024
* [3]: Distributed Bayesian Learning with Stochastic Natural Gradient Expectation Propagation and the Posterior Server

The reviewer mentions that the relationship between moment matching in the exponential family and NGD is well known and can be found in these references, and suggests that the authors should include a discussion on this point and cite the relevant literature around Prop 1.",1,"2018, 2024",MCMC-driven learning 
dZVNEgrxB1,"This work addresses the sensitivity of expectation propagation (EP) to the randomness of Monte Carlo (MC) estimates involved in its update steps. It tackles this issue by recasting the moment matching step in EP as natural gradient descent (NGD) in the mean space of an exponential family distribution. The author identifies that the instability of EP to MC noise is due to the nonlinearity of the mirror map defined by the log partition function of the exponential family. By cleverly moving the NGD from the mean space to the natural parameter space, this issue is bypassed.
The author also studies the influence of the stepsize on the accumulation of MC error, finding that decreasing the stepsize of the NGD updates helps to reduce the bias.","- This is a well-written work. It starts with a succinct overview of the expectation propagation (EP) algorithm and summarizes several variants of EP updates in a unified manner (in Algorithm 1). This review also makes the contribution of this work very clear. It provides a sufficient discussion on why EP is sensitive to stochasticity and clearly motivates the design of the methodology. I also appreciate the self-contained review of the exponential family, natural gradient descent, and detailed derivation of EP updates provided in the appendix. Although these materials are standard, they help to make the work more accessible to a general audience.

- The feasibility of performing unbiased NGD updates in the natural space of $\tilde p_i$ (Prop1) is a smart observation, and this simple modification makes the inner loop significantly more robust to the stochasticity in MC est. This simple modification (from mean space to natural parameter space) makes the inner loop significantly more robust to the stochasticity in Monte Carlo estimation. I'm indeed impressed that EP can work with single-sample estimation in the inner loop.

- I also appreciate the rigorous investigation of the effect of $\alpha$ and $\epsilon$ to the bias of estimated mean parmaeter.

- The empirical performance of proposed methods are superior; it outperforms the standard EP by a significant margin (as shown in Fig2).","The technical side of this work is very strong in my perspective, and I don't observe many weakness on this regard. 
However, I think the novelty of this NGD perspective is overclaimed. To my knowledge, the relationship between moment matching in the exponential family and NGD is very well known (e.g., [1][2][3]). Once it is identified that $\tidle p_i$ is in the exponential family, the derivation of NGD (in either mean space Prop1 or natural parameter space) becomes quite straightforward. I hope the authors can elaborate on this point, and include discussion on some relavant literature arolund prop 1.

I believe the real contribution of this work lies in the rigorous understanding of the influence of the stepsize on the accumulation of Monte Carlo (MC) error and the identification of the nonlinearity of the mirror map that leads to this error accumulation, which is already impactful to me.




- [1]: Conjugate-Computation Variational Inference : Converting Variational Inference in Non-Conjugate Models to Inferences in Conjugate Models, 2018
- [2]: MCMC-driven learning, 2024
- [3]: Distributed Bayesian Learning with Stochastic Natural Gradient Expectation Propagation and the Posterior Server","- How do you estimate the KL divergence in the experiments? Maybe I'm missing something, but the target posterior is only known up to a constant, so unbiased KL est is not feasible?

- I'm curious to see the relative performance of this work to NGVI [1] (specified in the Weakness section).",The limitation is well discussed.,['No ethics review needed.'],8,2,,Yes,3,3,3,1720849505685,,,NeurIPS.cc/2024/Conference,3kDWoqs2X2,"['NeurIPS.cc/2024/Conference/Submission10953/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879429403,[],2,,,['everyone'],3kDWoqs2X2,['NeurIPS.cc/2024/Conference/Submission10953/Reviewer_YMg2'],1720849505685,1730879429403,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10953/Reviewer_YMg2']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, namely:

* [1]: Conjugate-Computation Variational Inference : Converting Variational Inference in Non-Conjugate Models to Inferences in Conjugate Models, 2018
* [2]: MCMC-driven learning, 2024
* [3]: Distributed Bayesian Learning with Stochastic Natural Gradient Expectation Propagation and the Posterior Server

The reviewer mentions that the relationship between moment matching in the exponential family and NGD is well known and can be found in these references, and suggests that the authors should include a discussion on this point and cite the relevant literature around Prop 1.",1,"2018, 2024",Distributed Bayesian Learning with Stochastic Natural Gradient Expectation Propagation and the Posterior Server
ZuPTKylSGF,"The paper proposes an attention-based methodology for supervised graph classification and regression. It adopts a pipeline similar to GraphViT, involving graph partition, cluster-wise representation learning, and aggregation. However, the core mechanism for learning cluster-wise representations is novel. Specifically, it introduces an inter-cluster attention and a cluster-to-node attention, using both attention maps to formulate the attention weights that aggregate node features into the query cluster's representation. This method is evaluated on eight graph classification/regression benchmarks, demonstrating promising results compared to the listed baselines.","1. The paper presents a clear and well-supported motivation for the proposed methodology, with technical details that are thoroughly demonstrated.

2. The methodology is novel, and considering both the features of each node and the cluster it is affiliated with when calculating the attention weight is highly reasonable.

3. Experimental results demonstrate the effectiveness of the method. Additionally, the exploratory study on combination weights validates the significance of introducing the learnable bias of the affiliated cluster into the attention weights.","1. The comparison with graph pooling methods misses MVPooL [1], a recent baseline that has achieved higher accuracy on these benchmarks.

2. Typo: the expression of the attention score between the $i$-th cluster and the $t$-th node in the $j$-th cluster should not contain the value $v_t$.

3. Suggestion: in Figure 2, combining Step 1 with Step 4 might provide a clearer illustration. Only with the presence of queries, keys, and values can the result of an attention operation be in the form of an aggregated representation; the result involving only keys and values is not well-defined. Additionally, combining Step 1 with Step 4 would better match the computation order of Equation 11.

**Reference**

[1] Zhang, Zhen, et al. ""Hierarchical multi-view graph pooling with structure learning."" IEEE Transactions on Knowledge and Data Engineering 35.1 (2021): 545-559.","1. Could the authors provide a heuristic explanation for why the cluster-level attention outperforms node-level attention on many benchmarks (as shown in Figure 5)? Cluster-level attention assigns the same weight to all nodes within a cluster, while node-level attention allows more flexible integration between cluster and node representations. It is not immediately clear why a more rigid approach would outperform a more flexible one.",,['No ethics review needed.'],7,5,,Yes,3,3,3,1721972233422,,,NeurIPS.cc/2024/Conference,3j2nasmKkP,"['NeurIPS.cc/2024/Conference/Submission8271/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879230816,[],4,,,['everyone'],3j2nasmKkP,['NeurIPS.cc/2024/Conference/Submission8271/Reviewer_azHs'],1721972233422,1730879230816,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8271/Reviewer_azHs']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature, namely:

[1] Zhang, Zhen, et al. ""Hierarchical multi-view graph pooling with structure learning."" IEEE Transactions on Knowledge and Data Engineering 35.1 (2021): 545-559.

The reviewer mentions that the comparison with graph pooling methods misses MVPooL, a recent baseline that has achieved higher accuracy on these benchmarks, and references this paper.",1,2021,Hierarchical multi-view graph pooling with structure learning
uLdnGPDOUx,"This paper introduces a new dataset called VideoPrefer, a collection of (simulated) human preferences on videos conditioned on certain language prompts. VideoPrefer utilizes GPT-4v as an automatic reward assessor, which contains videos from both machine-generated and real-world curated videos. The work then utilizes the collected preference as a reward to learn a reward model named VideoRM, constructed on top of a prior model HPS v2, extending its capabilities to temporal dimension and thus can present reward modeling in videos.","- This work collects a large scale of preference data, potentially useful for evaluating text-to-video generative models.
- It is demonstrated that the designed reward model VideoRM is showing the most aligned preferences over a few baseline methods.
- Finetuned text-to-video models utilizing the presented VideoRM seems effective under the designed experimental settings.","- While I appreciate the Table 2’s analysis on TVGE dataset among the tested video assessor candidates, solely performing statistical analysis on the VideoPrefer dataset is still required. People would be relying on the VideoRM which is trained on the VideoPrefer data and it remains questionable how faithful the dataset is.
- Lack of some analysis between real-world and generated videos. Under the same prompt, are real-world videos always or more likely to be better? What heuristics can people use to expand beyond the collected video sets?
- Is it unclear how text prompts are aligned with real-world videos in Section 2.2.
- Lack of rigorous statistical analysis on the curated video prompts. How diverse are they? What is the type-token ratio? What are the top frequent predicates and affected entities? What are the genres? It is hard to understand how challenging and/or how underlying bias would have affected the video generation process from this curated resource.
- Why only consider extension of HPS v2 as the base reward model? There are plenty of good video-language models that can be potentially useful (such as [1]) to be adapted as a reward model. If the work can show more unbiased learning from the dataset solely with video-based preference models, it would strengthen the work more.

[1] Sung, Yi-Lin, Jaemin Cho, and Mohit Bansal. ""Vl-adapter: Parameter-efficient transfer learning for vision-and-language tasks."" CVPR 2022.","- There are some minor typos, for example, L84 the “K” is already a thousand there. Please be more mindful when writing.
- What or who is deciding the “win” in Figure 2? The GPT-4v assessor?",- The limitations of this work do not seem to be explicitly addressed.,['No ethics review needed.'],5,4,,Yes,2,2,3,1720790430645,,,NeurIPS.cc/2024/Conference,3ivnixHy16,"['NeurIPS.cc/2024/Conference/Submission79/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878622333,[],4,,,['everyone'],3ivnixHy16,['NeurIPS.cc/2024/Conference/Submission79/Reviewer_nZ7n'],1720790430645,1730878622333,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission79/Reviewer_nZ7n']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

Sung, Yi-Lin, Jaemin Cho, and Mohit Bansal. ""Vl-adapter: Parameter-efficient transfer learning for vision-and-language tasks."" CVPR 2022.

This is mentioned in the weaknesses section, where the reviewer suggests that the authors could have considered other video-language models, such as the one presented in the cited paper, as a base reward model instead of only extending HPS v2.",1,2022,Vl-adapter Parameter-efficient transfer learning for vision-and-language tasks
SvJLI47X5C,"The paper investigates a phenomena in model-based offline RL that most existing algorithms fail when they are given the perfect model of the environment. Through multiple experiments, the paper argues the failure is due to the wrong estimated values at the states in the end of model rollouts. These states are called edge of reach and are used for targets of Q values but are never trained themselves. The paper continues to propose a fix in the form of pessimistic target value estimate using ensemble Q networks.","- The paper does an admirable job with empirical investigations of the root cause of the observed phenomenon.  I find the perfect model experiments, the simple environment example, and the patch oracle fix to be a very convincing set of evidences for the paper's claim. The paper sets a good example for this kind of empirical research.
- The introduced fix is practical and simple, and I believe might improve other existing model-based offline RL algorithms as well
- The empirical results obtained by the 
- I find the paper well written and free of typos.","**1)** The paper could benefit from more investigations on the necessity of the _detection_ of an edge-of-reach state. The current proposed value learning only uses the pessimistic Q target when it decides that the state is an edge-of-reach state. 

**Q1)** I wonder whether if this distinction is necessary and if we could always use the pessimistic value and get the similar results.

I believe this could be doable because in states with low variance, the pessimistic value will not defer from the normal one anyway. Potentially, this removes a hyperparameter which sets the threshold for the choice of value target. It also reduces the number of ensemble networks needed for the algorithm.

**2)** The paper could better position itself in the literature. The pessimistic value target is a ubiquitous trick in RL to overcome value estimation. See for example TD3 [1] paper for actor critic methods. The issue where models query Q networks in untrained states has also been pointed out in MBRL research. See for example [2]. 

**3)** It probably is out of the scope of the paper, but I wonder how much of this issue is shared with online MBRL algorithms. They also usually only create rollouts of a limited length. A discussion on this matter will be welcome.

**4)** It could be a personal matter, but the paper has too many future referencing. For example lines 160, 220, 231, 253, 260, 261. I find these confusing as a reader. Jumping to read the future section while reading is not ideal or even possible. Also when the future section is being read, the connection made in the past sections to the current one is probably forgotten. I recommend reducing these references and only make such connections when necessary. A general comment that more discussions about a topic will appear in the future could be enough for the reader without asking them to jump. 


[1] Fujimoto, Scott, Herke Hoof, and David Meger. ""Addressing function approximation error in actor-critic methods."" International conference on machine learning. PMLR, 2018.
[2] Jafferjee, Taher, et al. ""Hallucinating value: A pitfall of dyna-style planning with imperfect environment models."" arXiv preprint arXiv:2006.04363 (2020).","See Q1, and weakness 3 above.",I find the limitation discussions sufficient.,['No ethics review needed.'],7,3,,Yes,3,3,3,1721090742346,,,NeurIPS.cc/2024/Conference,3dn1hINA6o,"['NeurIPS.cc/2024/Conference/Submission11466/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879467746,[],4,,,['everyone'],3dn1hINA6o,['NeurIPS.cc/2024/Conference/Submission11466/Reviewer_biRH'],1721090742346,1730879467746,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11466/Reviewer_biRH']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two specific papers:

1. Fujimoto, Scott, Herke Hoof, and David Meger. ""Addressing function approximation error in actor-critic methods."" International conference on machine learning. PMLR, 2018. (Referenced as [1])
2. Jafferjee, Taher, et al. ""Hallucinating value: A pitfall of dyna-style planning with imperfect environment models."" arXiv preprint arXiv:2006.04363 (2020). (Referenced as [2])

The reviewer suggests that the paper could better position itself in the literature by citing these papers, which discuss related concepts such as pessimistic value targets and issues with model-based reinforcement learning.",1,"2018, 2020, 2020",Addressing function approximation error in actor-critic methods 
SvJLI47X5C,"The paper investigates a phenomena in model-based offline RL that most existing algorithms fail when they are given the perfect model of the environment. Through multiple experiments, the paper argues the failure is due to the wrong estimated values at the states in the end of model rollouts. These states are called edge of reach and are used for targets of Q values but are never trained themselves. The paper continues to propose a fix in the form of pessimistic target value estimate using ensemble Q networks.","- The paper does an admirable job with empirical investigations of the root cause of the observed phenomenon.  I find the perfect model experiments, the simple environment example, and the patch oracle fix to be a very convincing set of evidences for the paper's claim. The paper sets a good example for this kind of empirical research.
- The introduced fix is practical and simple, and I believe might improve other existing model-based offline RL algorithms as well
- The empirical results obtained by the 
- I find the paper well written and free of typos.","**1)** The paper could benefit from more investigations on the necessity of the _detection_ of an edge-of-reach state. The current proposed value learning only uses the pessimistic Q target when it decides that the state is an edge-of-reach state. 

**Q1)** I wonder whether if this distinction is necessary and if we could always use the pessimistic value and get the similar results.

I believe this could be doable because in states with low variance, the pessimistic value will not defer from the normal one anyway. Potentially, this removes a hyperparameter which sets the threshold for the choice of value target. It also reduces the number of ensemble networks needed for the algorithm.

**2)** The paper could better position itself in the literature. The pessimistic value target is a ubiquitous trick in RL to overcome value estimation. See for example TD3 [1] paper for actor critic methods. The issue where models query Q networks in untrained states has also been pointed out in MBRL research. See for example [2]. 

**3)** It probably is out of the scope of the paper, but I wonder how much of this issue is shared with online MBRL algorithms. They also usually only create rollouts of a limited length. A discussion on this matter will be welcome.

**4)** It could be a personal matter, but the paper has too many future referencing. For example lines 160, 220, 231, 253, 260, 261. I find these confusing as a reader. Jumping to read the future section while reading is not ideal or even possible. Also when the future section is being read, the connection made in the past sections to the current one is probably forgotten. I recommend reducing these references and only make such connections when necessary. A general comment that more discussions about a topic will appear in the future could be enough for the reader without asking them to jump. 


[1] Fujimoto, Scott, Herke Hoof, and David Meger. ""Addressing function approximation error in actor-critic methods."" International conference on machine learning. PMLR, 2018.
[2] Jafferjee, Taher, et al. ""Hallucinating value: A pitfall of dyna-style planning with imperfect environment models."" arXiv preprint arXiv:2006.04363 (2020).","See Q1, and weakness 3 above.",I find the limitation discussions sufficient.,['No ethics review needed.'],7,3,,Yes,3,3,3,1721090742346,,,NeurIPS.cc/2024/Conference,3dn1hINA6o,"['NeurIPS.cc/2024/Conference/Submission11466/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879467746,[],4,,,['everyone'],3dn1hINA6o,['NeurIPS.cc/2024/Conference/Submission11466/Reviewer_biRH'],1721090742346,1730879467746,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11466/Reviewer_biRH']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two specific papers:

1. Fujimoto, Scott, Herke Hoof, and David Meger. ""Addressing function approximation error in actor-critic methods."" International conference on machine learning. PMLR, 2018. (Referenced as [1])
2. Jafferjee, Taher, et al. ""Hallucinating value: A pitfall of dyna-style planning with imperfect environment models."" arXiv preprint arXiv:2006.04363 (2020). (Referenced as [2])

The reviewer suggests that the paper could better position itself in the literature by citing these papers, which discuss related concepts such as pessimistic value targets and issues with model-based reinforcement learning.",1,"2018, 2020, 2020",Hallucinating value A pitfall of dyna-style planning with imperfect environment models
q6RmAol6xD,"This work studies the Bahncard Problem and proposes a new learning-augmented algorithm, PFSUM. The writing of the paper is clear and easy to follow. The work also provides detailed mathematical proofs for six patterns followed by the experiments validate the theoretical findings.","This paper presents several interesting elements, particularly in its approach to a more generalized version of the Bahncard Problem. The consistency of the proposed algorithm, with its bounded promises, is a noteworthy feature. Unlike traditional approaches, this algorithm does not require predicting the entire future input, which simplifies the decision-making process. Additionally, the paper provides a detailed analysis of the cost-effectiveness across six different travel patterns, offering valuable insights into the performance of the algorithm.","The contributions of this paper are relatively narrow and ambiguous. One significant issue is that the robustness of the PFSUM algorithm remains unbounded when β converges to 0. This limitation undermines the reliability of the algorithm in scenarios where β is very small. Additionally, the parameter T is critical as it defines the boundaries of both the time interval and the prediction interval. However, the paper does not provide a clear analysis of how variations in T impact the competitive ratio, leaving an essential aspect of the algorithm's performance unexplored.

The related work section fails to engage with recent literature that could provide context for this study's contributions. While [12] is a milestone work from 2020, recent publications exploring different facets of the same problem are omitted. These could include the works like ""Online algorithms with costly predictions (2023)"", ""Learning-Augmented Online Algorithm for Two-Level Ski-Rental Problem (2024)"" and others. Including these works would offer a more comprehensive view of the field's current state. The authors could also indicate the principle and mechanism differences, rather than contextual disparities, between their work and [25]. 

The experimental validation is insufficient, relying on only two benchmarks, which inadequately demonstrates the generalizability and robustness of the proposed algorithm. While the paper claims to measure online algorithm performance using competitive ratios, the experiments primarily employ cost ratios. This discrepancy between theoretical claims and experimental measures undermines the impact of the findings and may lead to misinterpretation of the PFSUM's actual performance improvements.","1. What are the specific contributions of your work compared to other studies on the same problem, including those not cited in this paper?

2. Have you explored the effects of varying the length of the prediction interval on the performance of PFSUM? Could you provide insights into the trade-off between consistency and robustness in your algorithm?

3. Could you explain why your experimental validation relies on only two benchmarks? What are the reasons behind this choice, and do you believe that including more performance benchmarks could address potential limitations in demonstrating the algorithm's effectiveness?",There is no negative societal impact of this work.,['No ethics review needed.'],3,5,,Yes,2,3,2,1720351500074,,,NeurIPS.cc/2024/Conference,3cb6pF3Tvf,"['NeurIPS.cc/2024/Conference/Submission10170/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879365909,[],1,,,['everyone'],3cb6pF3Tvf,['NeurIPS.cc/2024/Conference/Submission10170/Reviewer_ZK3p'],1720351500074,1730879365909,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10170/Reviewer_ZK3p']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. ""Online algorithms with costly predictions (2023)""
2. ""Learning-Augmented Online Algorithm for Two-Level Ski-Rental Problem (2024)""

The reviewer mentions that including these works would offer a more comprehensive view of the field's current state. Additionally, the reviewer suggests that the authors should also engage with recent literature to provide context for their study's contributions, implying that the authors should consider citing other relevant and recent publications in the field.",1,"2023, 2024",Online algorithms with costly predictions 
q6RmAol6xD,"This work studies the Bahncard Problem and proposes a new learning-augmented algorithm, PFSUM. The writing of the paper is clear and easy to follow. The work also provides detailed mathematical proofs for six patterns followed by the experiments validate the theoretical findings.","This paper presents several interesting elements, particularly in its approach to a more generalized version of the Bahncard Problem. The consistency of the proposed algorithm, with its bounded promises, is a noteworthy feature. Unlike traditional approaches, this algorithm does not require predicting the entire future input, which simplifies the decision-making process. Additionally, the paper provides a detailed analysis of the cost-effectiveness across six different travel patterns, offering valuable insights into the performance of the algorithm.","The contributions of this paper are relatively narrow and ambiguous. One significant issue is that the robustness of the PFSUM algorithm remains unbounded when β converges to 0. This limitation undermines the reliability of the algorithm in scenarios where β is very small. Additionally, the parameter T is critical as it defines the boundaries of both the time interval and the prediction interval. However, the paper does not provide a clear analysis of how variations in T impact the competitive ratio, leaving an essential aspect of the algorithm's performance unexplored.

The related work section fails to engage with recent literature that could provide context for this study's contributions. While [12] is a milestone work from 2020, recent publications exploring different facets of the same problem are omitted. These could include the works like ""Online algorithms with costly predictions (2023)"", ""Learning-Augmented Online Algorithm for Two-Level Ski-Rental Problem (2024)"" and others. Including these works would offer a more comprehensive view of the field's current state. The authors could also indicate the principle and mechanism differences, rather than contextual disparities, between their work and [25]. 

The experimental validation is insufficient, relying on only two benchmarks, which inadequately demonstrates the generalizability and robustness of the proposed algorithm. While the paper claims to measure online algorithm performance using competitive ratios, the experiments primarily employ cost ratios. This discrepancy between theoretical claims and experimental measures undermines the impact of the findings and may lead to misinterpretation of the PFSUM's actual performance improvements.","1. What are the specific contributions of your work compared to other studies on the same problem, including those not cited in this paper?

2. Have you explored the effects of varying the length of the prediction interval on the performance of PFSUM? Could you provide insights into the trade-off between consistency and robustness in your algorithm?

3. Could you explain why your experimental validation relies on only two benchmarks? What are the reasons behind this choice, and do you believe that including more performance benchmarks could address potential limitations in demonstrating the algorithm's effectiveness?",There is no negative societal impact of this work.,['No ethics review needed.'],3,5,,Yes,2,3,2,1720351500074,,,NeurIPS.cc/2024/Conference,3cb6pF3Tvf,"['NeurIPS.cc/2024/Conference/Submission10170/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879365909,[],1,,,['everyone'],3cb6pF3Tvf,['NeurIPS.cc/2024/Conference/Submission10170/Reviewer_ZK3p'],1720351500074,1730879365909,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10170/Reviewer_ZK3p']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. ""Online algorithms with costly predictions (2023)""
2. ""Learning-Augmented Online Algorithm for Two-Level Ski-Rental Problem (2024)""

The reviewer mentions that including these works would offer a more comprehensive view of the field's current state. Additionally, the reviewer suggests that the authors should also engage with recent literature to provide context for their study's contributions, implying that the authors should consider citing other relevant and recent publications in the field.",1,"2023, 2024",Learning-Augmented Online Algorithm for Two-Level Ski-Rental Problem
QslCxN5YGC,"This paper introduces a new method EGonc for open-set node classification in graphs. EGonc performs open-set classification by incorporating energy-based models into the graph learning diagram. The training of the model only requires in-distribution data, while out-of-distribution training data are generated synthetically. In the experiments, the authors compare EGonc against a wide range of baseline methods on several benchmarks and provide ablation studies.","1. The paper focuses on open-set node classification in graph learning, which is an important problem in real-world applications.
2. Incorporating energy-based models into graph learning is a new method that has not been explored.
3. The proposed method shows good performance, beating a wide range of baselines as is shown in the experiments.","1. An important claim made in the paper is not supported. The paper claims that the proposed method ""has nice theoretical properties that guarantee an overall distinguishable margin between the detection scores for IND and OOD samples"", but there is no theoretical analysis supporting this claim. 

2. The experiments are not sufficient. First, using one class as the out-of-distribution (OOD) class is very different from the real-world scenario where OOD examples can be quite diverse. Second, the paper does not compare against several important OOD detection baselines[1][2]. The proposed method has a negative impact on the in-distribution accuracy, while the methods in [1][2] will not. Third, the error bars are not reported. Fourth, an ablation study for energy propagation is missing, which seems to be an important component of the method.

3. The presentation needs major improvement. First, there are a lot of format issues (e.g., missing reference in line 127, texts in the equations are not corrected formatted). Second, the intuitions behind $l_2$ and $l_3$ are not well-explained. It is not clear what are the roles of the two losses. It would be more helpful to use examples to show the intent of the two losses. Same for equation 8 and 9. Third, Proposition 1 uses vague descriptions, which is not valid for a mathematical statement. 

[1] Liu, Weitang, et al. ""Energy-based out-of-distribution detection."" Advances in neural information processing systems 33 (2020): 21464-21475.

[2] Sun, Yiyou, et al. ""Out-of-distribution detection with deep nearest neighbors."" International Conference on Machine Learning. PMLR, 2022.","1. What's the intuition behind the unknown substitute generation formula (equations 8 and 9)? What is the intuition of including $l_2$ and $l_3$ into the learning objective? Can you use examples to explain them?
2. In line 127, the second kind of substitute is generated from nodes with low classification confidence. Would that also be affected by the over-confident problem?
3. In equation 14, how the $\lambda$'s are selected?
4. I suggest moving line 155-160 (the introduction of GNN) to the background section.",Yes,['No ethics review needed.'],5,4,,Yes,2,1,1,1719721045918,,,NeurIPS.cc/2024/Conference,3cL2XDyaEB,"['NeurIPS.cc/2024/Conference/Submission8259/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879229696,[],1,,,['everyone'],3cL2XDyaEB,['NeurIPS.cc/2024/Conference/Submission8259/Reviewer_exuD'],1719721045918,1730879229696,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8259/Reviewer_exuD']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two specific papers:

1. Liu, Weitang, et al. ""Energy-based out-of-distribution detection."" Advances in neural information processing systems 33 (2020): 21464-21475.
2. Sun, Yiyou, et al. ""Out-of-distribution detection with deep nearest neighbors."" International Conference on Machine Learning. PMLR, 2022.

The reviewer suggests that the authors should compare their proposed method against these important OOD detection baselines, implying that the authors should be aware of and cite these works.",1,"2020, 2022",Energy-based out-of-distribution detection 
QslCxN5YGC,"This paper introduces a new method EGonc for open-set node classification in graphs. EGonc performs open-set classification by incorporating energy-based models into the graph learning diagram. The training of the model only requires in-distribution data, while out-of-distribution training data are generated synthetically. In the experiments, the authors compare EGonc against a wide range of baseline methods on several benchmarks and provide ablation studies.","1. The paper focuses on open-set node classification in graph learning, which is an important problem in real-world applications.
2. Incorporating energy-based models into graph learning is a new method that has not been explored.
3. The proposed method shows good performance, beating a wide range of baselines as is shown in the experiments.","1. An important claim made in the paper is not supported. The paper claims that the proposed method ""has nice theoretical properties that guarantee an overall distinguishable margin between the detection scores for IND and OOD samples"", but there is no theoretical analysis supporting this claim. 

2. The experiments are not sufficient. First, using one class as the out-of-distribution (OOD) class is very different from the real-world scenario where OOD examples can be quite diverse. Second, the paper does not compare against several important OOD detection baselines[1][2]. The proposed method has a negative impact on the in-distribution accuracy, while the methods in [1][2] will not. Third, the error bars are not reported. Fourth, an ablation study for energy propagation is missing, which seems to be an important component of the method.

3. The presentation needs major improvement. First, there are a lot of format issues (e.g., missing reference in line 127, texts in the equations are not corrected formatted). Second, the intuitions behind $l_2$ and $l_3$ are not well-explained. It is not clear what are the roles of the two losses. It would be more helpful to use examples to show the intent of the two losses. Same for equation 8 and 9. Third, Proposition 1 uses vague descriptions, which is not valid for a mathematical statement. 

[1] Liu, Weitang, et al. ""Energy-based out-of-distribution detection."" Advances in neural information processing systems 33 (2020): 21464-21475.

[2] Sun, Yiyou, et al. ""Out-of-distribution detection with deep nearest neighbors."" International Conference on Machine Learning. PMLR, 2022.","1. What's the intuition behind the unknown substitute generation formula (equations 8 and 9)? What is the intuition of including $l_2$ and $l_3$ into the learning objective? Can you use examples to explain them?
2. In line 127, the second kind of substitute is generated from nodes with low classification confidence. Would that also be affected by the over-confident problem?
3. In equation 14, how the $\lambda$'s are selected?
4. I suggest moving line 155-160 (the introduction of GNN) to the background section.",Yes,['No ethics review needed.'],5,4,,Yes,2,1,1,1719721045918,,,NeurIPS.cc/2024/Conference,3cL2XDyaEB,"['NeurIPS.cc/2024/Conference/Submission8259/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879229696,[],1,,,['everyone'],3cL2XDyaEB,['NeurIPS.cc/2024/Conference/Submission8259/Reviewer_exuD'],1719721045918,1730879229696,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8259/Reviewer_exuD']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two specific papers:

1. Liu, Weitang, et al. ""Energy-based out-of-distribution detection."" Advances in neural information processing systems 33 (2020): 21464-21475.
2. Sun, Yiyou, et al. ""Out-of-distribution detection with deep nearest neighbors."" International Conference on Machine Learning. PMLR, 2022.

The reviewer suggests that the authors should compare their proposed method against these important OOD detection baselines, implying that the authors should be aware of and cite these works.",1,"2020, 2022",Out-of-distribution detection with deep nearest neighbors
VlEcV2WAvd,"This paper proposes a suite of fast methods to approximately compute graph diffusion vectors such as Personalized PageRank, Katz centrality and the heat kernel. A notable feature of the proposed methods is that they are easily parallelizable and hence can achieve further acceleration on GPU. The authors also provide a running time bound for each method that they introduce. Empirical results show that the new local methods can achieve up to a hundred-fold speedup when compared to their global counterpart.","- The paper is well-written and easy to follow.
- The local diffusion framework is applicable to computing several important graph diffusion vectors.
- The experiments are reasonably comprehensive.","- When compared with APPR, the speedup is not really captured by Theorem 3.3 and Corollary 3.6. The authors only showed that $\overline{\mbox{vol}}(\mathcal{S}_T)/\bar\gamma_T \le 1/\epsilon$, but it requires strict inequality to achieve nontrivial speedup in terms of worse-case running time. It is not clear how tight this bound is in general. If the bound is tight, then in the worst case there is no speedup. The authors should comment on if there are classes of graphs over which there will be a notable gap between the 2 quantities $\overline{\mbox{vol}}(\mathcal{S}_T)/\bar\gamma_T$ and $1/\epsilon$, so that the result provides a meaningful improvement.
- Because the theorems concerning the worst-case running time do not seem to capture a clear improvement over simple baseline local methods, it is unclear where exactly the speedup reported in Table 2 comes from.
- In LocalGD and LocalCH, the authors did not provide an update rule (or even a definition) for $\mathcal{S}_t$. Since $\mathcal{S}_t$ is part of the local diffusion process, the authors should specify how $\mathcal{S}_t$ is updated or defined at each step. I guess that $\mathcal{S}_t$ depends on the termination condition, but I could not find where the authors mention about it in the main paper.","- Line 188: The open problem is recently solved by Martínez-Rubio et al, Accelerated and Sparse Algorithms for Approximate Personalized PageRank and Beyond, 2023.
- When eps goes to 0, do the approximate solutions converge to the exact global solutions?",Yes,['No ethics review needed.'],6,4,,Yes,3,3,3,1721006548222,,,NeurIPS.cc/2024/Conference,3Z0LTDjIM0,"['NeurIPS.cc/2024/Conference/Submission8635/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879255896,[],4,,,['everyone'],3Z0LTDjIM0,['NeurIPS.cc/2024/Conference/Submission8635/Reviewer_kfsj'],1721006548222,1730879255896,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8635/Reviewer_kfsj']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature: ""Martínez-Rubio et al, Accelerated and Sparse Algorithms for Approximate Personalized PageRank and Beyond, 2023"" in relation to the open problem mentioned in Line 188.",1,2023,Accelerated and Sparse Algorithms for Approximate Personalized PageRank and Beyond
M1T5NlVoT0,"The paper presents GS-Hider, a novel steganography framework designed for 3D Gaussian Splatting (3DGS). The framework enables the invisible embedding of 3D scenes and images into 3DGS point clouds, ensuring accurate extraction of hidden messages without compromising rendering quality. Extensive experiments demonstrate GS-Hider's effectiveness in concealing multimodal messages while maintaining exceptional security, robustness, capacity, and flexibility.","(+) The paper introduces an interesting steganography framework for 3DGS, which is a novel and emerging field in 3D scene reconstruction and rendering. GS-Hider maintains the rendering quality of the original scene while securely embedding hidden messages, addressing the challenges of fidelity and security effectively. The framework has significant potential applications in copyright protection, encrypted communication, and 3D asset compression.

(+) Comprehensive experiments are conducted to validate the performance, security, robustness, and flexibility of GS-Hider. The experiment results demonstrate robustness against various forms of degradation and support hiding multiple 3D scenes or images, showcasing its versatility.  Further Applications effectively explain the results of the proposed method when dealing with other scenarios.","(-) The implementation of GS-Hider involves some techniques and may require substantial computational resources, limiting its accessibility and usability for some ordinary users without deep learning backgrounds.
(-) The comparison with existing methods is somewhat limited, as it primarily focuses on a specific type of 3DGS. It overlooks a broader range of state-of-the-art techniques in 3DGS. It may be beneficial for the author to consider implementing their methods in other 3DGS variants like [1] to highlight the advantages of the proposed method.

[1] Mip-Splatting: Alias-free 3D Gaussian Splatting.",Please see the weakness.,The authors have addressed the limitations in the paper.,['No ethics review needed.'],8,4,,Yes,3,3,3,1720763943700,,,NeurIPS.cc/2024/Conference,3XLQp2Xx3J,"['NeurIPS.cc/2024/Conference/Submission902/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878666041,[],3,,,['everyone'],3XLQp2Xx3J,['NeurIPS.cc/2024/Conference/Submission902/Reviewer_S9BH'],1720763943700,1730878666041,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission902/Reviewer_S9BH']","Yes, this peer review explicitly suggests the authors of the paper to consider implementing their methods in other 3DGS variants, specifically mentioning ""[1] Mip-Splatting: Alias-free 3D Gaussian Splatting"" as an example. This implies that the reviewer is recommending the authors to cite and explore this specific literature to further strengthen their work.",1,,Mip-Splatting: Alias-free 3D Gaussian Splatting
KQb8KkxRw9,"This paper presents a comprehensive analysis of leveraging visual foundation models for complex 3D scene understanding. The authors unify three kinds of feature representation: image, video and 3D in a unified paradigm and analyze the effectiveness of those representations on different kinds of 3D tasks.","1. The study is thorough and meaningful. I think it provides interesting finds to the 3D vision community.
2. Experiments are extensive and comprehensive. The chosen tasks and methods are representative.","1. This work lacks a unified conclusion. The experimental observations are independent (in some extent like an experimental report rather than a research paper). It is better for the authors to summarize the core underlying principles, or design some models according to the observation, which may make this work more applicable. 
2. Since indoor 3D perception is mainly applied in embodied AI system, I suggest the author further study 3D scene understanding in an online setting [1, 2] rather than the current offline setting, which can be directly adopted in real-world robotic tasks.

[1] Fusion-aware point convolution for online semantic 3d scene segmentation, CVPR 2020
[2] Memory-based Adapters for Online 3D Scene Perception, CVPR 2024",No,Limitation is well addressed.,['No ethics review needed.'],6,4,,Yes,3,4,3,1719826196376,,,NeurIPS.cc/2024/Conference,3TxyhBZHT2,"['NeurIPS.cc/2024/Conference/Submission7712/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879186090,[],1,,,['everyone'],3TxyhBZHT2,['NeurIPS.cc/2024/Conference/Submission7712/Reviewer_vFsT'],1719826196376,1730879186090,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7712/Reviewer_vFsT']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely two papers:

1. ""Fusion-aware point convolution for online semantic 3d scene segmentation, CVPR 2020""
2. ""Memory-based Adapters for Online 3D Scene Perception, CVPR 2024""

These papers are referenced as [1] and [2] in the review, and the reviewer suggests that the authors further study 3D scene understanding in an online setting, similar to what is presented in these papers.",1,"2020, 2024",Fusion-aware point convolution for online semantic 3d scene segmentation 
KQb8KkxRw9,"This paper presents a comprehensive analysis of leveraging visual foundation models for complex 3D scene understanding. The authors unify three kinds of feature representation: image, video and 3D in a unified paradigm and analyze the effectiveness of those representations on different kinds of 3D tasks.","1. The study is thorough and meaningful. I think it provides interesting finds to the 3D vision community.
2. Experiments are extensive and comprehensive. The chosen tasks and methods are representative.","1. This work lacks a unified conclusion. The experimental observations are independent (in some extent like an experimental report rather than a research paper). It is better for the authors to summarize the core underlying principles, or design some models according to the observation, which may make this work more applicable. 
2. Since indoor 3D perception is mainly applied in embodied AI system, I suggest the author further study 3D scene understanding in an online setting [1, 2] rather than the current offline setting, which can be directly adopted in real-world robotic tasks.

[1] Fusion-aware point convolution for online semantic 3d scene segmentation, CVPR 2020
[2] Memory-based Adapters for Online 3D Scene Perception, CVPR 2024",No,Limitation is well addressed.,['No ethics review needed.'],6,4,,Yes,3,4,3,1719826196376,,,NeurIPS.cc/2024/Conference,3TxyhBZHT2,"['NeurIPS.cc/2024/Conference/Submission7712/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879186090,[],1,,,['everyone'],3TxyhBZHT2,['NeurIPS.cc/2024/Conference/Submission7712/Reviewer_vFsT'],1719826196376,1730879186090,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7712/Reviewer_vFsT']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely two papers:

1. ""Fusion-aware point convolution for online semantic 3d scene segmentation, CVPR 2020""
2. ""Memory-based Adapters for Online 3D Scene Perception, CVPR 2024""

These papers are referenced as [1] and [2] in the review, and the reviewer suggests that the authors further study 3D scene understanding in an online setting, similar to what is presented in these papers.",1,"2020, 2024",Memory-based Adapters for Online 3D Scene Perception
eGjqMDEnPM,"The paper proposed GABO, a novel Bayesian optimization method for offline model-based optimization problems. GABO regulates the surrogate model with source critic actor so that the BO procedure remains in the in-distribution. Experiment results validate that GABO outperforms several baselines in terms of the mean rank.","- Bayesian optimization is a widely used algorithm for black-box optimization but unexplored in offline MBO settings. As far as I know, it is the first paper that improves BO for offline MBO settings

- Mathematical formulation seems to be valid, and practical algorithm is given","- It seems that the tasks used for evaluation from the Design Bench are discrete, **biological sequence design tasks**. There are several continuous tasks, such as Superconductor, Ant, and Dkitty, which are also high-dimensional and challenging problems. I think the research scope is then limited to offline biological sequence design, not general offline optimization tasks. Then, authors should compare their method with papers specialized in biological sequence designs, such as BIB[1] and BootGen[2].

- If my understanding is correct, the **evaluation procedure is a bit different from the offline MBO conventions**. The authors first train a surrogate model and choose the top-1 candidate among 2048 candidates according to the predicted score of the surrogate model. As the surrogate model gives inaccurate predictions on the data points outside of the offline dataset, it is not convincing to choose the best one with the surrogate model for evaluation. The authors should elaborate on the reason why they changed the evaluation setting.

[1] Chen, Can, et al. ""Bidirectional learning for offline model-based biological sequence design."" International Conference on Machine Learning. PMLR, 2023.

[2] Kim, Minsu, et al. ""Bootstrapped training of score-conditioned generator for offline design of biological sequences."" Advances in Neural Information Processing Systems 36 (2024).","- In the experiment part, there is a new task called Warfarin, which is a conditional offline MBO task. I think the problem setting is practical and important. However, it seems that the proposed method lags behind other baselines in terms of performance. Could authors elaborate on why this phenomenon happens?

- It is also hard for me to accept the results of BONET and DDOM in the Branin task, as both papers deeply analyze the behavior of their methods in the Branin function. Is it due to the different evaluation settings?","As written in the weakness section, authors should specify the scope of the research and compare their method with proper baselines. Furthermore, the authors should explain why the evaluation setting has been changed.

There are a few minor comments on the manuscript.

- In the related work part, it might be beneficial that authors clearly state the limitations of prior methods rather than just explain the methods.

- In the background part, it might mislead readers if we define offline MBO as solving the optimization problem in Eq (2). There are several methods that formulate the problem as conditional generative modeling. Even for forward approaches, they do not solve the problem in Eq (2) and propose various approaches such as regularization.",['No ethics review needed.'],6,3,,Yes,2,2,3,1720190104483,,,NeurIPS.cc/2024/Conference,3RxcarQFRn,"['NeurIPS.cc/2024/Conference/Submission7166/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879138327,[],1,,,['everyone'],3RxcarQFRn,['NeurIPS.cc/2024/Conference/Submission7166/Reviewer_yPeb'],1720190104483,1730879138327,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7166/Reviewer_yPeb']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two specific papers that the authors should compare their method with:

1. Chen, Can, et al. ""Bidirectional learning for offline model-based biological sequence design."" International Conference on Machine Learning. PMLR, 2023. (referred to as [1])
2. Kim, Minsu, et al. ""Bootstrapped training of score-conditioned generator for offline design of biological sequences."" Advances in Neural Information Processing Systems 36 (2024). (referred to as [2])

The reviewer suggests that the authors should compare their method with these papers, which are specialized in biological sequence designs, to demonstrate the effectiveness of their proposed method in the context of offline biological sequence design.",1,"2023, 2024",Bidirectional learning for offline model-based biological sequence design 
eGjqMDEnPM,"The paper proposed GABO, a novel Bayesian optimization method for offline model-based optimization problems. GABO regulates the surrogate model with source critic actor so that the BO procedure remains in the in-distribution. Experiment results validate that GABO outperforms several baselines in terms of the mean rank.","- Bayesian optimization is a widely used algorithm for black-box optimization but unexplored in offline MBO settings. As far as I know, it is the first paper that improves BO for offline MBO settings

- Mathematical formulation seems to be valid, and practical algorithm is given","- It seems that the tasks used for evaluation from the Design Bench are discrete, **biological sequence design tasks**. There are several continuous tasks, such as Superconductor, Ant, and Dkitty, which are also high-dimensional and challenging problems. I think the research scope is then limited to offline biological sequence design, not general offline optimization tasks. Then, authors should compare their method with papers specialized in biological sequence designs, such as BIB[1] and BootGen[2].

- If my understanding is correct, the **evaluation procedure is a bit different from the offline MBO conventions**. The authors first train a surrogate model and choose the top-1 candidate among 2048 candidates according to the predicted score of the surrogate model. As the surrogate model gives inaccurate predictions on the data points outside of the offline dataset, it is not convincing to choose the best one with the surrogate model for evaluation. The authors should elaborate on the reason why they changed the evaluation setting.

[1] Chen, Can, et al. ""Bidirectional learning for offline model-based biological sequence design."" International Conference on Machine Learning. PMLR, 2023.

[2] Kim, Minsu, et al. ""Bootstrapped training of score-conditioned generator for offline design of biological sequences."" Advances in Neural Information Processing Systems 36 (2024).","- In the experiment part, there is a new task called Warfarin, which is a conditional offline MBO task. I think the problem setting is practical and important. However, it seems that the proposed method lags behind other baselines in terms of performance. Could authors elaborate on why this phenomenon happens?

- It is also hard for me to accept the results of BONET and DDOM in the Branin task, as both papers deeply analyze the behavior of their methods in the Branin function. Is it due to the different evaluation settings?","As written in the weakness section, authors should specify the scope of the research and compare their method with proper baselines. Furthermore, the authors should explain why the evaluation setting has been changed.

There are a few minor comments on the manuscript.

- In the related work part, it might be beneficial that authors clearly state the limitations of prior methods rather than just explain the methods.

- In the background part, it might mislead readers if we define offline MBO as solving the optimization problem in Eq (2). There are several methods that formulate the problem as conditional generative modeling. Even for forward approaches, they do not solve the problem in Eq (2) and propose various approaches such as regularization.",['No ethics review needed.'],6,3,,Yes,2,2,3,1720190104483,,,NeurIPS.cc/2024/Conference,3RxcarQFRn,"['NeurIPS.cc/2024/Conference/Submission7166/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879138327,[],1,,,['everyone'],3RxcarQFRn,['NeurIPS.cc/2024/Conference/Submission7166/Reviewer_yPeb'],1720190104483,1730879138327,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7166/Reviewer_yPeb']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two specific papers that the authors should compare their method with:

1. Chen, Can, et al. ""Bidirectional learning for offline model-based biological sequence design."" International Conference on Machine Learning. PMLR, 2023. (referred to as [1])
2. Kim, Minsu, et al. ""Bootstrapped training of score-conditioned generator for offline design of biological sequences."" Advances in Neural Information Processing Systems 36 (2024). (referred to as [2])

The reviewer suggests that the authors should compare their method with these papers, which are specialized in biological sequence designs, to demonstrate the effectiveness of their proposed method in the context of offline biological sequence design.",1,"2023, 2024",Bootstrapped training of score-conditioned generator for offline design of biological sequences
o5c0Rc6FnD,"The paper considers the problem of offline black-box optimization where only limited (zero-shot or few-shot) online interactions with the objective function is available. Existing approaches commonly train a neural net parametrized surrogate model of the objective using the offline data. The paper proposes to use a source critic model, inspired by discriminator training in generative adversarial networks, to regularize this surrogate. This is accomplished by formulating a constrained optimization problem which constrains the optimization (over the surrogate model) trajectory samples to be similar to the training data using the source critic model. The Lagrangian version of this constrained optimization is used as the objective for a standard batch mode Bayesian optimization algorithm. Experiments are performed on tasks from Design-bench benchmark and a new Warfarin task.","- One thing I really like about the paper is its evaluation which truly mirrors the offline optimization setting. The paper compares the proposed approach and baselines on a single evaluation from the oracle which I believe is the right way to evaluate algorithms for offline model-based optimization.

- The proposed approach shows good performance across all the tasks on both zero-shot and few-shot evaluation. The ablation study in 5.5 also shows that adaptively tuning the lagrangian coefficient is also important for good performance.

- The constrained optimization formulation is well-formulated and principled approach to tackle this problem. The design choice of constraining the surrogate model using the source critic model makes sense and is relevant for the problem.

- Some of the tasks in design-bench benchmark have multiple errors which makes them not so informative for evaluation. I like the paper didn't include superconductor task where the original offline dataset itself has multiple copies of the same inputs but with different outputs. Similarly, I think the ChemBL and UTR tasks are also not useful. In my practical experience, samples searched over ChemBL generates a lot of syntactic errors. I like the fact that the paper introduces new tasks like LogP and Warfarin which will be useful to the broader community.","- One question I have is about the broader picture of using Bayesian optimization (BO) for this problem space. Why should we first train the neural network surrogate model and then fit the Gaussian process (GP) on top of the neural surrogate model to do few steps of BO? Why can't we just fit a GP (with a latent space presumably to handle high/structured dimensionality) directly on the offline data and do one step of BO? I am assuming the TurBO-qEI baseline doesn't do that and also fits the Turbo's GP on the neural network surrogate.

- It would be nice to see more justification for the BO hyperparameters (like sampling budget (T) and batch size (b)). Is the method sensitive to the choice of these parameters?

- One thing I like about the paper is that it can work with any choice of the surrogate model. I would also like to point out one very recent related work that also constrains the optimization given any surrogate model by formulating the search as an offline RL problem.

        - Yassine Chemingui, Aryan Deshwal, Nghia Hoang, Janardhan Rao Doppa. Offline Model-based Black-Box Optimization via Policy-guided Gradient Search. Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI), 2024.",Please see weaknesses section.,Please see weaknesses section.,['No ethics review needed.'],7,4,,Yes,3,3,3,1721084588473,,,NeurIPS.cc/2024/Conference,3RxcarQFRn,"['NeurIPS.cc/2024/Conference/Submission7166/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879137939,[],4,,,['everyone'],3RxcarQFRn,['NeurIPS.cc/2024/Conference/Submission7166/Reviewer_bMXC'],1721084588473,1730879137939,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7166/Reviewer_bMXC']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature:

Yassine Chemingui, Aryan Deshwal, Nghia Hoang, Janardhan Rao Doppa. Offline Model-based Black-Box Optimization via Policy-guided Gradient Search. Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI), 2024.",1,2024,Offline Model-based Black-Box Optimization via Policy-guided Gradient Search
rDHAEw34ph,"This paper studies how to extract useful visual features from out-of-domain and action-free human videos to enhance robotic visualmotor control. Specifically, the authors argure that naively extracting spatial features via MAE is insufficient for robotics control, in contrast, jointly captureing spatial control and temporal movement will be more effective. To do so, the authors propose STP, a new self-supervised learning method, that simutaneously performs MAE on current frame to extract spatial information and predict furture frames to extract temporal motion clues. The overall motivation, idea and method are straightforward and reasonable. The authors evaluate STP on diverse benchmarks including 21 tasks spanning from simulation to real world tasks using imitation learning.","1. The paper is well-motivated, highlighting the importance of pre-training visual features for robotic foundation models.

2. The logic in the paper is clear and easy to follow.


3. The proposed method is straightforward and simple to implement.","1. The high costs associated with evaluating real-world tasks using different random seeds make it challenging to report variances. However, assessing the impact of multiple random seeds in simulated tasks could provide more reliable statistical insights. As shown in Table 1, STP's performance improvement over baselines is marginal (STP 63.7 vs. VC-1 61.8, and STP-L/16(Post PT) 78.4 vs. MAE-L/16(Post PT) 76.7). Given the inherent stochastic nature of imitation learning and reinforcement learning, evaluations across multiple episodes and various random seeds are crucial to validate the proposed methods effectively.

2. Some previous methods also consider the temporal movements when extracting the visual features. For instance, the video-language alignment loss in R3M [1] tries to align language with correct visual transitions, which can extract semantic informations about visual movements. Voltron[2] and DecisionNCE [3] also try to extract the semantic features of the temporal movements between two frames. VIP[3] and LIV[4] use RL to extract visual features, which may also capture long-term movements via bootstrapping. Therefore, the authors could strengthen their paper by highlighting these related works, demonstrating awareness of existing methods, situating their contributions and highlighting the differences between STP and these baselines.

[1] R3M: A Universal Visual Representation for Robot Manipulation. CoRL 2023

[2] Language-Driven Representation Learning for Robotics. RSS 2023.

[3] DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning. ICML 2024.

[4] VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training. ICLR 2023.

[5] LIV: Language-Image Representations and Rewards for Robotic Control. ICML 2023",Please refer to the weakness for details.,The authors have properly discussed the limiations in the Appendix.,['No ethics review needed.'],5,3,,Yes,2,3,2,1719557119956,,,NeurIPS.cc/2024/Conference,3Rtn1OMTC4,"['NeurIPS.cc/2024/Conference/Submission5716/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879024466,[],1,,,['everyone'],3Rtn1OMTC4,['NeurIPS.cc/2024/Conference/Submission5716/Reviewer_Dk2S'],1719557119956,1730879024466,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5716/Reviewer_Dk2S']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. R3M: A Universal Visual Representation for Robot Manipulation (CoRL 2023)
2. Voltron: Language-Driven Representation Learning for Robotics (RSS 2023)
3. DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning (ICML 2024)
4. VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training (ICLR 2023)
5. LIV: Language-Image Representations and Rewards for Robotic Control (ICML 2023)

The reviewer suggests that the authors should be aware of these existing methods, demonstrate how their contributions differ from these baselines, and highlight the differences between STP and these related works.",1,"2023, 2023, 2024, 2023, 2023",R3M A Universal Visual Representation for Robot Manipulation 
rDHAEw34ph,"This paper studies how to extract useful visual features from out-of-domain and action-free human videos to enhance robotic visualmotor control. Specifically, the authors argure that naively extracting spatial features via MAE is insufficient for robotics control, in contrast, jointly captureing spatial control and temporal movement will be more effective. To do so, the authors propose STP, a new self-supervised learning method, that simutaneously performs MAE on current frame to extract spatial information and predict furture frames to extract temporal motion clues. The overall motivation, idea and method are straightforward and reasonable. The authors evaluate STP on diverse benchmarks including 21 tasks spanning from simulation to real world tasks using imitation learning.","1. The paper is well-motivated, highlighting the importance of pre-training visual features for robotic foundation models.

2. The logic in the paper is clear and easy to follow.


3. The proposed method is straightforward and simple to implement.","1. The high costs associated with evaluating real-world tasks using different random seeds make it challenging to report variances. However, assessing the impact of multiple random seeds in simulated tasks could provide more reliable statistical insights. As shown in Table 1, STP's performance improvement over baselines is marginal (STP 63.7 vs. VC-1 61.8, and STP-L/16(Post PT) 78.4 vs. MAE-L/16(Post PT) 76.7). Given the inherent stochastic nature of imitation learning and reinforcement learning, evaluations across multiple episodes and various random seeds are crucial to validate the proposed methods effectively.

2. Some previous methods also consider the temporal movements when extracting the visual features. For instance, the video-language alignment loss in R3M [1] tries to align language with correct visual transitions, which can extract semantic informations about visual movements. Voltron[2] and DecisionNCE [3] also try to extract the semantic features of the temporal movements between two frames. VIP[3] and LIV[4] use RL to extract visual features, which may also capture long-term movements via bootstrapping. Therefore, the authors could strengthen their paper by highlighting these related works, demonstrating awareness of existing methods, situating their contributions and highlighting the differences between STP and these baselines.

[1] R3M: A Universal Visual Representation for Robot Manipulation. CoRL 2023

[2] Language-Driven Representation Learning for Robotics. RSS 2023.

[3] DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning. ICML 2024.

[4] VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training. ICLR 2023.

[5] LIV: Language-Image Representations and Rewards for Robotic Control. ICML 2023",Please refer to the weakness for details.,The authors have properly discussed the limiations in the Appendix.,['No ethics review needed.'],5,3,,Yes,2,3,2,1719557119956,,,NeurIPS.cc/2024/Conference,3Rtn1OMTC4,"['NeurIPS.cc/2024/Conference/Submission5716/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879024466,[],1,,,['everyone'],3Rtn1OMTC4,['NeurIPS.cc/2024/Conference/Submission5716/Reviewer_Dk2S'],1719557119956,1730879024466,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5716/Reviewer_Dk2S']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. R3M: A Universal Visual Representation for Robot Manipulation (CoRL 2023)
2. Voltron: Language-Driven Representation Learning for Robotics (RSS 2023)
3. DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning (ICML 2024)
4. VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training (ICLR 2023)
5. LIV: Language-Image Representations and Rewards for Robotic Control (ICML 2023)

The reviewer suggests that the authors should be aware of these existing methods, demonstrate how their contributions differ from these baselines, and highlight the differences between STP and these related works.",1,"2023, 2023, 2024, 2023, 2023",Voltron Language-Driven Representation Learning for Robotics 
rDHAEw34ph,"This paper studies how to extract useful visual features from out-of-domain and action-free human videos to enhance robotic visualmotor control. Specifically, the authors argure that naively extracting spatial features via MAE is insufficient for robotics control, in contrast, jointly captureing spatial control and temporal movement will be more effective. To do so, the authors propose STP, a new self-supervised learning method, that simutaneously performs MAE on current frame to extract spatial information and predict furture frames to extract temporal motion clues. The overall motivation, idea and method are straightforward and reasonable. The authors evaluate STP on diverse benchmarks including 21 tasks spanning from simulation to real world tasks using imitation learning.","1. The paper is well-motivated, highlighting the importance of pre-training visual features for robotic foundation models.

2. The logic in the paper is clear and easy to follow.


3. The proposed method is straightforward and simple to implement.","1. The high costs associated with evaluating real-world tasks using different random seeds make it challenging to report variances. However, assessing the impact of multiple random seeds in simulated tasks could provide more reliable statistical insights. As shown in Table 1, STP's performance improvement over baselines is marginal (STP 63.7 vs. VC-1 61.8, and STP-L/16(Post PT) 78.4 vs. MAE-L/16(Post PT) 76.7). Given the inherent stochastic nature of imitation learning and reinforcement learning, evaluations across multiple episodes and various random seeds are crucial to validate the proposed methods effectively.

2. Some previous methods also consider the temporal movements when extracting the visual features. For instance, the video-language alignment loss in R3M [1] tries to align language with correct visual transitions, which can extract semantic informations about visual movements. Voltron[2] and DecisionNCE [3] also try to extract the semantic features of the temporal movements between two frames. VIP[3] and LIV[4] use RL to extract visual features, which may also capture long-term movements via bootstrapping. Therefore, the authors could strengthen their paper by highlighting these related works, demonstrating awareness of existing methods, situating their contributions and highlighting the differences between STP and these baselines.

[1] R3M: A Universal Visual Representation for Robot Manipulation. CoRL 2023

[2] Language-Driven Representation Learning for Robotics. RSS 2023.

[3] DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning. ICML 2024.

[4] VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training. ICLR 2023.

[5] LIV: Language-Image Representations and Rewards for Robotic Control. ICML 2023",Please refer to the weakness for details.,The authors have properly discussed the limiations in the Appendix.,['No ethics review needed.'],5,3,,Yes,2,3,2,1719557119956,,,NeurIPS.cc/2024/Conference,3Rtn1OMTC4,"['NeurIPS.cc/2024/Conference/Submission5716/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879024466,[],1,,,['everyone'],3Rtn1OMTC4,['NeurIPS.cc/2024/Conference/Submission5716/Reviewer_Dk2S'],1719557119956,1730879024466,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5716/Reviewer_Dk2S']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. R3M: A Universal Visual Representation for Robot Manipulation (CoRL 2023)
2. Voltron: Language-Driven Representation Learning for Robotics (RSS 2023)
3. DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning (ICML 2024)
4. VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training (ICLR 2023)
5. LIV: Language-Image Representations and Rewards for Robotic Control (ICML 2023)

The reviewer suggests that the authors should be aware of these existing methods, demonstrate how their contributions differ from these baselines, and highlight the differences between STP and these related works.",1,"2023, 2023, 2024, 2023, 2023",DecisionNCE Embodied Multimodal Representations via Implicit Preference Learning 
rDHAEw34ph,"This paper studies how to extract useful visual features from out-of-domain and action-free human videos to enhance robotic visualmotor control. Specifically, the authors argure that naively extracting spatial features via MAE is insufficient for robotics control, in contrast, jointly captureing spatial control and temporal movement will be more effective. To do so, the authors propose STP, a new self-supervised learning method, that simutaneously performs MAE on current frame to extract spatial information and predict furture frames to extract temporal motion clues. The overall motivation, idea and method are straightforward and reasonable. The authors evaluate STP on diverse benchmarks including 21 tasks spanning from simulation to real world tasks using imitation learning.","1. The paper is well-motivated, highlighting the importance of pre-training visual features for robotic foundation models.

2. The logic in the paper is clear and easy to follow.


3. The proposed method is straightforward and simple to implement.","1. The high costs associated with evaluating real-world tasks using different random seeds make it challenging to report variances. However, assessing the impact of multiple random seeds in simulated tasks could provide more reliable statistical insights. As shown in Table 1, STP's performance improvement over baselines is marginal (STP 63.7 vs. VC-1 61.8, and STP-L/16(Post PT) 78.4 vs. MAE-L/16(Post PT) 76.7). Given the inherent stochastic nature of imitation learning and reinforcement learning, evaluations across multiple episodes and various random seeds are crucial to validate the proposed methods effectively.

2. Some previous methods also consider the temporal movements when extracting the visual features. For instance, the video-language alignment loss in R3M [1] tries to align language with correct visual transitions, which can extract semantic informations about visual movements. Voltron[2] and DecisionNCE [3] also try to extract the semantic features of the temporal movements between two frames. VIP[3] and LIV[4] use RL to extract visual features, which may also capture long-term movements via bootstrapping. Therefore, the authors could strengthen their paper by highlighting these related works, demonstrating awareness of existing methods, situating their contributions and highlighting the differences between STP and these baselines.

[1] R3M: A Universal Visual Representation for Robot Manipulation. CoRL 2023

[2] Language-Driven Representation Learning for Robotics. RSS 2023.

[3] DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning. ICML 2024.

[4] VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training. ICLR 2023.

[5] LIV: Language-Image Representations and Rewards for Robotic Control. ICML 2023",Please refer to the weakness for details.,The authors have properly discussed the limiations in the Appendix.,['No ethics review needed.'],5,3,,Yes,2,3,2,1719557119956,,,NeurIPS.cc/2024/Conference,3Rtn1OMTC4,"['NeurIPS.cc/2024/Conference/Submission5716/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879024466,[],1,,,['everyone'],3Rtn1OMTC4,['NeurIPS.cc/2024/Conference/Submission5716/Reviewer_Dk2S'],1719557119956,1730879024466,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5716/Reviewer_Dk2S']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. R3M: A Universal Visual Representation for Robot Manipulation (CoRL 2023)
2. Voltron: Language-Driven Representation Learning for Robotics (RSS 2023)
3. DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning (ICML 2024)
4. VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training (ICLR 2023)
5. LIV: Language-Image Representations and Rewards for Robotic Control (ICML 2023)

The reviewer suggests that the authors should be aware of these existing methods, demonstrate how their contributions differ from these baselines, and highlight the differences between STP and these related works.",1,"2023, 2023, 2024, 2023, 2023",VIP Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training 
rDHAEw34ph,"This paper studies how to extract useful visual features from out-of-domain and action-free human videos to enhance robotic visualmotor control. Specifically, the authors argure that naively extracting spatial features via MAE is insufficient for robotics control, in contrast, jointly captureing spatial control and temporal movement will be more effective. To do so, the authors propose STP, a new self-supervised learning method, that simutaneously performs MAE on current frame to extract spatial information and predict furture frames to extract temporal motion clues. The overall motivation, idea and method are straightforward and reasonable. The authors evaluate STP on diverse benchmarks including 21 tasks spanning from simulation to real world tasks using imitation learning.","1. The paper is well-motivated, highlighting the importance of pre-training visual features for robotic foundation models.

2. The logic in the paper is clear and easy to follow.


3. The proposed method is straightforward and simple to implement.","1. The high costs associated with evaluating real-world tasks using different random seeds make it challenging to report variances. However, assessing the impact of multiple random seeds in simulated tasks could provide more reliable statistical insights. As shown in Table 1, STP's performance improvement over baselines is marginal (STP 63.7 vs. VC-1 61.8, and STP-L/16(Post PT) 78.4 vs. MAE-L/16(Post PT) 76.7). Given the inherent stochastic nature of imitation learning and reinforcement learning, evaluations across multiple episodes and various random seeds are crucial to validate the proposed methods effectively.

2. Some previous methods also consider the temporal movements when extracting the visual features. For instance, the video-language alignment loss in R3M [1] tries to align language with correct visual transitions, which can extract semantic informations about visual movements. Voltron[2] and DecisionNCE [3] also try to extract the semantic features of the temporal movements between two frames. VIP[3] and LIV[4] use RL to extract visual features, which may also capture long-term movements via bootstrapping. Therefore, the authors could strengthen their paper by highlighting these related works, demonstrating awareness of existing methods, situating their contributions and highlighting the differences between STP and these baselines.

[1] R3M: A Universal Visual Representation for Robot Manipulation. CoRL 2023

[2] Language-Driven Representation Learning for Robotics. RSS 2023.

[3] DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning. ICML 2024.

[4] VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training. ICLR 2023.

[5] LIV: Language-Image Representations and Rewards for Robotic Control. ICML 2023",Please refer to the weakness for details.,The authors have properly discussed the limiations in the Appendix.,['No ethics review needed.'],5,3,,Yes,2,3,2,1719557119956,,,NeurIPS.cc/2024/Conference,3Rtn1OMTC4,"['NeurIPS.cc/2024/Conference/Submission5716/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879024466,[],1,,,['everyone'],3Rtn1OMTC4,['NeurIPS.cc/2024/Conference/Submission5716/Reviewer_Dk2S'],1719557119956,1730879024466,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5716/Reviewer_Dk2S']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. R3M: A Universal Visual Representation for Robot Manipulation (CoRL 2023)
2. Voltron: Language-Driven Representation Learning for Robotics (RSS 2023)
3. DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning (ICML 2024)
4. VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training (ICLR 2023)
5. LIV: Language-Image Representations and Rewards for Robotic Control (ICML 2023)

The reviewer suggests that the authors should be aware of these existing methods, demonstrate how their contributions differ from these baselines, and highlight the differences between STP and these related works.",1,"2023, 2023, 2024, 2023, 2023",LIV Language-Image Representations and Rewards for Robotic Control
7xPVFQDPat,"This paper proposes STP, a visual representation learning method for robotic motor control. Trained on human videos, STP uses masked auto-encoders for spatial-temporal prediction. The spatial decoder predicts the current frame from its representation with 75% of patches masked. The temporal decoder predicts the future frame using the representations of 75%-masked current frame and the 95%-masked future frame. Experiments on various simulation and real-world tasks show the effectiveness of STP compared with baselines.","1. The proposed method is simple yet effective, utilizing a masked spatial-temporal prediction objective to learn visual representations for robotics.
2. The paper presents extensive experimental results in both simulation and real-world settings, comparing with proper visual representation baselines.","1. Many works have considered temporal information for robot visual representation learning. This paper should mention these and highlight the differences. For example, R3M [1] uses temporal contrastive learning, while VIP [2] and V-PTR [3] use temporal difference.
2. Though STP outperforms the baselines in many benchmarks, the performance gap is not significant (Table 1). The slight performance difference may be due to hyperparameter selection and randomness, as the paper did not provide error bars over multiple seeds.

[1] R3m: A universal visual representation for robot manipulation, 2023
[2] Vip: Towards universal visual reward and representation via value-implicit pre-training, 2022
[3] Robotic Offline RL from Internet Videos via Value-Function Pre-Training, 2023","1. I think VIP and V-PTR should be included as baselines.
2. What is the evaluation protocol for downstream tasks? Does all evaluation use an expert dataset and perform imitation learning to learn a policy? How did you collect the dataset for real-world experiments?",The authors have discussed the limitations. These cannot be addressed within the scope of this paper.,['No ethics review needed.'],6,4,,Yes,2,3,3,1721138113430,,,NeurIPS.cc/2024/Conference,3Rtn1OMTC4,"['NeurIPS.cc/2024/Conference/Submission5716/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879024215,[],3,,,['everyone'],3Rtn1OMTC4,['NeurIPS.cc/2024/Conference/Submission5716/Reviewer_UXtm'],1721138113430,1730879024215,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5716/Reviewer_UXtm']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. R3M [1] - ""A universal visual representation for robot manipulation, 2023""
2. VIP [2] - ""Towards universal visual reward and representation via value-implicit pre-training, 2022""
3. V-PTR [3] - ""Robotic Offline RL from Internet Videos via Value-Function Pre-Training, 2023""

The reviewer mentions that the paper should discuss these works and highlight the differences between them and the proposed method, STP. Additionally, the reviewer suggests including VIP and V-PTR as baselines in the experiments.",1,"2023, 2022, 2023",A universal visual representation for robot manipulation 
7xPVFQDPat,"This paper proposes STP, a visual representation learning method for robotic motor control. Trained on human videos, STP uses masked auto-encoders for spatial-temporal prediction. The spatial decoder predicts the current frame from its representation with 75% of patches masked. The temporal decoder predicts the future frame using the representations of 75%-masked current frame and the 95%-masked future frame. Experiments on various simulation and real-world tasks show the effectiveness of STP compared with baselines.","1. The proposed method is simple yet effective, utilizing a masked spatial-temporal prediction objective to learn visual representations for robotics.
2. The paper presents extensive experimental results in both simulation and real-world settings, comparing with proper visual representation baselines.","1. Many works have considered temporal information for robot visual representation learning. This paper should mention these and highlight the differences. For example, R3M [1] uses temporal contrastive learning, while VIP [2] and V-PTR [3] use temporal difference.
2. Though STP outperforms the baselines in many benchmarks, the performance gap is not significant (Table 1). The slight performance difference may be due to hyperparameter selection and randomness, as the paper did not provide error bars over multiple seeds.

[1] R3m: A universal visual representation for robot manipulation, 2023
[2] Vip: Towards universal visual reward and representation via value-implicit pre-training, 2022
[3] Robotic Offline RL from Internet Videos via Value-Function Pre-Training, 2023","1. I think VIP and V-PTR should be included as baselines.
2. What is the evaluation protocol for downstream tasks? Does all evaluation use an expert dataset and perform imitation learning to learn a policy? How did you collect the dataset for real-world experiments?",The authors have discussed the limitations. These cannot be addressed within the scope of this paper.,['No ethics review needed.'],6,4,,Yes,2,3,3,1721138113430,,,NeurIPS.cc/2024/Conference,3Rtn1OMTC4,"['NeurIPS.cc/2024/Conference/Submission5716/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879024215,[],3,,,['everyone'],3Rtn1OMTC4,['NeurIPS.cc/2024/Conference/Submission5716/Reviewer_UXtm'],1721138113430,1730879024215,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5716/Reviewer_UXtm']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. R3M [1] - ""A universal visual representation for robot manipulation, 2023""
2. VIP [2] - ""Towards universal visual reward and representation via value-implicit pre-training, 2022""
3. V-PTR [3] - ""Robotic Offline RL from Internet Videos via Value-Function Pre-Training, 2023""

The reviewer mentions that the paper should discuss these works and highlight the differences between them and the proposed method, STP. Additionally, the reviewer suggests including VIP and V-PTR as baselines in the experiments.",1,"2023, 2022, 2023",Towards universal visual reward and representation via value-implicit pre-training 
7xPVFQDPat,"This paper proposes STP, a visual representation learning method for robotic motor control. Trained on human videos, STP uses masked auto-encoders for spatial-temporal prediction. The spatial decoder predicts the current frame from its representation with 75% of patches masked. The temporal decoder predicts the future frame using the representations of 75%-masked current frame and the 95%-masked future frame. Experiments on various simulation and real-world tasks show the effectiveness of STP compared with baselines.","1. The proposed method is simple yet effective, utilizing a masked spatial-temporal prediction objective to learn visual representations for robotics.
2. The paper presents extensive experimental results in both simulation and real-world settings, comparing with proper visual representation baselines.","1. Many works have considered temporal information for robot visual representation learning. This paper should mention these and highlight the differences. For example, R3M [1] uses temporal contrastive learning, while VIP [2] and V-PTR [3] use temporal difference.
2. Though STP outperforms the baselines in many benchmarks, the performance gap is not significant (Table 1). The slight performance difference may be due to hyperparameter selection and randomness, as the paper did not provide error bars over multiple seeds.

[1] R3m: A universal visual representation for robot manipulation, 2023
[2] Vip: Towards universal visual reward and representation via value-implicit pre-training, 2022
[3] Robotic Offline RL from Internet Videos via Value-Function Pre-Training, 2023","1. I think VIP and V-PTR should be included as baselines.
2. What is the evaluation protocol for downstream tasks? Does all evaluation use an expert dataset and perform imitation learning to learn a policy? How did you collect the dataset for real-world experiments?",The authors have discussed the limitations. These cannot be addressed within the scope of this paper.,['No ethics review needed.'],6,4,,Yes,2,3,3,1721138113430,,,NeurIPS.cc/2024/Conference,3Rtn1OMTC4,"['NeurIPS.cc/2024/Conference/Submission5716/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879024215,[],3,,,['everyone'],3Rtn1OMTC4,['NeurIPS.cc/2024/Conference/Submission5716/Reviewer_UXtm'],1721138113430,1730879024215,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5716/Reviewer_UXtm']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. R3M [1] - ""A universal visual representation for robot manipulation, 2023""
2. VIP [2] - ""Towards universal visual reward and representation via value-implicit pre-training, 2022""
3. V-PTR [3] - ""Robotic Offline RL from Internet Videos via Value-Function Pre-Training, 2023""

The reviewer mentions that the paper should discuss these works and highlight the differences between them and the proposed method, STP. Additionally, the reviewer suggests including VIP and V-PTR as baselines in the experiments.",1,"2023, 2022, 2023",Robotic Offline RL from Internet Videos via Value-Function Pre-Training
hAVARdMiDH,"The article discusses the limitations of existing training data attribution (TDA) methods, which aim to estimate how a model's behavior would change if specific data points were removed from the training set. The authors propose a new method called Source, which combines the benefits of implicit-differentiation-based and unrolling-based approaches. Source is computationally efficient and suitable for cases where implicit-differentiation-based methods struggle, such as non-converged models and multi-stage training pipelines. Empirical results show that Source outperforms existing TDA techniques, particularly in counterfactual prediction, where implicit-differentiation-based approaches fall short.","1. The writing in this article is very clear and excellent, making it easy to read and follow.

2. The design of this article avoids the assumption made by Koh et al.'s estimator that the loss is a graph function.",See the question part.,"Regarding this article, as a practitioner in the field, I would like the authors to answer a series of questions.

1. We all hope that Data-attribution/Influence Analysis can find suitable application areas, such as the work done by Gross et al. in explaining the output of LLM. However, currently, we have not seen Data-attribution/Influence Analysis truly solve a series of real problems, especially for large models such as Stable-Diffusion/LLM/LVM.

2. If the time and computational cost required for attribution is much higher than that for training (as it should compute the gradient one-sample-by-one-sample, and even for many checkpoints), is there any practical application significance worth for such high complexities?","1. Error Bound: This article lacks an analysis of the error bound for the estimator.

2. Regarding the contribution: The claim ""it allows the attribution of data points at different stages of training"" is not a unique contribution of this article, as some previous works [1,2,3] have achieved this without assuming that a checkpoint with testing is necessarily at gradient=0. Therefore, I do not believe that this claim can be considered a significant contribution to this article.

3. Experiments: This article lacks validation on significant datasets (even without experiments on relatively old datasets like ImageNet) and instead tests on very small toy datasets.

[1]. S Hara, et al. Data Cleansing for Models Trained with SGD. NeurIPS. 

[2]. G Pruthi, et al.  Estimating Training Data Influence by Tracing Gradient Descent. NeurIPS. 

[3]. H Tan, et al. Data pruning via moving-one-sample-out. NeurIPS.",['No ethics review needed.'],3,4,,Yes,2,4,3,1720784220812,,,NeurIPS.cc/2024/Conference,3NaqGg92KZ,"['NeurIPS.cc/2024/Conference/Submission7769/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879190962,[],3,,,['everyone'],3NaqGg92KZ,['NeurIPS.cc/2024/Conference/Submission7769/Reviewer_hk4U'],1720784220812,1730879190962,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7769/Reviewer_hk4U']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions three specific papers ([1], [2], and [3]) that have achieved the attribution of data points at different stages of training without assuming a checkpoint with testing is necessarily at gradient=0. The reviewer implies that the authors should be aware of and cite these previous works, as they have already addressed a similar contribution claimed by the authors. 

The cited papers are:
[1]. S Hara, et al. Data Cleansing for Models Trained with SGD. NeurIPS. 
[2]. G Pruthi, et al.  Estimating Training Data Influence by Tracing Gradient Descent. NeurIPS. 
[3]. H Tan, et al. Data pruning via moving-one-sample-out. NeurIPS.",1,,Data Cleansing for Models Trained with SGD
hAVARdMiDH,"The article discusses the limitations of existing training data attribution (TDA) methods, which aim to estimate how a model's behavior would change if specific data points were removed from the training set. The authors propose a new method called Source, which combines the benefits of implicit-differentiation-based and unrolling-based approaches. Source is computationally efficient and suitable for cases where implicit-differentiation-based methods struggle, such as non-converged models and multi-stage training pipelines. Empirical results show that Source outperforms existing TDA techniques, particularly in counterfactual prediction, where implicit-differentiation-based approaches fall short.","1. The writing in this article is very clear and excellent, making it easy to read and follow.

2. The design of this article avoids the assumption made by Koh et al.'s estimator that the loss is a graph function.",See the question part.,"Regarding this article, as a practitioner in the field, I would like the authors to answer a series of questions.

1. We all hope that Data-attribution/Influence Analysis can find suitable application areas, such as the work done by Gross et al. in explaining the output of LLM. However, currently, we have not seen Data-attribution/Influence Analysis truly solve a series of real problems, especially for large models such as Stable-Diffusion/LLM/LVM.

2. If the time and computational cost required for attribution is much higher than that for training (as it should compute the gradient one-sample-by-one-sample, and even for many checkpoints), is there any practical application significance worth for such high complexities?","1. Error Bound: This article lacks an analysis of the error bound for the estimator.

2. Regarding the contribution: The claim ""it allows the attribution of data points at different stages of training"" is not a unique contribution of this article, as some previous works [1,2,3] have achieved this without assuming that a checkpoint with testing is necessarily at gradient=0. Therefore, I do not believe that this claim can be considered a significant contribution to this article.

3. Experiments: This article lacks validation on significant datasets (even without experiments on relatively old datasets like ImageNet) and instead tests on very small toy datasets.

[1]. S Hara, et al. Data Cleansing for Models Trained with SGD. NeurIPS. 

[2]. G Pruthi, et al.  Estimating Training Data Influence by Tracing Gradient Descent. NeurIPS. 

[3]. H Tan, et al. Data pruning via moving-one-sample-out. NeurIPS.",['No ethics review needed.'],3,4,,Yes,2,4,3,1720784220812,,,NeurIPS.cc/2024/Conference,3NaqGg92KZ,"['NeurIPS.cc/2024/Conference/Submission7769/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879190962,[],3,,,['everyone'],3NaqGg92KZ,['NeurIPS.cc/2024/Conference/Submission7769/Reviewer_hk4U'],1720784220812,1730879190962,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7769/Reviewer_hk4U']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions three specific papers ([1], [2], and [3]) that have achieved the attribution of data points at different stages of training without assuming a checkpoint with testing is necessarily at gradient=0. The reviewer implies that the authors should be aware of and cite these previous works, as they have already addressed a similar contribution claimed by the authors. 

The cited papers are:
[1]. S Hara, et al. Data Cleansing for Models Trained with SGD. NeurIPS. 
[2]. G Pruthi, et al.  Estimating Training Data Influence by Tracing Gradient Descent. NeurIPS. 
[3]. H Tan, et al. Data pruning via moving-one-sample-out. NeurIPS.",1,,Estimating Training Data Influence by Tracing Gradient Descent
hAVARdMiDH,"The article discusses the limitations of existing training data attribution (TDA) methods, which aim to estimate how a model's behavior would change if specific data points were removed from the training set. The authors propose a new method called Source, which combines the benefits of implicit-differentiation-based and unrolling-based approaches. Source is computationally efficient and suitable for cases where implicit-differentiation-based methods struggle, such as non-converged models and multi-stage training pipelines. Empirical results show that Source outperforms existing TDA techniques, particularly in counterfactual prediction, where implicit-differentiation-based approaches fall short.","1. The writing in this article is very clear and excellent, making it easy to read and follow.

2. The design of this article avoids the assumption made by Koh et al.'s estimator that the loss is a graph function.",See the question part.,"Regarding this article, as a practitioner in the field, I would like the authors to answer a series of questions.

1. We all hope that Data-attribution/Influence Analysis can find suitable application areas, such as the work done by Gross et al. in explaining the output of LLM. However, currently, we have not seen Data-attribution/Influence Analysis truly solve a series of real problems, especially for large models such as Stable-Diffusion/LLM/LVM.

2. If the time and computational cost required for attribution is much higher than that for training (as it should compute the gradient one-sample-by-one-sample, and even for many checkpoints), is there any practical application significance worth for such high complexities?","1. Error Bound: This article lacks an analysis of the error bound for the estimator.

2. Regarding the contribution: The claim ""it allows the attribution of data points at different stages of training"" is not a unique contribution of this article, as some previous works [1,2,3] have achieved this without assuming that a checkpoint with testing is necessarily at gradient=0. Therefore, I do not believe that this claim can be considered a significant contribution to this article.

3. Experiments: This article lacks validation on significant datasets (even without experiments on relatively old datasets like ImageNet) and instead tests on very small toy datasets.

[1]. S Hara, et al. Data Cleansing for Models Trained with SGD. NeurIPS. 

[2]. G Pruthi, et al.  Estimating Training Data Influence by Tracing Gradient Descent. NeurIPS. 

[3]. H Tan, et al. Data pruning via moving-one-sample-out. NeurIPS.",['No ethics review needed.'],3,4,,Yes,2,4,3,1720784220812,,,NeurIPS.cc/2024/Conference,3NaqGg92KZ,"['NeurIPS.cc/2024/Conference/Submission7769/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879190962,[],3,,,['everyone'],3NaqGg92KZ,['NeurIPS.cc/2024/Conference/Submission7769/Reviewer_hk4U'],1720784220812,1730879190962,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7769/Reviewer_hk4U']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions three specific papers ([1], [2], and [3]) that have achieved the attribution of data points at different stages of training without assuming a checkpoint with testing is necessarily at gradient=0. The reviewer implies that the authors should be aware of and cite these previous works, as they have already addressed a similar contribution claimed by the authors. 

The cited papers are:
[1]. S Hara, et al. Data Cleansing for Models Trained with SGD. NeurIPS. 
[2]. G Pruthi, et al.  Estimating Training Data Influence by Tracing Gradient Descent. NeurIPS. 
[3]. H Tan, et al. Data pruning via moving-one-sample-out. NeurIPS.",1,,Data pruning via moving-one-sample-out
AHSE4UPFWk,"This paper introduces ""OpenGaussian,"" a novel method for 3D point-level open vocabulary understanding using 3D Gaussian Splatting (3DGS). The authors address the limitations of existing 3DGS-based methods that primarily focus on 2D pixel-level parsing. OpenGaussian aims to enhance 3D point-level understanding by training instance features with 3D consistency and proposing a two-stage codebook for feature discretization. The method also introduces an instance-level 3D-2D feature association to link 3D points to 2D masks and CLIP features. Extensive experiments demonstrate the effectiveness of OpenGaussian in various 3D tasks, and the source code will be released.","- **Novelty**: The paper introduces a unique approach to 3D point-level open vocabulary understanding, which is a significant advancement over existing methods that focus on 2D pixel-level parsing.  
 &nbsp; 
- **Technical Contributions**: The proposal of a two-stage codebook for feature discretization and the introduction of a 3D-2D feature association method are innovative and well-executed.  
 &nbsp; 
- **Experiments**: The extensive experiments, including open vocabulary-based 3D object selection and 3D point cloud understanding, validate the effectiveness of the proposed method.  
 &nbsp; 
- **Clarity**: The paper is well-written and clearly explains the methodology, making it easy to follow the proposed approach and its benefits.","- **Limitations Discussion**: The paper does not discuss the limitations of the proposed method in detail, which could provide a more balanced view of its applicability and potential drawbacks.  
 &nbsp; 
- **Comparative Analysis**: While the paper compares OpenGaussian with LangSplat and LEGaussians, additional comparisons with other state-of-the-art methods in OV 3D understanding could strengthen the evaluation, like Open-vocabulary 3D object detection[1, 2]   
 &nbsp; 
- **Complexity**: The implementation details, especially the two-stage codebook and feature association, may be complex and could benefit from further simplification or more detailed explanations for reproducibility.  
 &nbsp; 
- **Generalization**: The experiments are conducted on specific datasets, and it's unclear how well the method generalizes to other types of 3D scenes or datasets.

[1] Yuheng Lu, Chenfeng Xu, Xiaobao Wei, Xiaodong Xie, Masayoshi Tomizuka, Kurt Keutzer, and Shanghang Zhang. Open-vocabulary point-cloud object detection without 3d annotation. In CVPR, 2023. 1, 3  
[2] Yang Cao, Zeng Yihan, Hang Xu, and Dan Xu. Coda: Collaborative novel box discovery and cross-modal alignment for open-vocabulary 3d object detection. In NeurIPS, 2023","- **Scalability**: How does the method perform on larger and more complex 3D scenes? Are there any scalability issues?  
 &nbsp; 
- **Real-time Performance**: Can the method be applied in real-time applications, especially in robotics and embodied intelligence scenarios?  
 &nbsp; 
- **Ablation Studies**: Can you provide more detailed ablation studies to isolate the contributions of each component of the proposed method?  
 &nbsp; 
- **Generalization**: Have you tested the method on different types of 3D datasets to evaluate its generalization capabilities?","The authors did not provide an analysis of the limitations. For suggestions on improvement, please refer to the weaknesses section.",['No ethics review needed.'],6,5,,Yes,3,3,3,1720854640252,,,NeurIPS.cc/2024/Conference,3NAEowLh7Q,"['NeurIPS.cc/2024/Conference/Submission1591/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878712184,[],3,,,['everyone'],3NAEowLh7Q,['NeurIPS.cc/2024/Conference/Submission1591/Reviewer_ANGY'],1720854640252,1730878712184,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission1591/Reviewer_ANGY']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. Yuheng Lu, Chenfeng Xu, Xiaobao Wei, Xiaodong Xie, Masayoshi Tomizuka, Kurt Keutzer, and Shanghang Zhang. Open-vocabulary point-cloud object detection without 3d annotation. In CVPR, 2023.
2. Yang Cao, Zeng Yihan, Hang Xu, and Dan Xu. Coda: Collaborative novel box discovery and cross-modal alignment for open-vocabulary 3d object detection. In NeurIPS, 2023.

The reviewer mentions that comparing OpenGaussian with these state-of-the-art methods in open-vocabulary 3D understanding could strengthen the evaluation.",1,"2023, 2023",Open-vocabulary point-cloud object detection without 3d annotation 
AHSE4UPFWk,"This paper introduces ""OpenGaussian,"" a novel method for 3D point-level open vocabulary understanding using 3D Gaussian Splatting (3DGS). The authors address the limitations of existing 3DGS-based methods that primarily focus on 2D pixel-level parsing. OpenGaussian aims to enhance 3D point-level understanding by training instance features with 3D consistency and proposing a two-stage codebook for feature discretization. The method also introduces an instance-level 3D-2D feature association to link 3D points to 2D masks and CLIP features. Extensive experiments demonstrate the effectiveness of OpenGaussian in various 3D tasks, and the source code will be released.","- **Novelty**: The paper introduces a unique approach to 3D point-level open vocabulary understanding, which is a significant advancement over existing methods that focus on 2D pixel-level parsing.  
 &nbsp; 
- **Technical Contributions**: The proposal of a two-stage codebook for feature discretization and the introduction of a 3D-2D feature association method are innovative and well-executed.  
 &nbsp; 
- **Experiments**: The extensive experiments, including open vocabulary-based 3D object selection and 3D point cloud understanding, validate the effectiveness of the proposed method.  
 &nbsp; 
- **Clarity**: The paper is well-written and clearly explains the methodology, making it easy to follow the proposed approach and its benefits.","- **Limitations Discussion**: The paper does not discuss the limitations of the proposed method in detail, which could provide a more balanced view of its applicability and potential drawbacks.  
 &nbsp; 
- **Comparative Analysis**: While the paper compares OpenGaussian with LangSplat and LEGaussians, additional comparisons with other state-of-the-art methods in OV 3D understanding could strengthen the evaluation, like Open-vocabulary 3D object detection[1, 2]   
 &nbsp; 
- **Complexity**: The implementation details, especially the two-stage codebook and feature association, may be complex and could benefit from further simplification or more detailed explanations for reproducibility.  
 &nbsp; 
- **Generalization**: The experiments are conducted on specific datasets, and it's unclear how well the method generalizes to other types of 3D scenes or datasets.

[1] Yuheng Lu, Chenfeng Xu, Xiaobao Wei, Xiaodong Xie, Masayoshi Tomizuka, Kurt Keutzer, and Shanghang Zhang. Open-vocabulary point-cloud object detection without 3d annotation. In CVPR, 2023. 1, 3  
[2] Yang Cao, Zeng Yihan, Hang Xu, and Dan Xu. Coda: Collaborative novel box discovery and cross-modal alignment for open-vocabulary 3d object detection. In NeurIPS, 2023","- **Scalability**: How does the method perform on larger and more complex 3D scenes? Are there any scalability issues?  
 &nbsp; 
- **Real-time Performance**: Can the method be applied in real-time applications, especially in robotics and embodied intelligence scenarios?  
 &nbsp; 
- **Ablation Studies**: Can you provide more detailed ablation studies to isolate the contributions of each component of the proposed method?  
 &nbsp; 
- **Generalization**: Have you tested the method on different types of 3D datasets to evaluate its generalization capabilities?","The authors did not provide an analysis of the limitations. For suggestions on improvement, please refer to the weaknesses section.",['No ethics review needed.'],6,5,,Yes,3,3,3,1720854640252,,,NeurIPS.cc/2024/Conference,3NAEowLh7Q,"['NeurIPS.cc/2024/Conference/Submission1591/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878712184,[],3,,,['everyone'],3NAEowLh7Q,['NeurIPS.cc/2024/Conference/Submission1591/Reviewer_ANGY'],1720854640252,1730878712184,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission1591/Reviewer_ANGY']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. Yuheng Lu, Chenfeng Xu, Xiaobao Wei, Xiaodong Xie, Masayoshi Tomizuka, Kurt Keutzer, and Shanghang Zhang. Open-vocabulary point-cloud object detection without 3d annotation. In CVPR, 2023.
2. Yang Cao, Zeng Yihan, Hang Xu, and Dan Xu. Coda: Collaborative novel box discovery and cross-modal alignment for open-vocabulary 3d object detection. In NeurIPS, 2023.

The reviewer mentions that comparing OpenGaussian with these state-of-the-art methods in open-vocabulary 3D understanding could strengthen the evaluation.",1,"2023, 2023",Coda Collaborative novel box discovery and cross-modal alignment for open-vocabulary 3d object detection
susUbaYpLt,"The paper proposes a multi-resolution network for diffusion model which emphasizes the learning features across resolutions. The method further introduces a time-dependent layer norm to boost the model performance with fewer parameters compared to AdaLN in DiT. This proposed network demonstrates a SoTA performance on ImageNet at 1.70 and 2.89 on ImageNet 256 & 512, respectively.","- The paper addresses image distortion caused by varying patch sizes by integrating a multi-resolution structure into the network. The choice of patch sizes involves a trade-off between computational complexity and model performance: larger patch sizes reduce computational complexity but degrade performance. 
- The method finds a balance between compute complexity and performance by introducing a multi-branch architecture and multi-resolution loss to decompose the learning process from low to high resolution. The idea is a substantial contribution. Through quantitative and qualitative results, the method can alleviate distortion of image generation and achieve SoTA FID scores.
- The time-dependent layer norm is a simplified form of AdaLN with less intensive parameters by removing the cumbersome MLP layer and rearranging class embedding and time embedding for parameter-efficient time conditioning.","- The discussion between the method and cascaded methods like ""Cascaded diffusion models"" and ""Matryoshka diffusion models"" should be included to highlight the advantages of the method. 
- In table 1, it needs to be updated with some latest SoTa methods like MDTv2 with the best FID of 1.58 and PaGoDA with the best FID of 1.56 on ImageNet 256x256. Not to compete with them, but to get an overview picture of the latest methods.
- The proposed multi-scale diffusion loss is also introduced in SimpleDiffusion. So, the authors need to mention the difference in the paper. 
- Equation 2: have the authors used concat instead of adding the upsampling features directly to the larger-resolution features of the next branch?
- The current method only uses the output features of the previous branch and injects them into the start of the next branch. However, this design lacks interconnections between blocks from the low-resolution and high-resolution branches. Ideally, there should be skip-connections across branches. What is the motivation behind this? If authors have not tested this, it is encouraged to do so.
- In table 2, what is the reason why using AdaLN-Zero with Multi-branch (row 3) causes a bad result? 
- The root problem of distortion boils down to the use of patch size which is the main motivation of the work. However, in the design of multiscale network, the authors also patchify the input image to the corresponding resolution for each branch. I wonder why the author do not use different-resolution noisy images as the input to each branch like Matryoshka Diffusion Models. I think this is more effective to completely remove distortion problem. As shown in Figure 5, the method still exhibits a certain level of distortion rates. 
- Sampling speed: it is valid to include a comparison of sampling time with baselines.
- Figure 3: What is the red line meaning?

Misc: L37, L130: the figure 7 of DiT paper is incorrectly linked.

Ref: 
- Gao, Shanghua, et al. ""MDTv2: Masked Diffusion Transformer is a Strong Image Synthesizer."" arXiv preprint arXiv:2303.14389 (2023).
- Kim, Dongjun, et al. ""PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher."" arXiv preprint arXiv:2405.14822 (2024).
- Hoogeboom, Emiel, Jonathan Heek, and Tim Salimans. ""simple diffusion: End-to-end diffusion for high resolution images."" International Conference on Machine Learning. PMLR, 2023.",,"As pointed out in Weaknesses, the method still has a certain distortion rate which is due to the use of strided convolution (a form of patchification) at the start of each branch. I think the author should include this in the revised manuscript.",['No ethics review needed.'],7,5,,Yes,3,3,3,1719512079722,,,NeurIPS.cc/2024/Conference,3JwMwL8i5f,"['NeurIPS.cc/2024/Conference/Submission4202/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878909051,[],1,,,['everyone'],3JwMwL8i5f,['NeurIPS.cc/2024/Conference/Submission4202/Reviewer_Wwps'],1719512079722,1730878909051,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4202/Reviewer_Wwps']","Yes, the peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. Gao, Shanghua, et al. ""MDTv2: Masked Diffusion Transformer is a Strong Image Synthesizer."" arXiv preprint arXiv:2303.14389 (2023).
2. Kim, Dongjun, et al. ""PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher."" arXiv preprint arXiv:2405.14822 (2024).
3. Hoogeboom, Emiel, Jonathan Heek, and Tim Salimans. ""simple diffusion: End-to-end diffusion for high resolution images."" International Conference on Machine Learning. PMLR, 2023.

The reviewer suggests that the authors update Table 1 with the latest state-of-the-art methods, including MDTv2 and PaGoDA, and also mention the difference between their proposed multi-scale diffusion loss and the one introduced in SimpleDiffusion.",1,"2023, 2023, 2024, 2024, 2023",MDTv2: Masked Diffusion Transformer is a Strong Image Synthesizer 
susUbaYpLt,"The paper proposes a multi-resolution network for diffusion model which emphasizes the learning features across resolutions. The method further introduces a time-dependent layer norm to boost the model performance with fewer parameters compared to AdaLN in DiT. This proposed network demonstrates a SoTA performance on ImageNet at 1.70 and 2.89 on ImageNet 256 & 512, respectively.","- The paper addresses image distortion caused by varying patch sizes by integrating a multi-resolution structure into the network. The choice of patch sizes involves a trade-off between computational complexity and model performance: larger patch sizes reduce computational complexity but degrade performance. 
- The method finds a balance between compute complexity and performance by introducing a multi-branch architecture and multi-resolution loss to decompose the learning process from low to high resolution. The idea is a substantial contribution. Through quantitative and qualitative results, the method can alleviate distortion of image generation and achieve SoTA FID scores.
- The time-dependent layer norm is a simplified form of AdaLN with less intensive parameters by removing the cumbersome MLP layer and rearranging class embedding and time embedding for parameter-efficient time conditioning.","- The discussion between the method and cascaded methods like ""Cascaded diffusion models"" and ""Matryoshka diffusion models"" should be included to highlight the advantages of the method. 
- In table 1, it needs to be updated with some latest SoTa methods like MDTv2 with the best FID of 1.58 and PaGoDA with the best FID of 1.56 on ImageNet 256x256. Not to compete with them, but to get an overview picture of the latest methods.
- The proposed multi-scale diffusion loss is also introduced in SimpleDiffusion. So, the authors need to mention the difference in the paper. 
- Equation 2: have the authors used concat instead of adding the upsampling features directly to the larger-resolution features of the next branch?
- The current method only uses the output features of the previous branch and injects them into the start of the next branch. However, this design lacks interconnections between blocks from the low-resolution and high-resolution branches. Ideally, there should be skip-connections across branches. What is the motivation behind this? If authors have not tested this, it is encouraged to do so.
- In table 2, what is the reason why using AdaLN-Zero with Multi-branch (row 3) causes a bad result? 
- The root problem of distortion boils down to the use of patch size which is the main motivation of the work. However, in the design of multiscale network, the authors also patchify the input image to the corresponding resolution for each branch. I wonder why the author do not use different-resolution noisy images as the input to each branch like Matryoshka Diffusion Models. I think this is more effective to completely remove distortion problem. As shown in Figure 5, the method still exhibits a certain level of distortion rates. 
- Sampling speed: it is valid to include a comparison of sampling time with baselines.
- Figure 3: What is the red line meaning?

Misc: L37, L130: the figure 7 of DiT paper is incorrectly linked.

Ref: 
- Gao, Shanghua, et al. ""MDTv2: Masked Diffusion Transformer is a Strong Image Synthesizer."" arXiv preprint arXiv:2303.14389 (2023).
- Kim, Dongjun, et al. ""PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher."" arXiv preprint arXiv:2405.14822 (2024).
- Hoogeboom, Emiel, Jonathan Heek, and Tim Salimans. ""simple diffusion: End-to-end diffusion for high resolution images."" International Conference on Machine Learning. PMLR, 2023.",,"As pointed out in Weaknesses, the method still has a certain distortion rate which is due to the use of strided convolution (a form of patchification) at the start of each branch. I think the author should include this in the revised manuscript.",['No ethics review needed.'],7,5,,Yes,3,3,3,1719512079722,,,NeurIPS.cc/2024/Conference,3JwMwL8i5f,"['NeurIPS.cc/2024/Conference/Submission4202/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878909051,[],1,,,['everyone'],3JwMwL8i5f,['NeurIPS.cc/2024/Conference/Submission4202/Reviewer_Wwps'],1719512079722,1730878909051,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4202/Reviewer_Wwps']","Yes, the peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. Gao, Shanghua, et al. ""MDTv2: Masked Diffusion Transformer is a Strong Image Synthesizer."" arXiv preprint arXiv:2303.14389 (2023).
2. Kim, Dongjun, et al. ""PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher."" arXiv preprint arXiv:2405.14822 (2024).
3. Hoogeboom, Emiel, Jonathan Heek, and Tim Salimans. ""simple diffusion: End-to-end diffusion for high resolution images."" International Conference on Machine Learning. PMLR, 2023.

The reviewer suggests that the authors update Table 1 with the latest state-of-the-art methods, including MDTv2 and PaGoDA, and also mention the difference between their proposed multi-scale diffusion loss and the one introduced in SimpleDiffusion.",1,"2023, 2023, 2024, 2024, 2023",PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher 
susUbaYpLt,"The paper proposes a multi-resolution network for diffusion model which emphasizes the learning features across resolutions. The method further introduces a time-dependent layer norm to boost the model performance with fewer parameters compared to AdaLN in DiT. This proposed network demonstrates a SoTA performance on ImageNet at 1.70 and 2.89 on ImageNet 256 & 512, respectively.","- The paper addresses image distortion caused by varying patch sizes by integrating a multi-resolution structure into the network. The choice of patch sizes involves a trade-off between computational complexity and model performance: larger patch sizes reduce computational complexity but degrade performance. 
- The method finds a balance between compute complexity and performance by introducing a multi-branch architecture and multi-resolution loss to decompose the learning process from low to high resolution. The idea is a substantial contribution. Through quantitative and qualitative results, the method can alleviate distortion of image generation and achieve SoTA FID scores.
- The time-dependent layer norm is a simplified form of AdaLN with less intensive parameters by removing the cumbersome MLP layer and rearranging class embedding and time embedding for parameter-efficient time conditioning.","- The discussion between the method and cascaded methods like ""Cascaded diffusion models"" and ""Matryoshka diffusion models"" should be included to highlight the advantages of the method. 
- In table 1, it needs to be updated with some latest SoTa methods like MDTv2 with the best FID of 1.58 and PaGoDA with the best FID of 1.56 on ImageNet 256x256. Not to compete with them, but to get an overview picture of the latest methods.
- The proposed multi-scale diffusion loss is also introduced in SimpleDiffusion. So, the authors need to mention the difference in the paper. 
- Equation 2: have the authors used concat instead of adding the upsampling features directly to the larger-resolution features of the next branch?
- The current method only uses the output features of the previous branch and injects them into the start of the next branch. However, this design lacks interconnections between blocks from the low-resolution and high-resolution branches. Ideally, there should be skip-connections across branches. What is the motivation behind this? If authors have not tested this, it is encouraged to do so.
- In table 2, what is the reason why using AdaLN-Zero with Multi-branch (row 3) causes a bad result? 
- The root problem of distortion boils down to the use of patch size which is the main motivation of the work. However, in the design of multiscale network, the authors also patchify the input image to the corresponding resolution for each branch. I wonder why the author do not use different-resolution noisy images as the input to each branch like Matryoshka Diffusion Models. I think this is more effective to completely remove distortion problem. As shown in Figure 5, the method still exhibits a certain level of distortion rates. 
- Sampling speed: it is valid to include a comparison of sampling time with baselines.
- Figure 3: What is the red line meaning?

Misc: L37, L130: the figure 7 of DiT paper is incorrectly linked.

Ref: 
- Gao, Shanghua, et al. ""MDTv2: Masked Diffusion Transformer is a Strong Image Synthesizer."" arXiv preprint arXiv:2303.14389 (2023).
- Kim, Dongjun, et al. ""PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher."" arXiv preprint arXiv:2405.14822 (2024).
- Hoogeboom, Emiel, Jonathan Heek, and Tim Salimans. ""simple diffusion: End-to-end diffusion for high resolution images."" International Conference on Machine Learning. PMLR, 2023.",,"As pointed out in Weaknesses, the method still has a certain distortion rate which is due to the use of strided convolution (a form of patchification) at the start of each branch. I think the author should include this in the revised manuscript.",['No ethics review needed.'],7,5,,Yes,3,3,3,1719512079722,,,NeurIPS.cc/2024/Conference,3JwMwL8i5f,"['NeurIPS.cc/2024/Conference/Submission4202/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878909051,[],1,,,['everyone'],3JwMwL8i5f,['NeurIPS.cc/2024/Conference/Submission4202/Reviewer_Wwps'],1719512079722,1730878909051,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4202/Reviewer_Wwps']","Yes, the peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. Gao, Shanghua, et al. ""MDTv2: Masked Diffusion Transformer is a Strong Image Synthesizer."" arXiv preprint arXiv:2303.14389 (2023).
2. Kim, Dongjun, et al. ""PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher."" arXiv preprint arXiv:2405.14822 (2024).
3. Hoogeboom, Emiel, Jonathan Heek, and Tim Salimans. ""simple diffusion: End-to-end diffusion for high resolution images."" International Conference on Machine Learning. PMLR, 2023.

The reviewer suggests that the authors update Table 1 with the latest state-of-the-art methods, including MDTv2 and PaGoDA, and also mention the difference between their proposed multi-scale diffusion loss and the one introduced in SimpleDiffusion.",1,"2023, 2023, 2024, 2024, 2023",simple diffusion: End-to-end diffusion for high resolution images
et87jHn303,"Pretrained large language models know information about a wide range of topics, but since pre-training is often done on internet scale data, these models are not aligned with human values. Offline preference learning methods such as DPO are getting increasingly popular for this task.

A key assumption for DPO is that it sees a binary preference dataset  of $(x, y_w, y_l)$ tuples, where $x$ is the prompt, $y_w$ is the preferred and $y_l$ is the dispreferred response. However, this binary labeling is often too hard and does not count for the difference between two responses: while responses $y_1$ and $y_2$ may have a very clear preferred-dispreferred relationship, another pair $y_3$ and $y_4$ might have a much smaller difference. 

This paper proposes an algorithm to take into account the relative preference between two responses. The relative preference is not binary and can take any value between 0.5 and 1.0: closer to 1.0 means the preference is almost binary, whereas closer to 0.5 means it is a tossup between two responses. Prior work such as cDPO has used a linear interpolation between two different DPO losses with reversed preference relationships. In comparison, this paper assumes geometric averaging between two LLM policies, and this results in a simple modification to the existing DPO algorithm and its derivatives. This paper’s method, GDPO, outperforms DPO in the case of different soft preference labels.","1. The algorithm presented comes from a simple assumption. The final form of the algorithm’s loss functions is simple and intuitive.
2. The paper is nicely written.

In short, this paper comes from a long line of recent papers that try to fix one or more of DPO’s algorithmic issues. The authors focus on the strict binary nature of the preference dataset utilized by DPO, and try to improve it when additional information, i.e., how strong the preference relationship is, is known. This is an interesting question and nicely answered.","I will list the weaknesses from most important to less important, in my opinion.

**(What about DPO pushing down probabilities of both positive and negative examples)**

The biggest problem with DPO in my opinion, is that it pushes down the log probabilities of both positives and negatives, though it pushes down that of negatives much more, increasing the reward margin. Recent work such as [1] discusses this issue. This makes DPO extrapolate to an OOD region, which might be either good or bad. Discussing the results of [1] in context of this paper’s algorithm would be necessary: we would not want an algorithm that would push down probabilities of winning responses. On the other hand, GDPO’s gradient weighting term, $w_{\theta}$, can actually improve this situation too, and it would be good to know. 

Prior work such as RPO [2] has attempted to fix this issue by adding a SFT loss to the DPO loss, whereas SimPO [3] shows that a lot of the mismatches happen because of the reference model’s wrong reward attribution, and removing the reference model from the loss calculation can help. While comparing all of these might be out-of-scope for this paper, at least documenting the basic results from [1], i.e., what happens to the log probabilities of winning vs losing responses under GDPO, DPO and cDPO, would strengthen the paper. Also how does this vary depending on the soft preference distribution?

**(Online DPO)**

Multiple works have shown since DPO that offline preference tuning methods are sub-optimal, and the DPO objective, coupled with samples generated from the model itself, is generally better [1, 4, 5, 6, 7]. These methods can either use the reward from the language model itself to train it [6], or a separate reward model [1]. Could the authors expand this paper’s method to the online variant of DPO? Two problems I can see from the start: in order to use a self-rewarding scheme, the probability/reward from the policy needs to somehow inform us of the soft preference label. Would model miscalibration hurt this? Also for a separate reward model, if not sufficiently strong enough, obtaining the soft preference label can be hard. Also obtaining it during training, for every training sample, can become computationally expensive.


**(More architectures/models tried out)**

Trying this algorithm with more recent models, such as LLama3, or other more commonly used models such as Pythia or Mistral would strengthen the paper. **Note that I do not consider this a major weakness, just something that would make the paper more comprehensive.**","**Possibility of extension to token level labels**

Could this paper’s method be extended to token level labels? Eg, assume a math problem that has 5 steps. Assume responses $y_1$ and $y_2$ that are both wrong, but wrong in different steps, i.e., $y_1$ gets it correct up till 3rd step, whereas $y_2$ gets it correct till 2nd step. Can the soft preference labels reflect that/can we still make the model learn something here?

# References

[1] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data, https://arxiv.org/abs/2404.14367

[2] Iterative Reasoning Preference Optimization, https://arxiv.org/abs/2404.19733

[3] SimPO: Simple Preference Optimization with a Reference-Free Reward, https://arxiv.org/abs/2405.14734

[4] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study, https://arxiv.org/abs/2404.10719

[5] Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint, https://arxiv.org/abs/2312.11456

[6] Self-Rewarding Language Models, https://arxiv.org/abs/2401.10020

[7] Direct Language Model Alignment from Online AI Feedback, https://arxiv.org/abs/2402.04792",Yes,['No ethics review needed.'],6,4,,Yes,3,3,3,1719407397002,,,NeurIPS.cc/2024/Conference,3HpCVZV9it,"['NeurIPS.cc/2024/Conference/Submission10266/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879373781,[],1,,,['everyone'],3HpCVZV9it,['NeurIPS.cc/2024/Conference/Submission10266/Reviewer_98AM'],1719407397002,1730879373781,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10266/Reviewer_98AM']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. [1] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data
2. [2] Iterative Reasoning Preference Optimization
3. [3] SimPO: Simple Preference Optimization with a Reference-Free Reward
4. [4] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study
5. [5] Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint
6. [6] Self-Rewarding Language Models
7. [7] Direct Language Model Alignment from Online AI Feedback

The reviewer mentions that discussing the results of [1] in the context of the paper's algorithm would be necessary, and that documenting the basic results from [1] would strengthen the paper. This implies that the reviewer is suggesting the authors to cite and incorporate the findings of these papers into their work.",1,,"Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data"
et87jHn303,"Pretrained large language models know information about a wide range of topics, but since pre-training is often done on internet scale data, these models are not aligned with human values. Offline preference learning methods such as DPO are getting increasingly popular for this task.

A key assumption for DPO is that it sees a binary preference dataset  of $(x, y_w, y_l)$ tuples, where $x$ is the prompt, $y_w$ is the preferred and $y_l$ is the dispreferred response. However, this binary labeling is often too hard and does not count for the difference between two responses: while responses $y_1$ and $y_2$ may have a very clear preferred-dispreferred relationship, another pair $y_3$ and $y_4$ might have a much smaller difference. 

This paper proposes an algorithm to take into account the relative preference between two responses. The relative preference is not binary and can take any value between 0.5 and 1.0: closer to 1.0 means the preference is almost binary, whereas closer to 0.5 means it is a tossup between two responses. Prior work such as cDPO has used a linear interpolation between two different DPO losses with reversed preference relationships. In comparison, this paper assumes geometric averaging between two LLM policies, and this results in a simple modification to the existing DPO algorithm and its derivatives. This paper’s method, GDPO, outperforms DPO in the case of different soft preference labels.","1. The algorithm presented comes from a simple assumption. The final form of the algorithm’s loss functions is simple and intuitive.
2. The paper is nicely written.

In short, this paper comes from a long line of recent papers that try to fix one or more of DPO’s algorithmic issues. The authors focus on the strict binary nature of the preference dataset utilized by DPO, and try to improve it when additional information, i.e., how strong the preference relationship is, is known. This is an interesting question and nicely answered.","I will list the weaknesses from most important to less important, in my opinion.

**(What about DPO pushing down probabilities of both positive and negative examples)**

The biggest problem with DPO in my opinion, is that it pushes down the log probabilities of both positives and negatives, though it pushes down that of negatives much more, increasing the reward margin. Recent work such as [1] discusses this issue. This makes DPO extrapolate to an OOD region, which might be either good or bad. Discussing the results of [1] in context of this paper’s algorithm would be necessary: we would not want an algorithm that would push down probabilities of winning responses. On the other hand, GDPO’s gradient weighting term, $w_{\theta}$, can actually improve this situation too, and it would be good to know. 

Prior work such as RPO [2] has attempted to fix this issue by adding a SFT loss to the DPO loss, whereas SimPO [3] shows that a lot of the mismatches happen because of the reference model’s wrong reward attribution, and removing the reference model from the loss calculation can help. While comparing all of these might be out-of-scope for this paper, at least documenting the basic results from [1], i.e., what happens to the log probabilities of winning vs losing responses under GDPO, DPO and cDPO, would strengthen the paper. Also how does this vary depending on the soft preference distribution?

**(Online DPO)**

Multiple works have shown since DPO that offline preference tuning methods are sub-optimal, and the DPO objective, coupled with samples generated from the model itself, is generally better [1, 4, 5, 6, 7]. These methods can either use the reward from the language model itself to train it [6], or a separate reward model [1]. Could the authors expand this paper’s method to the online variant of DPO? Two problems I can see from the start: in order to use a self-rewarding scheme, the probability/reward from the policy needs to somehow inform us of the soft preference label. Would model miscalibration hurt this? Also for a separate reward model, if not sufficiently strong enough, obtaining the soft preference label can be hard. Also obtaining it during training, for every training sample, can become computationally expensive.


**(More architectures/models tried out)**

Trying this algorithm with more recent models, such as LLama3, or other more commonly used models such as Pythia or Mistral would strengthen the paper. **Note that I do not consider this a major weakness, just something that would make the paper more comprehensive.**","**Possibility of extension to token level labels**

Could this paper’s method be extended to token level labels? Eg, assume a math problem that has 5 steps. Assume responses $y_1$ and $y_2$ that are both wrong, but wrong in different steps, i.e., $y_1$ gets it correct up till 3rd step, whereas $y_2$ gets it correct till 2nd step. Can the soft preference labels reflect that/can we still make the model learn something here?

# References

[1] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data, https://arxiv.org/abs/2404.14367

[2] Iterative Reasoning Preference Optimization, https://arxiv.org/abs/2404.19733

[3] SimPO: Simple Preference Optimization with a Reference-Free Reward, https://arxiv.org/abs/2405.14734

[4] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study, https://arxiv.org/abs/2404.10719

[5] Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint, https://arxiv.org/abs/2312.11456

[6] Self-Rewarding Language Models, https://arxiv.org/abs/2401.10020

[7] Direct Language Model Alignment from Online AI Feedback, https://arxiv.org/abs/2402.04792",Yes,['No ethics review needed.'],6,4,,Yes,3,3,3,1719407397002,,,NeurIPS.cc/2024/Conference,3HpCVZV9it,"['NeurIPS.cc/2024/Conference/Submission10266/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879373781,[],1,,,['everyone'],3HpCVZV9it,['NeurIPS.cc/2024/Conference/Submission10266/Reviewer_98AM'],1719407397002,1730879373781,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10266/Reviewer_98AM']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. [1] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data
2. [2] Iterative Reasoning Preference Optimization
3. [3] SimPO: Simple Preference Optimization with a Reference-Free Reward
4. [4] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study
5. [5] Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint
6. [6] Self-Rewarding Language Models
7. [7] Direct Language Model Alignment from Online AI Feedback

The reviewer mentions that discussing the results of [1] in the context of the paper's algorithm would be necessary, and that documenting the basic results from [1] would strengthen the paper. This implies that the reviewer is suggesting the authors to cite and incorporate the findings of these papers into their work.",1,,Iterative Reasoning Preference Optimization
et87jHn303,"Pretrained large language models know information about a wide range of topics, but since pre-training is often done on internet scale data, these models are not aligned with human values. Offline preference learning methods such as DPO are getting increasingly popular for this task.

A key assumption for DPO is that it sees a binary preference dataset  of $(x, y_w, y_l)$ tuples, where $x$ is the prompt, $y_w$ is the preferred and $y_l$ is the dispreferred response. However, this binary labeling is often too hard and does not count for the difference between two responses: while responses $y_1$ and $y_2$ may have a very clear preferred-dispreferred relationship, another pair $y_3$ and $y_4$ might have a much smaller difference. 

This paper proposes an algorithm to take into account the relative preference between two responses. The relative preference is not binary and can take any value between 0.5 and 1.0: closer to 1.0 means the preference is almost binary, whereas closer to 0.5 means it is a tossup between two responses. Prior work such as cDPO has used a linear interpolation between two different DPO losses with reversed preference relationships. In comparison, this paper assumes geometric averaging between two LLM policies, and this results in a simple modification to the existing DPO algorithm and its derivatives. This paper’s method, GDPO, outperforms DPO in the case of different soft preference labels.","1. The algorithm presented comes from a simple assumption. The final form of the algorithm’s loss functions is simple and intuitive.
2. The paper is nicely written.

In short, this paper comes from a long line of recent papers that try to fix one or more of DPO’s algorithmic issues. The authors focus on the strict binary nature of the preference dataset utilized by DPO, and try to improve it when additional information, i.e., how strong the preference relationship is, is known. This is an interesting question and nicely answered.","I will list the weaknesses from most important to less important, in my opinion.

**(What about DPO pushing down probabilities of both positive and negative examples)**

The biggest problem with DPO in my opinion, is that it pushes down the log probabilities of both positives and negatives, though it pushes down that of negatives much more, increasing the reward margin. Recent work such as [1] discusses this issue. This makes DPO extrapolate to an OOD region, which might be either good or bad. Discussing the results of [1] in context of this paper’s algorithm would be necessary: we would not want an algorithm that would push down probabilities of winning responses. On the other hand, GDPO’s gradient weighting term, $w_{\theta}$, can actually improve this situation too, and it would be good to know. 

Prior work such as RPO [2] has attempted to fix this issue by adding a SFT loss to the DPO loss, whereas SimPO [3] shows that a lot of the mismatches happen because of the reference model’s wrong reward attribution, and removing the reference model from the loss calculation can help. While comparing all of these might be out-of-scope for this paper, at least documenting the basic results from [1], i.e., what happens to the log probabilities of winning vs losing responses under GDPO, DPO and cDPO, would strengthen the paper. Also how does this vary depending on the soft preference distribution?

**(Online DPO)**

Multiple works have shown since DPO that offline preference tuning methods are sub-optimal, and the DPO objective, coupled with samples generated from the model itself, is generally better [1, 4, 5, 6, 7]. These methods can either use the reward from the language model itself to train it [6], or a separate reward model [1]. Could the authors expand this paper’s method to the online variant of DPO? Two problems I can see from the start: in order to use a self-rewarding scheme, the probability/reward from the policy needs to somehow inform us of the soft preference label. Would model miscalibration hurt this? Also for a separate reward model, if not sufficiently strong enough, obtaining the soft preference label can be hard. Also obtaining it during training, for every training sample, can become computationally expensive.


**(More architectures/models tried out)**

Trying this algorithm with more recent models, such as LLama3, or other more commonly used models such as Pythia or Mistral would strengthen the paper. **Note that I do not consider this a major weakness, just something that would make the paper more comprehensive.**","**Possibility of extension to token level labels**

Could this paper’s method be extended to token level labels? Eg, assume a math problem that has 5 steps. Assume responses $y_1$ and $y_2$ that are both wrong, but wrong in different steps, i.e., $y_1$ gets it correct up till 3rd step, whereas $y_2$ gets it correct till 2nd step. Can the soft preference labels reflect that/can we still make the model learn something here?

# References

[1] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data, https://arxiv.org/abs/2404.14367

[2] Iterative Reasoning Preference Optimization, https://arxiv.org/abs/2404.19733

[3] SimPO: Simple Preference Optimization with a Reference-Free Reward, https://arxiv.org/abs/2405.14734

[4] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study, https://arxiv.org/abs/2404.10719

[5] Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint, https://arxiv.org/abs/2312.11456

[6] Self-Rewarding Language Models, https://arxiv.org/abs/2401.10020

[7] Direct Language Model Alignment from Online AI Feedback, https://arxiv.org/abs/2402.04792",Yes,['No ethics review needed.'],6,4,,Yes,3,3,3,1719407397002,,,NeurIPS.cc/2024/Conference,3HpCVZV9it,"['NeurIPS.cc/2024/Conference/Submission10266/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879373781,[],1,,,['everyone'],3HpCVZV9it,['NeurIPS.cc/2024/Conference/Submission10266/Reviewer_98AM'],1719407397002,1730879373781,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10266/Reviewer_98AM']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. [1] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data
2. [2] Iterative Reasoning Preference Optimization
3. [3] SimPO: Simple Preference Optimization with a Reference-Free Reward
4. [4] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study
5. [5] Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint
6. [6] Self-Rewarding Language Models
7. [7] Direct Language Model Alignment from Online AI Feedback

The reviewer mentions that discussing the results of [1] in the context of the paper's algorithm would be necessary, and that documenting the basic results from [1] would strengthen the paper. This implies that the reviewer is suggesting the authors to cite and incorporate the findings of these papers into their work.",1,,SimPO: Simple Preference Optimization with a Reference-Free Reward
et87jHn303,"Pretrained large language models know information about a wide range of topics, but since pre-training is often done on internet scale data, these models are not aligned with human values. Offline preference learning methods such as DPO are getting increasingly popular for this task.

A key assumption for DPO is that it sees a binary preference dataset  of $(x, y_w, y_l)$ tuples, where $x$ is the prompt, $y_w$ is the preferred and $y_l$ is the dispreferred response. However, this binary labeling is often too hard and does not count for the difference between two responses: while responses $y_1$ and $y_2$ may have a very clear preferred-dispreferred relationship, another pair $y_3$ and $y_4$ might have a much smaller difference. 

This paper proposes an algorithm to take into account the relative preference between two responses. The relative preference is not binary and can take any value between 0.5 and 1.0: closer to 1.0 means the preference is almost binary, whereas closer to 0.5 means it is a tossup between two responses. Prior work such as cDPO has used a linear interpolation between two different DPO losses with reversed preference relationships. In comparison, this paper assumes geometric averaging between two LLM policies, and this results in a simple modification to the existing DPO algorithm and its derivatives. This paper’s method, GDPO, outperforms DPO in the case of different soft preference labels.","1. The algorithm presented comes from a simple assumption. The final form of the algorithm’s loss functions is simple and intuitive.
2. The paper is nicely written.

In short, this paper comes from a long line of recent papers that try to fix one or more of DPO’s algorithmic issues. The authors focus on the strict binary nature of the preference dataset utilized by DPO, and try to improve it when additional information, i.e., how strong the preference relationship is, is known. This is an interesting question and nicely answered.","I will list the weaknesses from most important to less important, in my opinion.

**(What about DPO pushing down probabilities of both positive and negative examples)**

The biggest problem with DPO in my opinion, is that it pushes down the log probabilities of both positives and negatives, though it pushes down that of negatives much more, increasing the reward margin. Recent work such as [1] discusses this issue. This makes DPO extrapolate to an OOD region, which might be either good or bad. Discussing the results of [1] in context of this paper’s algorithm would be necessary: we would not want an algorithm that would push down probabilities of winning responses. On the other hand, GDPO’s gradient weighting term, $w_{\theta}$, can actually improve this situation too, and it would be good to know. 

Prior work such as RPO [2] has attempted to fix this issue by adding a SFT loss to the DPO loss, whereas SimPO [3] shows that a lot of the mismatches happen because of the reference model’s wrong reward attribution, and removing the reference model from the loss calculation can help. While comparing all of these might be out-of-scope for this paper, at least documenting the basic results from [1], i.e., what happens to the log probabilities of winning vs losing responses under GDPO, DPO and cDPO, would strengthen the paper. Also how does this vary depending on the soft preference distribution?

**(Online DPO)**

Multiple works have shown since DPO that offline preference tuning methods are sub-optimal, and the DPO objective, coupled with samples generated from the model itself, is generally better [1, 4, 5, 6, 7]. These methods can either use the reward from the language model itself to train it [6], or a separate reward model [1]. Could the authors expand this paper’s method to the online variant of DPO? Two problems I can see from the start: in order to use a self-rewarding scheme, the probability/reward from the policy needs to somehow inform us of the soft preference label. Would model miscalibration hurt this? Also for a separate reward model, if not sufficiently strong enough, obtaining the soft preference label can be hard. Also obtaining it during training, for every training sample, can become computationally expensive.


**(More architectures/models tried out)**

Trying this algorithm with more recent models, such as LLama3, or other more commonly used models such as Pythia or Mistral would strengthen the paper. **Note that I do not consider this a major weakness, just something that would make the paper more comprehensive.**","**Possibility of extension to token level labels**

Could this paper’s method be extended to token level labels? Eg, assume a math problem that has 5 steps. Assume responses $y_1$ and $y_2$ that are both wrong, but wrong in different steps, i.e., $y_1$ gets it correct up till 3rd step, whereas $y_2$ gets it correct till 2nd step. Can the soft preference labels reflect that/can we still make the model learn something here?

# References

[1] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data, https://arxiv.org/abs/2404.14367

[2] Iterative Reasoning Preference Optimization, https://arxiv.org/abs/2404.19733

[3] SimPO: Simple Preference Optimization with a Reference-Free Reward, https://arxiv.org/abs/2405.14734

[4] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study, https://arxiv.org/abs/2404.10719

[5] Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint, https://arxiv.org/abs/2312.11456

[6] Self-Rewarding Language Models, https://arxiv.org/abs/2401.10020

[7] Direct Language Model Alignment from Online AI Feedback, https://arxiv.org/abs/2402.04792",Yes,['No ethics review needed.'],6,4,,Yes,3,3,3,1719407397002,,,NeurIPS.cc/2024/Conference,3HpCVZV9it,"['NeurIPS.cc/2024/Conference/Submission10266/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879373781,[],1,,,['everyone'],3HpCVZV9it,['NeurIPS.cc/2024/Conference/Submission10266/Reviewer_98AM'],1719407397002,1730879373781,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10266/Reviewer_98AM']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. [1] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data
2. [2] Iterative Reasoning Preference Optimization
3. [3] SimPO: Simple Preference Optimization with a Reference-Free Reward
4. [4] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study
5. [5] Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint
6. [6] Self-Rewarding Language Models
7. [7] Direct Language Model Alignment from Online AI Feedback

The reviewer mentions that discussing the results of [1] in the context of the paper's algorithm would be necessary, and that documenting the basic results from [1] would strengthen the paper. This implies that the reviewer is suggesting the authors to cite and incorporate the findings of these papers into their work.",1,,Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study
et87jHn303,"Pretrained large language models know information about a wide range of topics, but since pre-training is often done on internet scale data, these models are not aligned with human values. Offline preference learning methods such as DPO are getting increasingly popular for this task.

A key assumption for DPO is that it sees a binary preference dataset  of $(x, y_w, y_l)$ tuples, where $x$ is the prompt, $y_w$ is the preferred and $y_l$ is the dispreferred response. However, this binary labeling is often too hard and does not count for the difference between two responses: while responses $y_1$ and $y_2$ may have a very clear preferred-dispreferred relationship, another pair $y_3$ and $y_4$ might have a much smaller difference. 

This paper proposes an algorithm to take into account the relative preference between two responses. The relative preference is not binary and can take any value between 0.5 and 1.0: closer to 1.0 means the preference is almost binary, whereas closer to 0.5 means it is a tossup between two responses. Prior work such as cDPO has used a linear interpolation between two different DPO losses with reversed preference relationships. In comparison, this paper assumes geometric averaging between two LLM policies, and this results in a simple modification to the existing DPO algorithm and its derivatives. This paper’s method, GDPO, outperforms DPO in the case of different soft preference labels.","1. The algorithm presented comes from a simple assumption. The final form of the algorithm’s loss functions is simple and intuitive.
2. The paper is nicely written.

In short, this paper comes from a long line of recent papers that try to fix one or more of DPO’s algorithmic issues. The authors focus on the strict binary nature of the preference dataset utilized by DPO, and try to improve it when additional information, i.e., how strong the preference relationship is, is known. This is an interesting question and nicely answered.","I will list the weaknesses from most important to less important, in my opinion.

**(What about DPO pushing down probabilities of both positive and negative examples)**

The biggest problem with DPO in my opinion, is that it pushes down the log probabilities of both positives and negatives, though it pushes down that of negatives much more, increasing the reward margin. Recent work such as [1] discusses this issue. This makes DPO extrapolate to an OOD region, which might be either good or bad. Discussing the results of [1] in context of this paper’s algorithm would be necessary: we would not want an algorithm that would push down probabilities of winning responses. On the other hand, GDPO’s gradient weighting term, $w_{\theta}$, can actually improve this situation too, and it would be good to know. 

Prior work such as RPO [2] has attempted to fix this issue by adding a SFT loss to the DPO loss, whereas SimPO [3] shows that a lot of the mismatches happen because of the reference model’s wrong reward attribution, and removing the reference model from the loss calculation can help. While comparing all of these might be out-of-scope for this paper, at least documenting the basic results from [1], i.e., what happens to the log probabilities of winning vs losing responses under GDPO, DPO and cDPO, would strengthen the paper. Also how does this vary depending on the soft preference distribution?

**(Online DPO)**

Multiple works have shown since DPO that offline preference tuning methods are sub-optimal, and the DPO objective, coupled with samples generated from the model itself, is generally better [1, 4, 5, 6, 7]. These methods can either use the reward from the language model itself to train it [6], or a separate reward model [1]. Could the authors expand this paper’s method to the online variant of DPO? Two problems I can see from the start: in order to use a self-rewarding scheme, the probability/reward from the policy needs to somehow inform us of the soft preference label. Would model miscalibration hurt this? Also for a separate reward model, if not sufficiently strong enough, obtaining the soft preference label can be hard. Also obtaining it during training, for every training sample, can become computationally expensive.


**(More architectures/models tried out)**

Trying this algorithm with more recent models, such as LLama3, or other more commonly used models such as Pythia or Mistral would strengthen the paper. **Note that I do not consider this a major weakness, just something that would make the paper more comprehensive.**","**Possibility of extension to token level labels**

Could this paper’s method be extended to token level labels? Eg, assume a math problem that has 5 steps. Assume responses $y_1$ and $y_2$ that are both wrong, but wrong in different steps, i.e., $y_1$ gets it correct up till 3rd step, whereas $y_2$ gets it correct till 2nd step. Can the soft preference labels reflect that/can we still make the model learn something here?

# References

[1] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data, https://arxiv.org/abs/2404.14367

[2] Iterative Reasoning Preference Optimization, https://arxiv.org/abs/2404.19733

[3] SimPO: Simple Preference Optimization with a Reference-Free Reward, https://arxiv.org/abs/2405.14734

[4] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study, https://arxiv.org/abs/2404.10719

[5] Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint, https://arxiv.org/abs/2312.11456

[6] Self-Rewarding Language Models, https://arxiv.org/abs/2401.10020

[7] Direct Language Model Alignment from Online AI Feedback, https://arxiv.org/abs/2402.04792",Yes,['No ethics review needed.'],6,4,,Yes,3,3,3,1719407397002,,,NeurIPS.cc/2024/Conference,3HpCVZV9it,"['NeurIPS.cc/2024/Conference/Submission10266/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879373781,[],1,,,['everyone'],3HpCVZV9it,['NeurIPS.cc/2024/Conference/Submission10266/Reviewer_98AM'],1719407397002,1730879373781,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10266/Reviewer_98AM']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. [1] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data
2. [2] Iterative Reasoning Preference Optimization
3. [3] SimPO: Simple Preference Optimization with a Reference-Free Reward
4. [4] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study
5. [5] Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint
6. [6] Self-Rewarding Language Models
7. [7] Direct Language Model Alignment from Online AI Feedback

The reviewer mentions that discussing the results of [1] in the context of the paper's algorithm would be necessary, and that documenting the basic results from [1] would strengthen the paper. This implies that the reviewer is suggesting the authors to cite and incorporate the findings of these papers into their work.",1,,Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint
et87jHn303,"Pretrained large language models know information about a wide range of topics, but since pre-training is often done on internet scale data, these models are not aligned with human values. Offline preference learning methods such as DPO are getting increasingly popular for this task.

A key assumption for DPO is that it sees a binary preference dataset  of $(x, y_w, y_l)$ tuples, where $x$ is the prompt, $y_w$ is the preferred and $y_l$ is the dispreferred response. However, this binary labeling is often too hard and does not count for the difference between two responses: while responses $y_1$ and $y_2$ may have a very clear preferred-dispreferred relationship, another pair $y_3$ and $y_4$ might have a much smaller difference. 

This paper proposes an algorithm to take into account the relative preference between two responses. The relative preference is not binary and can take any value between 0.5 and 1.0: closer to 1.0 means the preference is almost binary, whereas closer to 0.5 means it is a tossup between two responses. Prior work such as cDPO has used a linear interpolation between two different DPO losses with reversed preference relationships. In comparison, this paper assumes geometric averaging between two LLM policies, and this results in a simple modification to the existing DPO algorithm and its derivatives. This paper’s method, GDPO, outperforms DPO in the case of different soft preference labels.","1. The algorithm presented comes from a simple assumption. The final form of the algorithm’s loss functions is simple and intuitive.
2. The paper is nicely written.

In short, this paper comes from a long line of recent papers that try to fix one or more of DPO’s algorithmic issues. The authors focus on the strict binary nature of the preference dataset utilized by DPO, and try to improve it when additional information, i.e., how strong the preference relationship is, is known. This is an interesting question and nicely answered.","I will list the weaknesses from most important to less important, in my opinion.

**(What about DPO pushing down probabilities of both positive and negative examples)**

The biggest problem with DPO in my opinion, is that it pushes down the log probabilities of both positives and negatives, though it pushes down that of negatives much more, increasing the reward margin. Recent work such as [1] discusses this issue. This makes DPO extrapolate to an OOD region, which might be either good or bad. Discussing the results of [1] in context of this paper’s algorithm would be necessary: we would not want an algorithm that would push down probabilities of winning responses. On the other hand, GDPO’s gradient weighting term, $w_{\theta}$, can actually improve this situation too, and it would be good to know. 

Prior work such as RPO [2] has attempted to fix this issue by adding a SFT loss to the DPO loss, whereas SimPO [3] shows that a lot of the mismatches happen because of the reference model’s wrong reward attribution, and removing the reference model from the loss calculation can help. While comparing all of these might be out-of-scope for this paper, at least documenting the basic results from [1], i.e., what happens to the log probabilities of winning vs losing responses under GDPO, DPO and cDPO, would strengthen the paper. Also how does this vary depending on the soft preference distribution?

**(Online DPO)**

Multiple works have shown since DPO that offline preference tuning methods are sub-optimal, and the DPO objective, coupled with samples generated from the model itself, is generally better [1, 4, 5, 6, 7]. These methods can either use the reward from the language model itself to train it [6], or a separate reward model [1]. Could the authors expand this paper’s method to the online variant of DPO? Two problems I can see from the start: in order to use a self-rewarding scheme, the probability/reward from the policy needs to somehow inform us of the soft preference label. Would model miscalibration hurt this? Also for a separate reward model, if not sufficiently strong enough, obtaining the soft preference label can be hard. Also obtaining it during training, for every training sample, can become computationally expensive.


**(More architectures/models tried out)**

Trying this algorithm with more recent models, such as LLama3, or other more commonly used models such as Pythia or Mistral would strengthen the paper. **Note that I do not consider this a major weakness, just something that would make the paper more comprehensive.**","**Possibility of extension to token level labels**

Could this paper’s method be extended to token level labels? Eg, assume a math problem that has 5 steps. Assume responses $y_1$ and $y_2$ that are both wrong, but wrong in different steps, i.e., $y_1$ gets it correct up till 3rd step, whereas $y_2$ gets it correct till 2nd step. Can the soft preference labels reflect that/can we still make the model learn something here?

# References

[1] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data, https://arxiv.org/abs/2404.14367

[2] Iterative Reasoning Preference Optimization, https://arxiv.org/abs/2404.19733

[3] SimPO: Simple Preference Optimization with a Reference-Free Reward, https://arxiv.org/abs/2405.14734

[4] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study, https://arxiv.org/abs/2404.10719

[5] Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint, https://arxiv.org/abs/2312.11456

[6] Self-Rewarding Language Models, https://arxiv.org/abs/2401.10020

[7] Direct Language Model Alignment from Online AI Feedback, https://arxiv.org/abs/2402.04792",Yes,['No ethics review needed.'],6,4,,Yes,3,3,3,1719407397002,,,NeurIPS.cc/2024/Conference,3HpCVZV9it,"['NeurIPS.cc/2024/Conference/Submission10266/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879373781,[],1,,,['everyone'],3HpCVZV9it,['NeurIPS.cc/2024/Conference/Submission10266/Reviewer_98AM'],1719407397002,1730879373781,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10266/Reviewer_98AM']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. [1] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data
2. [2] Iterative Reasoning Preference Optimization
3. [3] SimPO: Simple Preference Optimization with a Reference-Free Reward
4. [4] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study
5. [5] Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint
6. [6] Self-Rewarding Language Models
7. [7] Direct Language Model Alignment from Online AI Feedback

The reviewer mentions that discussing the results of [1] in the context of the paper's algorithm would be necessary, and that documenting the basic results from [1] would strengthen the paper. This implies that the reviewer is suggesting the authors to cite and incorporate the findings of these papers into their work.",1,,Self-Rewarding Language Models
et87jHn303,"Pretrained large language models know information about a wide range of topics, but since pre-training is often done on internet scale data, these models are not aligned with human values. Offline preference learning methods such as DPO are getting increasingly popular for this task.

A key assumption for DPO is that it sees a binary preference dataset  of $(x, y_w, y_l)$ tuples, where $x$ is the prompt, $y_w$ is the preferred and $y_l$ is the dispreferred response. However, this binary labeling is often too hard and does not count for the difference between two responses: while responses $y_1$ and $y_2$ may have a very clear preferred-dispreferred relationship, another pair $y_3$ and $y_4$ might have a much smaller difference. 

This paper proposes an algorithm to take into account the relative preference between two responses. The relative preference is not binary and can take any value between 0.5 and 1.0: closer to 1.0 means the preference is almost binary, whereas closer to 0.5 means it is a tossup between two responses. Prior work such as cDPO has used a linear interpolation between two different DPO losses with reversed preference relationships. In comparison, this paper assumes geometric averaging between two LLM policies, and this results in a simple modification to the existing DPO algorithm and its derivatives. This paper’s method, GDPO, outperforms DPO in the case of different soft preference labels.","1. The algorithm presented comes from a simple assumption. The final form of the algorithm’s loss functions is simple and intuitive.
2. The paper is nicely written.

In short, this paper comes from a long line of recent papers that try to fix one or more of DPO’s algorithmic issues. The authors focus on the strict binary nature of the preference dataset utilized by DPO, and try to improve it when additional information, i.e., how strong the preference relationship is, is known. This is an interesting question and nicely answered.","I will list the weaknesses from most important to less important, in my opinion.

**(What about DPO pushing down probabilities of both positive and negative examples)**

The biggest problem with DPO in my opinion, is that it pushes down the log probabilities of both positives and negatives, though it pushes down that of negatives much more, increasing the reward margin. Recent work such as [1] discusses this issue. This makes DPO extrapolate to an OOD region, which might be either good or bad. Discussing the results of [1] in context of this paper’s algorithm would be necessary: we would not want an algorithm that would push down probabilities of winning responses. On the other hand, GDPO’s gradient weighting term, $w_{\theta}$, can actually improve this situation too, and it would be good to know. 

Prior work such as RPO [2] has attempted to fix this issue by adding a SFT loss to the DPO loss, whereas SimPO [3] shows that a lot of the mismatches happen because of the reference model’s wrong reward attribution, and removing the reference model from the loss calculation can help. While comparing all of these might be out-of-scope for this paper, at least documenting the basic results from [1], i.e., what happens to the log probabilities of winning vs losing responses under GDPO, DPO and cDPO, would strengthen the paper. Also how does this vary depending on the soft preference distribution?

**(Online DPO)**

Multiple works have shown since DPO that offline preference tuning methods are sub-optimal, and the DPO objective, coupled with samples generated from the model itself, is generally better [1, 4, 5, 6, 7]. These methods can either use the reward from the language model itself to train it [6], or a separate reward model [1]. Could the authors expand this paper’s method to the online variant of DPO? Two problems I can see from the start: in order to use a self-rewarding scheme, the probability/reward from the policy needs to somehow inform us of the soft preference label. Would model miscalibration hurt this? Also for a separate reward model, if not sufficiently strong enough, obtaining the soft preference label can be hard. Also obtaining it during training, for every training sample, can become computationally expensive.


**(More architectures/models tried out)**

Trying this algorithm with more recent models, such as LLama3, or other more commonly used models such as Pythia or Mistral would strengthen the paper. **Note that I do not consider this a major weakness, just something that would make the paper more comprehensive.**","**Possibility of extension to token level labels**

Could this paper’s method be extended to token level labels? Eg, assume a math problem that has 5 steps. Assume responses $y_1$ and $y_2$ that are both wrong, but wrong in different steps, i.e., $y_1$ gets it correct up till 3rd step, whereas $y_2$ gets it correct till 2nd step. Can the soft preference labels reflect that/can we still make the model learn something here?

# References

[1] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data, https://arxiv.org/abs/2404.14367

[2] Iterative Reasoning Preference Optimization, https://arxiv.org/abs/2404.19733

[3] SimPO: Simple Preference Optimization with a Reference-Free Reward, https://arxiv.org/abs/2405.14734

[4] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study, https://arxiv.org/abs/2404.10719

[5] Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint, https://arxiv.org/abs/2312.11456

[6] Self-Rewarding Language Models, https://arxiv.org/abs/2401.10020

[7] Direct Language Model Alignment from Online AI Feedback, https://arxiv.org/abs/2402.04792",Yes,['No ethics review needed.'],6,4,,Yes,3,3,3,1719407397002,,,NeurIPS.cc/2024/Conference,3HpCVZV9it,"['NeurIPS.cc/2024/Conference/Submission10266/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879373781,[],1,,,['everyone'],3HpCVZV9it,['NeurIPS.cc/2024/Conference/Submission10266/Reviewer_98AM'],1719407397002,1730879373781,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10266/Reviewer_98AM']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. [1] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data
2. [2] Iterative Reasoning Preference Optimization
3. [3] SimPO: Simple Preference Optimization with a Reference-Free Reward
4. [4] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study
5. [5] Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint
6. [6] Self-Rewarding Language Models
7. [7] Direct Language Model Alignment from Online AI Feedback

The reviewer mentions that discussing the results of [1] in the context of the paper's algorithm would be necessary, and that documenting the basic results from [1] would strengthen the paper. This implies that the reviewer is suggesting the authors to cite and incorporate the findings of these papers into their work.",1,,Direct Language Model Alignment from Online AI Feedback
rNi21bmtFm,This study introduces an adaptive tokenizer whose development is integrated with the performance of the LLM. The tokenizer has the particularity that it is fine-tuned based on the model’s perplexity during training. Empirical results show that this approach improves accuracy compared to “traditional” tokenization methods.,"- Well motivate and easy to understand
- Experiments are very comprehensive
- Insightful ablation study
- Answer most of the questions that one may have for a tokenizer: impact on perplexity, accuracy in downstream tasks, and performance depending on the vocabulary size,","- There are only comparisons with very common tokenizers: BPE, BytePiece, and Unigram. This is enough to guide engineers but for scientific work, I would expect comparisons with related work, even if they are not widely adopted. For instance, how does it compare to other adaptive tokenizers such as the one proposed by “Task-Adaptive Tokenization: Enhancing Long-Form Text Generation Efficacy in Mental Health and Beyond” (not cited)?
- The limitations of this work are not very well discussed. When does ADAT completely fail? For which scenario shouldn’t we use it?",The main suggestion that I have for this work would be to compare it with other tokenizers that might not be mainstream but that have been shown to perform better. Comparing it with other Task-Adaptive Tokenizers would be a start.,See weaknesses.,['No ethics review needed.'],5,2,,Yes,2,3,2,1720803118585,,,NeurIPS.cc/2024/Conference,3H1wqEdK4z,"['NeurIPS.cc/2024/Conference/Submission5871/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879036181,[],2,,,['everyone'],3H1wqEdK4z,['NeurIPS.cc/2024/Conference/Submission5871/Reviewer_GBKH'],1720803118585,1730879036181,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5871/Reviewer_GBKH']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, namely ""Task-Adaptive Tokenization: Enhancing Long-Form Text Generation Efficacy in Mental Health and Beyond"". The reviewer mentions that this work is not cited and suggests comparing the proposed adaptive tokenizer (ADAT) with this task-adaptive tokenizer.",1,,Task-Adaptive Tokenization: Enhancing Long-Form Text Generation Efficacy in Mental Health and Beyond
dPZiZPoCui,"This paper studies the stability of circuits in language models during pre-training and across different model sizes. Specifically, it examines the Pythia model suite and a selection of four simple tasks with known circuits: indirect object identification (IOI), subject-verb agreement, greater-than, and gendered pronouns. The analysis involves multiple steps, each repeated across different model sizes (70m - 2.8b) and pre-training checkpoints: 

1. Evaluate the ability of the language model to solve each of these tasks. 
2. Evaluate the emergence of specific attention heads, which previous work has established as important for each of these tasks. 
3. Narrow down on the IOI task to evaluate whether the three core algorithmic steps, again known from previous work, are consistent across training and scale. To this end, the authors use path patching to ablate the connection between the components involved in each of these steps. 
4. Evaluate the consistency of the circuits during training by looking at component and edge overlap. To identify these circuits, the authors use edge attribution patching.

Overall, the results reveal a significant level of consistency of circuits during training and across scale: important attention heads tend to start emerging after roughly the same number of tokens, although at different paces; the effect of important heads in the IOI circuit is somewhat consistent once these components emerge; and there is significant circuit component overlap across checkpoints.","- The paper investigates an interesting question: to what extent might existing circuit analysis results generalise across training and scale? Understanding the training dynamics of circuits is important for the field of (mechanistic) interpretability.
- The authors employ a variety of analysis techniques, including path patching and edge attribution patching, to systematically and causally test their hypotheses.
- Despite focusing on a narrow set of tasks, the authors identify potentially general motifs, such as “load balancing”. These insights open up avenues for future work to develop a more fundamental understanding of the stability of circuits across training and scale.","- While the results demonstrate a significant degree of consistency and stability of circuits across training, the focus on a small number of simple tasks provides limited insight into whether circuits for other tasks are consistent as well. 
- The results reveal several training dynamics that are left unexplored. For example, load balancing or the observation that many attention heads emerge after roughly the same number could have been explored in more detail. I believe a detailed investigation of one of these phenomenons could have significantly improved the paper.

Minor issues:
- The title of the paper (“Stability and Generalizability of Language Model Mechanisms Across Training and Scale”) does not match the title in OpenReview (“LLM Circuit Analyses Are Consistent Across Training and Scale”). 
- Typo in L67: “… we can verify that they are …”","1. In Figure 5, you focused on the Jaccard similarity with *all* previous checkpoints. This makes it hard to evaluate whether circuits had phases of high consistency with only the previous checkpoint. Did you observe any periods of significant circuit stability during training? This would be interesting to see as the authors of latent state models of training dynamics [1] suggest phase transitions between different algorithmic solutions.

2. You mention that “Circuits in larger models require more components, with circuit sizes positively  correlating with model scale” in your contributions, but I don’t see this discussed in the following sections. Have you been able to study how these circuits differ across scale? Do we find duplications of the same components? How does this relate to the higher stability of circuits in larger models?

[1] M. Y. Hu, A. Chen, N. Saphra, and K. Cho, ‘Latent State Models of Training Dynamics’, arXiv [cs.LG]. 2024.","The selection of tasks limits the generalisation of their findings, as previous studies suggested that various behaviours of language models emerge at scale [2] or qualitatively change across scale [3]. Both of these suggest that circuits still fundamentally change for more complex tasks. However, I believe that this is mostly addressed in the limitations section of the paper.

[2] J. Wei et al., ‘Emergent Abilities of Large Language Models’, arXiv [cs.CL]. 2022.

[3] J. Wei et al., ‘Larger Language Models Do In-Context Learning Differently’, arXiv [cs.CL]. 2023.",['No ethics review needed.'],7,4,,Yes,2,4,3,1720046298492,,,NeurIPS.cc/2024/Conference,3Ds5vNudIE,"['NeurIPS.cc/2024/Conference/Submission19968/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880078078,[],2,,,['everyone'],3Ds5vNudIE,['NeurIPS.cc/2024/Conference/Submission19968/Reviewer_wt3i'],1720046298492,1730880078078,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission19968/Reviewer_wt3i']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. M. Y. Hu, A. Chen, N. Saphra, and K. Cho, ‘Latent State Models of Training Dynamics’, arXiv [cs.LG]. 2024.
2. J. Wei et al., ‘Emergent Abilities of Large Language Models’, arXiv [cs.CL]. 2022.
3. J. Wei et al., ‘Larger Language Models Do In-Context Learning Differently’, arXiv [cs.CL]. 2023.

These citations are mentioned in the ""questions"" and ""limitations"" sections of the peer review, and are related to the topics of training dynamics, emergent abilities of large language models, and how larger language models learn differently.",1,"2024, 2022, 2023",Latent State Models of Training Dynamics 
dPZiZPoCui,"This paper studies the stability of circuits in language models during pre-training and across different model sizes. Specifically, it examines the Pythia model suite and a selection of four simple tasks with known circuits: indirect object identification (IOI), subject-verb agreement, greater-than, and gendered pronouns. The analysis involves multiple steps, each repeated across different model sizes (70m - 2.8b) and pre-training checkpoints: 

1. Evaluate the ability of the language model to solve each of these tasks. 
2. Evaluate the emergence of specific attention heads, which previous work has established as important for each of these tasks. 
3. Narrow down on the IOI task to evaluate whether the three core algorithmic steps, again known from previous work, are consistent across training and scale. To this end, the authors use path patching to ablate the connection between the components involved in each of these steps. 
4. Evaluate the consistency of the circuits during training by looking at component and edge overlap. To identify these circuits, the authors use edge attribution patching.

Overall, the results reveal a significant level of consistency of circuits during training and across scale: important attention heads tend to start emerging after roughly the same number of tokens, although at different paces; the effect of important heads in the IOI circuit is somewhat consistent once these components emerge; and there is significant circuit component overlap across checkpoints.","- The paper investigates an interesting question: to what extent might existing circuit analysis results generalise across training and scale? Understanding the training dynamics of circuits is important for the field of (mechanistic) interpretability.
- The authors employ a variety of analysis techniques, including path patching and edge attribution patching, to systematically and causally test their hypotheses.
- Despite focusing on a narrow set of tasks, the authors identify potentially general motifs, such as “load balancing”. These insights open up avenues for future work to develop a more fundamental understanding of the stability of circuits across training and scale.","- While the results demonstrate a significant degree of consistency and stability of circuits across training, the focus on a small number of simple tasks provides limited insight into whether circuits for other tasks are consistent as well. 
- The results reveal several training dynamics that are left unexplored. For example, load balancing or the observation that many attention heads emerge after roughly the same number could have been explored in more detail. I believe a detailed investigation of one of these phenomenons could have significantly improved the paper.

Minor issues:
- The title of the paper (“Stability and Generalizability of Language Model Mechanisms Across Training and Scale”) does not match the title in OpenReview (“LLM Circuit Analyses Are Consistent Across Training and Scale”). 
- Typo in L67: “… we can verify that they are …”","1. In Figure 5, you focused on the Jaccard similarity with *all* previous checkpoints. This makes it hard to evaluate whether circuits had phases of high consistency with only the previous checkpoint. Did you observe any periods of significant circuit stability during training? This would be interesting to see as the authors of latent state models of training dynamics [1] suggest phase transitions between different algorithmic solutions.

2. You mention that “Circuits in larger models require more components, with circuit sizes positively  correlating with model scale” in your contributions, but I don’t see this discussed in the following sections. Have you been able to study how these circuits differ across scale? Do we find duplications of the same components? How does this relate to the higher stability of circuits in larger models?

[1] M. Y. Hu, A. Chen, N. Saphra, and K. Cho, ‘Latent State Models of Training Dynamics’, arXiv [cs.LG]. 2024.","The selection of tasks limits the generalisation of their findings, as previous studies suggested that various behaviours of language models emerge at scale [2] or qualitatively change across scale [3]. Both of these suggest that circuits still fundamentally change for more complex tasks. However, I believe that this is mostly addressed in the limitations section of the paper.

[2] J. Wei et al., ‘Emergent Abilities of Large Language Models’, arXiv [cs.CL]. 2022.

[3] J. Wei et al., ‘Larger Language Models Do In-Context Learning Differently’, arXiv [cs.CL]. 2023.",['No ethics review needed.'],7,4,,Yes,2,4,3,1720046298492,,,NeurIPS.cc/2024/Conference,3Ds5vNudIE,"['NeurIPS.cc/2024/Conference/Submission19968/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880078078,[],2,,,['everyone'],3Ds5vNudIE,['NeurIPS.cc/2024/Conference/Submission19968/Reviewer_wt3i'],1720046298492,1730880078078,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission19968/Reviewer_wt3i']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. M. Y. Hu, A. Chen, N. Saphra, and K. Cho, ‘Latent State Models of Training Dynamics’, arXiv [cs.LG]. 2024.
2. J. Wei et al., ‘Emergent Abilities of Large Language Models’, arXiv [cs.CL]. 2022.
3. J. Wei et al., ‘Larger Language Models Do In-Context Learning Differently’, arXiv [cs.CL]. 2023.

These citations are mentioned in the ""questions"" and ""limitations"" sections of the peer review, and are related to the topics of training dynamics, emergent abilities of large language models, and how larger language models learn differently.",1,"2024, 2022, 2023",Emergent Abilities of Large Language Models 
dPZiZPoCui,"This paper studies the stability of circuits in language models during pre-training and across different model sizes. Specifically, it examines the Pythia model suite and a selection of four simple tasks with known circuits: indirect object identification (IOI), subject-verb agreement, greater-than, and gendered pronouns. The analysis involves multiple steps, each repeated across different model sizes (70m - 2.8b) and pre-training checkpoints: 

1. Evaluate the ability of the language model to solve each of these tasks. 
2. Evaluate the emergence of specific attention heads, which previous work has established as important for each of these tasks. 
3. Narrow down on the IOI task to evaluate whether the three core algorithmic steps, again known from previous work, are consistent across training and scale. To this end, the authors use path patching to ablate the connection between the components involved in each of these steps. 
4. Evaluate the consistency of the circuits during training by looking at component and edge overlap. To identify these circuits, the authors use edge attribution patching.

Overall, the results reveal a significant level of consistency of circuits during training and across scale: important attention heads tend to start emerging after roughly the same number of tokens, although at different paces; the effect of important heads in the IOI circuit is somewhat consistent once these components emerge; and there is significant circuit component overlap across checkpoints.","- The paper investigates an interesting question: to what extent might existing circuit analysis results generalise across training and scale? Understanding the training dynamics of circuits is important for the field of (mechanistic) interpretability.
- The authors employ a variety of analysis techniques, including path patching and edge attribution patching, to systematically and causally test their hypotheses.
- Despite focusing on a narrow set of tasks, the authors identify potentially general motifs, such as “load balancing”. These insights open up avenues for future work to develop a more fundamental understanding of the stability of circuits across training and scale.","- While the results demonstrate a significant degree of consistency and stability of circuits across training, the focus on a small number of simple tasks provides limited insight into whether circuits for other tasks are consistent as well. 
- The results reveal several training dynamics that are left unexplored. For example, load balancing or the observation that many attention heads emerge after roughly the same number could have been explored in more detail. I believe a detailed investigation of one of these phenomenons could have significantly improved the paper.

Minor issues:
- The title of the paper (“Stability and Generalizability of Language Model Mechanisms Across Training and Scale”) does not match the title in OpenReview (“LLM Circuit Analyses Are Consistent Across Training and Scale”). 
- Typo in L67: “… we can verify that they are …”","1. In Figure 5, you focused on the Jaccard similarity with *all* previous checkpoints. This makes it hard to evaluate whether circuits had phases of high consistency with only the previous checkpoint. Did you observe any periods of significant circuit stability during training? This would be interesting to see as the authors of latent state models of training dynamics [1] suggest phase transitions between different algorithmic solutions.

2. You mention that “Circuits in larger models require more components, with circuit sizes positively  correlating with model scale” in your contributions, but I don’t see this discussed in the following sections. Have you been able to study how these circuits differ across scale? Do we find duplications of the same components? How does this relate to the higher stability of circuits in larger models?

[1] M. Y. Hu, A. Chen, N. Saphra, and K. Cho, ‘Latent State Models of Training Dynamics’, arXiv [cs.LG]. 2024.","The selection of tasks limits the generalisation of their findings, as previous studies suggested that various behaviours of language models emerge at scale [2] or qualitatively change across scale [3]. Both of these suggest that circuits still fundamentally change for more complex tasks. However, I believe that this is mostly addressed in the limitations section of the paper.

[2] J. Wei et al., ‘Emergent Abilities of Large Language Models’, arXiv [cs.CL]. 2022.

[3] J. Wei et al., ‘Larger Language Models Do In-Context Learning Differently’, arXiv [cs.CL]. 2023.",['No ethics review needed.'],7,4,,Yes,2,4,3,1720046298492,,,NeurIPS.cc/2024/Conference,3Ds5vNudIE,"['NeurIPS.cc/2024/Conference/Submission19968/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880078078,[],2,,,['everyone'],3Ds5vNudIE,['NeurIPS.cc/2024/Conference/Submission19968/Reviewer_wt3i'],1720046298492,1730880078078,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission19968/Reviewer_wt3i']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. M. Y. Hu, A. Chen, N. Saphra, and K. Cho, ‘Latent State Models of Training Dynamics’, arXiv [cs.LG]. 2024.
2. J. Wei et al., ‘Emergent Abilities of Large Language Models’, arXiv [cs.CL]. 2022.
3. J. Wei et al., ‘Larger Language Models Do In-Context Learning Differently’, arXiv [cs.CL]. 2023.

These citations are mentioned in the ""questions"" and ""limitations"" sections of the peer review, and are related to the topics of training dynamics, emergent abilities of large language models, and how larger language models learn differently.",1,"2024, 2022, 2023",Larger Language Models Do In-Context Learning Differently
WzkWajYSx8,"This study explores the emergence and evolution of internal mechanisms in language models of varied sizes during the training process. Specifically, it examines simple tasks such as IOI, Greater-than, Gender Pronoun, and Subject-verb agreement using Pythia models. The findings indicate that models of different sizes tend to learn these tasks after a similar number of token counts during training. Moreover, while individual components of the models may change in functionality, the overall algorithm implemented by the models remains consistent throughout the training process. Lastly, the study identifies that once a circuit emerges, it generally remains stable thereafter.","1. This work is highly relevant for two key reasons: 
   - Most mechanistic interpretability studies do not examine the internal mechanisms of models throughout the training and fine-tuning processes. As a result, they fail to offer a comprehensive understanding of how and when a model learns its mechanisms and how these mechanisms evolve after their creation.
   - Unlike many existing studies, this work analyzes multiple tasks across various models of different sizes.
2. The results from Section 4 indicate that, although some components of the model change their functionality, the overall algorithm used by the model to solve simple tasks, such as IOI, remains consistent. This finding aligns with previous results from [1], which state that even though fine-tuned models have larger circuits, their mechanisms remain consistent, even for more complex tasks like entity tracking.
3. The presentation is clear, but it does require the reader to have some background in mechanistic interpretability. Additionally, there are a few other pertinent works on mechanistically understanding the impact of fine-tuning that the authors should cite [2, 3].


[1] Prakash et al, ""Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking"", 2024.

[2] Jain et al, “Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks”, 2023.

[3] Lee et al, “A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity”, 2024.","1. I’m unsure about the results of section 3.2 stating that emergence of circuit components that are involved in the internal computation of the tasks at the same time as the model behavior performance, suggests that the former is responsible for the emergence of latter, because of the following reasons:
   - All the model heads are evaluated, rather than only those involved in the circuit performing the task. It is possible that some heads exhibit certain behaviors without actually being part of the circuit. Thus, concluding that their occurrence is responsible for the model's performance could be misleading.
   - Furthermore, the analysis is primarily conducted for a single task, IOI, rather than all four tasks mentioned earlier. Although some of the heads studied are involved in the Greater-than tasks, MLP neurons, which have been shown to be part of the circuit, are not analyzed.
2. While it is interesting to note that individual circuit components emerge simultaneously with the model's behavior, it still does not explain why these components emerge after similar token counts in models of varied scales.
3. Section 4 investigates only the IOI task, which raises concerns regarding the generalizability of its results.","1. The finding that models of varied sizes learn a task after a similar number of tokens is intriguing and somewhat counterintuitive. This makes me wonder if analyzing how gradient updates modify model weights and comparing these changes across models could provide a better understanding of how language models learn (potentially in future works).
2. Section 3.2 states that to validate the importance of four mentioned types of attention heads, a circuit is discovered for each model at each checkpoint. I’m unsure of what a circuit discovery algorithm will discover for early checkpoints where the model does not even have behavioral ability to perform the task. So, it’s surprising to me that authors were still able to identify circuits and functionality of their components which is consistent with existing discovered circuits in the literature. I would like to see evaluation results of these circuits.
3. Section 2.2 mentions that there is no definitive method for verifying the entirety of the identified circuit. This needs more explanation,  particularly regarding why metrics like completeness proposed in [4] are considered inadequate for this purpose.

[4] Wang et al, “Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small”, 2022.","The primary limitation of this work is the use of simple tasks such as IOI, Greater-than, Subject-verb, and Gender Pronoun for analysis. Some of the results may not be applicable to more complex tasks. Additionally, relying solely on Pythia model suits trained using the same training data poses a risk to the generalizability of the findings. However, despite these limitations, the results are insightful and should be valuable for the mechanistic interpretability community and beyond.",['No ethics review needed.'],6,4,,Yes,4,3,3,1720197139224,,,NeurIPS.cc/2024/Conference,3Ds5vNudIE,"['NeurIPS.cc/2024/Conference/Submission19968/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880077919,[],3,,,['everyone'],3Ds5vNudIE,['NeurIPS.cc/2024/Conference/Submission19968/Reviewer_865w'],1720197139224,1730880077919,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission19968/Reviewer_865w']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. It mentions that there are a few other pertinent works on mechanistically understanding the impact of fine-tuning that the authors should cite, specifically:

1. Jain et al, “Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks”, 2023.
2. Lee et al, “A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity”, 2024.

Additionally, it references another work (Wang et al, “Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small”, 2022) and a previous result from Prakash et al, ""Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking"", 2024, but these are not suggestions for additional citations, rather they are used to support or compare the findings of the paper being reviewed.",1,"2023, 2024, 2022, 2024",Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks 
WzkWajYSx8,"This study explores the emergence and evolution of internal mechanisms in language models of varied sizes during the training process. Specifically, it examines simple tasks such as IOI, Greater-than, Gender Pronoun, and Subject-verb agreement using Pythia models. The findings indicate that models of different sizes tend to learn these tasks after a similar number of token counts during training. Moreover, while individual components of the models may change in functionality, the overall algorithm implemented by the models remains consistent throughout the training process. Lastly, the study identifies that once a circuit emerges, it generally remains stable thereafter.","1. This work is highly relevant for two key reasons: 
   - Most mechanistic interpretability studies do not examine the internal mechanisms of models throughout the training and fine-tuning processes. As a result, they fail to offer a comprehensive understanding of how and when a model learns its mechanisms and how these mechanisms evolve after their creation.
   - Unlike many existing studies, this work analyzes multiple tasks across various models of different sizes.
2. The results from Section 4 indicate that, although some components of the model change their functionality, the overall algorithm used by the model to solve simple tasks, such as IOI, remains consistent. This finding aligns with previous results from [1], which state that even though fine-tuned models have larger circuits, their mechanisms remain consistent, even for more complex tasks like entity tracking.
3. The presentation is clear, but it does require the reader to have some background in mechanistic interpretability. Additionally, there are a few other pertinent works on mechanistically understanding the impact of fine-tuning that the authors should cite [2, 3].


[1] Prakash et al, ""Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking"", 2024.

[2] Jain et al, “Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks”, 2023.

[3] Lee et al, “A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity”, 2024.","1. I’m unsure about the results of section 3.2 stating that emergence of circuit components that are involved in the internal computation of the tasks at the same time as the model behavior performance, suggests that the former is responsible for the emergence of latter, because of the following reasons:
   - All the model heads are evaluated, rather than only those involved in the circuit performing the task. It is possible that some heads exhibit certain behaviors without actually being part of the circuit. Thus, concluding that their occurrence is responsible for the model's performance could be misleading.
   - Furthermore, the analysis is primarily conducted for a single task, IOI, rather than all four tasks mentioned earlier. Although some of the heads studied are involved in the Greater-than tasks, MLP neurons, which have been shown to be part of the circuit, are not analyzed.
2. While it is interesting to note that individual circuit components emerge simultaneously with the model's behavior, it still does not explain why these components emerge after similar token counts in models of varied scales.
3. Section 4 investigates only the IOI task, which raises concerns regarding the generalizability of its results.","1. The finding that models of varied sizes learn a task after a similar number of tokens is intriguing and somewhat counterintuitive. This makes me wonder if analyzing how gradient updates modify model weights and comparing these changes across models could provide a better understanding of how language models learn (potentially in future works).
2. Section 3.2 states that to validate the importance of four mentioned types of attention heads, a circuit is discovered for each model at each checkpoint. I’m unsure of what a circuit discovery algorithm will discover for early checkpoints where the model does not even have behavioral ability to perform the task. So, it’s surprising to me that authors were still able to identify circuits and functionality of their components which is consistent with existing discovered circuits in the literature. I would like to see evaluation results of these circuits.
3. Section 2.2 mentions that there is no definitive method for verifying the entirety of the identified circuit. This needs more explanation,  particularly regarding why metrics like completeness proposed in [4] are considered inadequate for this purpose.

[4] Wang et al, “Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small”, 2022.","The primary limitation of this work is the use of simple tasks such as IOI, Greater-than, Subject-verb, and Gender Pronoun for analysis. Some of the results may not be applicable to more complex tasks. Additionally, relying solely on Pythia model suits trained using the same training data poses a risk to the generalizability of the findings. However, despite these limitations, the results are insightful and should be valuable for the mechanistic interpretability community and beyond.",['No ethics review needed.'],6,4,,Yes,4,3,3,1720197139224,,,NeurIPS.cc/2024/Conference,3Ds5vNudIE,"['NeurIPS.cc/2024/Conference/Submission19968/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880077919,[],3,,,['everyone'],3Ds5vNudIE,['NeurIPS.cc/2024/Conference/Submission19968/Reviewer_865w'],1720197139224,1730880077919,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission19968/Reviewer_865w']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. It mentions that there are a few other pertinent works on mechanistically understanding the impact of fine-tuning that the authors should cite, specifically:

1. Jain et al, “Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks”, 2023.
2. Lee et al, “A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity”, 2024.

Additionally, it references another work (Wang et al, “Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small”, 2022) and a previous result from Prakash et al, ""Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking"", 2024, but these are not suggestions for additional citations, rather they are used to support or compare the findings of the paper being reviewed.",1,"2023, 2024, 2022, 2024",A Mechanistic Understanding of Alignment Algorithms A Case Study on DPO and Toxicity
b0ZMjUd5j5,"The paper focuses on improving the expressiveness of digital human avatars, particularly through detailed hand and facial expressions, learned from monocular RGB video. The main contributions are:
- SMPL-X Alignment improves the alignment of the SMPL-X model with RGB frames and aids in accurately recovering avatars. 
- Context-Aware Adaptive Density Control Strategy adjusts gradient thresholds to handle the varied granularity across different body parts, enhancing the expressiveness of the avatars.
- Feedback Mechanism that predicts per-pixel confidence to better guide the learning and optimization of 3D Gaussians.

Overall, the paper presents a comprehensive framework that enhances the realism and expressiveness of digital human representations, validated by substantial quantitative and qualitative experiments.",The paper is written in a clear and understandable manner. Comprehensive ablation studies and clear visualizations help to demonstrate the effectiveness of different components of the method. The paper also compares the new method with previous methods and shows that it achieves better performance. It is commendable that the authors added SMPL-X to existing methods for fair and thorough comparisons.,"- One of the contributions of using and optimizing SMPL-X for expressive avatar is not novel. This has been done in previous works [1]. 
- The paper lacks a comparison to recent methods such as Splatting Avatar [2]. Including this comparison in Table 1 can help to distinguish the improvement made by the proposed approach. 
- There is an inconsistent ablation study across the datasets. Table 2 should illustrate how the alignment affects the baseline method by comparing scenarios with and without CADC, CL, and alignment. Similarly, Table 3 should also show the method with CADC and CL included.
- PSNR, SSIM, and LPIPS should be calculated from four novel views to ensure the robustness of the method across different perspectives. Additionally, animation and novel pose metrics can be included to display differences between methods.
- From Table 2, it seems that CL does not have a significant impact. This should be addressed or clarified to understand its role in the framework. It would be good to provide more qualitative visualization to demonstrate its effectiveness. 


[1] (Liu et al., 2024) GVA: Reconstructing Vivid 3D Gaussian Avatars from Monocular Videos. 

[2] (Shao et al., 2024) SplattingAvatar: Realistic Real-Time Human Avatars with Mesh-Embedded Gaussian Splatting.","- **Project Page for Visualizations:** Is there a project page available that shows visualizations of the rendered method, such as a 360-degree rotating video of the generated person and animation to better illustrate the quality? Specifically, could visualizations zoom into detailed areas such as the hands and face?
- Is e and λt in Equation 14 learned or fixed? If learned, it would be advantageous to list the values to demonstrate that the learned parameters effectively handle different resolution details for different body parts.
- Discussing failure cases and outlining potential future work would provide a more comprehensive view of the method's limitations and areas for improvement.
- Information on the optimization time compared to previous methods and the resource requirements for running the proposed method would be valuable for assessing its efficiency and scalability.","While the use of CADC is interesting, the other two contributions are of limited novelty. SMPL-X usage and alignment have been incorporated by previous works. The improvement of CL is not significant. The addition of project page for visualizations would be helpful to demonstrate the improvements made by the methods. In addition, more quantitative results should be added to Tables 1, 2 and 3.",['No ethics review needed.'],5,4,,Yes,3,3,3,1720589670665,,,NeurIPS.cc/2024/Conference,3CweLZFNyl,"['NeurIPS.cc/2024/Conference/Submission3671/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878867161,[],1,,,['everyone'],3CweLZFNyl,['NeurIPS.cc/2024/Conference/Submission3671/Reviewer_ZKQ6'],1720589670665,1730878867161,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3671/Reviewer_ZKQ6']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. [1] (Liu et al., 2024) GVA: Reconstructing Vivid 3D Gaussian Avatars from Monocular Videos.
2. [2] (Shao et al., 2024) SplattingAvatar: Realistic Real-Time Human Avatars with Mesh-Embedded Gaussian Splatting.

The reviewer mentions that the use of SMPL-X for expressive avatars is not novel and has been done in previous works, citing [1]. They also suggest that the authors should include a comparison to recent methods such as Splatting Avatar [2] in Table 1 to distinguish the improvement made by the proposed approach.",1,"2024, 2024",GVA: Reconstructing Vivid 3D Gaussian Avatars from Monocular Videos
b0ZMjUd5j5,"The paper focuses on improving the expressiveness of digital human avatars, particularly through detailed hand and facial expressions, learned from monocular RGB video. The main contributions are:
- SMPL-X Alignment improves the alignment of the SMPL-X model with RGB frames and aids in accurately recovering avatars. 
- Context-Aware Adaptive Density Control Strategy adjusts gradient thresholds to handle the varied granularity across different body parts, enhancing the expressiveness of the avatars.
- Feedback Mechanism that predicts per-pixel confidence to better guide the learning and optimization of 3D Gaussians.

Overall, the paper presents a comprehensive framework that enhances the realism and expressiveness of digital human representations, validated by substantial quantitative and qualitative experiments.",The paper is written in a clear and understandable manner. Comprehensive ablation studies and clear visualizations help to demonstrate the effectiveness of different components of the method. The paper also compares the new method with previous methods and shows that it achieves better performance. It is commendable that the authors added SMPL-X to existing methods for fair and thorough comparisons.,"- One of the contributions of using and optimizing SMPL-X for expressive avatar is not novel. This has been done in previous works [1]. 
- The paper lacks a comparison to recent methods such as Splatting Avatar [2]. Including this comparison in Table 1 can help to distinguish the improvement made by the proposed approach. 
- There is an inconsistent ablation study across the datasets. Table 2 should illustrate how the alignment affects the baseline method by comparing scenarios with and without CADC, CL, and alignment. Similarly, Table 3 should also show the method with CADC and CL included.
- PSNR, SSIM, and LPIPS should be calculated from four novel views to ensure the robustness of the method across different perspectives. Additionally, animation and novel pose metrics can be included to display differences between methods.
- From Table 2, it seems that CL does not have a significant impact. This should be addressed or clarified to understand its role in the framework. It would be good to provide more qualitative visualization to demonstrate its effectiveness. 


[1] (Liu et al., 2024) GVA: Reconstructing Vivid 3D Gaussian Avatars from Monocular Videos. 

[2] (Shao et al., 2024) SplattingAvatar: Realistic Real-Time Human Avatars with Mesh-Embedded Gaussian Splatting.","- **Project Page for Visualizations:** Is there a project page available that shows visualizations of the rendered method, such as a 360-degree rotating video of the generated person and animation to better illustrate the quality? Specifically, could visualizations zoom into detailed areas such as the hands and face?
- Is e and λt in Equation 14 learned or fixed? If learned, it would be advantageous to list the values to demonstrate that the learned parameters effectively handle different resolution details for different body parts.
- Discussing failure cases and outlining potential future work would provide a more comprehensive view of the method's limitations and areas for improvement.
- Information on the optimization time compared to previous methods and the resource requirements for running the proposed method would be valuable for assessing its efficiency and scalability.","While the use of CADC is interesting, the other two contributions are of limited novelty. SMPL-X usage and alignment have been incorporated by previous works. The improvement of CL is not significant. The addition of project page for visualizations would be helpful to demonstrate the improvements made by the methods. In addition, more quantitative results should be added to Tables 1, 2 and 3.",['No ethics review needed.'],5,4,,Yes,3,3,3,1720589670665,,,NeurIPS.cc/2024/Conference,3CweLZFNyl,"['NeurIPS.cc/2024/Conference/Submission3671/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878867161,[],1,,,['everyone'],3CweLZFNyl,['NeurIPS.cc/2024/Conference/Submission3671/Reviewer_ZKQ6'],1720589670665,1730878867161,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3671/Reviewer_ZKQ6']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. [1] (Liu et al., 2024) GVA: Reconstructing Vivid 3D Gaussian Avatars from Monocular Videos.
2. [2] (Shao et al., 2024) SplattingAvatar: Realistic Real-Time Human Avatars with Mesh-Embedded Gaussian Splatting.

The reviewer mentions that the use of SMPL-X for expressive avatars is not novel and has been done in previous works, citing [1]. They also suggest that the authors should include a comparison to recent methods such as Splatting Avatar [2] in Table 1 to distinguish the improvement made by the proposed approach.",1,"2024, 2024",SplattingAvatar: Realistic Real-Time Human Avatars with Mesh-Embedded Gaussian Splatting
h221YgtoxI,"In the paper ""Better by default: Strong pre-tuned MLPs and boosted trees on tabular data"", the authors make two major contributions: (i) they propose a multi-layer perceptron configurations that is tuned on a set of training datasets and (ii) investigate in a large scale empirical study how different default parameterizations (library vs tuned on a set of training datasets) compares to optimized hyperparameters on a set of test datasets. The study reveals interesting results regarding the performance of default parameterizations set in standard ML libraries, better default parameterizations exist (at least for the scope of the benchmark), and that the proposed MLP often performs competitive to gradient-boosted decision trees when it comes to a Pareto-optimal tradeoff between accuracy and training time.","- The paper is very well written and easy to follow. Sufficient details on the architecture of RealMLP and the implementation of tuning the default parameterization or optimizing the hyperparameters are given.
- Generally speaking, the authors are very eager to provide all the details to make their work reproducible which is of high importance for such a paper.
- In principle, I like the 2D-comparisons but a summary plot how the D vs TD vs HPO behaves for the different methods would be very much appreciated.","- Intuitively one would expect that the performance of TD lies in between D and HPO but I could also imagine that TD is oftentimes very close to HPO or might even exceed HPO's performance due to overtuning. But this comparison is not considered as an overview.
- It is not clear why random search has been used as HPO technique in the paper, especially, since the authors even mention more sophisticated techniques such as SMAC that are based on Bayesian optimization.
- The style of writing in Section 3 could be improved as there are various content-wise enumerations in the form of sentences starting with ""We"".","- How would a CASH approach compare here if we would first select the learning algorithm according to the (tuned) default parameterization and then optimize its hyperparameters? As it is done in Mohr, F., Wever, M. Naive automated machine learning. Mach Learn 112, 1131–1170 (2023). https://doi.org/10.1007/s10994-022-06200-0
- Why was random search used for hyperparameter optimization?
- Is there any intuition why using the last of tied epochs as the final model as stated on line 161?
- Why are hyperparameter values rounded as stated on line 170?",Limitations have properly been described in the paper.,['No ethics review needed.'],7,4,,Yes,4,4,4,1720510824086,,,NeurIPS.cc/2024/Conference,3BNPUDvqMt,"['NeurIPS.cc/2024/Conference/Submission21034/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880157925,[],2,,,['everyone'],3BNPUDvqMt,['NeurIPS.cc/2024/Conference/Submission21034/Reviewer_J8gT'],1720510824086,1730880157925,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission21034/Reviewer_J8gT']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature, namely:

Mohr, F., Wever, M. Naive automated machine learning. Mach Learn 112, 1131–1170 (2023). https://doi.org/10.1007/s10994-022-06200-0

This is mentioned in the ""questions"" section of the review, where the reviewer asks how a CASH approach (as described in the mentioned paper) would compare to the methods presented in the paper.",1,2023,Naive automated machine learning
ZVOf1MtIWX,"The paper introduces a method called D2DMoE aimed at enhancing the efficiency of transformer models. D2DMoE implements a dynamic-k routing mechanism that allows the model to select a variable number of experts based on the input. The method leverages the inherent activation sparsity in transformer models to reduce the number of active parameters during inference, leading to significant computational savings—up to 60%—without compromising performance. The approach demonstrates that by converting dense layers into Mixture-of-Experts (MoE) layers, transformer models can achieve better accuracy-sparsity trade-offs, making them more efficient for various NLP and vision tasks.","The paper presents a thorough empirical evaluation across multiple tasks (image classification, text classification, language modeling) and model architectures (ViT, BERT, GPT-2, Gemma). The experiments compare against relevant baselines and demonstrate consistent improvements.","In my view, this paper appears to be primarily a repackaged sparse-activated pruning technique stemming from the MoE concept. Several concerns arise:

1. Limited comparison with alternative sparsification methods: The paper predominantly contrasts with MoEfication, neglecting a thorough analysis against other compression or sparsification strategies beyond early-exit techniques. Consequently, the comparative experiments presented lack depth and fail to be fully convincing.

2. Lack of practical acceleration results: The paper only presents theoretical reductions in FLOPs and parameter counts. Without actual inference acceleration results on real hardware (e.g., V100, H100, GTX-4090Ti), it's impossible to assess the practical benefits of the method. The additional overhead from the gating mechanism could potentially negate some of the theoretical gains.

3. Questionable novelty of Dynamic-k gating: The proposed expert selection based on ℓ2-norm of output is indeed more reminiscent of pruning techniques than traditional MoE approaches. This calls into question the novelty of the method when viewed in the context of pruning literature, and makes the comparisons with MoE methods potentially unfair or irrelevant.

4. Limited novelty and inadequate discussion of related work: Many of the proposed operations bear similarities to existing sparse activation pruning methods. The paper fails to adequately discuss these connections, instead focusing on less relevant work. This omission of crucial related work in pruning literature significantly undermines the claimed novelty of the approach.

5. Lack of discussion of some SOTA sparse methods: such as Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models. ICML2024.

6. Theoretical foundation: The paper lacks a strong theoretical justification for why the proposed methods work better, which becomes even more critical given the concerns about its relationship to existing pruning techniques.",See weaknesses.,,['No ethics review needed.'],5,5,,Yes,3,3,3,1722330521110,,,NeurIPS.cc/2024/Conference,38UFpdt3Tr,"['NeurIPS.cc/2024/Conference/Submission4114/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878900136,[],5,,,['everyone'],38UFpdt3Tr,['NeurIPS.cc/2024/Conference/Submission4114/Reviewer_VwY8'],1722330521110,1730878900136,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4114/Reviewer_VwY8']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, namely ""Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models. ICML2024"", which is mentioned as a state-of-the-art (SOTA) sparse method that the paper fails to discuss.",1,,Pruner-Zero Evolving Symbolic Pruning Metric From Scratch for Large Language Models
pDM2QR5Txi,"This paper introduces X-Ray, a new 3D representation designed for efficient generation of 3D objects from single images. The key idea is to represent a 3D object as a sequence of 2D ""surface frames"" capturing hit/miss, depth, normal, and color information along rays cast from the camera viewpoint. This sequential representation lends itself well to generation using video diffusion models, enabling the synthesis of both visible and hidden surfaces. The authors propose a pipeline consisting of an X-Ray diffusion model to generate low-resolution surface frames from an input image, followed by an X-Ray upsampler to enhance resolution. They evaluate their method on single-view 3D reconstruction and unconditional 3D shape generation tasks, reporting quantitative results on standard benchmarks.","- The paper tackles the important challenge of reconstructing complete 3D models, including hidden surfaces, from single images. This is a significant limitation of current rendering-based approaches, and the authors' focus on this problem is well-motivated and timely.

-  The X-Ray representation, while its novelty requires further substantiation, offers an intuitive way to encode 3D surface information in a sequential manner. By focusing solely on surface details rather than volumetric data, the representation has the potential to be more memory-efficient than voxel grids or dense point clouds, especially for objects with complex internal structures.

- The authors smartly leverage recent advancements in video diffusion models for 3D generation. This is a promising direction, as video diffusion models have shown impressive capabilities in synthesizing high-quality and temporally coherent sequences of images. Adapting these models to the task of 3D generation through the X-Ray representation is a reasonable and potentially fruitful approach.","- The paper does not provide a convincing argument for the novelty of the X-Ray representation. While its sequential capture of surface information is intuitive, a thorough comparison to existing techniques is lacking. Specifically, the authors should clearly differentiate X-Ray from methods like depth peeling, multi-view depth images, multi-plane images (MPI), and notably, the PI3D representation (Liu et al., CVPR 2024), which also leverages diffusion models for 3D generation. 
  * Liu, Ying-Tian, Yuan-Chen Guo, Guan Luo, Heyi Sun, Wei Yin, and Song-Hai Zhang. ""Pi3d: Efficient text-to-3d generation with pseudo-image diffusion."" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 19915-19924. 2024.

- The paper repeatedly emphasizes the efficiency of the X-Ray representation without providing concrete evidence or analysis. The authors should quantify their claims by comparing the memory footprint and computational costs of X-Ray to alternative representations like voxel grids, point clouds, and neural implicit representations (e.g., NeRFs) for objects of varying complexity.

- While leveraging video diffusion models is promising, the paper does not clearly articulate how the specific properties of the X-Ray representation are exploited within the diffusion process beyond being a sequential data format. Do the hit/miss indicators or the ordered nature of surface frames influence the model architecture or training? Would similar performance be achieved with alternative sequential representations as input to the diffusion model?

- The evaluation heavily relies on reconstruction metrics (CD, EMD), even when assessing a generative model. While these metrics are relevant for the single-view reconstruction task, they do not capture the generative capabilities of X-Ray. The authors should expand generative evaluation to diverse categories beyond ShapeNet Cars. The paper could assess generative quality by evaluating the diversity and realism of multiple shapes generated from the same input image.

- The evaluation would be also strengthened by: (1) Including recent SDS-based single-view 3D generation methods as baselines; (2) Providing visualizations of generated shapes for the unconditional generation experiment; (3) Dedicating a section to analyze failure cases, visually showcasing problematic inputs and outputs.","- Could the authors please elaborate on the key differences between the X-Ray representation and existing techniques like depth peeling, multi-view depth images, and multi-plane images (MPI)? Also please include the discussion with PI3D.

- To support the claims of efficiency, could the authors provide a quantitative analysis of the memory footprint and computational cost (encoding, decoding, generation) of X-Ray compared to voxel grids, point clouds, or NeRFs? This analysis should consider objects of varying complexity and resolutions.

- Could the authors please include generative metrics for the single-view 3D reconstruction experiments on GSO and OmniObject3D?","- The authors merely state limitations without explaining their causes, impact, or potential solutions. E.g., saying ""X-Ray frames become sparse"" is not enough. How does this sparsity affect generation? How can it be addressed?",['No ethics review needed.'],5,4,,Yes,3,3,3,1720792735168,,,NeurIPS.cc/2024/Conference,36tMV15dPO,"['NeurIPS.cc/2024/Conference/Submission2779/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878802244,[],4,,,['everyone'],36tMV15dPO,['NeurIPS.cc/2024/Conference/Submission2779/Reviewer_xHzv'],1720792735168,1730878802244,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2779/Reviewer_xHzv']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

Liu, Ying-Tian, Yuan-Chen Guo, Guan Luo, Heyi Sun, Wei Yin, and Song-Hai Zhang. ""Pi3d: Efficient text-to-3d generation with pseudo-image diffusion."" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 19915-19924. 2024.

The reviewer mentions this paper in the weaknesses section, stating that the authors should clearly differentiate X-Ray from the PI3D representation, which also leverages diffusion models for 3D generation.",1,2024,Pi3d Efficient text-to-3d generation with pseudo-image diffusion
a8Mrkk9fcX,"They demonstrate that 1) pre-training loss is generally predictive of downstream capabilities in language models, rather than models size or number of tokens used during pre-training; and 2) emergent capabilities can also be clearly described in terms of pre-training loss. They also demonstrate that using continuous metrics, they still observe emergence, countering findings from prior work. They conduct their analysis on a suite of standard English and Chinese evals, using a range of models that they pre-trained themselves. They also further validate their findings using the llama and Pythia series of models.","* The paper does a good job of correcting an extremely prominent (but largely incorrect) narrative/claim that the phenomenon of emergence in LLMs always completely disappears when a continuous metric is used in place of a discontinuous one. This paper demonstrates a few cases where even in the presence of a continuous metric, emergence is still observed. Correcting this misconception in the scientific discourse is important.
* The paper is overall well written and the experiments are very thorough, encompassing a range of models and tasks.
* They even went out of their way to ablate the effect of learning rate schedule on their findings in Section 2.4, this is extremely thorough work, and they should be commended for it.

I have a handful of concerns regarding the writing, as discussed in the weaknesses section, but on balance I think this paper should be accepted, on the condition that my concerns are fixed in the camera ready.","* From the intro: ""For example, LLaMA-13B with less compute [53] can outperform GPT-3 (175B) on MMLU [21]"": Training for longer could be one explanation for this, another one could be llama used a higher quality corpus than gpt-3 did. I think the data quality element is a little underrated. In general we should expect different pretraining datasets to potentially have different loss / different emergence points (even if the x-axis loss is on a held out validation set and models have the same vocabulary). There is some discussion of this in the limitations section, but in general I think this point should be highlighted more in the paper. Concretely, the pretraining loss -> emergence point phenomenon is only guarenteed to be consistent for a series of models pretrained on the same data.
* The discussion of exact match in Section 2 kind of comes out no nowhere, and I'm not sure why it is discussed where it is. It would be great if there were more motivation for this in the paper.
* I understand why you did the ablation that you did in Section 2.4 (ablate the effect of lr schedule, as in Chinchilla), but in the paper this is not very clearly motivated and readers with less background knowledge might not understand why this ablation is important.
* “Note that there is one only exception at the early stage of LLaMA-65B. We can see that when the training loss is higher than 1.8, LLaMA-65B performs worse than smaller models with the same training loss.”: This could be because they used some exponential smoothing on either their loss or downstream performance plots. Exponential smoothing would perturb the earlier points more than other points (especially for curves that are fast changing or have a rapid change at the beginning), potentially leading to this effect. Moreover, did you smooth out the loss in some way when plotting loss verses downstream in the previous sections? If so, this would at least be good to note in the paper.
* Section 3.1 could use clearer discussion of explanations for why emergence occurs on the different tasks. I think grokking is a possible explanation, but what exactly grokking means (outside of the context of the simple algorithmic tasks presented in the original grokking paper) is a little vague/imprecise, and I also don't think this is the only explanation. In the case of gsm8k, emergence is, in my opinion, more likely due to the fact that the model has to get a sequence of reasoning steps correct to answer the question, this leads to an exponential (e.g. p(step_correct)^n_steps) for getting the full answer correct (some analysis of this in the paper could be cool). In the case of MMLU and C-Eval there actually is an existing paper which discovers an explanation, using interpretability techniques, for emergence on multiple choice tasks (https://arxiv.org/pdf/2307.09458).
* There's a handful of related works that aren't discussed in the paper and whose findings contradict those of this paper (I'll give you my reasoning for why your work might not contradict theirs, as a suggestion in parentheses, but you should include some discussion of this in the paper somewhere, either in the related work or elsewhere):
1) https://proceedings.mlr.press/v202/liu23ao.html (my understanding is that their theory only applies near the global optim, which is generally not the case with real-world language models)
2) https://arxiv.org/pdf/2109.10686 (see the paragraph ""zooming in verses zooming out"", your paper is more about the zoomed out setting)
3) Not strictly language modeling, but see Figure 3 of https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf (could be because they are doing probing so hidden-state size increases probe capacity causing differences with model size, but it's unclear if this is actually the case)",See the weaknesses for most of my questions/concerns.,No major limitations. See the weaknesses section.,['No ethics review needed.'],7,5,,Yes,4,3,4,1720564982439,,,NeurIPS.cc/2024/Conference,35DAviqMFo,"['NeurIPS.cc/2024/Conference/Submission16390/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879843205,[],3,,,['everyone'],35DAviqMFo,['NeurIPS.cc/2024/Conference/Submission16390/Reviewer_ZLu4'],1720564982439,1730879843205,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16390/Reviewer_ZLu4']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several related works that are not discussed in the paper, including:

1. https://proceedings.mlr.press/v202/liu23ao.html
2. https://arxiv.org/pdf/2109.10686
3. https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf
4. https://arxiv.org/pdf/2307.09458 (specifically mentioned as a paper that discovers an explanation for emergence on multiple choice tasks using interpretability techniques)

The reviewer suggests that the authors should include a discussion of these related works in the paper, either in the related work section or elsewhere, to address potential contradictions and provide a more comprehensive overview of the topic.",1,"2021, 2023",Emergence of Complex Behavior in Large Language Models
a8Mrkk9fcX,"They demonstrate that 1) pre-training loss is generally predictive of downstream capabilities in language models, rather than models size or number of tokens used during pre-training; and 2) emergent capabilities can also be clearly described in terms of pre-training loss. They also demonstrate that using continuous metrics, they still observe emergence, countering findings from prior work. They conduct their analysis on a suite of standard English and Chinese evals, using a range of models that they pre-trained themselves. They also further validate their findings using the llama and Pythia series of models.","* The paper does a good job of correcting an extremely prominent (but largely incorrect) narrative/claim that the phenomenon of emergence in LLMs always completely disappears when a continuous metric is used in place of a discontinuous one. This paper demonstrates a few cases where even in the presence of a continuous metric, emergence is still observed. Correcting this misconception in the scientific discourse is important.
* The paper is overall well written and the experiments are very thorough, encompassing a range of models and tasks.
* They even went out of their way to ablate the effect of learning rate schedule on their findings in Section 2.4, this is extremely thorough work, and they should be commended for it.

I have a handful of concerns regarding the writing, as discussed in the weaknesses section, but on balance I think this paper should be accepted, on the condition that my concerns are fixed in the camera ready.","* From the intro: ""For example, LLaMA-13B with less compute [53] can outperform GPT-3 (175B) on MMLU [21]"": Training for longer could be one explanation for this, another one could be llama used a higher quality corpus than gpt-3 did. I think the data quality element is a little underrated. In general we should expect different pretraining datasets to potentially have different loss / different emergence points (even if the x-axis loss is on a held out validation set and models have the same vocabulary). There is some discussion of this in the limitations section, but in general I think this point should be highlighted more in the paper. Concretely, the pretraining loss -> emergence point phenomenon is only guarenteed to be consistent for a series of models pretrained on the same data.
* The discussion of exact match in Section 2 kind of comes out no nowhere, and I'm not sure why it is discussed where it is. It would be great if there were more motivation for this in the paper.
* I understand why you did the ablation that you did in Section 2.4 (ablate the effect of lr schedule, as in Chinchilla), but in the paper this is not very clearly motivated and readers with less background knowledge might not understand why this ablation is important.
* “Note that there is one only exception at the early stage of LLaMA-65B. We can see that when the training loss is higher than 1.8, LLaMA-65B performs worse than smaller models with the same training loss.”: This could be because they used some exponential smoothing on either their loss or downstream performance plots. Exponential smoothing would perturb the earlier points more than other points (especially for curves that are fast changing or have a rapid change at the beginning), potentially leading to this effect. Moreover, did you smooth out the loss in some way when plotting loss verses downstream in the previous sections? If so, this would at least be good to note in the paper.
* Section 3.1 could use clearer discussion of explanations for why emergence occurs on the different tasks. I think grokking is a possible explanation, but what exactly grokking means (outside of the context of the simple algorithmic tasks presented in the original grokking paper) is a little vague/imprecise, and I also don't think this is the only explanation. In the case of gsm8k, emergence is, in my opinion, more likely due to the fact that the model has to get a sequence of reasoning steps correct to answer the question, this leads to an exponential (e.g. p(step_correct)^n_steps) for getting the full answer correct (some analysis of this in the paper could be cool). In the case of MMLU and C-Eval there actually is an existing paper which discovers an explanation, using interpretability techniques, for emergence on multiple choice tasks (https://arxiv.org/pdf/2307.09458).
* There's a handful of related works that aren't discussed in the paper and whose findings contradict those of this paper (I'll give you my reasoning for why your work might not contradict theirs, as a suggestion in parentheses, but you should include some discussion of this in the paper somewhere, either in the related work or elsewhere):
1) https://proceedings.mlr.press/v202/liu23ao.html (my understanding is that their theory only applies near the global optim, which is generally not the case with real-world language models)
2) https://arxiv.org/pdf/2109.10686 (see the paragraph ""zooming in verses zooming out"", your paper is more about the zoomed out setting)
3) Not strictly language modeling, but see Figure 3 of https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf (could be because they are doing probing so hidden-state size increases probe capacity causing differences with model size, but it's unclear if this is actually the case)",See the weaknesses for most of my questions/concerns.,No major limitations. See the weaknesses section.,['No ethics review needed.'],7,5,,Yes,4,3,4,1720564982439,,,NeurIPS.cc/2024/Conference,35DAviqMFo,"['NeurIPS.cc/2024/Conference/Submission16390/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879843205,[],3,,,['everyone'],35DAviqMFo,['NeurIPS.cc/2024/Conference/Submission16390/Reviewer_ZLu4'],1720564982439,1730879843205,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16390/Reviewer_ZLu4']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several related works that are not discussed in the paper, including:

1. https://proceedings.mlr.press/v202/liu23ao.html
2. https://arxiv.org/pdf/2109.10686
3. https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf
4. https://arxiv.org/pdf/2307.09458 (specifically mentioned as a paper that discovers an explanation for emergence on multiple choice tasks using interpretability techniques)

The reviewer suggests that the authors should include a discussion of these related works in the paper, either in the related work section or elsewhere, to address potential contradictions and provide a more comprehensive overview of the topic.",1,"2021, 2023",Generative Pretraining from Pixels
a8Mrkk9fcX,"They demonstrate that 1) pre-training loss is generally predictive of downstream capabilities in language models, rather than models size or number of tokens used during pre-training; and 2) emergent capabilities can also be clearly described in terms of pre-training loss. They also demonstrate that using continuous metrics, they still observe emergence, countering findings from prior work. They conduct their analysis on a suite of standard English and Chinese evals, using a range of models that they pre-trained themselves. They also further validate their findings using the llama and Pythia series of models.","* The paper does a good job of correcting an extremely prominent (but largely incorrect) narrative/claim that the phenomenon of emergence in LLMs always completely disappears when a continuous metric is used in place of a discontinuous one. This paper demonstrates a few cases where even in the presence of a continuous metric, emergence is still observed. Correcting this misconception in the scientific discourse is important.
* The paper is overall well written and the experiments are very thorough, encompassing a range of models and tasks.
* They even went out of their way to ablate the effect of learning rate schedule on their findings in Section 2.4, this is extremely thorough work, and they should be commended for it.

I have a handful of concerns regarding the writing, as discussed in the weaknesses section, but on balance I think this paper should be accepted, on the condition that my concerns are fixed in the camera ready.","* From the intro: ""For example, LLaMA-13B with less compute [53] can outperform GPT-3 (175B) on MMLU [21]"": Training for longer could be one explanation for this, another one could be llama used a higher quality corpus than gpt-3 did. I think the data quality element is a little underrated. In general we should expect different pretraining datasets to potentially have different loss / different emergence points (even if the x-axis loss is on a held out validation set and models have the same vocabulary). There is some discussion of this in the limitations section, but in general I think this point should be highlighted more in the paper. Concretely, the pretraining loss -> emergence point phenomenon is only guarenteed to be consistent for a series of models pretrained on the same data.
* The discussion of exact match in Section 2 kind of comes out no nowhere, and I'm not sure why it is discussed where it is. It would be great if there were more motivation for this in the paper.
* I understand why you did the ablation that you did in Section 2.4 (ablate the effect of lr schedule, as in Chinchilla), but in the paper this is not very clearly motivated and readers with less background knowledge might not understand why this ablation is important.
* “Note that there is one only exception at the early stage of LLaMA-65B. We can see that when the training loss is higher than 1.8, LLaMA-65B performs worse than smaller models with the same training loss.”: This could be because they used some exponential smoothing on either their loss or downstream performance plots. Exponential smoothing would perturb the earlier points more than other points (especially for curves that are fast changing or have a rapid change at the beginning), potentially leading to this effect. Moreover, did you smooth out the loss in some way when plotting loss verses downstream in the previous sections? If so, this would at least be good to note in the paper.
* Section 3.1 could use clearer discussion of explanations for why emergence occurs on the different tasks. I think grokking is a possible explanation, but what exactly grokking means (outside of the context of the simple algorithmic tasks presented in the original grokking paper) is a little vague/imprecise, and I also don't think this is the only explanation. In the case of gsm8k, emergence is, in my opinion, more likely due to the fact that the model has to get a sequence of reasoning steps correct to answer the question, this leads to an exponential (e.g. p(step_correct)^n_steps) for getting the full answer correct (some analysis of this in the paper could be cool). In the case of MMLU and C-Eval there actually is an existing paper which discovers an explanation, using interpretability techniques, for emergence on multiple choice tasks (https://arxiv.org/pdf/2307.09458).
* There's a handful of related works that aren't discussed in the paper and whose findings contradict those of this paper (I'll give you my reasoning for why your work might not contradict theirs, as a suggestion in parentheses, but you should include some discussion of this in the paper somewhere, either in the related work or elsewhere):
1) https://proceedings.mlr.press/v202/liu23ao.html (my understanding is that their theory only applies near the global optim, which is generally not the case with real-world language models)
2) https://arxiv.org/pdf/2109.10686 (see the paragraph ""zooming in verses zooming out"", your paper is more about the zoomed out setting)
3) Not strictly language modeling, but see Figure 3 of https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf (could be because they are doing probing so hidden-state size increases probe capacity causing differences with model size, but it's unclear if this is actually the case)",See the weaknesses for most of my questions/concerns.,No major limitations. See the weaknesses section.,['No ethics review needed.'],7,5,,Yes,4,3,4,1720564982439,,,NeurIPS.cc/2024/Conference,35DAviqMFo,"['NeurIPS.cc/2024/Conference/Submission16390/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879843205,[],3,,,['everyone'],35DAviqMFo,['NeurIPS.cc/2024/Conference/Submission16390/Reviewer_ZLu4'],1720564982439,1730879843205,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16390/Reviewer_ZLu4']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several related works that are not discussed in the paper, including:

1. https://proceedings.mlr.press/v202/liu23ao.html
2. https://arxiv.org/pdf/2109.10686
3. https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf
4. https://arxiv.org/pdf/2307.09458 (specifically mentioned as a paper that discovers an explanation for emergence on multiple choice tasks using interpretability techniques)

The reviewer suggests that the authors should include a discussion of these related works in the paper, either in the related work section or elsewhere, to address potential contradictions and provide a more comprehensive overview of the topic.",1,"2021, 2023",Learning to Reason with Emergent Relations
a8Mrkk9fcX,"They demonstrate that 1) pre-training loss is generally predictive of downstream capabilities in language models, rather than models size or number of tokens used during pre-training; and 2) emergent capabilities can also be clearly described in terms of pre-training loss. They also demonstrate that using continuous metrics, they still observe emergence, countering findings from prior work. They conduct their analysis on a suite of standard English and Chinese evals, using a range of models that they pre-trained themselves. They also further validate their findings using the llama and Pythia series of models.","* The paper does a good job of correcting an extremely prominent (but largely incorrect) narrative/claim that the phenomenon of emergence in LLMs always completely disappears when a continuous metric is used in place of a discontinuous one. This paper demonstrates a few cases where even in the presence of a continuous metric, emergence is still observed. Correcting this misconception in the scientific discourse is important.
* The paper is overall well written and the experiments are very thorough, encompassing a range of models and tasks.
* They even went out of their way to ablate the effect of learning rate schedule on their findings in Section 2.4, this is extremely thorough work, and they should be commended for it.

I have a handful of concerns regarding the writing, as discussed in the weaknesses section, but on balance I think this paper should be accepted, on the condition that my concerns are fixed in the camera ready.","* From the intro: ""For example, LLaMA-13B with less compute [53] can outperform GPT-3 (175B) on MMLU [21]"": Training for longer could be one explanation for this, another one could be llama used a higher quality corpus than gpt-3 did. I think the data quality element is a little underrated. In general we should expect different pretraining datasets to potentially have different loss / different emergence points (even if the x-axis loss is on a held out validation set and models have the same vocabulary). There is some discussion of this in the limitations section, but in general I think this point should be highlighted more in the paper. Concretely, the pretraining loss -> emergence point phenomenon is only guarenteed to be consistent for a series of models pretrained on the same data.
* The discussion of exact match in Section 2 kind of comes out no nowhere, and I'm not sure why it is discussed where it is. It would be great if there were more motivation for this in the paper.
* I understand why you did the ablation that you did in Section 2.4 (ablate the effect of lr schedule, as in Chinchilla), but in the paper this is not very clearly motivated and readers with less background knowledge might not understand why this ablation is important.
* “Note that there is one only exception at the early stage of LLaMA-65B. We can see that when the training loss is higher than 1.8, LLaMA-65B performs worse than smaller models with the same training loss.”: This could be because they used some exponential smoothing on either their loss or downstream performance plots. Exponential smoothing would perturb the earlier points more than other points (especially for curves that are fast changing or have a rapid change at the beginning), potentially leading to this effect. Moreover, did you smooth out the loss in some way when plotting loss verses downstream in the previous sections? If so, this would at least be good to note in the paper.
* Section 3.1 could use clearer discussion of explanations for why emergence occurs on the different tasks. I think grokking is a possible explanation, but what exactly grokking means (outside of the context of the simple algorithmic tasks presented in the original grokking paper) is a little vague/imprecise, and I also don't think this is the only explanation. In the case of gsm8k, emergence is, in my opinion, more likely due to the fact that the model has to get a sequence of reasoning steps correct to answer the question, this leads to an exponential (e.g. p(step_correct)^n_steps) for getting the full answer correct (some analysis of this in the paper could be cool). In the case of MMLU and C-Eval there actually is an existing paper which discovers an explanation, using interpretability techniques, for emergence on multiple choice tasks (https://arxiv.org/pdf/2307.09458).
* There's a handful of related works that aren't discussed in the paper and whose findings contradict those of this paper (I'll give you my reasoning for why your work might not contradict theirs, as a suggestion in parentheses, but you should include some discussion of this in the paper somewhere, either in the related work or elsewhere):
1) https://proceedings.mlr.press/v202/liu23ao.html (my understanding is that their theory only applies near the global optim, which is generally not the case with real-world language models)
2) https://arxiv.org/pdf/2109.10686 (see the paragraph ""zooming in verses zooming out"", your paper is more about the zoomed out setting)
3) Not strictly language modeling, but see Figure 3 of https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf (could be because they are doing probing so hidden-state size increases probe capacity causing differences with model size, but it's unclear if this is actually the case)",See the weaknesses for most of my questions/concerns.,No major limitations. See the weaknesses section.,['No ethics review needed.'],7,5,,Yes,4,3,4,1720564982439,,,NeurIPS.cc/2024/Conference,35DAviqMFo,"['NeurIPS.cc/2024/Conference/Submission16390/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879843205,[],3,,,['everyone'],35DAviqMFo,['NeurIPS.cc/2024/Conference/Submission16390/Reviewer_ZLu4'],1720564982439,1730879843205,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16390/Reviewer_ZLu4']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several related works that are not discussed in the paper, including:

1. https://proceedings.mlr.press/v202/liu23ao.html
2. https://arxiv.org/pdf/2109.10686
3. https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf
4. https://arxiv.org/pdf/2307.09458 (specifically mentioned as a paper that discovers an explanation for emergence on multiple choice tasks using interpretability techniques)

The reviewer suggests that the authors should include a discussion of these related works in the paper, either in the related work section or elsewhere, to address potential contradictions and provide a more comprehensive overview of the topic.",1,"2021, 2023",Generative Pretraining from Pixels V2
2VfDPDOtGM,"The paper investigates the link between the pre-training loss of LLMs and their downstream performance on popular benchmarks. The authors train a series of models ranging from 300M to 32B parameters on English-Chinese datasets of different sizes and study how these models perform on TriviaQA, HellaSwag, RACE, WinoGrande, MMLU and GSM8K benchmarks and their Chinese counterparts, as a function of their pre-training loss. They observe a strong link between pre-training loss and benchmark performance that is not affected by model size and dataset size, from which they conclude that pre-training loss is the main indicator of downstream performance. On MMLU and GSM8K (and their Chinese counterparts), models exhibit an emergent behavior wrt. loss, i.e. their performance is close to random before a loss value of about 2.2 and steadily increases for lower loss values. This relationship seems to hold, even under continuous evaluation metrics.","1. Formulating downstream (emergent) abilities in LLMs in terms of pre-training loss is a valuable contribution, that can unify several different factors that are so far thought to contribute to emergence, such as pre-training compute, model size, and (test-)perplexity. This perspective also provides a better connection between scaling laws -- which typically describe the relationship between parameter count, dataset size, compute, and pre-training loss -- and emergent abilities, which mostly have been studied through the lens of parameter count and compute so far.
2. The paper presents an extensive evaluation over a large range of model sizes, dataset sizes, compute budgets, that show a strong connection between pre-training loss and downstream performance. The results are additionally validated with results and models proposed by prior work (Llama-1 and Pythia).
2. The paper is easy to understand and follow.","1. The paper seems to make two main claims: 1) that pre-training loss is the main predictor of downstream performance, and 2) that emergent abilities appear suddenly after models cross a certain loss-threshold. I find the evidence for 1) to be convincing, but I am somewhat less confident about 2). This is mostly because the paper only shows emergent abilities on a subset of the benchmarks they were originally proposed on (MMLU and GSM8K) in [1]. Notably, BigBench is absent. Including results on the tasks in BigBench that were shown to exhibit emergent behavior would be helpful to judge whether pre-training loss predicts the emergence threshold as well as pre-training compute or model size. Including these benchmarks would also help to put the paper into a better perspective wrt. subsequent work questioning the existence of emergent abilities [2], which also studies these benchmarks.
2. There are some discrepancies and unexplored links between the results reported in the paper and findings in prior work. To develop a better understanding of how the findings here relate to prior work, it would be helpful to include a discussion in the paper. See Questions 2. and 3. below for more details.
3. I find the paragraph in 3.1, line 197 rather speculative. Grokking refers to an improvement on the test-set, despite stagnation on the training set, whereas the models studied here seem to still be improving on the training set. I am not sure whether there is a link between grokking and the emergent behavior on the specific tasks here.
4. Minor: There are a number of typos and small writing issues, e.g.
    - ""has thus far less studied"" (line 23), "", a highly over-parameterized models"" (line 79), ""coefficients how that"" (line 126),...
    - line 120: ""climbs as the loss increases"" should probably be ""decreases"".
    - line 141: ""On each line"" seems to be missing a reference to Figure 2.

References
- [ 1] Emergent Abilities of Large Language Models, Wei et al., https://arxiv.org/abs/2206.07682
- [ 2] Are Emergent Abilities of Large Language Models a Mirage?, Schaeffer et al., https://arxiv.org/abs/2304.15004","1. The paper claims that pre-training (test) loss is a good indicator of downstream performance. What is the composition and size of the test set that the loss is evaluated on? What properties (size, diversity, etc.) should such a test-set have in order to be predictive of downstream performance?
2. Prior work [1, 2] has found that emergent behaviors can become predictable with ""higher resolution"" benchmarks, i.e. with larger test sets or repeated sampling from the model. This is a dimension that the paper does not touch upon. Do the authors believe, that the studied emergent abilities would still appear only after models cross the particular loss threshold, i.e. be essentially 0 before, even with those higher resolution benchmarks?
3. In related work (line 254), the authors mention that some prior work [3] has observed a disconnect between pre-training loss and downstream performance, which stands in contrast to the claims made in the paper. It would be great if the authors could comment on more on the reasons for these discrepancies.

References
- [ 1] Are Emergent Abilities of Large Language Models a Mirage?, Schaeffer et al., https://arxiv.org/abs/2304.15004
- [ 2] Predicting Emergent Abilities with Infinite Resolution Evaluation, Hu et al., https://arxiv.org/abs/2310.03262
- [ 3] Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models, Liu et al., https://proceedings.mlr.press/v202/liu23ao.html","The paper sufficiently discusses limitations, in my opinion.",['No ethics review needed.'],6,4,,Yes,3,3,3,1720783358278,,,NeurIPS.cc/2024/Conference,35DAviqMFo,"['NeurIPS.cc/2024/Conference/Submission16390/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879843055,[],4,,,['everyone'],35DAviqMFo,['NeurIPS.cc/2024/Conference/Submission16390/Reviewer_NWes'],1720783358278,1730879843055,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16390/Reviewer_NWes']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references, including:

1. [1] Emergent Abilities of Large Language Models, Wei et al.
2. [2] Are Emergent Abilities of Large Language Models a Mirage?, Schaeffer et al.
3. [3] Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models, Liu et al.
4. Predicting Emergent Abilities with Infinite Resolution Evaluation, Hu et al.

The reviewer asks the authors to comment on the discrepancies between their findings and those of prior work, specifically referencing [3], and to include a discussion of how their findings relate to prior work, including [1] and [2]. This implies that the reviewer is suggesting the authors cite and engage with these specific papers in their work.",1,,Emergent Abilities of Large Language Models 
2VfDPDOtGM,"The paper investigates the link between the pre-training loss of LLMs and their downstream performance on popular benchmarks. The authors train a series of models ranging from 300M to 32B parameters on English-Chinese datasets of different sizes and study how these models perform on TriviaQA, HellaSwag, RACE, WinoGrande, MMLU and GSM8K benchmarks and their Chinese counterparts, as a function of their pre-training loss. They observe a strong link between pre-training loss and benchmark performance that is not affected by model size and dataset size, from which they conclude that pre-training loss is the main indicator of downstream performance. On MMLU and GSM8K (and their Chinese counterparts), models exhibit an emergent behavior wrt. loss, i.e. their performance is close to random before a loss value of about 2.2 and steadily increases for lower loss values. This relationship seems to hold, even under continuous evaluation metrics.","1. Formulating downstream (emergent) abilities in LLMs in terms of pre-training loss is a valuable contribution, that can unify several different factors that are so far thought to contribute to emergence, such as pre-training compute, model size, and (test-)perplexity. This perspective also provides a better connection between scaling laws -- which typically describe the relationship between parameter count, dataset size, compute, and pre-training loss -- and emergent abilities, which mostly have been studied through the lens of parameter count and compute so far.
2. The paper presents an extensive evaluation over a large range of model sizes, dataset sizes, compute budgets, that show a strong connection between pre-training loss and downstream performance. The results are additionally validated with results and models proposed by prior work (Llama-1 and Pythia).
2. The paper is easy to understand and follow.","1. The paper seems to make two main claims: 1) that pre-training loss is the main predictor of downstream performance, and 2) that emergent abilities appear suddenly after models cross a certain loss-threshold. I find the evidence for 1) to be convincing, but I am somewhat less confident about 2). This is mostly because the paper only shows emergent abilities on a subset of the benchmarks they were originally proposed on (MMLU and GSM8K) in [1]. Notably, BigBench is absent. Including results on the tasks in BigBench that were shown to exhibit emergent behavior would be helpful to judge whether pre-training loss predicts the emergence threshold as well as pre-training compute or model size. Including these benchmarks would also help to put the paper into a better perspective wrt. subsequent work questioning the existence of emergent abilities [2], which also studies these benchmarks.
2. There are some discrepancies and unexplored links between the results reported in the paper and findings in prior work. To develop a better understanding of how the findings here relate to prior work, it would be helpful to include a discussion in the paper. See Questions 2. and 3. below for more details.
3. I find the paragraph in 3.1, line 197 rather speculative. Grokking refers to an improvement on the test-set, despite stagnation on the training set, whereas the models studied here seem to still be improving on the training set. I am not sure whether there is a link between grokking and the emergent behavior on the specific tasks here.
4. Minor: There are a number of typos and small writing issues, e.g.
    - ""has thus far less studied"" (line 23), "", a highly over-parameterized models"" (line 79), ""coefficients how that"" (line 126),...
    - line 120: ""climbs as the loss increases"" should probably be ""decreases"".
    - line 141: ""On each line"" seems to be missing a reference to Figure 2.

References
- [ 1] Emergent Abilities of Large Language Models, Wei et al., https://arxiv.org/abs/2206.07682
- [ 2] Are Emergent Abilities of Large Language Models a Mirage?, Schaeffer et al., https://arxiv.org/abs/2304.15004","1. The paper claims that pre-training (test) loss is a good indicator of downstream performance. What is the composition and size of the test set that the loss is evaluated on? What properties (size, diversity, etc.) should such a test-set have in order to be predictive of downstream performance?
2. Prior work [1, 2] has found that emergent behaviors can become predictable with ""higher resolution"" benchmarks, i.e. with larger test sets or repeated sampling from the model. This is a dimension that the paper does not touch upon. Do the authors believe, that the studied emergent abilities would still appear only after models cross the particular loss threshold, i.e. be essentially 0 before, even with those higher resolution benchmarks?
3. In related work (line 254), the authors mention that some prior work [3] has observed a disconnect between pre-training loss and downstream performance, which stands in contrast to the claims made in the paper. It would be great if the authors could comment on more on the reasons for these discrepancies.

References
- [ 1] Are Emergent Abilities of Large Language Models a Mirage?, Schaeffer et al., https://arxiv.org/abs/2304.15004
- [ 2] Predicting Emergent Abilities with Infinite Resolution Evaluation, Hu et al., https://arxiv.org/abs/2310.03262
- [ 3] Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models, Liu et al., https://proceedings.mlr.press/v202/liu23ao.html","The paper sufficiently discusses limitations, in my opinion.",['No ethics review needed.'],6,4,,Yes,3,3,3,1720783358278,,,NeurIPS.cc/2024/Conference,35DAviqMFo,"['NeurIPS.cc/2024/Conference/Submission16390/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879843055,[],4,,,['everyone'],35DAviqMFo,['NeurIPS.cc/2024/Conference/Submission16390/Reviewer_NWes'],1720783358278,1730879843055,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16390/Reviewer_NWes']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references, including:

1. [1] Emergent Abilities of Large Language Models, Wei et al.
2. [2] Are Emergent Abilities of Large Language Models a Mirage?, Schaeffer et al.
3. [3] Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models, Liu et al.
4. Predicting Emergent Abilities with Infinite Resolution Evaluation, Hu et al.

The reviewer asks the authors to comment on the discrepancies between their findings and those of prior work, specifically referencing [3], and to include a discussion of how their findings relate to prior work, including [1] and [2]. This implies that the reviewer is suggesting the authors cite and engage with these specific papers in their work.",1,,Are Emergent Abilities of Large Language Models a Mirage 
2VfDPDOtGM,"The paper investigates the link between the pre-training loss of LLMs and their downstream performance on popular benchmarks. The authors train a series of models ranging from 300M to 32B parameters on English-Chinese datasets of different sizes and study how these models perform on TriviaQA, HellaSwag, RACE, WinoGrande, MMLU and GSM8K benchmarks and their Chinese counterparts, as a function of their pre-training loss. They observe a strong link between pre-training loss and benchmark performance that is not affected by model size and dataset size, from which they conclude that pre-training loss is the main indicator of downstream performance. On MMLU and GSM8K (and their Chinese counterparts), models exhibit an emergent behavior wrt. loss, i.e. their performance is close to random before a loss value of about 2.2 and steadily increases for lower loss values. This relationship seems to hold, even under continuous evaluation metrics.","1. Formulating downstream (emergent) abilities in LLMs in terms of pre-training loss is a valuable contribution, that can unify several different factors that are so far thought to contribute to emergence, such as pre-training compute, model size, and (test-)perplexity. This perspective also provides a better connection between scaling laws -- which typically describe the relationship between parameter count, dataset size, compute, and pre-training loss -- and emergent abilities, which mostly have been studied through the lens of parameter count and compute so far.
2. The paper presents an extensive evaluation over a large range of model sizes, dataset sizes, compute budgets, that show a strong connection between pre-training loss and downstream performance. The results are additionally validated with results and models proposed by prior work (Llama-1 and Pythia).
2. The paper is easy to understand and follow.","1. The paper seems to make two main claims: 1) that pre-training loss is the main predictor of downstream performance, and 2) that emergent abilities appear suddenly after models cross a certain loss-threshold. I find the evidence for 1) to be convincing, but I am somewhat less confident about 2). This is mostly because the paper only shows emergent abilities on a subset of the benchmarks they were originally proposed on (MMLU and GSM8K) in [1]. Notably, BigBench is absent. Including results on the tasks in BigBench that were shown to exhibit emergent behavior would be helpful to judge whether pre-training loss predicts the emergence threshold as well as pre-training compute or model size. Including these benchmarks would also help to put the paper into a better perspective wrt. subsequent work questioning the existence of emergent abilities [2], which also studies these benchmarks.
2. There are some discrepancies and unexplored links between the results reported in the paper and findings in prior work. To develop a better understanding of how the findings here relate to prior work, it would be helpful to include a discussion in the paper. See Questions 2. and 3. below for more details.
3. I find the paragraph in 3.1, line 197 rather speculative. Grokking refers to an improvement on the test-set, despite stagnation on the training set, whereas the models studied here seem to still be improving on the training set. I am not sure whether there is a link between grokking and the emergent behavior on the specific tasks here.
4. Minor: There are a number of typos and small writing issues, e.g.
    - ""has thus far less studied"" (line 23), "", a highly over-parameterized models"" (line 79), ""coefficients how that"" (line 126),...
    - line 120: ""climbs as the loss increases"" should probably be ""decreases"".
    - line 141: ""On each line"" seems to be missing a reference to Figure 2.

References
- [ 1] Emergent Abilities of Large Language Models, Wei et al., https://arxiv.org/abs/2206.07682
- [ 2] Are Emergent Abilities of Large Language Models a Mirage?, Schaeffer et al., https://arxiv.org/abs/2304.15004","1. The paper claims that pre-training (test) loss is a good indicator of downstream performance. What is the composition and size of the test set that the loss is evaluated on? What properties (size, diversity, etc.) should such a test-set have in order to be predictive of downstream performance?
2. Prior work [1, 2] has found that emergent behaviors can become predictable with ""higher resolution"" benchmarks, i.e. with larger test sets or repeated sampling from the model. This is a dimension that the paper does not touch upon. Do the authors believe, that the studied emergent abilities would still appear only after models cross the particular loss threshold, i.e. be essentially 0 before, even with those higher resolution benchmarks?
3. In related work (line 254), the authors mention that some prior work [3] has observed a disconnect between pre-training loss and downstream performance, which stands in contrast to the claims made in the paper. It would be great if the authors could comment on more on the reasons for these discrepancies.

References
- [ 1] Are Emergent Abilities of Large Language Models a Mirage?, Schaeffer et al., https://arxiv.org/abs/2304.15004
- [ 2] Predicting Emergent Abilities with Infinite Resolution Evaluation, Hu et al., https://arxiv.org/abs/2310.03262
- [ 3] Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models, Liu et al., https://proceedings.mlr.press/v202/liu23ao.html","The paper sufficiently discusses limitations, in my opinion.",['No ethics review needed.'],6,4,,Yes,3,3,3,1720783358278,,,NeurIPS.cc/2024/Conference,35DAviqMFo,"['NeurIPS.cc/2024/Conference/Submission16390/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879843055,[],4,,,['everyone'],35DAviqMFo,['NeurIPS.cc/2024/Conference/Submission16390/Reviewer_NWes'],1720783358278,1730879843055,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16390/Reviewer_NWes']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references, including:

1. [1] Emergent Abilities of Large Language Models, Wei et al.
2. [2] Are Emergent Abilities of Large Language Models a Mirage?, Schaeffer et al.
3. [3] Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models, Liu et al.
4. Predicting Emergent Abilities with Infinite Resolution Evaluation, Hu et al.

The reviewer asks the authors to comment on the discrepancies between their findings and those of prior work, specifically referencing [3], and to include a discussion of how their findings relate to prior work, including [1] and [2]. This implies that the reviewer is suggesting the authors cite and engage with these specific papers in their work.",1,,"Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models "
2VfDPDOtGM,"The paper investigates the link between the pre-training loss of LLMs and their downstream performance on popular benchmarks. The authors train a series of models ranging from 300M to 32B parameters on English-Chinese datasets of different sizes and study how these models perform on TriviaQA, HellaSwag, RACE, WinoGrande, MMLU and GSM8K benchmarks and their Chinese counterparts, as a function of their pre-training loss. They observe a strong link between pre-training loss and benchmark performance that is not affected by model size and dataset size, from which they conclude that pre-training loss is the main indicator of downstream performance. On MMLU and GSM8K (and their Chinese counterparts), models exhibit an emergent behavior wrt. loss, i.e. their performance is close to random before a loss value of about 2.2 and steadily increases for lower loss values. This relationship seems to hold, even under continuous evaluation metrics.","1. Formulating downstream (emergent) abilities in LLMs in terms of pre-training loss is a valuable contribution, that can unify several different factors that are so far thought to contribute to emergence, such as pre-training compute, model size, and (test-)perplexity. This perspective also provides a better connection between scaling laws -- which typically describe the relationship between parameter count, dataset size, compute, and pre-training loss -- and emergent abilities, which mostly have been studied through the lens of parameter count and compute so far.
2. The paper presents an extensive evaluation over a large range of model sizes, dataset sizes, compute budgets, that show a strong connection between pre-training loss and downstream performance. The results are additionally validated with results and models proposed by prior work (Llama-1 and Pythia).
2. The paper is easy to understand and follow.","1. The paper seems to make two main claims: 1) that pre-training loss is the main predictor of downstream performance, and 2) that emergent abilities appear suddenly after models cross a certain loss-threshold. I find the evidence for 1) to be convincing, but I am somewhat less confident about 2). This is mostly because the paper only shows emergent abilities on a subset of the benchmarks they were originally proposed on (MMLU and GSM8K) in [1]. Notably, BigBench is absent. Including results on the tasks in BigBench that were shown to exhibit emergent behavior would be helpful to judge whether pre-training loss predicts the emergence threshold as well as pre-training compute or model size. Including these benchmarks would also help to put the paper into a better perspective wrt. subsequent work questioning the existence of emergent abilities [2], which also studies these benchmarks.
2. There are some discrepancies and unexplored links between the results reported in the paper and findings in prior work. To develop a better understanding of how the findings here relate to prior work, it would be helpful to include a discussion in the paper. See Questions 2. and 3. below for more details.
3. I find the paragraph in 3.1, line 197 rather speculative. Grokking refers to an improvement on the test-set, despite stagnation on the training set, whereas the models studied here seem to still be improving on the training set. I am not sure whether there is a link between grokking and the emergent behavior on the specific tasks here.
4. Minor: There are a number of typos and small writing issues, e.g.
    - ""has thus far less studied"" (line 23), "", a highly over-parameterized models"" (line 79), ""coefficients how that"" (line 126),...
    - line 120: ""climbs as the loss increases"" should probably be ""decreases"".
    - line 141: ""On each line"" seems to be missing a reference to Figure 2.

References
- [ 1] Emergent Abilities of Large Language Models, Wei et al., https://arxiv.org/abs/2206.07682
- [ 2] Are Emergent Abilities of Large Language Models a Mirage?, Schaeffer et al., https://arxiv.org/abs/2304.15004","1. The paper claims that pre-training (test) loss is a good indicator of downstream performance. What is the composition and size of the test set that the loss is evaluated on? What properties (size, diversity, etc.) should such a test-set have in order to be predictive of downstream performance?
2. Prior work [1, 2] has found that emergent behaviors can become predictable with ""higher resolution"" benchmarks, i.e. with larger test sets or repeated sampling from the model. This is a dimension that the paper does not touch upon. Do the authors believe, that the studied emergent abilities would still appear only after models cross the particular loss threshold, i.e. be essentially 0 before, even with those higher resolution benchmarks?
3. In related work (line 254), the authors mention that some prior work [3] has observed a disconnect between pre-training loss and downstream performance, which stands in contrast to the claims made in the paper. It would be great if the authors could comment on more on the reasons for these discrepancies.

References
- [ 1] Are Emergent Abilities of Large Language Models a Mirage?, Schaeffer et al., https://arxiv.org/abs/2304.15004
- [ 2] Predicting Emergent Abilities with Infinite Resolution Evaluation, Hu et al., https://arxiv.org/abs/2310.03262
- [ 3] Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models, Liu et al., https://proceedings.mlr.press/v202/liu23ao.html","The paper sufficiently discusses limitations, in my opinion.",['No ethics review needed.'],6,4,,Yes,3,3,3,1720783358278,,,NeurIPS.cc/2024/Conference,35DAviqMFo,"['NeurIPS.cc/2024/Conference/Submission16390/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879843055,[],4,,,['everyone'],35DAviqMFo,['NeurIPS.cc/2024/Conference/Submission16390/Reviewer_NWes'],1720783358278,1730879843055,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16390/Reviewer_NWes']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references, including:

1. [1] Emergent Abilities of Large Language Models, Wei et al.
2. [2] Are Emergent Abilities of Large Language Models a Mirage?, Schaeffer et al.
3. [3] Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models, Liu et al.
4. Predicting Emergent Abilities with Infinite Resolution Evaluation, Hu et al.

The reviewer asks the authors to comment on the discrepancies between their findings and those of prior work, specifically referencing [3], and to include a discussion of how their findings relate to prior work, including [1] and [2]. This implies that the reviewer is suggesting the authors cite and engage with these specific papers in their work.",1,,Predicting Emergent Abilities with Infinite Resolution Evaluation
hExdpiczSR,"The paper propose a GNN plus LLM model for zero-shot learning in the graph domain. They first use contrastive learning to pretrain a GNN that can be applied to arbitrary graphs. They added a feature-wise contrastive learning  objective on the projected representation to the PCA of LLM token embeddings to bridge the gap between contrastively learned embedding and LLM token embeddings.  After training the GNN, they train additional linear projector to the map the GNN output to a sequence of graph tokens, and the tokens are combined with special prompt designed for graph learning tasks for LLM to perform downstream tasks. The methods does not need to fine-tune the LLM and acheived good performance on most of the datasets.","The PCA-based alignment with the LLM input is interesting, and potentially can shed lights on future research on GNN and LLM alignment.

The experimental results seem promising on most datasets compared to both LLM and GNN+LLM baselines. Especially, the model shows some-level of cross-task transferrability where the GNN and linear projector are pretrained only on node classification but, but show non-trivial performance on link prediction tasks.","My major concern about the paper is its novelty. Several important components, including using self-supervised learning to generate general node embedding [1], alignning graph representation with LLM input with linear projector [2], and the prompt design are proposed and already widely adopted in the research area. The feature-wise contrastive learning seems to be the main technical contribution, yet it is not studied and invectigated in details. For example, why pre-training on node classification leads to non-trivial link prediction results? According to the ablation study, feature-wise CL seems to be the key, yet no knowledge about link-prediction is injected into the model in any step of the method.

Related to the main concern, I think the experimental results do not fully justify the authors claim. The author claims that the aligned graph tokens provide the LLM with graph information. However, they still feed the node texts as direct text input to the LLM, for some datasets LLM can do well solely using node texts. To show that the pretraining process indeed brings in inductive/transferrable knowledge of the graph, the author should either show that by completely removing node text to from LLM text input (it is ok to keep task text), the model can still work or provide results of baseline models that tune the LLM on the node texts (tuning the LLM weight or use a soft prompt), and such baseline can not transfer or performs poorly. Note that the ablation study between w/o FC and w/o graph token is not enough. Essentially, if a soft prompt tuning can achieve similar effect, the proposed work is just adding linear layers as a substitute to soft prompts.

[1] He, Yufei, and Bryan Hooi. ""UniGraph: Learning a Cross-Domain Graph Foundation Model From Natural Language."" arXiv preprint arXiv:2402.13630 (2024).

[2] Tang, Jiabin, et al. ""Graphgpt: Graph instruction tuning for large language models."" arXiv preprint arXiv:2310.13023 (2023).","- Why do you need to map a single GNN node representation to multiple graph tokens? They should contain exactly the same amount of information.

- What is the prompt used for baseline LLM? Is it the same prompt as the one used for GNN? If so, what happen when you provide it with a more detailed prompt, but still only on the target node?

- For edge and graph tasks, you used the sum of node representation to compute graph tokens, wouldn't that break the aligned distribution as the pretraining only happens on node.",,['No ethics review needed.'],5,4,,Yes,2,3,2,1720570662600,,,NeurIPS.cc/2024/Conference,32g9BWTndc,"['NeurIPS.cc/2024/Conference/Submission16841/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879878209,[],2,,,['everyone'],32g9BWTndc,['NeurIPS.cc/2024/Conference/Submission16841/Reviewer_65Wi'],1720570662600,1730879878209,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16841/Reviewer_65Wi']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. He, Yufei, and Bryan Hooi. ""UniGraph: Learning a Cross-Domain Graph Foundation Model From Natural Language."" arXiv preprint arXiv:2402.13630 (2024).
2. Tang, Jiabin, et al. ""Graphgpt: Graph instruction tuning for large language models."" arXiv preprint arXiv:2310.13023 (2023).

These citations are mentioned in the ""weaknesses"" section of the review, where the reviewer mentions that several important components of the proposed method have been previously proposed and widely adopted in the research area, and suggests that the authors should acknowledge this by citing the relevant literature.",1,"2024, 2024, 2023, 2023",UniGraph Learning a Cross-Domain Graph Foundation Model From Natural Language 
hExdpiczSR,"The paper propose a GNN plus LLM model for zero-shot learning in the graph domain. They first use contrastive learning to pretrain a GNN that can be applied to arbitrary graphs. They added a feature-wise contrastive learning  objective on the projected representation to the PCA of LLM token embeddings to bridge the gap between contrastively learned embedding and LLM token embeddings.  After training the GNN, they train additional linear projector to the map the GNN output to a sequence of graph tokens, and the tokens are combined with special prompt designed for graph learning tasks for LLM to perform downstream tasks. The methods does not need to fine-tune the LLM and acheived good performance on most of the datasets.","The PCA-based alignment with the LLM input is interesting, and potentially can shed lights on future research on GNN and LLM alignment.

The experimental results seem promising on most datasets compared to both LLM and GNN+LLM baselines. Especially, the model shows some-level of cross-task transferrability where the GNN and linear projector are pretrained only on node classification but, but show non-trivial performance on link prediction tasks.","My major concern about the paper is its novelty. Several important components, including using self-supervised learning to generate general node embedding [1], alignning graph representation with LLM input with linear projector [2], and the prompt design are proposed and already widely adopted in the research area. The feature-wise contrastive learning seems to be the main technical contribution, yet it is not studied and invectigated in details. For example, why pre-training on node classification leads to non-trivial link prediction results? According to the ablation study, feature-wise CL seems to be the key, yet no knowledge about link-prediction is injected into the model in any step of the method.

Related to the main concern, I think the experimental results do not fully justify the authors claim. The author claims that the aligned graph tokens provide the LLM with graph information. However, they still feed the node texts as direct text input to the LLM, for some datasets LLM can do well solely using node texts. To show that the pretraining process indeed brings in inductive/transferrable knowledge of the graph, the author should either show that by completely removing node text to from LLM text input (it is ok to keep task text), the model can still work or provide results of baseline models that tune the LLM on the node texts (tuning the LLM weight or use a soft prompt), and such baseline can not transfer or performs poorly. Note that the ablation study between w/o FC and w/o graph token is not enough. Essentially, if a soft prompt tuning can achieve similar effect, the proposed work is just adding linear layers as a substitute to soft prompts.

[1] He, Yufei, and Bryan Hooi. ""UniGraph: Learning a Cross-Domain Graph Foundation Model From Natural Language."" arXiv preprint arXiv:2402.13630 (2024).

[2] Tang, Jiabin, et al. ""Graphgpt: Graph instruction tuning for large language models."" arXiv preprint arXiv:2310.13023 (2023).","- Why do you need to map a single GNN node representation to multiple graph tokens? They should contain exactly the same amount of information.

- What is the prompt used for baseline LLM? Is it the same prompt as the one used for GNN? If so, what happen when you provide it with a more detailed prompt, but still only on the target node?

- For edge and graph tasks, you used the sum of node representation to compute graph tokens, wouldn't that break the aligned distribution as the pretraining only happens on node.",,['No ethics review needed.'],5,4,,Yes,2,3,2,1720570662600,,,NeurIPS.cc/2024/Conference,32g9BWTndc,"['NeurIPS.cc/2024/Conference/Submission16841/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879878209,[],2,,,['everyone'],32g9BWTndc,['NeurIPS.cc/2024/Conference/Submission16841/Reviewer_65Wi'],1720570662600,1730879878209,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16841/Reviewer_65Wi']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. He, Yufei, and Bryan Hooi. ""UniGraph: Learning a Cross-Domain Graph Foundation Model From Natural Language."" arXiv preprint arXiv:2402.13630 (2024).
2. Tang, Jiabin, et al. ""Graphgpt: Graph instruction tuning for large language models."" arXiv preprint arXiv:2310.13023 (2023).

These citations are mentioned in the ""weaknesses"" section of the review, where the reviewer mentions that several important components of the proposed method have been previously proposed and widely adopted in the research area, and suggests that the authors should acknowledge this by citing the relevant literature.",1,"2024, 2024, 2023, 2023",Graphgpt Graph instruction tuning for large language models
RO4ZagShfy,"*** In line 12 there is a comment with acronyms of one of the authors, for the AC's consideration if it is a desk reject ***

The paper studies the setting of adversarial contextual MAB under the assumption of access to a realizable general function class for approximating the context-dependent rewards.
The authors prove both upper and lower regret bounds, that are variance dependent, i.e., dependent on the cumulative data variance rather than on $T$ which is the number of episodes. The authors present the regent bounds in three different settings (1) for strong adversary, (2) for weak adversary, (3) where learning from function class.
In all the cases, their bounds are also dependent on the Eluder dimension. They present a matching lower bound for each setting.
The presented algorithm is adapted from SquareCB of Foster and Rakhlin (2020), but additionally maintains a confidence function set, to learn faster when the functions in the confidence set have larger disagreement.","1.	Variance-dependent regret bound is an interesting benchmark in RL. An application of it to contextual bandits is nice and worth the community's attention. 
2.	The work is extensive – the authors fully analyze three different settings, and prove both upper and lower bounds.","1.	The related literature review is unclear.  In the presented previous results, there should be a clear separation between variance-dependent bounds and minimax regret bounds. 

2.	The difference between the three settings is unclear to me. I would expect the authors to use the accepted terms, i.e., oblivious and adaptive adversary. Moreover, to be comparable to previous literature, I think the most interesting case is strong adversary + learning from function class.

3.	I do not see why the eluder diminution is necessary in all the bounds. It would be appreciated if the authors could provide an intuitive explanation.

4.	It seems that the work over a confidence set of functions implies a running time complexity of $|F|$ that is not discussed. 

5.	The paper seems to be written at the last minute, as there are comments left inside the paper. See for additional example line 185 ""(our contribution)"".

6.	The use of the Hellinger-Eluder dimension is given without any justification or an appropriate citation of previous works. The classic Eluder dimension introduced by Russo and Van-Roy is defined with respect to the $\ell_2$ norm only. If the authors are using other versions of it, they have to cite related work, if such exists, or justify the used guarantees themselves.  In this case, [1] presents a version of the Eluder dimension to bounded metrics, that also holds to the squared Hellinger distance.


[1] Eluder-based regret for stochastic contextual MDPs, Levy et al. 2024.","1.	Please provide a specific comparison of your results with the known variance-dependent bounds in previous literature.

2.	What do you mean by $d_{elu}(0)$ ? For my understanding, the Eluder dimension is meaningful only for $\alpha \in (0,1] $.

3.	Please refer to the weaknesses.","Mentioned in the ""Weaknesses"" section.",['No ethics review needed.'],5,3,,Yes,3,2,3,1719126733218,,,NeurIPS.cc/2024/Conference,32Z3nfCnwa,"['NeurIPS.cc/2024/Conference/Submission17787/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879933787,[],1,,,['everyone'],32Z3nfCnwa,['NeurIPS.cc/2024/Conference/Submission17787/Reviewer_CuA6'],1719126733218,1730879933787,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17787/Reviewer_CuA6']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

[1] Eluder-based regret for stochastic contextual MDPs, Levy et al. 2024.

This citation is recommended to justify the use of the Hellinger-Eluder dimension in the paper.",1,2024,Eluder-based regret for stochastic contextual MDPs
KTFgGCFT3O,"This paper considers contextual bandits with function approximation, and studies the influence of the variance information on the regret bound. It studies three regimes: weak adversary where the variance is revealed before each time step; strong adversary where the variance depends on the chosen action at each time step; and learning with a model class where the reward follows a Gaussian distribution with the mean and the variance depending on the context and the arm. By incorporating the variance, both the upper and lower bounds of the regret are refined, subject to some gaps in some scenarios.","- The proposed problem is interesting and the result also answers the conjecture that $\tilde{O}(\sqrt{A\Lambda \log|\mathcal{F}|}+A\log |\mathcal{F}|)$  is not true, when we incorporate the variance into the algorithm design. The eluder dimension plays an important role in this bound and has been used to characterize the bounds.
- The paper studies three different cases and provides sufficient insights in this line of problems. While there are some gaps between the upper and lower bounds, the discussions are thorough and can lead to further research.",See the questions section,"- Can the authors summarize the main technical novelty used in the paper?
- Concerning the third case, learning with the model class, the authors indicate that the variance information is not required as input in line 105. Does it mean that the variance, given the model, the context and the action, the variance $\sigma_{M_t}^2(x_t,a)$ is revealed, as presented in line 7 in Algorithm 3? If we only assume that the variance is unknown but it only depends on the context and the arm, can the algorithm be modified such that it can work with estimating the variance on the fly, like [1]?
- The  lower bound result Theorem 6.2 is obtained via instances with the same variance. While the lower bound is indeed a minimax lower bound, as this paper is considering the role of the variance, is it possible to derive a lower bound for the case where the variances are heterogeneous?

[1] Jourdan, M., Rémy, D., & Emilie, K. Dealing with unknown variances in best-arm identification. International Conference on Algorithmic Learning Theory. PMLR. 2023.",,['No ethics review needed.'],6,3,,Yes,3,4,3,1720513492211,,,NeurIPS.cc/2024/Conference,32Z3nfCnwa,"['NeurIPS.cc/2024/Conference/Submission17787/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879933647,[],2,,,['everyone'],32Z3nfCnwa,['NeurIPS.cc/2024/Conference/Submission17787/Reviewer_u4Bf'],1720513492211,1730879933647,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17787/Reviewer_u4Bf']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

Jourdan, M., Rémy, D., & Emilie, K. Dealing with unknown variances in best-arm identification. International Conference on Algorithmic Learning Theory. PMLR. 2023.

This is mentioned in the ""questions"" section of the review, where the reviewer asks if the algorithm can be modified to work with estimating the variance on the fly, and references this paper ([1]) as an example of how this can be done.",1,2023,Dealing with unknown variances in best-arm identification
hU6nR5fE0Z,"This paper studies contextual bandits with general function approximation, emphasizing the impact of variance information. It proves lower bounds dependent on the Eluder dimension and variance information in both strong and weak adversary settings. It also proposes algorithms for both cases. When the adversary is weak, the proved regret upper bound is optimal, otherwise, there is a $\sqrt{d}$ gap from optimal. The paper also studies the learning problem when the function class contains the distributional information and provides optimal regret bound.","1. The paper studies contextual bandits with general function approximation. The proved lower bound dependent on the Eluder dimension and variance information is very novel.
2. The paper provides a comprehensive analysis for different settings, e.g, weak/strong adversaries, and distributional settings. The proved results are insightful and optimal in most cases.
3. The presentation is very clear, including comparison with previous works.","1. In the known variance section, this paper only focuses on a regime where $A \le d_{elu} \le \sqrt{AT}$. The case $d_{elu} \le A$ is also very important, especially when the action set is large and function approximation benefits. In such cases, the proved upper bound and lower bound do not match, so the contribution in this section is a bit overclaimed. (matching upper bound when variance is known)
2. Some missing related works.
More works on variance-dependent results of heteroscedastic bandits:

[1] Zhou et al. Nearly minimax optimal reinforcement learning for linear mixture markov decision processes, Colt 2021

[2] Zhou and Gu. Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs Neurips 2022

[3] Zhao et al. Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits

3. This description of ""checking disagreement"" (Line 166) is not very accurate. A similar definition of equation (4) has been used in previous works as weights ([4] [5]), bonus functions ([6][7]), and selection rules ([8][9]). I suggest adding more discussions on this.
 
[4] Agarwal et al. Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation. Colt 2023

[5] Ye et al.  Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes. ICML2023

[6] Di et al. Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning, ICLR 2024

[7] Huang et al. Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation AISTATS

[8] Gentile et al. Fast Rates in Pool-Based Batch Active Learning ICML 2024

[9] Zhao et al. A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation

4. Some minor errors: Line 12 worst case over what? 

In the proof of Lemma E.5, there is an abusive use of $\epsilon$, it represents both the Gaussian noise and a changeable parameter for $\sigma$.","1. Is it possible to prove a variance-dependent upper bound with $d_{elu}$ dependence in the first term of Theorem 4.2?
2. What difficulty did you meet when trying to recover Zhao et al. (2023)’s result for unknown variance?",The limitations and societal impact of this work have been addressed.,['No ethics review needed.'],7,4,,Yes,3,3,3,1720763359987,,,NeurIPS.cc/2024/Conference,32Z3nfCnwa,"['NeurIPS.cc/2024/Conference/Submission17787/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879933529,[],3,,,['everyone'],32Z3nfCnwa,['NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3'],1720763359987,1730879933529,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Zhou et al. (2021) - ""Nearly minimax optimal reinforcement learning for linear mixture markov decision processes""
2. Zhou and Gu (2022) - ""Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs""
3. Zhao et al. (no specific year mentioned) - ""Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits""
4. Agarwal et al. (2023) - ""Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation""
5. Ye et al. (2023) - ""Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes""
6. Di et al. (2024) - ""Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning""
7. Huang et al. (no specific conference mentioned, but AISTATS is mentioned as the conference) - ""Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation""
8. Gentile et al. (2024) - ""Fast Rates in Pool-Based Batch Active Learning""
9. Zhao et al. (no specific year mentioned, but a different paper from the one mentioned in [3]) - ""A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation""",1,"2021, 2022, 2023, 2023, 2024, 2024",Nearly minimax optimal reinforcement learning for linear mixture markov decision processes
hU6nR5fE0Z,"This paper studies contextual bandits with general function approximation, emphasizing the impact of variance information. It proves lower bounds dependent on the Eluder dimension and variance information in both strong and weak adversary settings. It also proposes algorithms for both cases. When the adversary is weak, the proved regret upper bound is optimal, otherwise, there is a $\sqrt{d}$ gap from optimal. The paper also studies the learning problem when the function class contains the distributional information and provides optimal regret bound.","1. The paper studies contextual bandits with general function approximation. The proved lower bound dependent on the Eluder dimension and variance information is very novel.
2. The paper provides a comprehensive analysis for different settings, e.g, weak/strong adversaries, and distributional settings. The proved results are insightful and optimal in most cases.
3. The presentation is very clear, including comparison with previous works.","1. In the known variance section, this paper only focuses on a regime where $A \le d_{elu} \le \sqrt{AT}$. The case $d_{elu} \le A$ is also very important, especially when the action set is large and function approximation benefits. In such cases, the proved upper bound and lower bound do not match, so the contribution in this section is a bit overclaimed. (matching upper bound when variance is known)
2. Some missing related works.
More works on variance-dependent results of heteroscedastic bandits:

[1] Zhou et al. Nearly minimax optimal reinforcement learning for linear mixture markov decision processes, Colt 2021

[2] Zhou and Gu. Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs Neurips 2022

[3] Zhao et al. Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits

3. This description of ""checking disagreement"" (Line 166) is not very accurate. A similar definition of equation (4) has been used in previous works as weights ([4] [5]), bonus functions ([6][7]), and selection rules ([8][9]). I suggest adding more discussions on this.
 
[4] Agarwal et al. Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation. Colt 2023

[5] Ye et al.  Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes. ICML2023

[6] Di et al. Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning, ICLR 2024

[7] Huang et al. Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation AISTATS

[8] Gentile et al. Fast Rates in Pool-Based Batch Active Learning ICML 2024

[9] Zhao et al. A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation

4. Some minor errors: Line 12 worst case over what? 

In the proof of Lemma E.5, there is an abusive use of $\epsilon$, it represents both the Gaussian noise and a changeable parameter for $\sigma$.","1. Is it possible to prove a variance-dependent upper bound with $d_{elu}$ dependence in the first term of Theorem 4.2?
2. What difficulty did you meet when trying to recover Zhao et al. (2023)’s result for unknown variance?",The limitations and societal impact of this work have been addressed.,['No ethics review needed.'],7,4,,Yes,3,3,3,1720763359987,,,NeurIPS.cc/2024/Conference,32Z3nfCnwa,"['NeurIPS.cc/2024/Conference/Submission17787/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879933529,[],3,,,['everyone'],32Z3nfCnwa,['NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3'],1720763359987,1730879933529,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Zhou et al. (2021) - ""Nearly minimax optimal reinforcement learning for linear mixture markov decision processes""
2. Zhou and Gu (2022) - ""Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs""
3. Zhao et al. (no specific year mentioned) - ""Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits""
4. Agarwal et al. (2023) - ""Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation""
5. Ye et al. (2023) - ""Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes""
6. Di et al. (2024) - ""Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning""
7. Huang et al. (no specific conference mentioned, but AISTATS is mentioned as the conference) - ""Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation""
8. Gentile et al. (2024) - ""Fast Rates in Pool-Based Batch Active Learning""
9. Zhao et al. (no specific year mentioned, but a different paper from the one mentioned in [3]) - ""A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation""",1,"2021, 2022, 2023, 2023, 2024, 2024",Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs
hU6nR5fE0Z,"This paper studies contextual bandits with general function approximation, emphasizing the impact of variance information. It proves lower bounds dependent on the Eluder dimension and variance information in both strong and weak adversary settings. It also proposes algorithms for both cases. When the adversary is weak, the proved regret upper bound is optimal, otherwise, there is a $\sqrt{d}$ gap from optimal. The paper also studies the learning problem when the function class contains the distributional information and provides optimal regret bound.","1. The paper studies contextual bandits with general function approximation. The proved lower bound dependent on the Eluder dimension and variance information is very novel.
2. The paper provides a comprehensive analysis for different settings, e.g, weak/strong adversaries, and distributional settings. The proved results are insightful and optimal in most cases.
3. The presentation is very clear, including comparison with previous works.","1. In the known variance section, this paper only focuses on a regime where $A \le d_{elu} \le \sqrt{AT}$. The case $d_{elu} \le A$ is also very important, especially when the action set is large and function approximation benefits. In such cases, the proved upper bound and lower bound do not match, so the contribution in this section is a bit overclaimed. (matching upper bound when variance is known)
2. Some missing related works.
More works on variance-dependent results of heteroscedastic bandits:

[1] Zhou et al. Nearly minimax optimal reinforcement learning for linear mixture markov decision processes, Colt 2021

[2] Zhou and Gu. Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs Neurips 2022

[3] Zhao et al. Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits

3. This description of ""checking disagreement"" (Line 166) is not very accurate. A similar definition of equation (4) has been used in previous works as weights ([4] [5]), bonus functions ([6][7]), and selection rules ([8][9]). I suggest adding more discussions on this.
 
[4] Agarwal et al. Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation. Colt 2023

[5] Ye et al.  Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes. ICML2023

[6] Di et al. Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning, ICLR 2024

[7] Huang et al. Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation AISTATS

[8] Gentile et al. Fast Rates in Pool-Based Batch Active Learning ICML 2024

[9] Zhao et al. A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation

4. Some minor errors: Line 12 worst case over what? 

In the proof of Lemma E.5, there is an abusive use of $\epsilon$, it represents both the Gaussian noise and a changeable parameter for $\sigma$.","1. Is it possible to prove a variance-dependent upper bound with $d_{elu}$ dependence in the first term of Theorem 4.2?
2. What difficulty did you meet when trying to recover Zhao et al. (2023)’s result for unknown variance?",The limitations and societal impact of this work have been addressed.,['No ethics review needed.'],7,4,,Yes,3,3,3,1720763359987,,,NeurIPS.cc/2024/Conference,32Z3nfCnwa,"['NeurIPS.cc/2024/Conference/Submission17787/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879933529,[],3,,,['everyone'],32Z3nfCnwa,['NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3'],1720763359987,1730879933529,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Zhou et al. (2021) - ""Nearly minimax optimal reinforcement learning for linear mixture markov decision processes""
2. Zhou and Gu (2022) - ""Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs""
3. Zhao et al. (no specific year mentioned) - ""Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits""
4. Agarwal et al. (2023) - ""Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation""
5. Ye et al. (2023) - ""Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes""
6. Di et al. (2024) - ""Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning""
7. Huang et al. (no specific conference mentioned, but AISTATS is mentioned as the conference) - ""Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation""
8. Gentile et al. (2024) - ""Fast Rates in Pool-Based Batch Active Learning""
9. Zhao et al. (no specific year mentioned, but a different paper from the one mentioned in [3]) - ""A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation""",1,"2021, 2022, 2023, 2023, 2024, 2024",Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits
hU6nR5fE0Z,"This paper studies contextual bandits with general function approximation, emphasizing the impact of variance information. It proves lower bounds dependent on the Eluder dimension and variance information in both strong and weak adversary settings. It also proposes algorithms for both cases. When the adversary is weak, the proved regret upper bound is optimal, otherwise, there is a $\sqrt{d}$ gap from optimal. The paper also studies the learning problem when the function class contains the distributional information and provides optimal regret bound.","1. The paper studies contextual bandits with general function approximation. The proved lower bound dependent on the Eluder dimension and variance information is very novel.
2. The paper provides a comprehensive analysis for different settings, e.g, weak/strong adversaries, and distributional settings. The proved results are insightful and optimal in most cases.
3. The presentation is very clear, including comparison with previous works.","1. In the known variance section, this paper only focuses on a regime where $A \le d_{elu} \le \sqrt{AT}$. The case $d_{elu} \le A$ is also very important, especially when the action set is large and function approximation benefits. In such cases, the proved upper bound and lower bound do not match, so the contribution in this section is a bit overclaimed. (matching upper bound when variance is known)
2. Some missing related works.
More works on variance-dependent results of heteroscedastic bandits:

[1] Zhou et al. Nearly minimax optimal reinforcement learning for linear mixture markov decision processes, Colt 2021

[2] Zhou and Gu. Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs Neurips 2022

[3] Zhao et al. Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits

3. This description of ""checking disagreement"" (Line 166) is not very accurate. A similar definition of equation (4) has been used in previous works as weights ([4] [5]), bonus functions ([6][7]), and selection rules ([8][9]). I suggest adding more discussions on this.
 
[4] Agarwal et al. Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation. Colt 2023

[5] Ye et al.  Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes. ICML2023

[6] Di et al. Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning, ICLR 2024

[7] Huang et al. Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation AISTATS

[8] Gentile et al. Fast Rates in Pool-Based Batch Active Learning ICML 2024

[9] Zhao et al. A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation

4. Some minor errors: Line 12 worst case over what? 

In the proof of Lemma E.5, there is an abusive use of $\epsilon$, it represents both the Gaussian noise and a changeable parameter for $\sigma$.","1. Is it possible to prove a variance-dependent upper bound with $d_{elu}$ dependence in the first term of Theorem 4.2?
2. What difficulty did you meet when trying to recover Zhao et al. (2023)’s result for unknown variance?",The limitations and societal impact of this work have been addressed.,['No ethics review needed.'],7,4,,Yes,3,3,3,1720763359987,,,NeurIPS.cc/2024/Conference,32Z3nfCnwa,"['NeurIPS.cc/2024/Conference/Submission17787/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879933529,[],3,,,['everyone'],32Z3nfCnwa,['NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3'],1720763359987,1730879933529,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Zhou et al. (2021) - ""Nearly minimax optimal reinforcement learning for linear mixture markov decision processes""
2. Zhou and Gu (2022) - ""Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs""
3. Zhao et al. (no specific year mentioned) - ""Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits""
4. Agarwal et al. (2023) - ""Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation""
5. Ye et al. (2023) - ""Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes""
6. Di et al. (2024) - ""Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning""
7. Huang et al. (no specific conference mentioned, but AISTATS is mentioned as the conference) - ""Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation""
8. Gentile et al. (2024) - ""Fast Rates in Pool-Based Batch Active Learning""
9. Zhao et al. (no specific year mentioned, but a different paper from the one mentioned in [3]) - ""A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation""",1,"2021, 2022, 2023, 2023, 2024, 2024",Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation
hU6nR5fE0Z,"This paper studies contextual bandits with general function approximation, emphasizing the impact of variance information. It proves lower bounds dependent on the Eluder dimension and variance information in both strong and weak adversary settings. It also proposes algorithms for both cases. When the adversary is weak, the proved regret upper bound is optimal, otherwise, there is a $\sqrt{d}$ gap from optimal. The paper also studies the learning problem when the function class contains the distributional information and provides optimal regret bound.","1. The paper studies contextual bandits with general function approximation. The proved lower bound dependent on the Eluder dimension and variance information is very novel.
2. The paper provides a comprehensive analysis for different settings, e.g, weak/strong adversaries, and distributional settings. The proved results are insightful and optimal in most cases.
3. The presentation is very clear, including comparison with previous works.","1. In the known variance section, this paper only focuses on a regime where $A \le d_{elu} \le \sqrt{AT}$. The case $d_{elu} \le A$ is also very important, especially when the action set is large and function approximation benefits. In such cases, the proved upper bound and lower bound do not match, so the contribution in this section is a bit overclaimed. (matching upper bound when variance is known)
2. Some missing related works.
More works on variance-dependent results of heteroscedastic bandits:

[1] Zhou et al. Nearly minimax optimal reinforcement learning for linear mixture markov decision processes, Colt 2021

[2] Zhou and Gu. Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs Neurips 2022

[3] Zhao et al. Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits

3. This description of ""checking disagreement"" (Line 166) is not very accurate. A similar definition of equation (4) has been used in previous works as weights ([4] [5]), bonus functions ([6][7]), and selection rules ([8][9]). I suggest adding more discussions on this.
 
[4] Agarwal et al. Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation. Colt 2023

[5] Ye et al.  Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes. ICML2023

[6] Di et al. Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning, ICLR 2024

[7] Huang et al. Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation AISTATS

[8] Gentile et al. Fast Rates in Pool-Based Batch Active Learning ICML 2024

[9] Zhao et al. A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation

4. Some minor errors: Line 12 worst case over what? 

In the proof of Lemma E.5, there is an abusive use of $\epsilon$, it represents both the Gaussian noise and a changeable parameter for $\sigma$.","1. Is it possible to prove a variance-dependent upper bound with $d_{elu}$ dependence in the first term of Theorem 4.2?
2. What difficulty did you meet when trying to recover Zhao et al. (2023)’s result for unknown variance?",The limitations and societal impact of this work have been addressed.,['No ethics review needed.'],7,4,,Yes,3,3,3,1720763359987,,,NeurIPS.cc/2024/Conference,32Z3nfCnwa,"['NeurIPS.cc/2024/Conference/Submission17787/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879933529,[],3,,,['everyone'],32Z3nfCnwa,['NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3'],1720763359987,1730879933529,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Zhou et al. (2021) - ""Nearly minimax optimal reinforcement learning for linear mixture markov decision processes""
2. Zhou and Gu (2022) - ""Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs""
3. Zhao et al. (no specific year mentioned) - ""Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits""
4. Agarwal et al. (2023) - ""Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation""
5. Ye et al. (2023) - ""Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes""
6. Di et al. (2024) - ""Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning""
7. Huang et al. (no specific conference mentioned, but AISTATS is mentioned as the conference) - ""Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation""
8. Gentile et al. (2024) - ""Fast Rates in Pool-Based Batch Active Learning""
9. Zhao et al. (no specific year mentioned, but a different paper from the one mentioned in [3]) - ""A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation""",1,"2021, 2022, 2023, 2023, 2024, 2024",Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes
hU6nR5fE0Z,"This paper studies contextual bandits with general function approximation, emphasizing the impact of variance information. It proves lower bounds dependent on the Eluder dimension and variance information in both strong and weak adversary settings. It also proposes algorithms for both cases. When the adversary is weak, the proved regret upper bound is optimal, otherwise, there is a $\sqrt{d}$ gap from optimal. The paper also studies the learning problem when the function class contains the distributional information and provides optimal regret bound.","1. The paper studies contextual bandits with general function approximation. The proved lower bound dependent on the Eluder dimension and variance information is very novel.
2. The paper provides a comprehensive analysis for different settings, e.g, weak/strong adversaries, and distributional settings. The proved results are insightful and optimal in most cases.
3. The presentation is very clear, including comparison with previous works.","1. In the known variance section, this paper only focuses on a regime where $A \le d_{elu} \le \sqrt{AT}$. The case $d_{elu} \le A$ is also very important, especially when the action set is large and function approximation benefits. In such cases, the proved upper bound and lower bound do not match, so the contribution in this section is a bit overclaimed. (matching upper bound when variance is known)
2. Some missing related works.
More works on variance-dependent results of heteroscedastic bandits:

[1] Zhou et al. Nearly minimax optimal reinforcement learning for linear mixture markov decision processes, Colt 2021

[2] Zhou and Gu. Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs Neurips 2022

[3] Zhao et al. Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits

3. This description of ""checking disagreement"" (Line 166) is not very accurate. A similar definition of equation (4) has been used in previous works as weights ([4] [5]), bonus functions ([6][7]), and selection rules ([8][9]). I suggest adding more discussions on this.
 
[4] Agarwal et al. Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation. Colt 2023

[5] Ye et al.  Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes. ICML2023

[6] Di et al. Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning, ICLR 2024

[7] Huang et al. Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation AISTATS

[8] Gentile et al. Fast Rates in Pool-Based Batch Active Learning ICML 2024

[9] Zhao et al. A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation

4. Some minor errors: Line 12 worst case over what? 

In the proof of Lemma E.5, there is an abusive use of $\epsilon$, it represents both the Gaussian noise and a changeable parameter for $\sigma$.","1. Is it possible to prove a variance-dependent upper bound with $d_{elu}$ dependence in the first term of Theorem 4.2?
2. What difficulty did you meet when trying to recover Zhao et al. (2023)’s result for unknown variance?",The limitations and societal impact of this work have been addressed.,['No ethics review needed.'],7,4,,Yes,3,3,3,1720763359987,,,NeurIPS.cc/2024/Conference,32Z3nfCnwa,"['NeurIPS.cc/2024/Conference/Submission17787/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879933529,[],3,,,['everyone'],32Z3nfCnwa,['NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3'],1720763359987,1730879933529,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Zhou et al. (2021) - ""Nearly minimax optimal reinforcement learning for linear mixture markov decision processes""
2. Zhou and Gu (2022) - ""Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs""
3. Zhao et al. (no specific year mentioned) - ""Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits""
4. Agarwal et al. (2023) - ""Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation""
5. Ye et al. (2023) - ""Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes""
6. Di et al. (2024) - ""Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning""
7. Huang et al. (no specific conference mentioned, but AISTATS is mentioned as the conference) - ""Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation""
8. Gentile et al. (2024) - ""Fast Rates in Pool-Based Batch Active Learning""
9. Zhao et al. (no specific year mentioned, but a different paper from the one mentioned in [3]) - ""A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation""",1,"2021, 2022, 2023, 2023, 2024, 2024",Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning
hU6nR5fE0Z,"This paper studies contextual bandits with general function approximation, emphasizing the impact of variance information. It proves lower bounds dependent on the Eluder dimension and variance information in both strong and weak adversary settings. It also proposes algorithms for both cases. When the adversary is weak, the proved regret upper bound is optimal, otherwise, there is a $\sqrt{d}$ gap from optimal. The paper also studies the learning problem when the function class contains the distributional information and provides optimal regret bound.","1. The paper studies contextual bandits with general function approximation. The proved lower bound dependent on the Eluder dimension and variance information is very novel.
2. The paper provides a comprehensive analysis for different settings, e.g, weak/strong adversaries, and distributional settings. The proved results are insightful and optimal in most cases.
3. The presentation is very clear, including comparison with previous works.","1. In the known variance section, this paper only focuses on a regime where $A \le d_{elu} \le \sqrt{AT}$. The case $d_{elu} \le A$ is also very important, especially when the action set is large and function approximation benefits. In such cases, the proved upper bound and lower bound do not match, so the contribution in this section is a bit overclaimed. (matching upper bound when variance is known)
2. Some missing related works.
More works on variance-dependent results of heteroscedastic bandits:

[1] Zhou et al. Nearly minimax optimal reinforcement learning for linear mixture markov decision processes, Colt 2021

[2] Zhou and Gu. Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs Neurips 2022

[3] Zhao et al. Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits

3. This description of ""checking disagreement"" (Line 166) is not very accurate. A similar definition of equation (4) has been used in previous works as weights ([4] [5]), bonus functions ([6][7]), and selection rules ([8][9]). I suggest adding more discussions on this.
 
[4] Agarwal et al. Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation. Colt 2023

[5] Ye et al.  Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes. ICML2023

[6] Di et al. Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning, ICLR 2024

[7] Huang et al. Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation AISTATS

[8] Gentile et al. Fast Rates in Pool-Based Batch Active Learning ICML 2024

[9] Zhao et al. A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation

4. Some minor errors: Line 12 worst case over what? 

In the proof of Lemma E.5, there is an abusive use of $\epsilon$, it represents both the Gaussian noise and a changeable parameter for $\sigma$.","1. Is it possible to prove a variance-dependent upper bound with $d_{elu}$ dependence in the first term of Theorem 4.2?
2. What difficulty did you meet when trying to recover Zhao et al. (2023)’s result for unknown variance?",The limitations and societal impact of this work have been addressed.,['No ethics review needed.'],7,4,,Yes,3,3,3,1720763359987,,,NeurIPS.cc/2024/Conference,32Z3nfCnwa,"['NeurIPS.cc/2024/Conference/Submission17787/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879933529,[],3,,,['everyone'],32Z3nfCnwa,['NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3'],1720763359987,1730879933529,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Zhou et al. (2021) - ""Nearly minimax optimal reinforcement learning for linear mixture markov decision processes""
2. Zhou and Gu (2022) - ""Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs""
3. Zhao et al. (no specific year mentioned) - ""Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits""
4. Agarwal et al. (2023) - ""Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation""
5. Ye et al. (2023) - ""Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes""
6. Di et al. (2024) - ""Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning""
7. Huang et al. (no specific conference mentioned, but AISTATS is mentioned as the conference) - ""Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation""
8. Gentile et al. (2024) - ""Fast Rates in Pool-Based Batch Active Learning""
9. Zhao et al. (no specific year mentioned, but a different paper from the one mentioned in [3]) - ""A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation""",1,"2021, 2022, 2023, 2023, 2024, 2024",Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation
hU6nR5fE0Z,"This paper studies contextual bandits with general function approximation, emphasizing the impact of variance information. It proves lower bounds dependent on the Eluder dimension and variance information in both strong and weak adversary settings. It also proposes algorithms for both cases. When the adversary is weak, the proved regret upper bound is optimal, otherwise, there is a $\sqrt{d}$ gap from optimal. The paper also studies the learning problem when the function class contains the distributional information and provides optimal regret bound.","1. The paper studies contextual bandits with general function approximation. The proved lower bound dependent on the Eluder dimension and variance information is very novel.
2. The paper provides a comprehensive analysis for different settings, e.g, weak/strong adversaries, and distributional settings. The proved results are insightful and optimal in most cases.
3. The presentation is very clear, including comparison with previous works.","1. In the known variance section, this paper only focuses on a regime where $A \le d_{elu} \le \sqrt{AT}$. The case $d_{elu} \le A$ is also very important, especially when the action set is large and function approximation benefits. In such cases, the proved upper bound and lower bound do not match, so the contribution in this section is a bit overclaimed. (matching upper bound when variance is known)
2. Some missing related works.
More works on variance-dependent results of heteroscedastic bandits:

[1] Zhou et al. Nearly minimax optimal reinforcement learning for linear mixture markov decision processes, Colt 2021

[2] Zhou and Gu. Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs Neurips 2022

[3] Zhao et al. Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits

3. This description of ""checking disagreement"" (Line 166) is not very accurate. A similar definition of equation (4) has been used in previous works as weights ([4] [5]), bonus functions ([6][7]), and selection rules ([8][9]). I suggest adding more discussions on this.
 
[4] Agarwal et al. Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation. Colt 2023

[5] Ye et al.  Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes. ICML2023

[6] Di et al. Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning, ICLR 2024

[7] Huang et al. Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation AISTATS

[8] Gentile et al. Fast Rates in Pool-Based Batch Active Learning ICML 2024

[9] Zhao et al. A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation

4. Some minor errors: Line 12 worst case over what? 

In the proof of Lemma E.5, there is an abusive use of $\epsilon$, it represents both the Gaussian noise and a changeable parameter for $\sigma$.","1. Is it possible to prove a variance-dependent upper bound with $d_{elu}$ dependence in the first term of Theorem 4.2?
2. What difficulty did you meet when trying to recover Zhao et al. (2023)’s result for unknown variance?",The limitations and societal impact of this work have been addressed.,['No ethics review needed.'],7,4,,Yes,3,3,3,1720763359987,,,NeurIPS.cc/2024/Conference,32Z3nfCnwa,"['NeurIPS.cc/2024/Conference/Submission17787/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879933529,[],3,,,['everyone'],32Z3nfCnwa,['NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3'],1720763359987,1730879933529,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Zhou et al. (2021) - ""Nearly minimax optimal reinforcement learning for linear mixture markov decision processes""
2. Zhou and Gu (2022) - ""Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs""
3. Zhao et al. (no specific year mentioned) - ""Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits""
4. Agarwal et al. (2023) - ""Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation""
5. Ye et al. (2023) - ""Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes""
6. Di et al. (2024) - ""Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning""
7. Huang et al. (no specific conference mentioned, but AISTATS is mentioned as the conference) - ""Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation""
8. Gentile et al. (2024) - ""Fast Rates in Pool-Based Batch Active Learning""
9. Zhao et al. (no specific year mentioned, but a different paper from the one mentioned in [3]) - ""A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation""",1,"2021, 2022, 2023, 2023, 2024, 2024",Fast Rates in Pool-Based Batch Active Learning
hU6nR5fE0Z,"This paper studies contextual bandits with general function approximation, emphasizing the impact of variance information. It proves lower bounds dependent on the Eluder dimension and variance information in both strong and weak adversary settings. It also proposes algorithms for both cases. When the adversary is weak, the proved regret upper bound is optimal, otherwise, there is a $\sqrt{d}$ gap from optimal. The paper also studies the learning problem when the function class contains the distributional information and provides optimal regret bound.","1. The paper studies contextual bandits with general function approximation. The proved lower bound dependent on the Eluder dimension and variance information is very novel.
2. The paper provides a comprehensive analysis for different settings, e.g, weak/strong adversaries, and distributional settings. The proved results are insightful and optimal in most cases.
3. The presentation is very clear, including comparison with previous works.","1. In the known variance section, this paper only focuses on a regime where $A \le d_{elu} \le \sqrt{AT}$. The case $d_{elu} \le A$ is also very important, especially when the action set is large and function approximation benefits. In such cases, the proved upper bound and lower bound do not match, so the contribution in this section is a bit overclaimed. (matching upper bound when variance is known)
2. Some missing related works.
More works on variance-dependent results of heteroscedastic bandits:

[1] Zhou et al. Nearly minimax optimal reinforcement learning for linear mixture markov decision processes, Colt 2021

[2] Zhou and Gu. Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs Neurips 2022

[3] Zhao et al. Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits

3. This description of ""checking disagreement"" (Line 166) is not very accurate. A similar definition of equation (4) has been used in previous works as weights ([4] [5]), bonus functions ([6][7]), and selection rules ([8][9]). I suggest adding more discussions on this.
 
[4] Agarwal et al. Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation. Colt 2023

[5] Ye et al.  Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes. ICML2023

[6] Di et al. Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning, ICLR 2024

[7] Huang et al. Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation AISTATS

[8] Gentile et al. Fast Rates in Pool-Based Batch Active Learning ICML 2024

[9] Zhao et al. A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation

4. Some minor errors: Line 12 worst case over what? 

In the proof of Lemma E.5, there is an abusive use of $\epsilon$, it represents both the Gaussian noise and a changeable parameter for $\sigma$.","1. Is it possible to prove a variance-dependent upper bound with $d_{elu}$ dependence in the first term of Theorem 4.2?
2. What difficulty did you meet when trying to recover Zhao et al. (2023)’s result for unknown variance?",The limitations and societal impact of this work have been addressed.,['No ethics review needed.'],7,4,,Yes,3,3,3,1720763359987,,,NeurIPS.cc/2024/Conference,32Z3nfCnwa,"['NeurIPS.cc/2024/Conference/Submission17787/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879933529,[],3,,,['everyone'],32Z3nfCnwa,['NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3'],1720763359987,1730879933529,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17787/Reviewer_W3F3']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Zhou et al. (2021) - ""Nearly minimax optimal reinforcement learning for linear mixture markov decision processes""
2. Zhou and Gu (2022) - ""Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs""
3. Zhao et al. (no specific year mentioned) - ""Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits""
4. Agarwal et al. (2023) - ""Vo q l: Towards optimal regret in model-free rl with nonlinear function approximation""
5. Ye et al. (2023) - ""Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes""
6. Di et al. (2024) - ""Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning""
7. Huang et al. (no specific conference mentioned, but AISTATS is mentioned as the conference) - ""Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation""
8. Gentile et al. (2024) - ""Fast Rates in Pool-Based Batch Active Learning""
9. Zhao et al. (no specific year mentioned, but a different paper from the one mentioned in [3]) - ""A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation""",1,"2021, 2022, 2023, 2023, 2024, 2024",A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation
f98yD1VIac,"This paper proposes a general framework for addressing safe RL problems via gradient-based primal-dual algorithms. The authors show that the proposed algorithm exhibit global last-iterate convergence guarantees under gradient domination assumptions. Additionally, the authors validate their algorithms on several constrained control problems.","1. This paper is well-written and easy to follow.
2. The paper is technically sound with most claims supported sufficiently.
3. The theoretical analysis seems novel.","Quality:

1. In Theorem 3.1, it requires w=O(\epsilon) to enforce an overall \epsilon error, but w should be a fixed number in C-PG algorithm. 
2. It is better to have some experimental results about cost constraints on MuJoCo and include more baselines, e.g., [Zhang et al., 2020, First Order Constrained Optimization in Policy Space].

Clarity:

1. The range of reward value is [-1, 0], which is a bit weird compared to normal settings.
2. The advantage of parameter-based hyperpolicy is not clearly mentioned in the paper.

Significance:

One relevant literature is missing. In [Liu et al. 2021, Policy Optimization for Constrained MDPs with Provable Fast Global Convergence], a fast convergence \tilde{O}(1/\epsilon) result is proved without multiple assumptions in this paper.","Please see the details in ""weakness"".",There is no potential negative social impact of this work.,['No ethics review needed.'],5,4,,Yes,2,3,2,1720337746120,,,NeurIPS.cc/2024/Conference,2vywag2lVC,"['NeurIPS.cc/2024/Conference/Submission11611/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879480359,[],3,,,['everyone'],2vywag2lVC,['NeurIPS.cc/2024/Conference/Submission11611/Reviewer_ZDP8'],1720337746120,1730879480359,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11611/Reviewer_ZDP8']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. Zhang et al., 2020, ""First Order Constrained Optimization in Policy Space""
2. Liu et al., 2021, ""Policy Optimization for Constrained MDPs with Provable Fast Global Convergence""

The reviewer mentions that including more baselines, such as the work by Zhang et al., would be beneficial, and also notes that the work by Liu et al. is a relevant literature that is missing from the paper.",1,"2020, 2021",First Order Constrained Optimization in Policy Space 
f98yD1VIac,"This paper proposes a general framework for addressing safe RL problems via gradient-based primal-dual algorithms. The authors show that the proposed algorithm exhibit global last-iterate convergence guarantees under gradient domination assumptions. Additionally, the authors validate their algorithms on several constrained control problems.","1. This paper is well-written and easy to follow.
2. The paper is technically sound with most claims supported sufficiently.
3. The theoretical analysis seems novel.","Quality:

1. In Theorem 3.1, it requires w=O(\epsilon) to enforce an overall \epsilon error, but w should be a fixed number in C-PG algorithm. 
2. It is better to have some experimental results about cost constraints on MuJoCo and include more baselines, e.g., [Zhang et al., 2020, First Order Constrained Optimization in Policy Space].

Clarity:

1. The range of reward value is [-1, 0], which is a bit weird compared to normal settings.
2. The advantage of parameter-based hyperpolicy is not clearly mentioned in the paper.

Significance:

One relevant literature is missing. In [Liu et al. 2021, Policy Optimization for Constrained MDPs with Provable Fast Global Convergence], a fast convergence \tilde{O}(1/\epsilon) result is proved without multiple assumptions in this paper.","Please see the details in ""weakness"".",There is no potential negative social impact of this work.,['No ethics review needed.'],5,4,,Yes,2,3,2,1720337746120,,,NeurIPS.cc/2024/Conference,2vywag2lVC,"['NeurIPS.cc/2024/Conference/Submission11611/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879480359,[],3,,,['everyone'],2vywag2lVC,['NeurIPS.cc/2024/Conference/Submission11611/Reviewer_ZDP8'],1720337746120,1730879480359,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11611/Reviewer_ZDP8']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. Zhang et al., 2020, ""First Order Constrained Optimization in Policy Space""
2. Liu et al., 2021, ""Policy Optimization for Constrained MDPs with Provable Fast Global Convergence""

The reviewer mentions that including more baselines, such as the work by Zhang et al., would be beneficial, and also notes that the work by Liu et al. is a relevant literature that is missing from the paper.",1,"2020, 2021",Policy Optimization for Constrained MDPs with Provable Fast Global Convergence
hlw6RJRxtx,"This paper focuses on the Multi-class Unsupervised Anomaly Detection task and proposes a minimalistic reconstruction-based anomaly detection framework — Dinomaly that consists of only vanilla Transformer blocks. In this framework, four key components (Foundation Transformers, Noisy Bottleneck, Linear Attention, and Loose Reconstruction) are introduced to alleviate the performance gap between multi-class and class-separated models. The paper conducts extensive experiments on three major datasets: MVTec-AD, VisA, and Real-IAD. Results show that Dinomaly outperforms current state-of-the-art methods.","(1)The paper is well-written and has clear statements which make it easy to understand. 

(2)The design of Dinomaly is straightforward but innovative. The use of foundation transformers, noisy bottleneck, linear attention, and loose reconstruction is well-justified. 

(3)The paper generally outperformed existing SOTA methods and did enough experiments and comparisons.","(1)The method relies heavily on transformer architectures, which might limit its applicability to other types of models.

(2)Transformers can be resource-intensive, and the paper does not fully address the computational cost of training and inference.

(3)The method's generalization to other domains or types of anomaly detection is not fully explored.","(1) Please specify the computational overhead of your work.

(2) There have been various recent works that attempt to perform anomaly detection in a more general zero-shot/few-shot setting, where the model trained on multiple classes is used to test samples from unseen classes. A discussion of these recent works and how the zero-shot (cross-dataset) performance of this approach should be added. e.g.,

""WinCLIP: Zero-/few-shot anomaly classification and segmentation"" CVPR'2023

""AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"" ICLR'2024

""Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts"" CVPR'2024

""PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection"" CVPR'2024

(3) If I understand correctly, the best and second-best results in each table should be highlighted, with the best results in bold and the second-best results underlined. However, in Table 2, the best results for MVTec-AD (P-AP) and VisA (P-AP) are incorrectly marked. Additionally, could you clarify why the Dinomaly (MUAD) model outperforms the Dinomaly (class-separated) model in this metric?",Limitations are discussed in Supplementary Sec. A.4.,['No ethics review needed.'],6,4,,Yes,3,4,3,1720774954588,,,NeurIPS.cc/2024/Conference,2vhkjOdlc8,"['NeurIPS.cc/2024/Conference/Submission2463/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878777780,[],2,,,['everyone'],2vhkjOdlc8,['NeurIPS.cc/2024/Conference/Submission2463/Reviewer_hJXx'],1720774954588,1730878777780,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2463/Reviewer_hJXx']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature related to zero-shot/few-shot anomaly detection, such as:

1. ""WinCLIP: Zero-/few-shot anomaly classification and segmentation"" CVPR'2023
2. ""AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"" ICLR'2024
3. ""Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts"" CVPR'2024
4. ""PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection"" CVPR'2024

The reviewer recommends that the authors discuss these recent works and compare the zero-shot (cross-dataset) performance of their approach with these methods.",1,"2020, 2020, 2020, 2020",WinCLIP Zero-/few-shot anomaly classification and segmentation 
hlw6RJRxtx,"This paper focuses on the Multi-class Unsupervised Anomaly Detection task and proposes a minimalistic reconstruction-based anomaly detection framework — Dinomaly that consists of only vanilla Transformer blocks. In this framework, four key components (Foundation Transformers, Noisy Bottleneck, Linear Attention, and Loose Reconstruction) are introduced to alleviate the performance gap between multi-class and class-separated models. The paper conducts extensive experiments on three major datasets: MVTec-AD, VisA, and Real-IAD. Results show that Dinomaly outperforms current state-of-the-art methods.","(1)The paper is well-written and has clear statements which make it easy to understand. 

(2)The design of Dinomaly is straightforward but innovative. The use of foundation transformers, noisy bottleneck, linear attention, and loose reconstruction is well-justified. 

(3)The paper generally outperformed existing SOTA methods and did enough experiments and comparisons.","(1)The method relies heavily on transformer architectures, which might limit its applicability to other types of models.

(2)Transformers can be resource-intensive, and the paper does not fully address the computational cost of training and inference.

(3)The method's generalization to other domains or types of anomaly detection is not fully explored.","(1) Please specify the computational overhead of your work.

(2) There have been various recent works that attempt to perform anomaly detection in a more general zero-shot/few-shot setting, where the model trained on multiple classes is used to test samples from unseen classes. A discussion of these recent works and how the zero-shot (cross-dataset) performance of this approach should be added. e.g.,

""WinCLIP: Zero-/few-shot anomaly classification and segmentation"" CVPR'2023

""AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"" ICLR'2024

""Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts"" CVPR'2024

""PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection"" CVPR'2024

(3) If I understand correctly, the best and second-best results in each table should be highlighted, with the best results in bold and the second-best results underlined. However, in Table 2, the best results for MVTec-AD (P-AP) and VisA (P-AP) are incorrectly marked. Additionally, could you clarify why the Dinomaly (MUAD) model outperforms the Dinomaly (class-separated) model in this metric?",Limitations are discussed in Supplementary Sec. A.4.,['No ethics review needed.'],6,4,,Yes,3,4,3,1720774954588,,,NeurIPS.cc/2024/Conference,2vhkjOdlc8,"['NeurIPS.cc/2024/Conference/Submission2463/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878777780,[],2,,,['everyone'],2vhkjOdlc8,['NeurIPS.cc/2024/Conference/Submission2463/Reviewer_hJXx'],1720774954588,1730878777780,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2463/Reviewer_hJXx']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature related to zero-shot/few-shot anomaly detection, such as:

1. ""WinCLIP: Zero-/few-shot anomaly classification and segmentation"" CVPR'2023
2. ""AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"" ICLR'2024
3. ""Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts"" CVPR'2024
4. ""PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection"" CVPR'2024

The reviewer recommends that the authors discuss these recent works and compare the zero-shot (cross-dataset) performance of their approach with these methods.",1,"2020, 2020, 2020, 2020",AnomalyCLIP Object-agnostic Prompt Learning for Zero-shot Anomaly Detection 
hlw6RJRxtx,"This paper focuses on the Multi-class Unsupervised Anomaly Detection task and proposes a minimalistic reconstruction-based anomaly detection framework — Dinomaly that consists of only vanilla Transformer blocks. In this framework, four key components (Foundation Transformers, Noisy Bottleneck, Linear Attention, and Loose Reconstruction) are introduced to alleviate the performance gap between multi-class and class-separated models. The paper conducts extensive experiments on three major datasets: MVTec-AD, VisA, and Real-IAD. Results show that Dinomaly outperforms current state-of-the-art methods.","(1)The paper is well-written and has clear statements which make it easy to understand. 

(2)The design of Dinomaly is straightforward but innovative. The use of foundation transformers, noisy bottleneck, linear attention, and loose reconstruction is well-justified. 

(3)The paper generally outperformed existing SOTA methods and did enough experiments and comparisons.","(1)The method relies heavily on transformer architectures, which might limit its applicability to other types of models.

(2)Transformers can be resource-intensive, and the paper does not fully address the computational cost of training and inference.

(3)The method's generalization to other domains or types of anomaly detection is not fully explored.","(1) Please specify the computational overhead of your work.

(2) There have been various recent works that attempt to perform anomaly detection in a more general zero-shot/few-shot setting, where the model trained on multiple classes is used to test samples from unseen classes. A discussion of these recent works and how the zero-shot (cross-dataset) performance of this approach should be added. e.g.,

""WinCLIP: Zero-/few-shot anomaly classification and segmentation"" CVPR'2023

""AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"" ICLR'2024

""Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts"" CVPR'2024

""PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection"" CVPR'2024

(3) If I understand correctly, the best and second-best results in each table should be highlighted, with the best results in bold and the second-best results underlined. However, in Table 2, the best results for MVTec-AD (P-AP) and VisA (P-AP) are incorrectly marked. Additionally, could you clarify why the Dinomaly (MUAD) model outperforms the Dinomaly (class-separated) model in this metric?",Limitations are discussed in Supplementary Sec. A.4.,['No ethics review needed.'],6,4,,Yes,3,4,3,1720774954588,,,NeurIPS.cc/2024/Conference,2vhkjOdlc8,"['NeurIPS.cc/2024/Conference/Submission2463/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878777780,[],2,,,['everyone'],2vhkjOdlc8,['NeurIPS.cc/2024/Conference/Submission2463/Reviewer_hJXx'],1720774954588,1730878777780,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2463/Reviewer_hJXx']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature related to zero-shot/few-shot anomaly detection, such as:

1. ""WinCLIP: Zero-/few-shot anomaly classification and segmentation"" CVPR'2023
2. ""AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"" ICLR'2024
3. ""Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts"" CVPR'2024
4. ""PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection"" CVPR'2024

The reviewer recommends that the authors discuss these recent works and compare the zero-shot (cross-dataset) performance of their approach with these methods.",1,"2020, 2020, 2020, 2020",Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts 
hlw6RJRxtx,"This paper focuses on the Multi-class Unsupervised Anomaly Detection task and proposes a minimalistic reconstruction-based anomaly detection framework — Dinomaly that consists of only vanilla Transformer blocks. In this framework, four key components (Foundation Transformers, Noisy Bottleneck, Linear Attention, and Loose Reconstruction) are introduced to alleviate the performance gap between multi-class and class-separated models. The paper conducts extensive experiments on three major datasets: MVTec-AD, VisA, and Real-IAD. Results show that Dinomaly outperforms current state-of-the-art methods.","(1)The paper is well-written and has clear statements which make it easy to understand. 

(2)The design of Dinomaly is straightforward but innovative. The use of foundation transformers, noisy bottleneck, linear attention, and loose reconstruction is well-justified. 

(3)The paper generally outperformed existing SOTA methods and did enough experiments and comparisons.","(1)The method relies heavily on transformer architectures, which might limit its applicability to other types of models.

(2)Transformers can be resource-intensive, and the paper does not fully address the computational cost of training and inference.

(3)The method's generalization to other domains or types of anomaly detection is not fully explored.","(1) Please specify the computational overhead of your work.

(2) There have been various recent works that attempt to perform anomaly detection in a more general zero-shot/few-shot setting, where the model trained on multiple classes is used to test samples from unseen classes. A discussion of these recent works and how the zero-shot (cross-dataset) performance of this approach should be added. e.g.,

""WinCLIP: Zero-/few-shot anomaly classification and segmentation"" CVPR'2023

""AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"" ICLR'2024

""Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts"" CVPR'2024

""PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection"" CVPR'2024

(3) If I understand correctly, the best and second-best results in each table should be highlighted, with the best results in bold and the second-best results underlined. However, in Table 2, the best results for MVTec-AD (P-AP) and VisA (P-AP) are incorrectly marked. Additionally, could you clarify why the Dinomaly (MUAD) model outperforms the Dinomaly (class-separated) model in this metric?",Limitations are discussed in Supplementary Sec. A.4.,['No ethics review needed.'],6,4,,Yes,3,4,3,1720774954588,,,NeurIPS.cc/2024/Conference,2vhkjOdlc8,"['NeurIPS.cc/2024/Conference/Submission2463/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878777780,[],2,,,['everyone'],2vhkjOdlc8,['NeurIPS.cc/2024/Conference/Submission2463/Reviewer_hJXx'],1720774954588,1730878777780,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2463/Reviewer_hJXx']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature related to zero-shot/few-shot anomaly detection, such as:

1. ""WinCLIP: Zero-/few-shot anomaly classification and segmentation"" CVPR'2023
2. ""AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"" ICLR'2024
3. ""Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts"" CVPR'2024
4. ""PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection"" CVPR'2024

The reviewer recommends that the authors discuss these recent works and compare the zero-shot (cross-dataset) performance of their approach with these methods.",1,"2020, 2020, 2020, 2020",PromptAD Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection
dVyF6HYyrz,"This paper proposes a framework for capturing the geometry, specular, and subsurface scattering appearance of 3D objects using a captured dataset composed of multi-view OLAT images. 
The appearance of the object is decomposed into two different models. 
First, a 3D Gaussian representation with a spatially varying BRDF model for explicit surface representation. Secondly, an implicit volumetric representation is used for subsurface scattering appearance. 
This framework enables material editing, relighting, and novel view synthesis in real-time.","1. I believe that the authors will provide a multi-view OLAT dataset for subsurface scattering objects in the future, and this dataset will be a great contribution to the vision and graphics community.
2. Screen space shading algorithm for 3D Gaussian representation improves the view-dependent appearance quality of the reconstructed object.
3. The use of two different appearance models enables the reconstruction of the geometry, BRDF, and subsurface scattering of 3D objects.","1. Missing references for diffusion-based SSS approximation models:

[1] A Practical Model for Subsurface Light Transport, Jensen et al., 2001.

[2] Light Diffusion in Multi-Layered Translucent Materials, Donner et al., 2005.

2. Lack of validation on the intrinsic properties. 

To generate realistic novel relit scenes and material edits, it is important to correctly acquire the intrinsic properties. For the synthetic data, each intrinsic property can be directly compared with the reconstructed one (RMSE). Although reconstructed properties can differ due to the different models from Blender or the limitations of the method, the author should address this. Currently, it is unclear if this method reconstructs each intrinsic property well because there is no ground truth intrinsic property information in the paper or supplemental material, even though the rendered results look realistic and similar to the ground truth data. For example, in the dragon dataset in the supplemental material, there are many specularity changes in the ground truth, but these are not observed in the renders.

3. The relighting results only include novel views with single-light images. 

There are no results for environmental lighting or changing light colors. Since the framework does not support multiple light sources, we could generate multiple light sources or environment-relighting results similar to the previous method [3]. Simply adding multiple OLAT images in screen space would provide much more powerful relighting results, which I would like to see.

[3] Neural Light Transport for Relighting and View Synthesis, Zhang et al., 2020.

4. It would be powerful to show the change in intrinsic properties between objects, for example, from bunny to dragon and vice versa.","1. The real-world dataset images look over-exposed in the specular regions. In the experimental setup. In the paper, same images were captured five times to reduce image noise. Did you change the exposure of the camera while capturing the raw images? Moreover, why did you choose 8-bit instead of 16-bit images?
2. This doesn't need to be addressed in the rebuttal (Minor), but it would be better to add some information about the name of each video. Without clear explanations, some notations can be misleading to the reader.","The author adequately addressed the limitations, including:
1. Difficulty in optimizing strongly heterogeneous materials.
2. Limitations in screen space shading.
I might add that this paper is also limited to static scenes only. Human skin, for example, is constrained not only by personal rights but also by the inability to handle movement during capturing. This will cause blurry results that the current framework cannot handle.",['No ethics review needed.'],6,4,,Yes,2,3,3,1719100999555,,,NeurIPS.cc/2024/Conference,2vMvh5XP0P,"['NeurIPS.cc/2024/Conference/Submission348/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878637977,[],1,,,['everyone'],2vMvh5XP0P,['NeurIPS.cc/2024/Conference/Submission348/Reviewer_uk4p'],1719100999555,1730878637977,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission348/Reviewer_uk4p']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. Specifically, it mentions two references for diffusion-based SSS (Subsurface Scattering) approximation models that are missing from the paper:

1. ""A Practical Model for Subsurface Light Transport"" by Jensen et al. (2001)
2. ""Light Diffusion in Multi-Layered Translucent Materials"" by Donner et al. (2005)

Additionally, it mentions another reference, ""Neural Light Transport for Relighting and View Synthesis"" by Zhang et al. (2020), as a previous method that the authors could build upon to generate more powerful relighting results.",1,"2001, 2005, 2020",A Practical Model for Subsurface Light Transport
dVyF6HYyrz,"This paper proposes a framework for capturing the geometry, specular, and subsurface scattering appearance of 3D objects using a captured dataset composed of multi-view OLAT images. 
The appearance of the object is decomposed into two different models. 
First, a 3D Gaussian representation with a spatially varying BRDF model for explicit surface representation. Secondly, an implicit volumetric representation is used for subsurface scattering appearance. 
This framework enables material editing, relighting, and novel view synthesis in real-time.","1. I believe that the authors will provide a multi-view OLAT dataset for subsurface scattering objects in the future, and this dataset will be a great contribution to the vision and graphics community.
2. Screen space shading algorithm for 3D Gaussian representation improves the view-dependent appearance quality of the reconstructed object.
3. The use of two different appearance models enables the reconstruction of the geometry, BRDF, and subsurface scattering of 3D objects.","1. Missing references for diffusion-based SSS approximation models:

[1] A Practical Model for Subsurface Light Transport, Jensen et al., 2001.

[2] Light Diffusion in Multi-Layered Translucent Materials, Donner et al., 2005.

2. Lack of validation on the intrinsic properties. 

To generate realistic novel relit scenes and material edits, it is important to correctly acquire the intrinsic properties. For the synthetic data, each intrinsic property can be directly compared with the reconstructed one (RMSE). Although reconstructed properties can differ due to the different models from Blender or the limitations of the method, the author should address this. Currently, it is unclear if this method reconstructs each intrinsic property well because there is no ground truth intrinsic property information in the paper or supplemental material, even though the rendered results look realistic and similar to the ground truth data. For example, in the dragon dataset in the supplemental material, there are many specularity changes in the ground truth, but these are not observed in the renders.

3. The relighting results only include novel views with single-light images. 

There are no results for environmental lighting or changing light colors. Since the framework does not support multiple light sources, we could generate multiple light sources or environment-relighting results similar to the previous method [3]. Simply adding multiple OLAT images in screen space would provide much more powerful relighting results, which I would like to see.

[3] Neural Light Transport for Relighting and View Synthesis, Zhang et al., 2020.

4. It would be powerful to show the change in intrinsic properties between objects, for example, from bunny to dragon and vice versa.","1. The real-world dataset images look over-exposed in the specular regions. In the experimental setup. In the paper, same images were captured five times to reduce image noise. Did you change the exposure of the camera while capturing the raw images? Moreover, why did you choose 8-bit instead of 16-bit images?
2. This doesn't need to be addressed in the rebuttal (Minor), but it would be better to add some information about the name of each video. Without clear explanations, some notations can be misleading to the reader.","The author adequately addressed the limitations, including:
1. Difficulty in optimizing strongly heterogeneous materials.
2. Limitations in screen space shading.
I might add that this paper is also limited to static scenes only. Human skin, for example, is constrained not only by personal rights but also by the inability to handle movement during capturing. This will cause blurry results that the current framework cannot handle.",['No ethics review needed.'],6,4,,Yes,2,3,3,1719100999555,,,NeurIPS.cc/2024/Conference,2vMvh5XP0P,"['NeurIPS.cc/2024/Conference/Submission348/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878637977,[],1,,,['everyone'],2vMvh5XP0P,['NeurIPS.cc/2024/Conference/Submission348/Reviewer_uk4p'],1719100999555,1730878637977,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission348/Reviewer_uk4p']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. Specifically, it mentions two references for diffusion-based SSS (Subsurface Scattering) approximation models that are missing from the paper:

1. ""A Practical Model for Subsurface Light Transport"" by Jensen et al. (2001)
2. ""Light Diffusion in Multi-Layered Translucent Materials"" by Donner et al. (2005)

Additionally, it mentions another reference, ""Neural Light Transport for Relighting and View Synthesis"" by Zhang et al. (2020), as a previous method that the authors could build upon to generate more powerful relighting results.",1,"2001, 2005, 2020",Light Diffusion in Multi-Layered Translucent Materials
dVyF6HYyrz,"This paper proposes a framework for capturing the geometry, specular, and subsurface scattering appearance of 3D objects using a captured dataset composed of multi-view OLAT images. 
The appearance of the object is decomposed into two different models. 
First, a 3D Gaussian representation with a spatially varying BRDF model for explicit surface representation. Secondly, an implicit volumetric representation is used for subsurface scattering appearance. 
This framework enables material editing, relighting, and novel view synthesis in real-time.","1. I believe that the authors will provide a multi-view OLAT dataset for subsurface scattering objects in the future, and this dataset will be a great contribution to the vision and graphics community.
2. Screen space shading algorithm for 3D Gaussian representation improves the view-dependent appearance quality of the reconstructed object.
3. The use of two different appearance models enables the reconstruction of the geometry, BRDF, and subsurface scattering of 3D objects.","1. Missing references for diffusion-based SSS approximation models:

[1] A Practical Model for Subsurface Light Transport, Jensen et al., 2001.

[2] Light Diffusion in Multi-Layered Translucent Materials, Donner et al., 2005.

2. Lack of validation on the intrinsic properties. 

To generate realistic novel relit scenes and material edits, it is important to correctly acquire the intrinsic properties. For the synthetic data, each intrinsic property can be directly compared with the reconstructed one (RMSE). Although reconstructed properties can differ due to the different models from Blender or the limitations of the method, the author should address this. Currently, it is unclear if this method reconstructs each intrinsic property well because there is no ground truth intrinsic property information in the paper or supplemental material, even though the rendered results look realistic and similar to the ground truth data. For example, in the dragon dataset in the supplemental material, there are many specularity changes in the ground truth, but these are not observed in the renders.

3. The relighting results only include novel views with single-light images. 

There are no results for environmental lighting or changing light colors. Since the framework does not support multiple light sources, we could generate multiple light sources or environment-relighting results similar to the previous method [3]. Simply adding multiple OLAT images in screen space would provide much more powerful relighting results, which I would like to see.

[3] Neural Light Transport for Relighting and View Synthesis, Zhang et al., 2020.

4. It would be powerful to show the change in intrinsic properties between objects, for example, from bunny to dragon and vice versa.","1. The real-world dataset images look over-exposed in the specular regions. In the experimental setup. In the paper, same images were captured five times to reduce image noise. Did you change the exposure of the camera while capturing the raw images? Moreover, why did you choose 8-bit instead of 16-bit images?
2. This doesn't need to be addressed in the rebuttal (Minor), but it would be better to add some information about the name of each video. Without clear explanations, some notations can be misleading to the reader.","The author adequately addressed the limitations, including:
1. Difficulty in optimizing strongly heterogeneous materials.
2. Limitations in screen space shading.
I might add that this paper is also limited to static scenes only. Human skin, for example, is constrained not only by personal rights but also by the inability to handle movement during capturing. This will cause blurry results that the current framework cannot handle.",['No ethics review needed.'],6,4,,Yes,2,3,3,1719100999555,,,NeurIPS.cc/2024/Conference,2vMvh5XP0P,"['NeurIPS.cc/2024/Conference/Submission348/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878637977,[],1,,,['everyone'],2vMvh5XP0P,['NeurIPS.cc/2024/Conference/Submission348/Reviewer_uk4p'],1719100999555,1730878637977,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission348/Reviewer_uk4p']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. Specifically, it mentions two references for diffusion-based SSS (Subsurface Scattering) approximation models that are missing from the paper:

1. ""A Practical Model for Subsurface Light Transport"" by Jensen et al. (2001)
2. ""Light Diffusion in Multi-Layered Translucent Materials"" by Donner et al. (2005)

Additionally, it mentions another reference, ""Neural Light Transport for Relighting and View Synthesis"" by Zhang et al. (2020), as a previous method that the authors could build upon to generate more powerful relighting results.",1,"2001, 2005, 2020",Neural Light Transport for Relighting and View Synthesis
Bf5tmQXxvX,"This paper proposes an algorithm to reconstruct relightable objects with subsurface scattering (SSS) effects. It proposes to model SSS as a residual to surface PBR using a neural network. It also proposes to perform shading in image space (i.e. deferred shading) to improve specularity. Lastly, the SSS network takes ray-trace light visibility as input, accounting for shadowing effects for the SSS component.","1. Modeling SSS is an under-explored research area in inverse rendering, and the demonstrated results in this paper look promising.

2. Using a neural network to predict residuals to surface-based PBR is straightforward yet effective, as demonstrated in the paper.","1. The approach assumes known point-light, which limits its applicability in real-world scenarios

2. The novelty is overclaimed: GS-IR ([19] in the paper) has already introduced deferred/pixel-space shading to Gaussian splatting. There are also several concurrent works reaching the same conclusion as this paper (e.g. deferred shading improves specularity) [1, 2], please cite them and discuss the relations between them and this paper in the final version of this paper. However, I do acknowledge that this paper is one of the first papers that argues deferred shading improves specularity.

3. Insufficient ablation: only qualitative results on ablation are presented. It would be preferable to have quantitative results on the ablation baselines. Also, the comparison to relightable 3D Gaussians is not fair. A more fair comparison is to remove the SSS part of the proposed method, which becomes a variant of relightable 3D Gaussians that can handle known illumination.


[1] Ye et. al. 3D Gaussian Splatting with Deferred Reflection, arXiv 2024

[2] Wu et. al. DeferredGS: Decoupled and Editable Gaussian Splatting with Deferred Shading, arXiv 2024","1. What prevents the method from working without knowing point-light?

2. Do the results in Tab. 1 include novel lighting conditions? How are light intensity set in both synthetic and real dataset? How would the method work if the light intensity changes drastically, i.e. can the model handle light intensity changes from e.g. 5 (training) to 20 (testing)?

3. Only point light is demonstrated in the results. Would the model still work under natural illumination (e.g. image-based lighting)? According to Eq. 6 it seems to be designed specifically for a single point light, which is quite limiting. Would be good to see both qualitative and quantitative results on synthetic datasets with image-based lighting","Limitation is discussed, though I think a crucial part (not supporting image-based lighting) is missing. Please see questions.",['No ethics review needed.'],6,4,,Yes,2,3,3,1720791679205,,,NeurIPS.cc/2024/Conference,2vMvh5XP0P,"['NeurIPS.cc/2024/Conference/Submission348/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878637515,[],5,,,['everyone'],2vMvh5XP0P,['NeurIPS.cc/2024/Conference/Submission348/Reviewer_pNBB'],1720791679205,1730878637515,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission348/Reviewer_pNBB']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. GS-IR ([19] in the paper)
2. Ye et. al. ""3D Gaussian Splatting with Deferred Reflection"" (arXiv 2024) [1]
3. Wu et. al. ""DeferredGS: Decoupled and Editable Gaussian Splatting with Deferred Shading"" (arXiv 2024) [2]

The reviewer asks the authors to discuss the relations between these works and the paper in the final version, indicating that the authors should cite and acknowledge these concurrent works that have reached similar conclusions.",1,"2020, 2020",3D Gaussian Splatting with Deferred Reflection 
Bf5tmQXxvX,"This paper proposes an algorithm to reconstruct relightable objects with subsurface scattering (SSS) effects. It proposes to model SSS as a residual to surface PBR using a neural network. It also proposes to perform shading in image space (i.e. deferred shading) to improve specularity. Lastly, the SSS network takes ray-trace light visibility as input, accounting for shadowing effects for the SSS component.","1. Modeling SSS is an under-explored research area in inverse rendering, and the demonstrated results in this paper look promising.

2. Using a neural network to predict residuals to surface-based PBR is straightforward yet effective, as demonstrated in the paper.","1. The approach assumes known point-light, which limits its applicability in real-world scenarios

2. The novelty is overclaimed: GS-IR ([19] in the paper) has already introduced deferred/pixel-space shading to Gaussian splatting. There are also several concurrent works reaching the same conclusion as this paper (e.g. deferred shading improves specularity) [1, 2], please cite them and discuss the relations between them and this paper in the final version of this paper. However, I do acknowledge that this paper is one of the first papers that argues deferred shading improves specularity.

3. Insufficient ablation: only qualitative results on ablation are presented. It would be preferable to have quantitative results on the ablation baselines. Also, the comparison to relightable 3D Gaussians is not fair. A more fair comparison is to remove the SSS part of the proposed method, which becomes a variant of relightable 3D Gaussians that can handle known illumination.


[1] Ye et. al. 3D Gaussian Splatting with Deferred Reflection, arXiv 2024

[2] Wu et. al. DeferredGS: Decoupled and Editable Gaussian Splatting with Deferred Shading, arXiv 2024","1. What prevents the method from working without knowing point-light?

2. Do the results in Tab. 1 include novel lighting conditions? How are light intensity set in both synthetic and real dataset? How would the method work if the light intensity changes drastically, i.e. can the model handle light intensity changes from e.g. 5 (training) to 20 (testing)?

3. Only point light is demonstrated in the results. Would the model still work under natural illumination (e.g. image-based lighting)? According to Eq. 6 it seems to be designed specifically for a single point light, which is quite limiting. Would be good to see both qualitative and quantitative results on synthetic datasets with image-based lighting","Limitation is discussed, though I think a crucial part (not supporting image-based lighting) is missing. Please see questions.",['No ethics review needed.'],6,4,,Yes,2,3,3,1720791679205,,,NeurIPS.cc/2024/Conference,2vMvh5XP0P,"['NeurIPS.cc/2024/Conference/Submission348/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878637515,[],5,,,['everyone'],2vMvh5XP0P,['NeurIPS.cc/2024/Conference/Submission348/Reviewer_pNBB'],1720791679205,1730878637515,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission348/Reviewer_pNBB']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. GS-IR ([19] in the paper)
2. Ye et. al. ""3D Gaussian Splatting with Deferred Reflection"" (arXiv 2024) [1]
3. Wu et. al. ""DeferredGS: Decoupled and Editable Gaussian Splatting with Deferred Shading"" (arXiv 2024) [2]

The reviewer asks the authors to discuss the relations between these works and the paper in the final version, indicating that the authors should cite and acknowledge these concurrent works that have reached similar conclusions.",1,"2020, 2020",DeferredGS Decoupled and Editable Gaussian Splatting with Deferred Shading
mXfjPSKXOV,"It is proposed to utilize 4D imaging 8 radar sensors for 3D occupancy prediction by directly processing the 4D radar tensor, thus preserving essential scene details. RadarOcc innovatively addresses the challenges associated with the voluminous and noisy 4D radar data by employing Doppler bins descriptors, sidelobe-aware spatial sparsification, and range-wise self-attention mechanisms. The demonstration of the RadarOcc’s state-of-the-art performance in radar-based 3D occupancy prediction was carried out on K-Radar dataset.",It is well-accepted that radar raw data could provide more information for perception tasks in autonomous driving. This submission follows the same direction to utilize 4D imaging radar measurement.,"It is not the first paper to utilize the 4D imaging radar raw measurement for perception. As mentioned by the authors, they focus on semantics, rather than typical road users detection and classification. 
For the reference to 4D imaging radar, please consider cite the following paper 
S. Sun and Y. D. Zhang, ""4D Automotive Radar Sensing for Autonomous Vehicles: A Sparsity-Oriented Approach,"" in IEEE Journal of Selected Topics in Signal Processing, vol. 15, no. 4, pp. 879-891, June 2021.

For general automotive radar contribution to autonomous driving, please consider cite the following paper 
S. Sun, A. P. Petropulu and H. V. Poor, ""MIMO Radar for Advanced Driver-Assistance Systems and Autonomous Driving: Advantages and Challenges,"" in IEEE Signal Processing Magazine, vol. 37, no. 4, pp. 98-117, July 2020.","It seems to be a trade-off in the sidelobe-aware spatial sparsification process. Is it interesting to know whether important feature information is lost due to this sparsification. For example, targets with weak reflections, such as the information of road curbs might be lost.","As mentioned before, the proposed work does not apply to the general road users detection and classification.",['No ethics review needed.'],5,5,,Yes,2,2,3,1720844831854,,,NeurIPS.cc/2024/Conference,2oZea6pKhl,"['NeurIPS.cc/2024/Conference/Submission391/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878641419,[],4,,,['everyone'],2oZea6pKhl,['NeurIPS.cc/2024/Conference/Submission391/Reviewer_v56z'],1720844831854,1730878641419,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission391/Reviewer_v56z']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific papers:

1. S. Sun and Y. D. Zhang, ""4D Automotive Radar Sensing for Autonomous Vehicles: A Sparsity-Oriented Approach,"" in IEEE Journal of Selected Topics in Signal Processing, vol. 15, no. 4, pp. 879-891, June 2021, for reference to 4D imaging radar.

2. S. Sun, A. P. Petropulu and H. V. Poor, ""MIMO Radar for Advanced Driver-Assistance Systems and Autonomous Driving: Advantages and Challenges,"" in IEEE Signal Processing Magazine, vol. 37, no. 4, pp. 98-117, July 2020, for general automotive radar contribution to autonomous driving.",1,"2021, 2020",4D Automotive Radar Sensing for Autonomous Vehicles A Sparsity-Oriented Approach 
mXfjPSKXOV,"It is proposed to utilize 4D imaging 8 radar sensors for 3D occupancy prediction by directly processing the 4D radar tensor, thus preserving essential scene details. RadarOcc innovatively addresses the challenges associated with the voluminous and noisy 4D radar data by employing Doppler bins descriptors, sidelobe-aware spatial sparsification, and range-wise self-attention mechanisms. The demonstration of the RadarOcc’s state-of-the-art performance in radar-based 3D occupancy prediction was carried out on K-Radar dataset.",It is well-accepted that radar raw data could provide more information for perception tasks in autonomous driving. This submission follows the same direction to utilize 4D imaging radar measurement.,"It is not the first paper to utilize the 4D imaging radar raw measurement for perception. As mentioned by the authors, they focus on semantics, rather than typical road users detection and classification. 
For the reference to 4D imaging radar, please consider cite the following paper 
S. Sun and Y. D. Zhang, ""4D Automotive Radar Sensing for Autonomous Vehicles: A Sparsity-Oriented Approach,"" in IEEE Journal of Selected Topics in Signal Processing, vol. 15, no. 4, pp. 879-891, June 2021.

For general automotive radar contribution to autonomous driving, please consider cite the following paper 
S. Sun, A. P. Petropulu and H. V. Poor, ""MIMO Radar for Advanced Driver-Assistance Systems and Autonomous Driving: Advantages and Challenges,"" in IEEE Signal Processing Magazine, vol. 37, no. 4, pp. 98-117, July 2020.","It seems to be a trade-off in the sidelobe-aware spatial sparsification process. Is it interesting to know whether important feature information is lost due to this sparsification. For example, targets with weak reflections, such as the information of road curbs might be lost.","As mentioned before, the proposed work does not apply to the general road users detection and classification.",['No ethics review needed.'],5,5,,Yes,2,2,3,1720844831854,,,NeurIPS.cc/2024/Conference,2oZea6pKhl,"['NeurIPS.cc/2024/Conference/Submission391/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878641419,[],4,,,['everyone'],2oZea6pKhl,['NeurIPS.cc/2024/Conference/Submission391/Reviewer_v56z'],1720844831854,1730878641419,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission391/Reviewer_v56z']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific papers:

1. S. Sun and Y. D. Zhang, ""4D Automotive Radar Sensing for Autonomous Vehicles: A Sparsity-Oriented Approach,"" in IEEE Journal of Selected Topics in Signal Processing, vol. 15, no. 4, pp. 879-891, June 2021, for reference to 4D imaging radar.

2. S. Sun, A. P. Petropulu and H. V. Poor, ""MIMO Radar for Advanced Driver-Assistance Systems and Autonomous Driving: Advantages and Challenges,"" in IEEE Signal Processing Magazine, vol. 37, no. 4, pp. 98-117, July 2020, for general automotive radar contribution to autonomous driving.",1,"2021, 2020",MIMO Radar for Advanced Driver-Assistance Systems and Autonomous Driving Advantages and Challenges
0QsotGVexU,"The paper proposes a framework to learn 3D dynamics from 2D observations. DEM uses hand-designed kernel functions to model interaction force between particles, which may vary significantly for different material types. The paper changes these kernels to learnable GNN kernels. The time integration still follows DEM. Combined with a differentiable particle renderer, these kernels can be trained to match 2D observations.","The framework is quite general, with force-based time integration providing a strong physics prior. The use of learnable kernels to model point interactions enables the DEM to effectively fit observations.

Numerous comparisons are conducted, and the results are promising.","The evaluations are conducted only on synthetic data.

The learned particle interactions are black-boxes, which are not explainable.","[Learning Neural Constitutive Laws From Motion Observations for Generalizable PDE Dynamics](https://arxiv.org/abs/2304.14369) should be cited, since it solves a similar task.

Are the material types in particle attribute A pre-known? Are the initial particle distributions known? The known assumptions should be listed in the paper.

How are particle colors assigned? In reality, objects usually have textures. Manually assigning colors may be impractical. 

The particle initialization step is illustrated in Fig. 1, but no technical details are discussed in the text. It seems that the initial geometry is provided in the experiments. In that case, the known-geometry assumption should be illustrated in the figure instead. However, geometry reconstruction is important for real data applications.",Limitations are discussed.,['No ethics review needed.'],6,4,,Yes,3,3,3,1720767621414,,,NeurIPS.cc/2024/Conference,2nvkD0sPOk,"['NeurIPS.cc/2024/Conference/Submission2729/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878798322,[],3,,,['everyone'],2nvkD0sPOk,['NeurIPS.cc/2024/Conference/Submission2729/Reviewer_qBCD'],1720767621414,1730878798322,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2729/Reviewer_qBCD']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature: [Learning Neural Constitutive Laws From Motion Observations for Generalizable PDE Dynamics](https://arxiv.org/abs/2304.14369), as it solves a similar task.",1,2023,Learning Neural Constitutive Laws From Motion Observations for Generalizable PDE Dynamics
PQqGFxIXiq,"The paper presents a method to correctly apply LRP to Mamba models. Through careful analysis, the authors demonstrate that applying LRP directly results in poor performance and propose modifications to recover the propagation rules. The obtained method outperforms the alternatives, grounded by theory, and the authors show several applications of their method, including identifying gender biases and measuring the long-range abilities of S6.","1) **Impact:** Mamba is an emerging architecture (~600+ citations, 10K+ stars on GitHub). Thus, providing an attribution method for these models is crucial. In this essence, correctly applying LRP is an important direction that facilitates the community in improving and understanding these models.

2) **Simplicity:** The method and modifications are very simple, with few hyper-parameters. While this might be seen as a lack of novelty, I view it as an advantage, making the method easy to use and adaptable to various applications, such as other variants of Mamba (Mamba2) and other domains (DNA, speech and more). 

3) **Informative Ablation studies** and justification of decision choices are insightful. For example, Figure 3 and Tables 1, 2, 6, 9 provide comparisons with naive LRP and also present ablation studies that allow the reader to measure the contribution of each modification to the method.

4) Section 6 (use cases) shows that the method is **applicable** and allows the authors to explore the gender bias and long-range abilities of Mamba models and provide insightful analyses about Mamba models.","1) **The comparison with previous work should be improved:**

- 1.1) Metrics and Benchmarking: Can the authors highlight which results are reproduced by them and which results are taken from previous work? Moreover, as far as I understand, the method in [4] is the only method that developed an interpretability method for Mamba before (perhaps in parallel) to this work. If I understand correctly, although the two methods share and use the same pre-trained models, there is no overlap in the metrics. Am I correct? If so, is there a reason for this discrepancy? Can the authors compare results directly with previous work using previously proposed metrics to ensure the gap doesn’t arise from employing [4] incorrectly?

- 1.2)  Informative Comparison: Additionally, I think the comparison with [4] can be more accurate. The method in [4] applies its method only to S6 layers (without gating and convs), while Mamba LRP is an end-to-end method (which is a strength of Mamba-LRP). However, it is still important to make some apple-to-apple comparisons. Can the authors check both methods on a model without conv and gating layers to determine which approach is better for providing an explanation to S6 layers? Alternatively, it seems that the issue with [4] is fixed in [Uni]. Would the authors be able to compare their method to [Uni]? Providing this comparison would be highly valuable to the community. (I understand that this is a very new paper, so I will not decrease my score if the results are less favorable than those of [Uni]).

2) **Insufficient empirical analysis:**

- 2.1) For the long-range experiments (Figure 6), it would be very insightful to compare the behaviour of Mamba to Transformers (Pythia pre-trained models can serve as the transformer baselines since they are trained on the same data). Additionally, analyzing the trend with larger models could yield valuable information on how increased model size enhances long-context capabilities in practice, perhaps the 7B models from [Sca] can be used (which exist in Hugging Face).

- 2.2)  
>  “Residual lack of conservation is due to the presence of biases in linear and convolution layers, which are typically non-attributable” 

 Can the authors empirically justify this claim? This can be easily validated by taking a pre-trained model, omitting the biases, fine-tuning it for several epochs, and then checking the conservation again. 

3) **Novelty:** The novelty of the method is somewhat limited. One could argue that it merely involves a few applications of detach and the simple half-propagation rule (in addition to previously proposed contributions), which can be easily summarized in a few lines of code (as detailed in Algorithm 2). However, I believe this is not a significant drawback, particularly given the demand for such simple tools in the community. Additionally, the thorough evaluation, including insightful ablation studies, novel test case evaluations, and theoretical justification, is sufficiently robust.

[Uni] A Unified Implicit Attention Formulation for Gated-Linear Recurrent Sequence. Models. Zimerman et al.

[Sca] An Empirical Study of Mamba-based Language Models. Waleffe et al.","1.	Mamba LRP uses ""Detach"" on the SSM recurrent matrices. Similarly, [4] uses an attention matrix determined by A, B, and C parameters.  It seems that both methods ignore the influence of the input on the system matrices (which is the core of the selection mechanism of Mamba). Am I right? Could addressing this issue provide a way to improve both methods? I would be glad to hear what the authors think about it.
2.	Minor: Traditionally in the SSM domain, Delta denotes the step size. I suggest the authors replace \Delta with \delta when discussing the differences between the two scores.
3.	In the Needle-in-a-haystack experiment (Figure 7), is there a reason not to increase the context length? It seems that the most interesting part of the figure is missing (which could show if there are edge cases, for example, regimes where the model succeeds in finding the needle, but Mamba-LRP fails).
4.	Minor: Perhaps a relevant work that is missing is “Does Transformer Interpretability Transfer to RNNs?” by Paulo et al.
5.	There is a standard trend in the SSM literature to omit D (and treat it as a parameter-based skip connection). Is it used in Mamba LRP, or is it ignored (like other biases, which are typically non-attributable)? It would be better if it were written explicitly in the paper.
6.	I wonder if the authors can explore the potential limitations or failure cases of the proposed Mamba-LRP. Such information can help the community improve the method in the future. Are there cases where [4] or naive LRP might be better than Mamba-LRP?
7.	Half propagation: While I'm not an expert in LRP, I suspect there are more effective methods to manage the gating mechanism. For instance, instead of normalizing the scores by averaging (0.5(x + y)), it may be better to use a weighted approach such as $$(1 - a) \cdot x + a\cdot y$$
where the value of a is determined by the actual norms of x and y, with different a values for each channel. Is there something I'm missing? Can this method improve the conservation properties?","From my perspective, the authors address most of the limitations, except those pointed out in the weaknesses section and question 6 (failure cases).",['No ethics review needed.'],6,5,,Yes,3,4,3,1720386595925,,,NeurIPS.cc/2024/Conference,2n1Ysn1EDl,"['NeurIPS.cc/2024/Conference/Submission9423/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879313038,[],1,,,['everyone'],2n1Ysn1EDl,['NeurIPS.cc/2024/Conference/Submission9423/Reviewer_dNt6'],1720386595925,1730879313038,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9423/Reviewer_dNt6']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. ""Does Transformer Interpretability Transfer to RNNs?"" by Paulo et al.
2. [Uni] A Unified Implicit Attention Formulation for Gated-Linear Recurrent Sequence. Models. Zimerman et al.
3. [Sca] An Empirical Study of Mamba-based Language Models. Waleffe et al.

These citations are suggested to provide a more comprehensive comparison with previous work, to explore the potential limitations or failure cases of the proposed Mamba-LRP, and to improve the overall quality of the paper.",1,,Does Transformer Interpretability Transfer to RNNs 
PQqGFxIXiq,"The paper presents a method to correctly apply LRP to Mamba models. Through careful analysis, the authors demonstrate that applying LRP directly results in poor performance and propose modifications to recover the propagation rules. The obtained method outperforms the alternatives, grounded by theory, and the authors show several applications of their method, including identifying gender biases and measuring the long-range abilities of S6.","1) **Impact:** Mamba is an emerging architecture (~600+ citations, 10K+ stars on GitHub). Thus, providing an attribution method for these models is crucial. In this essence, correctly applying LRP is an important direction that facilitates the community in improving and understanding these models.

2) **Simplicity:** The method and modifications are very simple, with few hyper-parameters. While this might be seen as a lack of novelty, I view it as an advantage, making the method easy to use and adaptable to various applications, such as other variants of Mamba (Mamba2) and other domains (DNA, speech and more). 

3) **Informative Ablation studies** and justification of decision choices are insightful. For example, Figure 3 and Tables 1, 2, 6, 9 provide comparisons with naive LRP and also present ablation studies that allow the reader to measure the contribution of each modification to the method.

4) Section 6 (use cases) shows that the method is **applicable** and allows the authors to explore the gender bias and long-range abilities of Mamba models and provide insightful analyses about Mamba models.","1) **The comparison with previous work should be improved:**

- 1.1) Metrics and Benchmarking: Can the authors highlight which results are reproduced by them and which results are taken from previous work? Moreover, as far as I understand, the method in [4] is the only method that developed an interpretability method for Mamba before (perhaps in parallel) to this work. If I understand correctly, although the two methods share and use the same pre-trained models, there is no overlap in the metrics. Am I correct? If so, is there a reason for this discrepancy? Can the authors compare results directly with previous work using previously proposed metrics to ensure the gap doesn’t arise from employing [4] incorrectly?

- 1.2)  Informative Comparison: Additionally, I think the comparison with [4] can be more accurate. The method in [4] applies its method only to S6 layers (without gating and convs), while Mamba LRP is an end-to-end method (which is a strength of Mamba-LRP). However, it is still important to make some apple-to-apple comparisons. Can the authors check both methods on a model without conv and gating layers to determine which approach is better for providing an explanation to S6 layers? Alternatively, it seems that the issue with [4] is fixed in [Uni]. Would the authors be able to compare their method to [Uni]? Providing this comparison would be highly valuable to the community. (I understand that this is a very new paper, so I will not decrease my score if the results are less favorable than those of [Uni]).

2) **Insufficient empirical analysis:**

- 2.1) For the long-range experiments (Figure 6), it would be very insightful to compare the behaviour of Mamba to Transformers (Pythia pre-trained models can serve as the transformer baselines since they are trained on the same data). Additionally, analyzing the trend with larger models could yield valuable information on how increased model size enhances long-context capabilities in practice, perhaps the 7B models from [Sca] can be used (which exist in Hugging Face).

- 2.2)  
>  “Residual lack of conservation is due to the presence of biases in linear and convolution layers, which are typically non-attributable” 

 Can the authors empirically justify this claim? This can be easily validated by taking a pre-trained model, omitting the biases, fine-tuning it for several epochs, and then checking the conservation again. 

3) **Novelty:** The novelty of the method is somewhat limited. One could argue that it merely involves a few applications of detach and the simple half-propagation rule (in addition to previously proposed contributions), which can be easily summarized in a few lines of code (as detailed in Algorithm 2). However, I believe this is not a significant drawback, particularly given the demand for such simple tools in the community. Additionally, the thorough evaluation, including insightful ablation studies, novel test case evaluations, and theoretical justification, is sufficiently robust.

[Uni] A Unified Implicit Attention Formulation for Gated-Linear Recurrent Sequence. Models. Zimerman et al.

[Sca] An Empirical Study of Mamba-based Language Models. Waleffe et al.","1.	Mamba LRP uses ""Detach"" on the SSM recurrent matrices. Similarly, [4] uses an attention matrix determined by A, B, and C parameters.  It seems that both methods ignore the influence of the input on the system matrices (which is the core of the selection mechanism of Mamba). Am I right? Could addressing this issue provide a way to improve both methods? I would be glad to hear what the authors think about it.
2.	Minor: Traditionally in the SSM domain, Delta denotes the step size. I suggest the authors replace \Delta with \delta when discussing the differences between the two scores.
3.	In the Needle-in-a-haystack experiment (Figure 7), is there a reason not to increase the context length? It seems that the most interesting part of the figure is missing (which could show if there are edge cases, for example, regimes where the model succeeds in finding the needle, but Mamba-LRP fails).
4.	Minor: Perhaps a relevant work that is missing is “Does Transformer Interpretability Transfer to RNNs?” by Paulo et al.
5.	There is a standard trend in the SSM literature to omit D (and treat it as a parameter-based skip connection). Is it used in Mamba LRP, or is it ignored (like other biases, which are typically non-attributable)? It would be better if it were written explicitly in the paper.
6.	I wonder if the authors can explore the potential limitations or failure cases of the proposed Mamba-LRP. Such information can help the community improve the method in the future. Are there cases where [4] or naive LRP might be better than Mamba-LRP?
7.	Half propagation: While I'm not an expert in LRP, I suspect there are more effective methods to manage the gating mechanism. For instance, instead of normalizing the scores by averaging (0.5(x + y)), it may be better to use a weighted approach such as $$(1 - a) \cdot x + a\cdot y$$
where the value of a is determined by the actual norms of x and y, with different a values for each channel. Is there something I'm missing? Can this method improve the conservation properties?","From my perspective, the authors address most of the limitations, except those pointed out in the weaknesses section and question 6 (failure cases).",['No ethics review needed.'],6,5,,Yes,3,4,3,1720386595925,,,NeurIPS.cc/2024/Conference,2n1Ysn1EDl,"['NeurIPS.cc/2024/Conference/Submission9423/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879313038,[],1,,,['everyone'],2n1Ysn1EDl,['NeurIPS.cc/2024/Conference/Submission9423/Reviewer_dNt6'],1720386595925,1730879313038,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9423/Reviewer_dNt6']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. ""Does Transformer Interpretability Transfer to RNNs?"" by Paulo et al.
2. [Uni] A Unified Implicit Attention Formulation for Gated-Linear Recurrent Sequence. Models. Zimerman et al.
3. [Sca] An Empirical Study of Mamba-based Language Models. Waleffe et al.

These citations are suggested to provide a more comprehensive comparison with previous work, to explore the potential limitations or failure cases of the proposed Mamba-LRP, and to improve the overall quality of the paper.",1,,A Unified Implicit Attention Formulation for Gated-Linear Recurrent Sequence Models 
PQqGFxIXiq,"The paper presents a method to correctly apply LRP to Mamba models. Through careful analysis, the authors demonstrate that applying LRP directly results in poor performance and propose modifications to recover the propagation rules. The obtained method outperforms the alternatives, grounded by theory, and the authors show several applications of their method, including identifying gender biases and measuring the long-range abilities of S6.","1) **Impact:** Mamba is an emerging architecture (~600+ citations, 10K+ stars on GitHub). Thus, providing an attribution method for these models is crucial. In this essence, correctly applying LRP is an important direction that facilitates the community in improving and understanding these models.

2) **Simplicity:** The method and modifications are very simple, with few hyper-parameters. While this might be seen as a lack of novelty, I view it as an advantage, making the method easy to use and adaptable to various applications, such as other variants of Mamba (Mamba2) and other domains (DNA, speech and more). 

3) **Informative Ablation studies** and justification of decision choices are insightful. For example, Figure 3 and Tables 1, 2, 6, 9 provide comparisons with naive LRP and also present ablation studies that allow the reader to measure the contribution of each modification to the method.

4) Section 6 (use cases) shows that the method is **applicable** and allows the authors to explore the gender bias and long-range abilities of Mamba models and provide insightful analyses about Mamba models.","1) **The comparison with previous work should be improved:**

- 1.1) Metrics and Benchmarking: Can the authors highlight which results are reproduced by them and which results are taken from previous work? Moreover, as far as I understand, the method in [4] is the only method that developed an interpretability method for Mamba before (perhaps in parallel) to this work. If I understand correctly, although the two methods share and use the same pre-trained models, there is no overlap in the metrics. Am I correct? If so, is there a reason for this discrepancy? Can the authors compare results directly with previous work using previously proposed metrics to ensure the gap doesn’t arise from employing [4] incorrectly?

- 1.2)  Informative Comparison: Additionally, I think the comparison with [4] can be more accurate. The method in [4] applies its method only to S6 layers (without gating and convs), while Mamba LRP is an end-to-end method (which is a strength of Mamba-LRP). However, it is still important to make some apple-to-apple comparisons. Can the authors check both methods on a model without conv and gating layers to determine which approach is better for providing an explanation to S6 layers? Alternatively, it seems that the issue with [4] is fixed in [Uni]. Would the authors be able to compare their method to [Uni]? Providing this comparison would be highly valuable to the community. (I understand that this is a very new paper, so I will not decrease my score if the results are less favorable than those of [Uni]).

2) **Insufficient empirical analysis:**

- 2.1) For the long-range experiments (Figure 6), it would be very insightful to compare the behaviour of Mamba to Transformers (Pythia pre-trained models can serve as the transformer baselines since they are trained on the same data). Additionally, analyzing the trend with larger models could yield valuable information on how increased model size enhances long-context capabilities in practice, perhaps the 7B models from [Sca] can be used (which exist in Hugging Face).

- 2.2)  
>  “Residual lack of conservation is due to the presence of biases in linear and convolution layers, which are typically non-attributable” 

 Can the authors empirically justify this claim? This can be easily validated by taking a pre-trained model, omitting the biases, fine-tuning it for several epochs, and then checking the conservation again. 

3) **Novelty:** The novelty of the method is somewhat limited. One could argue that it merely involves a few applications of detach and the simple half-propagation rule (in addition to previously proposed contributions), which can be easily summarized in a few lines of code (as detailed in Algorithm 2). However, I believe this is not a significant drawback, particularly given the demand for such simple tools in the community. Additionally, the thorough evaluation, including insightful ablation studies, novel test case evaluations, and theoretical justification, is sufficiently robust.

[Uni] A Unified Implicit Attention Formulation for Gated-Linear Recurrent Sequence. Models. Zimerman et al.

[Sca] An Empirical Study of Mamba-based Language Models. Waleffe et al.","1.	Mamba LRP uses ""Detach"" on the SSM recurrent matrices. Similarly, [4] uses an attention matrix determined by A, B, and C parameters.  It seems that both methods ignore the influence of the input on the system matrices (which is the core of the selection mechanism of Mamba). Am I right? Could addressing this issue provide a way to improve both methods? I would be glad to hear what the authors think about it.
2.	Minor: Traditionally in the SSM domain, Delta denotes the step size. I suggest the authors replace \Delta with \delta when discussing the differences between the two scores.
3.	In the Needle-in-a-haystack experiment (Figure 7), is there a reason not to increase the context length? It seems that the most interesting part of the figure is missing (which could show if there are edge cases, for example, regimes where the model succeeds in finding the needle, but Mamba-LRP fails).
4.	Minor: Perhaps a relevant work that is missing is “Does Transformer Interpretability Transfer to RNNs?” by Paulo et al.
5.	There is a standard trend in the SSM literature to omit D (and treat it as a parameter-based skip connection). Is it used in Mamba LRP, or is it ignored (like other biases, which are typically non-attributable)? It would be better if it were written explicitly in the paper.
6.	I wonder if the authors can explore the potential limitations or failure cases of the proposed Mamba-LRP. Such information can help the community improve the method in the future. Are there cases where [4] or naive LRP might be better than Mamba-LRP?
7.	Half propagation: While I'm not an expert in LRP, I suspect there are more effective methods to manage the gating mechanism. For instance, instead of normalizing the scores by averaging (0.5(x + y)), it may be better to use a weighted approach such as $$(1 - a) \cdot x + a\cdot y$$
where the value of a is determined by the actual norms of x and y, with different a values for each channel. Is there something I'm missing? Can this method improve the conservation properties?","From my perspective, the authors address most of the limitations, except those pointed out in the weaknesses section and question 6 (failure cases).",['No ethics review needed.'],6,5,,Yes,3,4,3,1720386595925,,,NeurIPS.cc/2024/Conference,2n1Ysn1EDl,"['NeurIPS.cc/2024/Conference/Submission9423/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879313038,[],1,,,['everyone'],2n1Ysn1EDl,['NeurIPS.cc/2024/Conference/Submission9423/Reviewer_dNt6'],1720386595925,1730879313038,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9423/Reviewer_dNt6']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. ""Does Transformer Interpretability Transfer to RNNs?"" by Paulo et al.
2. [Uni] A Unified Implicit Attention Formulation for Gated-Linear Recurrent Sequence. Models. Zimerman et al.
3. [Sca] An Empirical Study of Mamba-based Language Models. Waleffe et al.

These citations are suggested to provide a more comprehensive comparison with previous work, to explore the potential limitations or failure cases of the proposed Mamba-LRP, and to improve the overall quality of the paper.",1,,An Empirical Study of Mamba-based Language Models
BYSuVh8xwc,This paper addresses the problem of contextual multinomial logit (MNL) bandits with general value functions across both stochastic and adversarial settings. The authors develop a suite of algorithms for different settings and with different computation-regret trade-offs. The application to the linear case surpasses previous works in terms of both statistical and computational efficiency.,"1. **Novelty of the Setting**: This paper is the first to explore contextual MNL bandits with general value functions, representing a significant expansion in the scope of MNL bandit problems. The setting is both novel and interesting.
2. **Innovative Techniques**: The introduction of several new techniques to tackle the complexities introduced by general value functions is commendable. The methods may inspire the following works and be useful in other areas.
3. **Improved Efficiency**: The application of these methods to linear cases shows improvements over previous works in both statistical and computational efficiency, making this a valuable contribution to the field.","1. **Computational Inefficiency**: The Feel-Good Thompson sampling algorithm, as discussed, lacks computational efficiency, even for linear cases, which could limit its practical applicability.
2. **Lack of Experimental Validation**: The absence of empirical experiments to verify the theoretical claims weakens the paper's impact. Experimental results are crucial for validating the effectiveness and practicality of the proposed methods.","1. Zhang and Sugiyama (2023) developed a computationally efficient algorithm for MLogB bandit problem. As MLogB and MNL are similar, how might their approach be adapted to the MNL bandit problem addressed in this paper to enhance computational efficiency?
2. The authors claim that to ensure that no regret is possible, they make Assumption 1 in Line 96. Does this imply that achieving no regret is impossible in unrealizable scenarios? Could the authors provide some intuition about the reason?

Ref: Yu-Jie Zhang and Masashi Sugiyama. Online (Multinomial) Logistic Bandit: Improved Regret and Constant Computation Cost. In NeurIPS 2023.",,['No ethics review needed.'],6,3,,Yes,3,3,3,1720489623503,,,NeurIPS.cc/2024/Conference,2ltOkbo67R,"['NeurIPS.cc/2024/Conference/Submission9253/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879300504,[],2,,,['everyone'],2ltOkbo67R,['NeurIPS.cc/2024/Conference/Submission9253/Reviewer_a6sS'],1720489623503,1730879300504,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9253/Reviewer_a6sS']","Yes, this peer review explicitly suggests the authors of the paper to cite the literature ""Yu-Jie Zhang and Masashi Sugiyama. Online (Multinomial) Logistic Bandit: Improved Regret and Constant Computation Cost. In NeurIPS 2023"" as a potential approach to adapt for enhancing computational efficiency in the MNL bandit problem addressed in the paper.",1,2023,Online (Multinomial) Logistic Bandit: Improved Regret and Constant Computation Cost
KhVqCDrDna,"This work studies secluded partitions, which appear in the context of list-replicable learning (among other geometric/TCS applications). The complement known bounds on list complexity, the authors present new upper-bounds on the tolerance parameter as a function of the list complexity k and the ambient dimension d. They show a construction of a secluded partition that roughly achieves these bounds, showing the optimality of their bounds. The secluded partition results are then applied to give a ""neighborhood"" version of Sperner's lemma, for $\ell_\infty$ neighborhoods.","This work provides novel results with potentially broad applications in geometry and computer science. Sperner's lemma is widely useful across disciplines, and this neighborhood variant may prove similarly broadly useful.","As written, I don’t think this work is a good fit for NeurIPS. This work  studies secluded partitions, which have connections to list-replicable algorithms for, e.g., the d-coin bias estimation problem as mentioned by the authors. In this sense the results have applications to replicable learning, but the actual application of the secluded partitions results give somewhat marginal replicable learning results. Theorem 3.1 essentially shows that one cannot meaningfully tradeoff list complexity for better secluded partition tolerance, and therefore cannot hope to improve sample complexity for the d-coin bias problem via the secluded partition approach, but says nothing of other approaches or other problems. 

If I try to read this as a learning paper where the focus is improving sample complexity of list-replicable d-coin bias estimation algorithms, it seems like there should be more attention paid in related work to replicable (in the sense of ILPS22) algorithms for the d-coin bias estimation problem as well, as this has been studied in [1], [2], and recently (posted after NeurIPS submission deadline) [3]. 

[1] “Stability is Stable” Bun, Gaboardi, Hopkins, Impagliazzo, Lei, Pitassi, Sivakumar, Sorrell
[2] “Replicability in Reinforcement Learning” Karbasi, Velegkas, Yang, Zhou ’23
[3] “Replicability in High Dimensional Statistics” Hopkins, Impagliazzo, Kane, Liu, Ye ‘24

Typos/suggested edits:

Abstract

“We show that for each d” -> “we show for each d”

Section 1 pg 2
Brower -> Brouwer
should be seen as a fundamental endeavor. . 

Section 2 page 2
“belongs to a list L consisting of almost k good hypotheses”

“over which a family of distribution” -> “over which a family of distributions”

page 3

“the partitions considered in this work have a non-zero” -> “the partitions considered in this work have non-zero

Theorem 2.4 could be written a little more clearly. It would be good to define the mapping implicit in the term “coloring” and clarify that opposite faces mean faces of the hypercube

Section 3

“in general a $(k, \varepsilon)$-secluded partitions” 

“Can we improve this and construct a (d+1, \omega(1/d)-secluded partition?”

“is the following result upper bound result”

“Till this work we know”

“There exist a k-list replicable algorithm”

“Spener/KKM Lemma”

Section 4
“A learning algorithm A to be $(n, \eta)$-globally stable”

Section 5.1

Need a period before Thus/ what we do is to “replace”

I found the proof sketch for Theorem 3.1 had a few seemingly unnecessary detours that were a bit distracting. For instance, deriving the lower bound of 1 before deriving the desired bound. The footnote could be more precise (what does “becomes the wrong inequality” mean?)

Need a period before “Now that we have dealt with both issues” on page 6.

“So because there is a ceiling involved” could be made more precise, as could “by our change of perspective.”

Section 5.2

There’s a $d_n$ that should be $d_i$ in Definition 5.2

Section 6

“We also constructed secluded partitions for a wide all $k$”

The second paragraph of Section 6 is very vague, and doesn’t mention that the similar upper bounds are for general lp norms.","What direct implications do these results have for list-replicable learning?

How do these implications compare to what is known for $\rho$-replicable learning for similar problems?","Yes, the authors have addressed all limitations.",['No ethics review needed.'],5,4,,Yes,2,2,3,1720982677292,,,NeurIPS.cc/2024/Conference,2lL7s5ESTj,"['NeurIPS.cc/2024/Conference/Submission7381/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879157156,[],3,,,['everyone'],2lL7s5ESTj,['NeurIPS.cc/2024/Conference/Submission7381/Reviewer_W1GL'],1720982677292,1730879157156,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7381/Reviewer_W1GL']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. ""Stability is Stable"" by Bun, Gaboardi, Hopkins, Impagliazzo, Lei, Pitassi, Sivakumar, Sorrell
2. ""Replicability in Reinforcement Learning"" by Karbasi, Velegkas, Yang, Zhou '23
3. ""Replicability in High Dimensional Statistics"" by Hopkins, Impagliazzo, Kane, Liu, Ye '24

These citations are recommended to provide more attention to related work on replicable (in the sense of ILPS22) algorithms for the d-coin bias estimation problem.",1,"2023, 2024",Stability is Stable 
KhVqCDrDna,"This work studies secluded partitions, which appear in the context of list-replicable learning (among other geometric/TCS applications). The complement known bounds on list complexity, the authors present new upper-bounds on the tolerance parameter as a function of the list complexity k and the ambient dimension d. They show a construction of a secluded partition that roughly achieves these bounds, showing the optimality of their bounds. The secluded partition results are then applied to give a ""neighborhood"" version of Sperner's lemma, for $\ell_\infty$ neighborhoods.","This work provides novel results with potentially broad applications in geometry and computer science. Sperner's lemma is widely useful across disciplines, and this neighborhood variant may prove similarly broadly useful.","As written, I don’t think this work is a good fit for NeurIPS. This work  studies secluded partitions, which have connections to list-replicable algorithms for, e.g., the d-coin bias estimation problem as mentioned by the authors. In this sense the results have applications to replicable learning, but the actual application of the secluded partitions results give somewhat marginal replicable learning results. Theorem 3.1 essentially shows that one cannot meaningfully tradeoff list complexity for better secluded partition tolerance, and therefore cannot hope to improve sample complexity for the d-coin bias problem via the secluded partition approach, but says nothing of other approaches or other problems. 

If I try to read this as a learning paper where the focus is improving sample complexity of list-replicable d-coin bias estimation algorithms, it seems like there should be more attention paid in related work to replicable (in the sense of ILPS22) algorithms for the d-coin bias estimation problem as well, as this has been studied in [1], [2], and recently (posted after NeurIPS submission deadline) [3]. 

[1] “Stability is Stable” Bun, Gaboardi, Hopkins, Impagliazzo, Lei, Pitassi, Sivakumar, Sorrell
[2] “Replicability in Reinforcement Learning” Karbasi, Velegkas, Yang, Zhou ’23
[3] “Replicability in High Dimensional Statistics” Hopkins, Impagliazzo, Kane, Liu, Ye ‘24

Typos/suggested edits:

Abstract

“We show that for each d” -> “we show for each d”

Section 1 pg 2
Brower -> Brouwer
should be seen as a fundamental endeavor. . 

Section 2 page 2
“belongs to a list L consisting of almost k good hypotheses”

“over which a family of distribution” -> “over which a family of distributions”

page 3

“the partitions considered in this work have a non-zero” -> “the partitions considered in this work have non-zero

Theorem 2.4 could be written a little more clearly. It would be good to define the mapping implicit in the term “coloring” and clarify that opposite faces mean faces of the hypercube

Section 3

“in general a $(k, \varepsilon)$-secluded partitions” 

“Can we improve this and construct a (d+1, \omega(1/d)-secluded partition?”

“is the following result upper bound result”

“Till this work we know”

“There exist a k-list replicable algorithm”

“Spener/KKM Lemma”

Section 4
“A learning algorithm A to be $(n, \eta)$-globally stable”

Section 5.1

Need a period before Thus/ what we do is to “replace”

I found the proof sketch for Theorem 3.1 had a few seemingly unnecessary detours that were a bit distracting. For instance, deriving the lower bound of 1 before deriving the desired bound. The footnote could be more precise (what does “becomes the wrong inequality” mean?)

Need a period before “Now that we have dealt with both issues” on page 6.

“So because there is a ceiling involved” could be made more precise, as could “by our change of perspective.”

Section 5.2

There’s a $d_n$ that should be $d_i$ in Definition 5.2

Section 6

“We also constructed secluded partitions for a wide all $k$”

The second paragraph of Section 6 is very vague, and doesn’t mention that the similar upper bounds are for general lp norms.","What direct implications do these results have for list-replicable learning?

How do these implications compare to what is known for $\rho$-replicable learning for similar problems?","Yes, the authors have addressed all limitations.",['No ethics review needed.'],5,4,,Yes,2,2,3,1720982677292,,,NeurIPS.cc/2024/Conference,2lL7s5ESTj,"['NeurIPS.cc/2024/Conference/Submission7381/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879157156,[],3,,,['everyone'],2lL7s5ESTj,['NeurIPS.cc/2024/Conference/Submission7381/Reviewer_W1GL'],1720982677292,1730879157156,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7381/Reviewer_W1GL']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. ""Stability is Stable"" by Bun, Gaboardi, Hopkins, Impagliazzo, Lei, Pitassi, Sivakumar, Sorrell
2. ""Replicability in Reinforcement Learning"" by Karbasi, Velegkas, Yang, Zhou '23
3. ""Replicability in High Dimensional Statistics"" by Hopkins, Impagliazzo, Kane, Liu, Ye '24

These citations are recommended to provide more attention to related work on replicable (in the sense of ILPS22) algorithms for the d-coin bias estimation problem.",1,"2023, 2024",Replicability in Reinforcement Learning 
KhVqCDrDna,"This work studies secluded partitions, which appear in the context of list-replicable learning (among other geometric/TCS applications). The complement known bounds on list complexity, the authors present new upper-bounds on the tolerance parameter as a function of the list complexity k and the ambient dimension d. They show a construction of a secluded partition that roughly achieves these bounds, showing the optimality of their bounds. The secluded partition results are then applied to give a ""neighborhood"" version of Sperner's lemma, for $\ell_\infty$ neighborhoods.","This work provides novel results with potentially broad applications in geometry and computer science. Sperner's lemma is widely useful across disciplines, and this neighborhood variant may prove similarly broadly useful.","As written, I don’t think this work is a good fit for NeurIPS. This work  studies secluded partitions, which have connections to list-replicable algorithms for, e.g., the d-coin bias estimation problem as mentioned by the authors. In this sense the results have applications to replicable learning, but the actual application of the secluded partitions results give somewhat marginal replicable learning results. Theorem 3.1 essentially shows that one cannot meaningfully tradeoff list complexity for better secluded partition tolerance, and therefore cannot hope to improve sample complexity for the d-coin bias problem via the secluded partition approach, but says nothing of other approaches or other problems. 

If I try to read this as a learning paper where the focus is improving sample complexity of list-replicable d-coin bias estimation algorithms, it seems like there should be more attention paid in related work to replicable (in the sense of ILPS22) algorithms for the d-coin bias estimation problem as well, as this has been studied in [1], [2], and recently (posted after NeurIPS submission deadline) [3]. 

[1] “Stability is Stable” Bun, Gaboardi, Hopkins, Impagliazzo, Lei, Pitassi, Sivakumar, Sorrell
[2] “Replicability in Reinforcement Learning” Karbasi, Velegkas, Yang, Zhou ’23
[3] “Replicability in High Dimensional Statistics” Hopkins, Impagliazzo, Kane, Liu, Ye ‘24

Typos/suggested edits:

Abstract

“We show that for each d” -> “we show for each d”

Section 1 pg 2
Brower -> Brouwer
should be seen as a fundamental endeavor. . 

Section 2 page 2
“belongs to a list L consisting of almost k good hypotheses”

“over which a family of distribution” -> “over which a family of distributions”

page 3

“the partitions considered in this work have a non-zero” -> “the partitions considered in this work have non-zero

Theorem 2.4 could be written a little more clearly. It would be good to define the mapping implicit in the term “coloring” and clarify that opposite faces mean faces of the hypercube

Section 3

“in general a $(k, \varepsilon)$-secluded partitions” 

“Can we improve this and construct a (d+1, \omega(1/d)-secluded partition?”

“is the following result upper bound result”

“Till this work we know”

“There exist a k-list replicable algorithm”

“Spener/KKM Lemma”

Section 4
“A learning algorithm A to be $(n, \eta)$-globally stable”

Section 5.1

Need a period before Thus/ what we do is to “replace”

I found the proof sketch for Theorem 3.1 had a few seemingly unnecessary detours that were a bit distracting. For instance, deriving the lower bound of 1 before deriving the desired bound. The footnote could be more precise (what does “becomes the wrong inequality” mean?)

Need a period before “Now that we have dealt with both issues” on page 6.

“So because there is a ceiling involved” could be made more precise, as could “by our change of perspective.”

Section 5.2

There’s a $d_n$ that should be $d_i$ in Definition 5.2

Section 6

“We also constructed secluded partitions for a wide all $k$”

The second paragraph of Section 6 is very vague, and doesn’t mention that the similar upper bounds are for general lp norms.","What direct implications do these results have for list-replicable learning?

How do these implications compare to what is known for $\rho$-replicable learning for similar problems?","Yes, the authors have addressed all limitations.",['No ethics review needed.'],5,4,,Yes,2,2,3,1720982677292,,,NeurIPS.cc/2024/Conference,2lL7s5ESTj,"['NeurIPS.cc/2024/Conference/Submission7381/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879157156,[],3,,,['everyone'],2lL7s5ESTj,['NeurIPS.cc/2024/Conference/Submission7381/Reviewer_W1GL'],1720982677292,1730879157156,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7381/Reviewer_W1GL']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. ""Stability is Stable"" by Bun, Gaboardi, Hopkins, Impagliazzo, Lei, Pitassi, Sivakumar, Sorrell
2. ""Replicability in Reinforcement Learning"" by Karbasi, Velegkas, Yang, Zhou '23
3. ""Replicability in High Dimensional Statistics"" by Hopkins, Impagliazzo, Kane, Liu, Ye '24

These citations are recommended to provide more attention to related work on replicable (in the sense of ILPS22) algorithms for the d-coin bias estimation problem.",1,"2023, 2024",Replicability in High Dimensional Statistics
CyIaVUxqvO,"The authors design and analyze momentum-based algorithms on Lie groups.  They first study ODEs and provide convergence rates for them.  Then they discretize the ODEs (in two different ways -- Lie Heavy Ball and Lie NAG-SC), and show that the second discretization (Lie NAG-SC) has a *locally* accelerated convergence rate.","The paper is decently written (but not exceptional).  The most interesting feature of this paper is that one can use the group structure of the Lie group to design optimization algorithms, and avoid parallel transport or the log map usually present in the more general Riemannian setting.","(1) The requirement that the manifold is a Lie group is very restrictive.  There are many manifolds used in practice which are not Lie groups but still have very nice structure.  Perhaps the prime example is the Stiefel manifolds (which include spheres).  In many applications (especially those related to low rank problems), it is desirable to work with rectangular matrices like Stiefel matrices because storage required for them is much smaller than square matrices (like in SO(n)).  Can the authors provide examples of Lie groups used in practice which are not SO(n), U(n), or products of those?

(2) The paper fails to cite *many* important prior works, most notably (in this order):

* ""Accelerated gradient methods for geodesically convex optimization: Tractable algorithms and convergence analysis"" by Jungbin Kim and Insoon Yang 2022.  This is the first paper to truly achieve ""acceleration"" on Riemannian manifolds, specifically having *global* complexity guarantees which scale like O(sqrt{condition number}) or O(sqrt{1/epsilon}).  All prior work only achieved acceleration locally, which is *arguably* not too interesting (see below).

* The updated version of ""Global Riemannian Acceleration in Hyperbolic and Spherical Spaces"" by Martinez-Rubio also provides global acceleration rates (albeit only on spaces of constant curvature).  [Previous version had exponential dependence on the curvature/radius; this was reduced to a polynomial dependence in the updated version.]

* Lower bounds and obstructions for acceleration on Riemannian manifolds: (a) ""No-go Theorem for Acceleration in the Hyperbolic Plane"" by Hamilton and Moitra, (b) ""Negative curvature obstructs acceleration for strongly geodesically convex optimization, even with exact first-order oracles"" by Criscitiello and Boumal, (c) ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal

* Acceleration in the nonconvex case: ""An accelerated first-order method for non-convex optimization on manifolds"" by Criscitiello and Boumal

(3) The paper only provides local acceleration, which is *arguably* not too interesting (at least from a query-complexity viewpoint) because locally manifolds look like Euclidean spaces.  This can be made rigorous: there is a generally method for converting Euclidean algorithms to Riemannian ones which locally have the same convergence guarantees: see for example Appendix D of ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal.

(4) I am not 100% convinced that the Lie Heavy Ball does not have a locally accelerated rate.  My impression is that, with the right choice of parameters, Heavy Ball is *locally* accelerated (essentially because locally a strongly convex cost function looks like a quadratic): see for example ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu.  On the other hand, the provided numerical experiments seem to indicate that Lie Heavy Ball is not accelerated (but maybe a different choice of parameters would improve convergence?).

(5) For SO(n) or U(n), can the authors please explain why the log map and parallel transport are prohibitively costly (in comparison to the exponential)?

(6) Is it necessary to use the exponential map as the retraction?  From the reviewer's experience, for the manifold SO(n), using the matrix exponential is more expensive than using the QR-retraction.

(7) The experiments performed (the eigen decomposition problem) are limited.  The authors say the eigen decomposition problem ""is a hard non-convex problem on a manifold"".  The reviewer somewhat disagrees: in some sense, it is one of the easiest nonconvex optimization problems as all second order critical points (where gradient = 0, Hessian is PSD) are global minima.","Questions and comments (some of which were already asked in the ""weaknesses"" section):

* Explicitly, what do your algorithms look like when the Lie group is a torus (product of circles)?  Does it reduce to standard NAG?

* Can the authors provide examples of Lie groups used in practice which are not SO(n), U(n), or products of those?

* I am not 100% convinced that the Lie Heavy Ball does not have a locally accelerated rate.  My impression is that, with the right choice of parameters, Heavy Ball is *locally* accelerated (essentially because locally a strongly convex cost function looks like a quadratic): see for example ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu.  On the other hand, the provided numerical experiments seem to indicate that Lie Heavy Ball is not accelerated (but maybe a different choice of parameters would improve convergence?).

* For SO(n) or U(n), can the authors please explain why the log map and parallel transport are prohibitively costly (in comparison to the exponential)?

* Is it necessary to use the exponential map as the retraction?  From the reviewer's experience, for the manifold SO(n), using the matrix exponential is more expensive than using the QR-retraction.

* Line 277 typo: decreaing -> decreasing",No potential negative societal impacts.,['No ethics review needed.'],5,4,,Yes,2,2,3,1719000522621,,,NeurIPS.cc/2024/Conference,2hqHWD7wDb,"['NeurIPS.cc/2024/Conference/Submission16838/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879878317,[],1,,,['everyone'],2hqHWD7wDb,['NeurIPS.cc/2024/Conference/Submission16838/Reviewer_zKf2'],1719000522621,1730879878317,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16838/Reviewer_zKf2']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Accelerated gradient methods for geodesically convex optimization: Tractable algorithms and convergence analysis"" by Jungbin Kim and Insoon Yang (2022)
2. The updated version of ""Global Riemannian Acceleration in Hyperbolic and Spherical Spaces"" by Martinez-Rubio
3. ""No-go Theorem for Acceleration in the Hyperbolic Plane"" by Hamilton and Moitra
4. ""Negative curvature obstructs acceleration for strongly geodesically convex optimization, even with exact first-order oracles"" by Criscitiello and Boumal
5. ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal
6. ""An accelerated first-order method for non-convex optimization on manifolds"" by Criscitiello and Boumal
7. ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu

These citations are suggested to address the weaknesses of the paper, particularly the lack of citation of important prior works in the field of optimization on Riemannian manifolds.",1,2022,Accelerated gradient methods for geodesically convex optimization Tractable algorithms and convergence analysis 
CyIaVUxqvO,"The authors design and analyze momentum-based algorithms on Lie groups.  They first study ODEs and provide convergence rates for them.  Then they discretize the ODEs (in two different ways -- Lie Heavy Ball and Lie NAG-SC), and show that the second discretization (Lie NAG-SC) has a *locally* accelerated convergence rate.","The paper is decently written (but not exceptional).  The most interesting feature of this paper is that one can use the group structure of the Lie group to design optimization algorithms, and avoid parallel transport or the log map usually present in the more general Riemannian setting.","(1) The requirement that the manifold is a Lie group is very restrictive.  There are many manifolds used in practice which are not Lie groups but still have very nice structure.  Perhaps the prime example is the Stiefel manifolds (which include spheres).  In many applications (especially those related to low rank problems), it is desirable to work with rectangular matrices like Stiefel matrices because storage required for them is much smaller than square matrices (like in SO(n)).  Can the authors provide examples of Lie groups used in practice which are not SO(n), U(n), or products of those?

(2) The paper fails to cite *many* important prior works, most notably (in this order):

* ""Accelerated gradient methods for geodesically convex optimization: Tractable algorithms and convergence analysis"" by Jungbin Kim and Insoon Yang 2022.  This is the first paper to truly achieve ""acceleration"" on Riemannian manifolds, specifically having *global* complexity guarantees which scale like O(sqrt{condition number}) or O(sqrt{1/epsilon}).  All prior work only achieved acceleration locally, which is *arguably* not too interesting (see below).

* The updated version of ""Global Riemannian Acceleration in Hyperbolic and Spherical Spaces"" by Martinez-Rubio also provides global acceleration rates (albeit only on spaces of constant curvature).  [Previous version had exponential dependence on the curvature/radius; this was reduced to a polynomial dependence in the updated version.]

* Lower bounds and obstructions for acceleration on Riemannian manifolds: (a) ""No-go Theorem for Acceleration in the Hyperbolic Plane"" by Hamilton and Moitra, (b) ""Negative curvature obstructs acceleration for strongly geodesically convex optimization, even with exact first-order oracles"" by Criscitiello and Boumal, (c) ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal

* Acceleration in the nonconvex case: ""An accelerated first-order method for non-convex optimization on manifolds"" by Criscitiello and Boumal

(3) The paper only provides local acceleration, which is *arguably* not too interesting (at least from a query-complexity viewpoint) because locally manifolds look like Euclidean spaces.  This can be made rigorous: there is a generally method for converting Euclidean algorithms to Riemannian ones which locally have the same convergence guarantees: see for example Appendix D of ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal.

(4) I am not 100% convinced that the Lie Heavy Ball does not have a locally accelerated rate.  My impression is that, with the right choice of parameters, Heavy Ball is *locally* accelerated (essentially because locally a strongly convex cost function looks like a quadratic): see for example ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu.  On the other hand, the provided numerical experiments seem to indicate that Lie Heavy Ball is not accelerated (but maybe a different choice of parameters would improve convergence?).

(5) For SO(n) or U(n), can the authors please explain why the log map and parallel transport are prohibitively costly (in comparison to the exponential)?

(6) Is it necessary to use the exponential map as the retraction?  From the reviewer's experience, for the manifold SO(n), using the matrix exponential is more expensive than using the QR-retraction.

(7) The experiments performed (the eigen decomposition problem) are limited.  The authors say the eigen decomposition problem ""is a hard non-convex problem on a manifold"".  The reviewer somewhat disagrees: in some sense, it is one of the easiest nonconvex optimization problems as all second order critical points (where gradient = 0, Hessian is PSD) are global minima.","Questions and comments (some of which were already asked in the ""weaknesses"" section):

* Explicitly, what do your algorithms look like when the Lie group is a torus (product of circles)?  Does it reduce to standard NAG?

* Can the authors provide examples of Lie groups used in practice which are not SO(n), U(n), or products of those?

* I am not 100% convinced that the Lie Heavy Ball does not have a locally accelerated rate.  My impression is that, with the right choice of parameters, Heavy Ball is *locally* accelerated (essentially because locally a strongly convex cost function looks like a quadratic): see for example ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu.  On the other hand, the provided numerical experiments seem to indicate that Lie Heavy Ball is not accelerated (but maybe a different choice of parameters would improve convergence?).

* For SO(n) or U(n), can the authors please explain why the log map and parallel transport are prohibitively costly (in comparison to the exponential)?

* Is it necessary to use the exponential map as the retraction?  From the reviewer's experience, for the manifold SO(n), using the matrix exponential is more expensive than using the QR-retraction.

* Line 277 typo: decreaing -> decreasing",No potential negative societal impacts.,['No ethics review needed.'],5,4,,Yes,2,2,3,1719000522621,,,NeurIPS.cc/2024/Conference,2hqHWD7wDb,"['NeurIPS.cc/2024/Conference/Submission16838/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879878317,[],1,,,['everyone'],2hqHWD7wDb,['NeurIPS.cc/2024/Conference/Submission16838/Reviewer_zKf2'],1719000522621,1730879878317,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16838/Reviewer_zKf2']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Accelerated gradient methods for geodesically convex optimization: Tractable algorithms and convergence analysis"" by Jungbin Kim and Insoon Yang (2022)
2. The updated version of ""Global Riemannian Acceleration in Hyperbolic and Spherical Spaces"" by Martinez-Rubio
3. ""No-go Theorem for Acceleration in the Hyperbolic Plane"" by Hamilton and Moitra
4. ""Negative curvature obstructs acceleration for strongly geodesically convex optimization, even with exact first-order oracles"" by Criscitiello and Boumal
5. ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal
6. ""An accelerated first-order method for non-convex optimization on manifolds"" by Criscitiello and Boumal
7. ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu

These citations are suggested to address the weaknesses of the paper, particularly the lack of citation of important prior works in the field of optimization on Riemannian manifolds.",1,2022,Global Riemannian Acceleration in Hyperbolic and Spherical Spaces 
CyIaVUxqvO,"The authors design and analyze momentum-based algorithms on Lie groups.  They first study ODEs and provide convergence rates for them.  Then they discretize the ODEs (in two different ways -- Lie Heavy Ball and Lie NAG-SC), and show that the second discretization (Lie NAG-SC) has a *locally* accelerated convergence rate.","The paper is decently written (but not exceptional).  The most interesting feature of this paper is that one can use the group structure of the Lie group to design optimization algorithms, and avoid parallel transport or the log map usually present in the more general Riemannian setting.","(1) The requirement that the manifold is a Lie group is very restrictive.  There are many manifolds used in practice which are not Lie groups but still have very nice structure.  Perhaps the prime example is the Stiefel manifolds (which include spheres).  In many applications (especially those related to low rank problems), it is desirable to work with rectangular matrices like Stiefel matrices because storage required for them is much smaller than square matrices (like in SO(n)).  Can the authors provide examples of Lie groups used in practice which are not SO(n), U(n), or products of those?

(2) The paper fails to cite *many* important prior works, most notably (in this order):

* ""Accelerated gradient methods for geodesically convex optimization: Tractable algorithms and convergence analysis"" by Jungbin Kim and Insoon Yang 2022.  This is the first paper to truly achieve ""acceleration"" on Riemannian manifolds, specifically having *global* complexity guarantees which scale like O(sqrt{condition number}) or O(sqrt{1/epsilon}).  All prior work only achieved acceleration locally, which is *arguably* not too interesting (see below).

* The updated version of ""Global Riemannian Acceleration in Hyperbolic and Spherical Spaces"" by Martinez-Rubio also provides global acceleration rates (albeit only on spaces of constant curvature).  [Previous version had exponential dependence on the curvature/radius; this was reduced to a polynomial dependence in the updated version.]

* Lower bounds and obstructions for acceleration on Riemannian manifolds: (a) ""No-go Theorem for Acceleration in the Hyperbolic Plane"" by Hamilton and Moitra, (b) ""Negative curvature obstructs acceleration for strongly geodesically convex optimization, even with exact first-order oracles"" by Criscitiello and Boumal, (c) ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal

* Acceleration in the nonconvex case: ""An accelerated first-order method for non-convex optimization on manifolds"" by Criscitiello and Boumal

(3) The paper only provides local acceleration, which is *arguably* not too interesting (at least from a query-complexity viewpoint) because locally manifolds look like Euclidean spaces.  This can be made rigorous: there is a generally method for converting Euclidean algorithms to Riemannian ones which locally have the same convergence guarantees: see for example Appendix D of ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal.

(4) I am not 100% convinced that the Lie Heavy Ball does not have a locally accelerated rate.  My impression is that, with the right choice of parameters, Heavy Ball is *locally* accelerated (essentially because locally a strongly convex cost function looks like a quadratic): see for example ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu.  On the other hand, the provided numerical experiments seem to indicate that Lie Heavy Ball is not accelerated (but maybe a different choice of parameters would improve convergence?).

(5) For SO(n) or U(n), can the authors please explain why the log map and parallel transport are prohibitively costly (in comparison to the exponential)?

(6) Is it necessary to use the exponential map as the retraction?  From the reviewer's experience, for the manifold SO(n), using the matrix exponential is more expensive than using the QR-retraction.

(7) The experiments performed (the eigen decomposition problem) are limited.  The authors say the eigen decomposition problem ""is a hard non-convex problem on a manifold"".  The reviewer somewhat disagrees: in some sense, it is one of the easiest nonconvex optimization problems as all second order critical points (where gradient = 0, Hessian is PSD) are global minima.","Questions and comments (some of which were already asked in the ""weaknesses"" section):

* Explicitly, what do your algorithms look like when the Lie group is a torus (product of circles)?  Does it reduce to standard NAG?

* Can the authors provide examples of Lie groups used in practice which are not SO(n), U(n), or products of those?

* I am not 100% convinced that the Lie Heavy Ball does not have a locally accelerated rate.  My impression is that, with the right choice of parameters, Heavy Ball is *locally* accelerated (essentially because locally a strongly convex cost function looks like a quadratic): see for example ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu.  On the other hand, the provided numerical experiments seem to indicate that Lie Heavy Ball is not accelerated (but maybe a different choice of parameters would improve convergence?).

* For SO(n) or U(n), can the authors please explain why the log map and parallel transport are prohibitively costly (in comparison to the exponential)?

* Is it necessary to use the exponential map as the retraction?  From the reviewer's experience, for the manifold SO(n), using the matrix exponential is more expensive than using the QR-retraction.

* Line 277 typo: decreaing -> decreasing",No potential negative societal impacts.,['No ethics review needed.'],5,4,,Yes,2,2,3,1719000522621,,,NeurIPS.cc/2024/Conference,2hqHWD7wDb,"['NeurIPS.cc/2024/Conference/Submission16838/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879878317,[],1,,,['everyone'],2hqHWD7wDb,['NeurIPS.cc/2024/Conference/Submission16838/Reviewer_zKf2'],1719000522621,1730879878317,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16838/Reviewer_zKf2']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Accelerated gradient methods for geodesically convex optimization: Tractable algorithms and convergence analysis"" by Jungbin Kim and Insoon Yang (2022)
2. The updated version of ""Global Riemannian Acceleration in Hyperbolic and Spherical Spaces"" by Martinez-Rubio
3. ""No-go Theorem for Acceleration in the Hyperbolic Plane"" by Hamilton and Moitra
4. ""Negative curvature obstructs acceleration for strongly geodesically convex optimization, even with exact first-order oracles"" by Criscitiello and Boumal
5. ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal
6. ""An accelerated first-order method for non-convex optimization on manifolds"" by Criscitiello and Boumal
7. ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu

These citations are suggested to address the weaknesses of the paper, particularly the lack of citation of important prior works in the field of optimization on Riemannian manifolds.",1,2022,No-go Theorem for Acceleration in the Hyperbolic Plane 
CyIaVUxqvO,"The authors design and analyze momentum-based algorithms on Lie groups.  They first study ODEs and provide convergence rates for them.  Then they discretize the ODEs (in two different ways -- Lie Heavy Ball and Lie NAG-SC), and show that the second discretization (Lie NAG-SC) has a *locally* accelerated convergence rate.","The paper is decently written (but not exceptional).  The most interesting feature of this paper is that one can use the group structure of the Lie group to design optimization algorithms, and avoid parallel transport or the log map usually present in the more general Riemannian setting.","(1) The requirement that the manifold is a Lie group is very restrictive.  There are many manifolds used in practice which are not Lie groups but still have very nice structure.  Perhaps the prime example is the Stiefel manifolds (which include spheres).  In many applications (especially those related to low rank problems), it is desirable to work with rectangular matrices like Stiefel matrices because storage required for them is much smaller than square matrices (like in SO(n)).  Can the authors provide examples of Lie groups used in practice which are not SO(n), U(n), or products of those?

(2) The paper fails to cite *many* important prior works, most notably (in this order):

* ""Accelerated gradient methods for geodesically convex optimization: Tractable algorithms and convergence analysis"" by Jungbin Kim and Insoon Yang 2022.  This is the first paper to truly achieve ""acceleration"" on Riemannian manifolds, specifically having *global* complexity guarantees which scale like O(sqrt{condition number}) or O(sqrt{1/epsilon}).  All prior work only achieved acceleration locally, which is *arguably* not too interesting (see below).

* The updated version of ""Global Riemannian Acceleration in Hyperbolic and Spherical Spaces"" by Martinez-Rubio also provides global acceleration rates (albeit only on spaces of constant curvature).  [Previous version had exponential dependence on the curvature/radius; this was reduced to a polynomial dependence in the updated version.]

* Lower bounds and obstructions for acceleration on Riemannian manifolds: (a) ""No-go Theorem for Acceleration in the Hyperbolic Plane"" by Hamilton and Moitra, (b) ""Negative curvature obstructs acceleration for strongly geodesically convex optimization, even with exact first-order oracles"" by Criscitiello and Boumal, (c) ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal

* Acceleration in the nonconvex case: ""An accelerated first-order method for non-convex optimization on manifolds"" by Criscitiello and Boumal

(3) The paper only provides local acceleration, which is *arguably* not too interesting (at least from a query-complexity viewpoint) because locally manifolds look like Euclidean spaces.  This can be made rigorous: there is a generally method for converting Euclidean algorithms to Riemannian ones which locally have the same convergence guarantees: see for example Appendix D of ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal.

(4) I am not 100% convinced that the Lie Heavy Ball does not have a locally accelerated rate.  My impression is that, with the right choice of parameters, Heavy Ball is *locally* accelerated (essentially because locally a strongly convex cost function looks like a quadratic): see for example ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu.  On the other hand, the provided numerical experiments seem to indicate that Lie Heavy Ball is not accelerated (but maybe a different choice of parameters would improve convergence?).

(5) For SO(n) or U(n), can the authors please explain why the log map and parallel transport are prohibitively costly (in comparison to the exponential)?

(6) Is it necessary to use the exponential map as the retraction?  From the reviewer's experience, for the manifold SO(n), using the matrix exponential is more expensive than using the QR-retraction.

(7) The experiments performed (the eigen decomposition problem) are limited.  The authors say the eigen decomposition problem ""is a hard non-convex problem on a manifold"".  The reviewer somewhat disagrees: in some sense, it is one of the easiest nonconvex optimization problems as all second order critical points (where gradient = 0, Hessian is PSD) are global minima.","Questions and comments (some of which were already asked in the ""weaknesses"" section):

* Explicitly, what do your algorithms look like when the Lie group is a torus (product of circles)?  Does it reduce to standard NAG?

* Can the authors provide examples of Lie groups used in practice which are not SO(n), U(n), or products of those?

* I am not 100% convinced that the Lie Heavy Ball does not have a locally accelerated rate.  My impression is that, with the right choice of parameters, Heavy Ball is *locally* accelerated (essentially because locally a strongly convex cost function looks like a quadratic): see for example ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu.  On the other hand, the provided numerical experiments seem to indicate that Lie Heavy Ball is not accelerated (but maybe a different choice of parameters would improve convergence?).

* For SO(n) or U(n), can the authors please explain why the log map and parallel transport are prohibitively costly (in comparison to the exponential)?

* Is it necessary to use the exponential map as the retraction?  From the reviewer's experience, for the manifold SO(n), using the matrix exponential is more expensive than using the QR-retraction.

* Line 277 typo: decreaing -> decreasing",No potential negative societal impacts.,['No ethics review needed.'],5,4,,Yes,2,2,3,1719000522621,,,NeurIPS.cc/2024/Conference,2hqHWD7wDb,"['NeurIPS.cc/2024/Conference/Submission16838/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879878317,[],1,,,['everyone'],2hqHWD7wDb,['NeurIPS.cc/2024/Conference/Submission16838/Reviewer_zKf2'],1719000522621,1730879878317,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16838/Reviewer_zKf2']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Accelerated gradient methods for geodesically convex optimization: Tractable algorithms and convergence analysis"" by Jungbin Kim and Insoon Yang (2022)
2. The updated version of ""Global Riemannian Acceleration in Hyperbolic and Spherical Spaces"" by Martinez-Rubio
3. ""No-go Theorem for Acceleration in the Hyperbolic Plane"" by Hamilton and Moitra
4. ""Negative curvature obstructs acceleration for strongly geodesically convex optimization, even with exact first-order oracles"" by Criscitiello and Boumal
5. ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal
6. ""An accelerated first-order method for non-convex optimization on manifolds"" by Criscitiello and Boumal
7. ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu

These citations are suggested to address the weaknesses of the paper, particularly the lack of citation of important prior works in the field of optimization on Riemannian manifolds.",1,2022,Negative curvature obstructs acceleration for strongly geodesically convex optimization even with exact first-order oracles 
CyIaVUxqvO,"The authors design and analyze momentum-based algorithms on Lie groups.  They first study ODEs and provide convergence rates for them.  Then they discretize the ODEs (in two different ways -- Lie Heavy Ball and Lie NAG-SC), and show that the second discretization (Lie NAG-SC) has a *locally* accelerated convergence rate.","The paper is decently written (but not exceptional).  The most interesting feature of this paper is that one can use the group structure of the Lie group to design optimization algorithms, and avoid parallel transport or the log map usually present in the more general Riemannian setting.","(1) The requirement that the manifold is a Lie group is very restrictive.  There are many manifolds used in practice which are not Lie groups but still have very nice structure.  Perhaps the prime example is the Stiefel manifolds (which include spheres).  In many applications (especially those related to low rank problems), it is desirable to work with rectangular matrices like Stiefel matrices because storage required for them is much smaller than square matrices (like in SO(n)).  Can the authors provide examples of Lie groups used in practice which are not SO(n), U(n), or products of those?

(2) The paper fails to cite *many* important prior works, most notably (in this order):

* ""Accelerated gradient methods for geodesically convex optimization: Tractable algorithms and convergence analysis"" by Jungbin Kim and Insoon Yang 2022.  This is the first paper to truly achieve ""acceleration"" on Riemannian manifolds, specifically having *global* complexity guarantees which scale like O(sqrt{condition number}) or O(sqrt{1/epsilon}).  All prior work only achieved acceleration locally, which is *arguably* not too interesting (see below).

* The updated version of ""Global Riemannian Acceleration in Hyperbolic and Spherical Spaces"" by Martinez-Rubio also provides global acceleration rates (albeit only on spaces of constant curvature).  [Previous version had exponential dependence on the curvature/radius; this was reduced to a polynomial dependence in the updated version.]

* Lower bounds and obstructions for acceleration on Riemannian manifolds: (a) ""No-go Theorem for Acceleration in the Hyperbolic Plane"" by Hamilton and Moitra, (b) ""Negative curvature obstructs acceleration for strongly geodesically convex optimization, even with exact first-order oracles"" by Criscitiello and Boumal, (c) ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal

* Acceleration in the nonconvex case: ""An accelerated first-order method for non-convex optimization on manifolds"" by Criscitiello and Boumal

(3) The paper only provides local acceleration, which is *arguably* not too interesting (at least from a query-complexity viewpoint) because locally manifolds look like Euclidean spaces.  This can be made rigorous: there is a generally method for converting Euclidean algorithms to Riemannian ones which locally have the same convergence guarantees: see for example Appendix D of ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal.

(4) I am not 100% convinced that the Lie Heavy Ball does not have a locally accelerated rate.  My impression is that, with the right choice of parameters, Heavy Ball is *locally* accelerated (essentially because locally a strongly convex cost function looks like a quadratic): see for example ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu.  On the other hand, the provided numerical experiments seem to indicate that Lie Heavy Ball is not accelerated (but maybe a different choice of parameters would improve convergence?).

(5) For SO(n) or U(n), can the authors please explain why the log map and parallel transport are prohibitively costly (in comparison to the exponential)?

(6) Is it necessary to use the exponential map as the retraction?  From the reviewer's experience, for the manifold SO(n), using the matrix exponential is more expensive than using the QR-retraction.

(7) The experiments performed (the eigen decomposition problem) are limited.  The authors say the eigen decomposition problem ""is a hard non-convex problem on a manifold"".  The reviewer somewhat disagrees: in some sense, it is one of the easiest nonconvex optimization problems as all second order critical points (where gradient = 0, Hessian is PSD) are global minima.","Questions and comments (some of which were already asked in the ""weaknesses"" section):

* Explicitly, what do your algorithms look like when the Lie group is a torus (product of circles)?  Does it reduce to standard NAG?

* Can the authors provide examples of Lie groups used in practice which are not SO(n), U(n), or products of those?

* I am not 100% convinced that the Lie Heavy Ball does not have a locally accelerated rate.  My impression is that, with the right choice of parameters, Heavy Ball is *locally* accelerated (essentially because locally a strongly convex cost function looks like a quadratic): see for example ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu.  On the other hand, the provided numerical experiments seem to indicate that Lie Heavy Ball is not accelerated (but maybe a different choice of parameters would improve convergence?).

* For SO(n) or U(n), can the authors please explain why the log map and parallel transport are prohibitively costly (in comparison to the exponential)?

* Is it necessary to use the exponential map as the retraction?  From the reviewer's experience, for the manifold SO(n), using the matrix exponential is more expensive than using the QR-retraction.

* Line 277 typo: decreaing -> decreasing",No potential negative societal impacts.,['No ethics review needed.'],5,4,,Yes,2,2,3,1719000522621,,,NeurIPS.cc/2024/Conference,2hqHWD7wDb,"['NeurIPS.cc/2024/Conference/Submission16838/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879878317,[],1,,,['everyone'],2hqHWD7wDb,['NeurIPS.cc/2024/Conference/Submission16838/Reviewer_zKf2'],1719000522621,1730879878317,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16838/Reviewer_zKf2']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Accelerated gradient methods for geodesically convex optimization: Tractable algorithms and convergence analysis"" by Jungbin Kim and Insoon Yang (2022)
2. The updated version of ""Global Riemannian Acceleration in Hyperbolic and Spherical Spaces"" by Martinez-Rubio
3. ""No-go Theorem for Acceleration in the Hyperbolic Plane"" by Hamilton and Moitra
4. ""Negative curvature obstructs acceleration for strongly geodesically convex optimization, even with exact first-order oracles"" by Criscitiello and Boumal
5. ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal
6. ""An accelerated first-order method for non-convex optimization on manifolds"" by Criscitiello and Boumal
7. ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu

These citations are suggested to address the weaknesses of the paper, particularly the lack of citation of important prior works in the field of optimization on Riemannian manifolds.",1,2022,Curvature and complexity Better lower bounds for geodesically convex optimization 
CyIaVUxqvO,"The authors design and analyze momentum-based algorithms on Lie groups.  They first study ODEs and provide convergence rates for them.  Then they discretize the ODEs (in two different ways -- Lie Heavy Ball and Lie NAG-SC), and show that the second discretization (Lie NAG-SC) has a *locally* accelerated convergence rate.","The paper is decently written (but not exceptional).  The most interesting feature of this paper is that one can use the group structure of the Lie group to design optimization algorithms, and avoid parallel transport or the log map usually present in the more general Riemannian setting.","(1) The requirement that the manifold is a Lie group is very restrictive.  There are many manifolds used in practice which are not Lie groups but still have very nice structure.  Perhaps the prime example is the Stiefel manifolds (which include spheres).  In many applications (especially those related to low rank problems), it is desirable to work with rectangular matrices like Stiefel matrices because storage required for them is much smaller than square matrices (like in SO(n)).  Can the authors provide examples of Lie groups used in practice which are not SO(n), U(n), or products of those?

(2) The paper fails to cite *many* important prior works, most notably (in this order):

* ""Accelerated gradient methods for geodesically convex optimization: Tractable algorithms and convergence analysis"" by Jungbin Kim and Insoon Yang 2022.  This is the first paper to truly achieve ""acceleration"" on Riemannian manifolds, specifically having *global* complexity guarantees which scale like O(sqrt{condition number}) or O(sqrt{1/epsilon}).  All prior work only achieved acceleration locally, which is *arguably* not too interesting (see below).

* The updated version of ""Global Riemannian Acceleration in Hyperbolic and Spherical Spaces"" by Martinez-Rubio also provides global acceleration rates (albeit only on spaces of constant curvature).  [Previous version had exponential dependence on the curvature/radius; this was reduced to a polynomial dependence in the updated version.]

* Lower bounds and obstructions for acceleration on Riemannian manifolds: (a) ""No-go Theorem for Acceleration in the Hyperbolic Plane"" by Hamilton and Moitra, (b) ""Negative curvature obstructs acceleration for strongly geodesically convex optimization, even with exact first-order oracles"" by Criscitiello and Boumal, (c) ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal

* Acceleration in the nonconvex case: ""An accelerated first-order method for non-convex optimization on manifolds"" by Criscitiello and Boumal

(3) The paper only provides local acceleration, which is *arguably* not too interesting (at least from a query-complexity viewpoint) because locally manifolds look like Euclidean spaces.  This can be made rigorous: there is a generally method for converting Euclidean algorithms to Riemannian ones which locally have the same convergence guarantees: see for example Appendix D of ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal.

(4) I am not 100% convinced that the Lie Heavy Ball does not have a locally accelerated rate.  My impression is that, with the right choice of parameters, Heavy Ball is *locally* accelerated (essentially because locally a strongly convex cost function looks like a quadratic): see for example ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu.  On the other hand, the provided numerical experiments seem to indicate that Lie Heavy Ball is not accelerated (but maybe a different choice of parameters would improve convergence?).

(5) For SO(n) or U(n), can the authors please explain why the log map and parallel transport are prohibitively costly (in comparison to the exponential)?

(6) Is it necessary to use the exponential map as the retraction?  From the reviewer's experience, for the manifold SO(n), using the matrix exponential is more expensive than using the QR-retraction.

(7) The experiments performed (the eigen decomposition problem) are limited.  The authors say the eigen decomposition problem ""is a hard non-convex problem on a manifold"".  The reviewer somewhat disagrees: in some sense, it is one of the easiest nonconvex optimization problems as all second order critical points (where gradient = 0, Hessian is PSD) are global minima.","Questions and comments (some of which were already asked in the ""weaknesses"" section):

* Explicitly, what do your algorithms look like when the Lie group is a torus (product of circles)?  Does it reduce to standard NAG?

* Can the authors provide examples of Lie groups used in practice which are not SO(n), U(n), or products of those?

* I am not 100% convinced that the Lie Heavy Ball does not have a locally accelerated rate.  My impression is that, with the right choice of parameters, Heavy Ball is *locally* accelerated (essentially because locally a strongly convex cost function looks like a quadratic): see for example ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu.  On the other hand, the provided numerical experiments seem to indicate that Lie Heavy Ball is not accelerated (but maybe a different choice of parameters would improve convergence?).

* For SO(n) or U(n), can the authors please explain why the log map and parallel transport are prohibitively costly (in comparison to the exponential)?

* Is it necessary to use the exponential map as the retraction?  From the reviewer's experience, for the manifold SO(n), using the matrix exponential is more expensive than using the QR-retraction.

* Line 277 typo: decreaing -> decreasing",No potential negative societal impacts.,['No ethics review needed.'],5,4,,Yes,2,2,3,1719000522621,,,NeurIPS.cc/2024/Conference,2hqHWD7wDb,"['NeurIPS.cc/2024/Conference/Submission16838/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879878317,[],1,,,['everyone'],2hqHWD7wDb,['NeurIPS.cc/2024/Conference/Submission16838/Reviewer_zKf2'],1719000522621,1730879878317,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16838/Reviewer_zKf2']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Accelerated gradient methods for geodesically convex optimization: Tractable algorithms and convergence analysis"" by Jungbin Kim and Insoon Yang (2022)
2. The updated version of ""Global Riemannian Acceleration in Hyperbolic and Spherical Spaces"" by Martinez-Rubio
3. ""No-go Theorem for Acceleration in the Hyperbolic Plane"" by Hamilton and Moitra
4. ""Negative curvature obstructs acceleration for strongly geodesically convex optimization, even with exact first-order oracles"" by Criscitiello and Boumal
5. ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal
6. ""An accelerated first-order method for non-convex optimization on manifolds"" by Criscitiello and Boumal
7. ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu

These citations are suggested to address the weaknesses of the paper, particularly the lack of citation of important prior works in the field of optimization on Riemannian manifolds.",1,2022,An accelerated first-order method for non-convex optimization on manifolds 
CyIaVUxqvO,"The authors design and analyze momentum-based algorithms on Lie groups.  They first study ODEs and provide convergence rates for them.  Then they discretize the ODEs (in two different ways -- Lie Heavy Ball and Lie NAG-SC), and show that the second discretization (Lie NAG-SC) has a *locally* accelerated convergence rate.","The paper is decently written (but not exceptional).  The most interesting feature of this paper is that one can use the group structure of the Lie group to design optimization algorithms, and avoid parallel transport or the log map usually present in the more general Riemannian setting.","(1) The requirement that the manifold is a Lie group is very restrictive.  There are many manifolds used in practice which are not Lie groups but still have very nice structure.  Perhaps the prime example is the Stiefel manifolds (which include spheres).  In many applications (especially those related to low rank problems), it is desirable to work with rectangular matrices like Stiefel matrices because storage required for them is much smaller than square matrices (like in SO(n)).  Can the authors provide examples of Lie groups used in practice which are not SO(n), U(n), or products of those?

(2) The paper fails to cite *many* important prior works, most notably (in this order):

* ""Accelerated gradient methods for geodesically convex optimization: Tractable algorithms and convergence analysis"" by Jungbin Kim and Insoon Yang 2022.  This is the first paper to truly achieve ""acceleration"" on Riemannian manifolds, specifically having *global* complexity guarantees which scale like O(sqrt{condition number}) or O(sqrt{1/epsilon}).  All prior work only achieved acceleration locally, which is *arguably* not too interesting (see below).

* The updated version of ""Global Riemannian Acceleration in Hyperbolic and Spherical Spaces"" by Martinez-Rubio also provides global acceleration rates (albeit only on spaces of constant curvature).  [Previous version had exponential dependence on the curvature/radius; this was reduced to a polynomial dependence in the updated version.]

* Lower bounds and obstructions for acceleration on Riemannian manifolds: (a) ""No-go Theorem for Acceleration in the Hyperbolic Plane"" by Hamilton and Moitra, (b) ""Negative curvature obstructs acceleration for strongly geodesically convex optimization, even with exact first-order oracles"" by Criscitiello and Boumal, (c) ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal

* Acceleration in the nonconvex case: ""An accelerated first-order method for non-convex optimization on manifolds"" by Criscitiello and Boumal

(3) The paper only provides local acceleration, which is *arguably* not too interesting (at least from a query-complexity viewpoint) because locally manifolds look like Euclidean spaces.  This can be made rigorous: there is a generally method for converting Euclidean algorithms to Riemannian ones which locally have the same convergence guarantees: see for example Appendix D of ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal.

(4) I am not 100% convinced that the Lie Heavy Ball does not have a locally accelerated rate.  My impression is that, with the right choice of parameters, Heavy Ball is *locally* accelerated (essentially because locally a strongly convex cost function looks like a quadratic): see for example ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu.  On the other hand, the provided numerical experiments seem to indicate that Lie Heavy Ball is not accelerated (but maybe a different choice of parameters would improve convergence?).

(5) For SO(n) or U(n), can the authors please explain why the log map and parallel transport are prohibitively costly (in comparison to the exponential)?

(6) Is it necessary to use the exponential map as the retraction?  From the reviewer's experience, for the manifold SO(n), using the matrix exponential is more expensive than using the QR-retraction.

(7) The experiments performed (the eigen decomposition problem) are limited.  The authors say the eigen decomposition problem ""is a hard non-convex problem on a manifold"".  The reviewer somewhat disagrees: in some sense, it is one of the easiest nonconvex optimization problems as all second order critical points (where gradient = 0, Hessian is PSD) are global minima.","Questions and comments (some of which were already asked in the ""weaknesses"" section):

* Explicitly, what do your algorithms look like when the Lie group is a torus (product of circles)?  Does it reduce to standard NAG?

* Can the authors provide examples of Lie groups used in practice which are not SO(n), U(n), or products of those?

* I am not 100% convinced that the Lie Heavy Ball does not have a locally accelerated rate.  My impression is that, with the right choice of parameters, Heavy Ball is *locally* accelerated (essentially because locally a strongly convex cost function looks like a quadratic): see for example ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu.  On the other hand, the provided numerical experiments seem to indicate that Lie Heavy Ball is not accelerated (but maybe a different choice of parameters would improve convergence?).

* For SO(n) or U(n), can the authors please explain why the log map and parallel transport are prohibitively costly (in comparison to the exponential)?

* Is it necessary to use the exponential map as the retraction?  From the reviewer's experience, for the manifold SO(n), using the matrix exponential is more expensive than using the QR-retraction.

* Line 277 typo: decreaing -> decreasing",No potential negative societal impacts.,['No ethics review needed.'],5,4,,Yes,2,2,3,1719000522621,,,NeurIPS.cc/2024/Conference,2hqHWD7wDb,"['NeurIPS.cc/2024/Conference/Submission16838/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879878317,[],1,,,['everyone'],2hqHWD7wDb,['NeurIPS.cc/2024/Conference/Submission16838/Reviewer_zKf2'],1719000522621,1730879878317,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16838/Reviewer_zKf2']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Accelerated gradient methods for geodesically convex optimization: Tractable algorithms and convergence analysis"" by Jungbin Kim and Insoon Yang (2022)
2. The updated version of ""Global Riemannian Acceleration in Hyperbolic and Spherical Spaces"" by Martinez-Rubio
3. ""No-go Theorem for Acceleration in the Hyperbolic Plane"" by Hamilton and Moitra
4. ""Negative curvature obstructs acceleration for strongly geodesically convex optimization, even with exact first-order oracles"" by Criscitiello and Boumal
5. ""Curvature and complexity: Better lower bounds for geodesically convex optimization"" by Criscitiello and Boumal
6. ""An accelerated first-order method for non-convex optimization on manifolds"" by Criscitiello and Boumal
7. ""Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out"" by Wang, Lin, Wibisono, Hu

These citations are suggested to address the weaknesses of the paper, particularly the lack of citation of important prior works in the field of optimization on Riemannian manifolds.",1,2022,Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out
XlQGkuTyio,"The authors present a generation paradigm called “OneActor” to generate consistent subject in text-to-image generating tasks. The core of this algorithm is called as “cluster-guided score function”, which is based on the concept of score function and created to maintain the consistency of generated images. Additionally, the superiorities of this method for consistency performance and faster tuning are shown quantitatively and qualitatively through various experiments.","1.	The authors creatively present an insight that samples of different subjects form different clusters, and analyze it in detail, which is the inspiration of their method.

2.	The derivation of formulas is in complete detail without errors and codes are committed.

3.	The experiments are sufficient and solidly conducted, including both qualitative and quantitative comparisons. The ablation studies are sensible and include user studies as well.","The overall quality of the paper is quite good, but some problems still exist:

1. The core of this method seems to split the scores of CFG into a target and an auxiliary part for customized generation and maintain consistent subject, which is also derived in detail in Appendix F. The novelty is straightforward, and it would be better to compare the results with the research of multi-concept text-to-image tasks, for example:

Kumari, Nupur, et al. ""Multi-concept customization of text-to-image diffusion."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.

2. There are some typos. For instance, as shown in line 119, the conditional and unconditional scores have the same notation ϵ_θ (x_t,t,c_∅ ).
	
3. Some experimental results are not good enough. For example, the beard of an old man shown in Figure.4 is not consistent. Additionally, a hobbit generated by DB look better than the “OneActor”.","1. The authors present a framework to maintain consistency property. How to connect the insights shown in this paper with score-sde? In other words, can we use score-matching to understand clusters?  

2. As shown in Eq.(5), since it is an expectation why is the expression not as follows?
p(x)∙p(S^tar |x)/(∏_(i=1)^(N-1) p(S_i^aux |x)+p(S^tar |x) )

3. Since the average condition indicates the center of all the auxiliary sub-clusters, is there a strategy to make sure a conception like “radius” for the clusters?

4. What are the advantages over methods based on the attention layer of neural networks?","1.	As shown in weakness, the method cannot capture all the details of a given target image.

2.	The subject-centric shown in this paper can be described by a word so that it would be meaningful to further explore more complex and diverse cases.",['No ethics review needed.'],6,5,,Yes,3,3,3,1719192654950,,,NeurIPS.cc/2024/Conference,2gtNa14V45,"['NeurIPS.cc/2024/Conference/Submission5313/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878992104,[],1,,,['everyone'],2gtNa14V45,['NeurIPS.cc/2024/Conference/Submission5313/Reviewer_BPQh'],1719192654950,1730878992104,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5313/Reviewer_BPQh']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature, namely:

Kumari, Nupur, et al. ""Multi-concept customization of text-to-image diffusion."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.

The reviewer mentions that it would be better to compare the results with this research on multi-concept text-to-image tasks.",1,2023,Multi-concept customization of text-to-image diffusion
lWeev3WTkM,"Authors propose ProjDiff which reframes noisy inverse problems with diffusion models as a two-variable constrained optimization by introducing an auxiliary optimization variable. Authors derive a two-variable ELBO as a proxy for the log-prior and solve the optimization problem via projection gradient descent. Authors conduct comprehensive experiments on several image restoration tasks (super-resolution, inpainting and deblurring), source separation, and partial generations tasks.","* Overall, paper is easy to follow and structured nicely.
* I appreciate extensive numerical results that are presented in the paper.
* Numbers for source separation look significantly better than the baselines (I have to note that I'm not an expert in that area)","* Prior work section is not comprehensive.
* The gains in performance compared to baseline methods (especially for noisy restoration tasks) is not convincing. Moreover, hyperparameter search for baseline models were not conducted and wrong baseline method was used (DDNM for measurements with noise).
* See the questions below.","* I have several questions regarding DDNM numbers. First of all, DDNM [1] is designed for noise-free image reconstruction problems. I believe that is the reason why DDNM on Gaussian deblurring performs bad (as in Table 1: 7db PSNR, 0.03 SSIM, etc.). I would suggest the authors to switch to the DDNM+ variant as described in [1] for noisy inverse problems. If authors are already using DDNM+, could you clarify why the performance is bad on Gaussian deblurring?
* line 37-39: ""However, it’s worth noting that, since diffusion models are inherently effective at denoising, considering the observation noise in the likelihood term fails to fully leverage diffusion models’ denoising capability."" Could the authors clarify what it means to not fully leverage diffusion models here?
* I would recommend the authors to include $\Pi$GDM [2] in their comparisons especially since it performs much better than DDRM.
* Some other missing citations on solving inverse problems with diffusion models: CCDF [3], latent diffusion models: PSLD [4]
* line 663-665: ""Since [23] did not conduct experiments on CelebA, we use the parameters on FFHQ for the CelebA dataset as both FFHQ and CelebA are datasets of faces."". I don't think this is a good practice. In my experience, even though both CelebA and FFHQ are face datasets, DPS is not robust to the choice of step size. I believe some hyper-parameter search on a small set of images is necessary for fair comparison.
* Do you think ProjDiff can be extended for using latent diffusion models as a prior?
---
References:

[1] Wang, Yinhuai, Jiwen Yu, and Jian Zhang. ""Zero-shot image restoration using denoising diffusion null-space model."" arXiv preprint arXiv:2212.00490 (2022).

[2] Song, Jiaming et al. “Pseudoinverse-Guided Diffusion Models for Inverse Problems.” International Conference on Learning Representations (2023).

[3] Chung, Hyungjin, Byeongsu Sim, and Jong Chul Ye. ""Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.

[4] Rout, Litu, et al. ""Solving linear inverse problems provably via posterior sampling with latent diffusion models."" Advances in Neural Information Processing Systems 36 (2024).",Limitations are adequately addressed by the authors.,['No ethics review needed.'],6,4,,Yes,3,2,3,1720765257607,,,NeurIPS.cc/2024/Conference,2fiYzs3YkH,"['NeurIPS.cc/2024/Conference/Submission8702/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879260953,[],1,,,['everyone'],2fiYzs3YkH,['NeurIPS.cc/2024/Conference/Submission8702/Reviewer_krnF'],1720765257607,1730879260953,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8702/Reviewer_krnF']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] Wang, Yinhuai, Jiwen Yu, and Jian Zhang. ""Zero-shot image restoration using denoising diffusion null-space model."" (for the DDNM+ variant)
2. [2] Song, Jiaming et al. “Pseudoinverse-Guided Diffusion Models for Inverse Problems.” (for comparison with $\Pi$GDM)
3. [3] Chung, Hyungjin, Byeongsu Sim, and Jong Chul Ye. ""Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction."" (for solving inverse problems with diffusion models)
4. [4] Rout, Litu, et al. ""Solving linear inverse problems provably via posterior sampling with latent diffusion models."" (for latent diffusion models)

These citations are suggested to improve the paper's prior work section, which the reviewer found to be not comprehensive.",1,,Zero-shot image restoration using denoising diffusion null-space model
lWeev3WTkM,"Authors propose ProjDiff which reframes noisy inverse problems with diffusion models as a two-variable constrained optimization by introducing an auxiliary optimization variable. Authors derive a two-variable ELBO as a proxy for the log-prior and solve the optimization problem via projection gradient descent. Authors conduct comprehensive experiments on several image restoration tasks (super-resolution, inpainting and deblurring), source separation, and partial generations tasks.","* Overall, paper is easy to follow and structured nicely.
* I appreciate extensive numerical results that are presented in the paper.
* Numbers for source separation look significantly better than the baselines (I have to note that I'm not an expert in that area)","* Prior work section is not comprehensive.
* The gains in performance compared to baseline methods (especially for noisy restoration tasks) is not convincing. Moreover, hyperparameter search for baseline models were not conducted and wrong baseline method was used (DDNM for measurements with noise).
* See the questions below.","* I have several questions regarding DDNM numbers. First of all, DDNM [1] is designed for noise-free image reconstruction problems. I believe that is the reason why DDNM on Gaussian deblurring performs bad (as in Table 1: 7db PSNR, 0.03 SSIM, etc.). I would suggest the authors to switch to the DDNM+ variant as described in [1] for noisy inverse problems. If authors are already using DDNM+, could you clarify why the performance is bad on Gaussian deblurring?
* line 37-39: ""However, it’s worth noting that, since diffusion models are inherently effective at denoising, considering the observation noise in the likelihood term fails to fully leverage diffusion models’ denoising capability."" Could the authors clarify what it means to not fully leverage diffusion models here?
* I would recommend the authors to include $\Pi$GDM [2] in their comparisons especially since it performs much better than DDRM.
* Some other missing citations on solving inverse problems with diffusion models: CCDF [3], latent diffusion models: PSLD [4]
* line 663-665: ""Since [23] did not conduct experiments on CelebA, we use the parameters on FFHQ for the CelebA dataset as both FFHQ and CelebA are datasets of faces."". I don't think this is a good practice. In my experience, even though both CelebA and FFHQ are face datasets, DPS is not robust to the choice of step size. I believe some hyper-parameter search on a small set of images is necessary for fair comparison.
* Do you think ProjDiff can be extended for using latent diffusion models as a prior?
---
References:

[1] Wang, Yinhuai, Jiwen Yu, and Jian Zhang. ""Zero-shot image restoration using denoising diffusion null-space model."" arXiv preprint arXiv:2212.00490 (2022).

[2] Song, Jiaming et al. “Pseudoinverse-Guided Diffusion Models for Inverse Problems.” International Conference on Learning Representations (2023).

[3] Chung, Hyungjin, Byeongsu Sim, and Jong Chul Ye. ""Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.

[4] Rout, Litu, et al. ""Solving linear inverse problems provably via posterior sampling with latent diffusion models."" Advances in Neural Information Processing Systems 36 (2024).",Limitations are adequately addressed by the authors.,['No ethics review needed.'],6,4,,Yes,3,2,3,1720765257607,,,NeurIPS.cc/2024/Conference,2fiYzs3YkH,"['NeurIPS.cc/2024/Conference/Submission8702/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879260953,[],1,,,['everyone'],2fiYzs3YkH,['NeurIPS.cc/2024/Conference/Submission8702/Reviewer_krnF'],1720765257607,1730879260953,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8702/Reviewer_krnF']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] Wang, Yinhuai, Jiwen Yu, and Jian Zhang. ""Zero-shot image restoration using denoising diffusion null-space model."" (for the DDNM+ variant)
2. [2] Song, Jiaming et al. “Pseudoinverse-Guided Diffusion Models for Inverse Problems.” (for comparison with $\Pi$GDM)
3. [3] Chung, Hyungjin, Byeongsu Sim, and Jong Chul Ye. ""Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction."" (for solving inverse problems with diffusion models)
4. [4] Rout, Litu, et al. ""Solving linear inverse problems provably via posterior sampling with latent diffusion models."" (for latent diffusion models)

These citations are suggested to improve the paper's prior work section, which the reviewer found to be not comprehensive.",1,,Pseudoinverse-Guided Diffusion Models for Inverse Problems
lWeev3WTkM,"Authors propose ProjDiff which reframes noisy inverse problems with diffusion models as a two-variable constrained optimization by introducing an auxiliary optimization variable. Authors derive a two-variable ELBO as a proxy for the log-prior and solve the optimization problem via projection gradient descent. Authors conduct comprehensive experiments on several image restoration tasks (super-resolution, inpainting and deblurring), source separation, and partial generations tasks.","* Overall, paper is easy to follow and structured nicely.
* I appreciate extensive numerical results that are presented in the paper.
* Numbers for source separation look significantly better than the baselines (I have to note that I'm not an expert in that area)","* Prior work section is not comprehensive.
* The gains in performance compared to baseline methods (especially for noisy restoration tasks) is not convincing. Moreover, hyperparameter search for baseline models were not conducted and wrong baseline method was used (DDNM for measurements with noise).
* See the questions below.","* I have several questions regarding DDNM numbers. First of all, DDNM [1] is designed for noise-free image reconstruction problems. I believe that is the reason why DDNM on Gaussian deblurring performs bad (as in Table 1: 7db PSNR, 0.03 SSIM, etc.). I would suggest the authors to switch to the DDNM+ variant as described in [1] for noisy inverse problems. If authors are already using DDNM+, could you clarify why the performance is bad on Gaussian deblurring?
* line 37-39: ""However, it’s worth noting that, since diffusion models are inherently effective at denoising, considering the observation noise in the likelihood term fails to fully leverage diffusion models’ denoising capability."" Could the authors clarify what it means to not fully leverage diffusion models here?
* I would recommend the authors to include $\Pi$GDM [2] in their comparisons especially since it performs much better than DDRM.
* Some other missing citations on solving inverse problems with diffusion models: CCDF [3], latent diffusion models: PSLD [4]
* line 663-665: ""Since [23] did not conduct experiments on CelebA, we use the parameters on FFHQ for the CelebA dataset as both FFHQ and CelebA are datasets of faces."". I don't think this is a good practice. In my experience, even though both CelebA and FFHQ are face datasets, DPS is not robust to the choice of step size. I believe some hyper-parameter search on a small set of images is necessary for fair comparison.
* Do you think ProjDiff can be extended for using latent diffusion models as a prior?
---
References:

[1] Wang, Yinhuai, Jiwen Yu, and Jian Zhang. ""Zero-shot image restoration using denoising diffusion null-space model."" arXiv preprint arXiv:2212.00490 (2022).

[2] Song, Jiaming et al. “Pseudoinverse-Guided Diffusion Models for Inverse Problems.” International Conference on Learning Representations (2023).

[3] Chung, Hyungjin, Byeongsu Sim, and Jong Chul Ye. ""Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.

[4] Rout, Litu, et al. ""Solving linear inverse problems provably via posterior sampling with latent diffusion models."" Advances in Neural Information Processing Systems 36 (2024).",Limitations are adequately addressed by the authors.,['No ethics review needed.'],6,4,,Yes,3,2,3,1720765257607,,,NeurIPS.cc/2024/Conference,2fiYzs3YkH,"['NeurIPS.cc/2024/Conference/Submission8702/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879260953,[],1,,,['everyone'],2fiYzs3YkH,['NeurIPS.cc/2024/Conference/Submission8702/Reviewer_krnF'],1720765257607,1730879260953,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8702/Reviewer_krnF']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] Wang, Yinhuai, Jiwen Yu, and Jian Zhang. ""Zero-shot image restoration using denoising diffusion null-space model."" (for the DDNM+ variant)
2. [2] Song, Jiaming et al. “Pseudoinverse-Guided Diffusion Models for Inverse Problems.” (for comparison with $\Pi$GDM)
3. [3] Chung, Hyungjin, Byeongsu Sim, and Jong Chul Ye. ""Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction."" (for solving inverse problems with diffusion models)
4. [4] Rout, Litu, et al. ""Solving linear inverse problems provably via posterior sampling with latent diffusion models."" (for latent diffusion models)

These citations are suggested to improve the paper's prior work section, which the reviewer found to be not comprehensive.",1,,Come-closer-diffuse-faster Accelerating conditional diffusion models for inverse problems through stochastic contraction
lWeev3WTkM,"Authors propose ProjDiff which reframes noisy inverse problems with diffusion models as a two-variable constrained optimization by introducing an auxiliary optimization variable. Authors derive a two-variable ELBO as a proxy for the log-prior and solve the optimization problem via projection gradient descent. Authors conduct comprehensive experiments on several image restoration tasks (super-resolution, inpainting and deblurring), source separation, and partial generations tasks.","* Overall, paper is easy to follow and structured nicely.
* I appreciate extensive numerical results that are presented in the paper.
* Numbers for source separation look significantly better than the baselines (I have to note that I'm not an expert in that area)","* Prior work section is not comprehensive.
* The gains in performance compared to baseline methods (especially for noisy restoration tasks) is not convincing. Moreover, hyperparameter search for baseline models were not conducted and wrong baseline method was used (DDNM for measurements with noise).
* See the questions below.","* I have several questions regarding DDNM numbers. First of all, DDNM [1] is designed for noise-free image reconstruction problems. I believe that is the reason why DDNM on Gaussian deblurring performs bad (as in Table 1: 7db PSNR, 0.03 SSIM, etc.). I would suggest the authors to switch to the DDNM+ variant as described in [1] for noisy inverse problems. If authors are already using DDNM+, could you clarify why the performance is bad on Gaussian deblurring?
* line 37-39: ""However, it’s worth noting that, since diffusion models are inherently effective at denoising, considering the observation noise in the likelihood term fails to fully leverage diffusion models’ denoising capability."" Could the authors clarify what it means to not fully leverage diffusion models here?
* I would recommend the authors to include $\Pi$GDM [2] in their comparisons especially since it performs much better than DDRM.
* Some other missing citations on solving inverse problems with diffusion models: CCDF [3], latent diffusion models: PSLD [4]
* line 663-665: ""Since [23] did not conduct experiments on CelebA, we use the parameters on FFHQ for the CelebA dataset as both FFHQ and CelebA are datasets of faces."". I don't think this is a good practice. In my experience, even though both CelebA and FFHQ are face datasets, DPS is not robust to the choice of step size. I believe some hyper-parameter search on a small set of images is necessary for fair comparison.
* Do you think ProjDiff can be extended for using latent diffusion models as a prior?
---
References:

[1] Wang, Yinhuai, Jiwen Yu, and Jian Zhang. ""Zero-shot image restoration using denoising diffusion null-space model."" arXiv preprint arXiv:2212.00490 (2022).

[2] Song, Jiaming et al. “Pseudoinverse-Guided Diffusion Models for Inverse Problems.” International Conference on Learning Representations (2023).

[3] Chung, Hyungjin, Byeongsu Sim, and Jong Chul Ye. ""Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.

[4] Rout, Litu, et al. ""Solving linear inverse problems provably via posterior sampling with latent diffusion models."" Advances in Neural Information Processing Systems 36 (2024).",Limitations are adequately addressed by the authors.,['No ethics review needed.'],6,4,,Yes,3,2,3,1720765257607,,,NeurIPS.cc/2024/Conference,2fiYzs3YkH,"['NeurIPS.cc/2024/Conference/Submission8702/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879260953,[],1,,,['everyone'],2fiYzs3YkH,['NeurIPS.cc/2024/Conference/Submission8702/Reviewer_krnF'],1720765257607,1730879260953,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8702/Reviewer_krnF']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] Wang, Yinhuai, Jiwen Yu, and Jian Zhang. ""Zero-shot image restoration using denoising diffusion null-space model."" (for the DDNM+ variant)
2. [2] Song, Jiaming et al. “Pseudoinverse-Guided Diffusion Models for Inverse Problems.” (for comparison with $\Pi$GDM)
3. [3] Chung, Hyungjin, Byeongsu Sim, and Jong Chul Ye. ""Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction."" (for solving inverse problems with diffusion models)
4. [4] Rout, Litu, et al. ""Solving linear inverse problems provably via posterior sampling with latent diffusion models."" (for latent diffusion models)

These citations are suggested to improve the paper's prior work section, which the reviewer found to be not comprehensive.",1,,Solving linear inverse problems provably via posterior sampling with latent diffusion models
sRd9xgmEsr,"This paper presents Chain-of-preference optimization (CPO) a self-supervised learning extension of Tree of Thought (ToT). Rather than use ToT during test time, which takes exponentially longer than end-to-end sampling, this paper proposes to use ToT at training time to annotate data for DPO fine-tuning and then use the DPO-tuned model end-to-end at test time. Notably, the DPO annotations are performed by the untuned model itself being prompted to label inferences as either useful or not. This differs from other approaches that are trained on only full successful reasoning paths.

For certain QA and reasoning tasks, the paper presents experimental evidence that CPO yields stronger models than either (1) fine-tuning the same LM on positive examples (TS-SFT) as done in previous papers or (2) running regular chain-of-thought prompting.","1. The approach is an intuitive and straightforward improvement to multi-hop reasoning that that is much faster than tree-based inference procedures.
2. The approach is appealing as it doesn't rely on correct labels nor external LLMs other than the LLM being fine-tuned on its own preference data.
3. The methodology is well explained and easily reproducible.","1. While the authors run evaluation over several datasets, they only consider 300 questions per dataset which is quite small. A stronger evaluation would use the whole test sets.
2. Details about the baseline implementation are unclear. The authors refer to both ""TS-SFT"" and ""TS-LLM"" (l.206) which in the original paper refer to different things-- SFT refers to the model fine-tuned on training examples with reasoning traces pulled from both a gold-annotated dataset and/or reasoning traces from the model that led to correct answers. However, TS-LLM in the original paper refers to the result of an iterative refinement process.
3. The choice of datasets is somewhat odd. E.g. HotpotQA is meant to be evaluated against support documents, which might explain the very low scores. They also compare against approaches (ToT, TS-SFT) that were not evaluated on any of the QA or Fact Verification tasks under consideration.  This paper did _not_ consider the Game of 24 or GSM datasets, which both ToT and TS-SFT did evaluate. 

Missing references:
1. Khalifa et al 2023: [GRACE: Discriminator-Guided Chain-of-Thought Reasoning](https://aclanthology.org/2023.findings-emnlp.1022.pdf)
2. Li et al 2023: [Learning Math Reasoning from Self-Sampled Correct and Partially-Correct Solutions](https://openreview.net/pdf?id=4D4TSJE6-K)","* What metrics did you use for the QA datasets? many of them use more than exact match, e.g. HotpotQA uses F1.
* The discussion around ablations in 5.3 is unclear. Are the trends consistent across different models and datasets? 
* It is odd to have only considered up to 200 instances for constructing preference pairs. Why is this experiment limited to such a small maximum? The difference between e.g. 160 and 200 seems much less important than the difference between 200 and 1000 or 1000 and 5000. 
* How many total preference pairs do you end up training on? It would be helpful to include this number in the main body of the paper.
* How stable is this approach to different prompts for state evaluation? Did you experiment with other prompts?",yes,['No ethics review needed.'],6,4,,Yes,3,4,3,1720910750823,,,NeurIPS.cc/2024/Conference,2cczgOfMP4,"['NeurIPS.cc/2024/Conference/Submission7273/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879147246,[],5,,,['everyone'],2cczgOfMP4,['NeurIPS.cc/2024/Conference/Submission7273/Reviewer_VaVd'],1720910750823,1730879147246,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7273/Reviewer_VaVd']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. Khalifa et al 2023: [GRACE: Discriminator-Guided Chain-of-Thought Reasoning](https://aclanthology.org/2023.findings-emnlp.1022.pdf)
2. Li et al 2023: [Learning Math Reasoning from Self-Sampled Correct and Partially-Correct Solutions](https://openreview.net/pdf?id=4D4TSJE6-K)

These references are mentioned under the section ""Missing references"" in the review.",1,"2023, 2023, 2023",GRACE Discriminator-Guided Chain-of-Thought Reasoning 
sRd9xgmEsr,"This paper presents Chain-of-preference optimization (CPO) a self-supervised learning extension of Tree of Thought (ToT). Rather than use ToT during test time, which takes exponentially longer than end-to-end sampling, this paper proposes to use ToT at training time to annotate data for DPO fine-tuning and then use the DPO-tuned model end-to-end at test time. Notably, the DPO annotations are performed by the untuned model itself being prompted to label inferences as either useful or not. This differs from other approaches that are trained on only full successful reasoning paths.

For certain QA and reasoning tasks, the paper presents experimental evidence that CPO yields stronger models than either (1) fine-tuning the same LM on positive examples (TS-SFT) as done in previous papers or (2) running regular chain-of-thought prompting.","1. The approach is an intuitive and straightforward improvement to multi-hop reasoning that that is much faster than tree-based inference procedures.
2. The approach is appealing as it doesn't rely on correct labels nor external LLMs other than the LLM being fine-tuned on its own preference data.
3. The methodology is well explained and easily reproducible.","1. While the authors run evaluation over several datasets, they only consider 300 questions per dataset which is quite small. A stronger evaluation would use the whole test sets.
2. Details about the baseline implementation are unclear. The authors refer to both ""TS-SFT"" and ""TS-LLM"" (l.206) which in the original paper refer to different things-- SFT refers to the model fine-tuned on training examples with reasoning traces pulled from both a gold-annotated dataset and/or reasoning traces from the model that led to correct answers. However, TS-LLM in the original paper refers to the result of an iterative refinement process.
3. The choice of datasets is somewhat odd. E.g. HotpotQA is meant to be evaluated against support documents, which might explain the very low scores. They also compare against approaches (ToT, TS-SFT) that were not evaluated on any of the QA or Fact Verification tasks under consideration.  This paper did _not_ consider the Game of 24 or GSM datasets, which both ToT and TS-SFT did evaluate. 

Missing references:
1. Khalifa et al 2023: [GRACE: Discriminator-Guided Chain-of-Thought Reasoning](https://aclanthology.org/2023.findings-emnlp.1022.pdf)
2. Li et al 2023: [Learning Math Reasoning from Self-Sampled Correct and Partially-Correct Solutions](https://openreview.net/pdf?id=4D4TSJE6-K)","* What metrics did you use for the QA datasets? many of them use more than exact match, e.g. HotpotQA uses F1.
* The discussion around ablations in 5.3 is unclear. Are the trends consistent across different models and datasets? 
* It is odd to have only considered up to 200 instances for constructing preference pairs. Why is this experiment limited to such a small maximum? The difference between e.g. 160 and 200 seems much less important than the difference between 200 and 1000 or 1000 and 5000. 
* How many total preference pairs do you end up training on? It would be helpful to include this number in the main body of the paper.
* How stable is this approach to different prompts for state evaluation? Did you experiment with other prompts?",yes,['No ethics review needed.'],6,4,,Yes,3,4,3,1720910750823,,,NeurIPS.cc/2024/Conference,2cczgOfMP4,"['NeurIPS.cc/2024/Conference/Submission7273/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879147246,[],5,,,['everyone'],2cczgOfMP4,['NeurIPS.cc/2024/Conference/Submission7273/Reviewer_VaVd'],1720910750823,1730879147246,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7273/Reviewer_VaVd']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. Khalifa et al 2023: [GRACE: Discriminator-Guided Chain-of-Thought Reasoning](https://aclanthology.org/2023.findings-emnlp.1022.pdf)
2. Li et al 2023: [Learning Math Reasoning from Self-Sampled Correct and Partially-Correct Solutions](https://openreview.net/pdf?id=4D4TSJE6-K)

These references are mentioned under the section ""Missing references"" in the review.",1,"2023, 2023, 2023",Learning Math Reasoning from Self-Sampled Correct and Partially-Correct Solutions
9MprPdUj7Y,"This manuscript aims to tackle the evolving domain generalization (EDG) issue, namely the domain gradually evolves in an underlying continuous structure. The paper introduces the idea of Weight Diffusion (W-Diff), a conditional diffusion model in the parameter space to learn the evolving pattern of classifiers. Combining such types of classifier with weight ensembling and a domain-shared feature space allows robust prediction. The effectiveness of the proposed method is examined on two text classification datasets, three image classification datasets, and two multi-variate classification datasets.","* The evolving domain generalization is interesting yet important to the research community.
* The manuscript is well-structured. It explains its methodology design clearly and intuitively.
* The manuscript introduces the idea of model weight generation through the diffusion model to the area of evolving domain generalization. The concept itself is interesting. However, the authors still need to discuss the related work carefully.
* The proposed method is examined on two text classification datasets, three image classification datasets, and two multi-variate classification datasets.","* Unclear novelty. The idea of using a diffusion model to generate model weights/heads appeared in [1, 2]. However, the manuscript did not cite and discuss these two papers (and maybe their follow-up works), making the exact contribution unclear. From the reviewer's perspective, idea 1 of using the conditional diffusion model to model parameter evolution patterns is interesting and intuitive; idea 2 of learning domain-shared feature encoder is standard. Combining idea 1 and idea 2 and applying it to the area of evolving domain generalization is ok, but still needs a careful discussion and ablation study.
* The performance gain over different datasets looks marginal.
* The manuscript needs more ablation studies. E.g., What if instead of generating the classifiers on the fly for the unseen domain, we just leverage the past classifiers for the ensemble prediction, or test-time adaptive classifier ensembling as in [3]?


### Reference
[1] Learning to Learn with Generative Models of Neural Network Checkpoints. https://arxiv.org/abs/2209.12892

[2] Diffusion-based Neural Network Weights Generation. https://arxiv.org/abs/2402.18153

[3] Adaptive Test-Time Personalization for Federated Learning. https://arxiv.org/abs/2310.18816",,,['No ethics review needed.'],5,4,,Yes,2,3,3,1720613547028,,,NeurIPS.cc/2024/Conference,2cFUYnNL1m,"['NeurIPS.cc/2024/Conference/Submission9196/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879295218,[],1,,,['everyone'],2cFUYnNL1m,['NeurIPS.cc/2024/Conference/Submission9196/Reviewer_BuMk'],1720613547028,1730879295218,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9196/Reviewer_BuMk']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. ""Learning to Learn with Generative Models of Neural Network Checkpoints"" (https://arxiv.org/abs/2209.12892)
2. ""Diffusion-based Neural Network Weights Generation"" (https://arxiv.org/abs/2402.18153)
3. ""Adaptive Test-Time Personalization for Federated Learning"" (https://arxiv.org/abs/2310.18816)

The reviewer mentions that the manuscript did not cite and discuss these papers, which makes the exact contribution unclear, and suggests that the authors should discuss these related works carefully.",1,"2022, 2024, 2023",Learning to Learn with Generative Models of Neural Network Checkpoints
9MprPdUj7Y,"This manuscript aims to tackle the evolving domain generalization (EDG) issue, namely the domain gradually evolves in an underlying continuous structure. The paper introduces the idea of Weight Diffusion (W-Diff), a conditional diffusion model in the parameter space to learn the evolving pattern of classifiers. Combining such types of classifier with weight ensembling and a domain-shared feature space allows robust prediction. The effectiveness of the proposed method is examined on two text classification datasets, three image classification datasets, and two multi-variate classification datasets.","* The evolving domain generalization is interesting yet important to the research community.
* The manuscript is well-structured. It explains its methodology design clearly and intuitively.
* The manuscript introduces the idea of model weight generation through the diffusion model to the area of evolving domain generalization. The concept itself is interesting. However, the authors still need to discuss the related work carefully.
* The proposed method is examined on two text classification datasets, three image classification datasets, and two multi-variate classification datasets.","* Unclear novelty. The idea of using a diffusion model to generate model weights/heads appeared in [1, 2]. However, the manuscript did not cite and discuss these two papers (and maybe their follow-up works), making the exact contribution unclear. From the reviewer's perspective, idea 1 of using the conditional diffusion model to model parameter evolution patterns is interesting and intuitive; idea 2 of learning domain-shared feature encoder is standard. Combining idea 1 and idea 2 and applying it to the area of evolving domain generalization is ok, but still needs a careful discussion and ablation study.
* The performance gain over different datasets looks marginal.
* The manuscript needs more ablation studies. E.g., What if instead of generating the classifiers on the fly for the unseen domain, we just leverage the past classifiers for the ensemble prediction, or test-time adaptive classifier ensembling as in [3]?


### Reference
[1] Learning to Learn with Generative Models of Neural Network Checkpoints. https://arxiv.org/abs/2209.12892

[2] Diffusion-based Neural Network Weights Generation. https://arxiv.org/abs/2402.18153

[3] Adaptive Test-Time Personalization for Federated Learning. https://arxiv.org/abs/2310.18816",,,['No ethics review needed.'],5,4,,Yes,2,3,3,1720613547028,,,NeurIPS.cc/2024/Conference,2cFUYnNL1m,"['NeurIPS.cc/2024/Conference/Submission9196/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879295218,[],1,,,['everyone'],2cFUYnNL1m,['NeurIPS.cc/2024/Conference/Submission9196/Reviewer_BuMk'],1720613547028,1730879295218,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9196/Reviewer_BuMk']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. ""Learning to Learn with Generative Models of Neural Network Checkpoints"" (https://arxiv.org/abs/2209.12892)
2. ""Diffusion-based Neural Network Weights Generation"" (https://arxiv.org/abs/2402.18153)
3. ""Adaptive Test-Time Personalization for Federated Learning"" (https://arxiv.org/abs/2310.18816)

The reviewer mentions that the manuscript did not cite and discuss these papers, which makes the exact contribution unclear, and suggests that the authors should discuss these related works carefully.",1,"2022, 2024, 2023",Diffusion-based Neural Network Weights Generation
9MprPdUj7Y,"This manuscript aims to tackle the evolving domain generalization (EDG) issue, namely the domain gradually evolves in an underlying continuous structure. The paper introduces the idea of Weight Diffusion (W-Diff), a conditional diffusion model in the parameter space to learn the evolving pattern of classifiers. Combining such types of classifier with weight ensembling and a domain-shared feature space allows robust prediction. The effectiveness of the proposed method is examined on two text classification datasets, three image classification datasets, and two multi-variate classification datasets.","* The evolving domain generalization is interesting yet important to the research community.
* The manuscript is well-structured. It explains its methodology design clearly and intuitively.
* The manuscript introduces the idea of model weight generation through the diffusion model to the area of evolving domain generalization. The concept itself is interesting. However, the authors still need to discuss the related work carefully.
* The proposed method is examined on two text classification datasets, three image classification datasets, and two multi-variate classification datasets.","* Unclear novelty. The idea of using a diffusion model to generate model weights/heads appeared in [1, 2]. However, the manuscript did not cite and discuss these two papers (and maybe their follow-up works), making the exact contribution unclear. From the reviewer's perspective, idea 1 of using the conditional diffusion model to model parameter evolution patterns is interesting and intuitive; idea 2 of learning domain-shared feature encoder is standard. Combining idea 1 and idea 2 and applying it to the area of evolving domain generalization is ok, but still needs a careful discussion and ablation study.
* The performance gain over different datasets looks marginal.
* The manuscript needs more ablation studies. E.g., What if instead of generating the classifiers on the fly for the unseen domain, we just leverage the past classifiers for the ensemble prediction, or test-time adaptive classifier ensembling as in [3]?


### Reference
[1] Learning to Learn with Generative Models of Neural Network Checkpoints. https://arxiv.org/abs/2209.12892

[2] Diffusion-based Neural Network Weights Generation. https://arxiv.org/abs/2402.18153

[3] Adaptive Test-Time Personalization for Federated Learning. https://arxiv.org/abs/2310.18816",,,['No ethics review needed.'],5,4,,Yes,2,3,3,1720613547028,,,NeurIPS.cc/2024/Conference,2cFUYnNL1m,"['NeurIPS.cc/2024/Conference/Submission9196/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879295218,[],1,,,['everyone'],2cFUYnNL1m,['NeurIPS.cc/2024/Conference/Submission9196/Reviewer_BuMk'],1720613547028,1730879295218,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9196/Reviewer_BuMk']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. ""Learning to Learn with Generative Models of Neural Network Checkpoints"" (https://arxiv.org/abs/2209.12892)
2. ""Diffusion-based Neural Network Weights Generation"" (https://arxiv.org/abs/2402.18153)
3. ""Adaptive Test-Time Personalization for Federated Learning"" (https://arxiv.org/abs/2310.18816)

The reviewer mentions that the manuscript did not cite and discuss these papers, which makes the exact contribution unclear, and suggests that the authors should discuss these related works carefully.",1,"2022, 2024, 2023",Adaptive Test-Time Personalization for Federated Learning
x48IMSe78H,"The paper propose compositional Incremental Learning to enable models to recognize state-object compositions incrementally. The paper provides two tailored datasets for composition-IL by modifying two existing datasets in the fashion domain. The paper propose a new prompt-based model comprising of multi-pool prompt learning, object-injected state prompting and generalized-mean prompt fusion. The method achieves competitive performance on the two proposed datasets.","1. The paper discusses a new direction which aims to exploit state primitives of objects for incremental classification. The authors propose a new incremental setting where objects or states can reappear in new classes in new tasks.
2. The paper provides two curated datasets in the fashion domain to study composition-IL.
3. The paper propose a new prompt-based model for composition-IL. It is nice to report HM accuracy for better evaluation.","I have major concerns with the experimental part of the paper.
1. Hyperparameters: It is very concerning that six hyperparameters are tuned on the testing set. The hyperparameter values even differ for different task splits on the same dataset. It is weird that the authors use 25 epochs for one dataset, while for the other dataset, 10 epochs for 5-task setting while 3 epochs for the 10 task setting. Even different learning rates are used for different settings on same datasets. How are these decided? It looks like everything is optimized for the test sets in all settings. This is not a fair way of doing experiments. It is acceptable if the authors fine-tune the model for one dataset and use the same parameters for all settings across different datasets (I think this is commonly done in continual learning domain). How can the proposed method be useful/practical if it needs to fine-tune so many hyper parameters on every setting using the test set to get good results?
2. Lack of experiments with random seeds: The experiments are conducted using a single random seed. The proposed method has improvements of 1% or even less in some settings. It is standard practice in CL to report results with multiple random seeds for fair evaluation and to establish the robustness of the model.
3. Competitive recent baselines like HiDe-prompt [1] are not included in the comparison.
4. Simple methods like NCM classifier [2] and Mahalanobis-distance based classifier [3] outperforms prompt methods like L2P on several datasets with first-task adaptation and no training in new tasks (using frozen model after the first task and doing continual evaluation). It would be interesting to see how these strong baseline methods work in the proposed settings.

[1] Wang, Liyuan, et al. ""Hierarchical decomposition of prompt-based continual learning: Rethinking obscured sub-optimality."" Advances in Neural Information Processing Systems 36 (2023).

[2] Paul Janson,  et al, A simple baseline that questions the use of pretrained models in continual learning. arXiv preprint arXiv:2210.04428, 2022. 

[3] Dipam Goswami, et al, Fecam: Exploiting the heterogeneity of class distributions in exemplar-free continual learning. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.","1. I am curious what is the difference between object-state pairs and a group of concepts describing a class? Like why limit the concepts to just object and state, there can be more concepts attached to a class. So, a class can also be described as a group of concepts and classes can then be learned incrementally with overlapping concepts from old classes.",Limitations of this work is not explicitly addressed in paper.,['No ethics review needed.'],6,4,,Yes,3,3,3,1720707016894,,,NeurIPS.cc/2024/Conference,2LRZhbTDtA,"['NeurIPS.cc/2024/Conference/Submission8122/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879219059,[],4,,,['everyone'],2LRZhbTDtA,['NeurIPS.cc/2024/Conference/Submission8122/Reviewer_x9g2'],1720707016894,1730879219059,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8122/Reviewer_x9g2']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Wang, Liyuan, et al. ""Hierarchical decomposition of prompt-based continual learning: Rethinking obscured sub-optimality."" Advances in Neural Information Processing Systems 36 (2023), referred to as [1].
2. Paul Janson, et al, ""A simple baseline that questions the use of pretrained models in continual learning."" arXiv preprint arXiv:2210.04428, 2022, referred to as [2].
3. Dipam Goswami, et al, ""Fecam: Exploiting the heterogeneity of class distributions in exemplar-free continual learning."" In Thirty-seventh Conference on Neural Information Processing Systems, 2023, referred to as [3].

These citations are suggested as relevant recent baselines or methods that the authors should consider including in their comparison or discussion.",1,"2023, 2022, 2022, 2023",Hierarchical decomposition of prompt-based continual learning Rethinking obscured sub-optimality
x48IMSe78H,"The paper propose compositional Incremental Learning to enable models to recognize state-object compositions incrementally. The paper provides two tailored datasets for composition-IL by modifying two existing datasets in the fashion domain. The paper propose a new prompt-based model comprising of multi-pool prompt learning, object-injected state prompting and generalized-mean prompt fusion. The method achieves competitive performance on the two proposed datasets.","1. The paper discusses a new direction which aims to exploit state primitives of objects for incremental classification. The authors propose a new incremental setting where objects or states can reappear in new classes in new tasks.
2. The paper provides two curated datasets in the fashion domain to study composition-IL.
3. The paper propose a new prompt-based model for composition-IL. It is nice to report HM accuracy for better evaluation.","I have major concerns with the experimental part of the paper.
1. Hyperparameters: It is very concerning that six hyperparameters are tuned on the testing set. The hyperparameter values even differ for different task splits on the same dataset. It is weird that the authors use 25 epochs for one dataset, while for the other dataset, 10 epochs for 5-task setting while 3 epochs for the 10 task setting. Even different learning rates are used for different settings on same datasets. How are these decided? It looks like everything is optimized for the test sets in all settings. This is not a fair way of doing experiments. It is acceptable if the authors fine-tune the model for one dataset and use the same parameters for all settings across different datasets (I think this is commonly done in continual learning domain). How can the proposed method be useful/practical if it needs to fine-tune so many hyper parameters on every setting using the test set to get good results?
2. Lack of experiments with random seeds: The experiments are conducted using a single random seed. The proposed method has improvements of 1% or even less in some settings. It is standard practice in CL to report results with multiple random seeds for fair evaluation and to establish the robustness of the model.
3. Competitive recent baselines like HiDe-prompt [1] are not included in the comparison.
4. Simple methods like NCM classifier [2] and Mahalanobis-distance based classifier [3] outperforms prompt methods like L2P on several datasets with first-task adaptation and no training in new tasks (using frozen model after the first task and doing continual evaluation). It would be interesting to see how these strong baseline methods work in the proposed settings.

[1] Wang, Liyuan, et al. ""Hierarchical decomposition of prompt-based continual learning: Rethinking obscured sub-optimality."" Advances in Neural Information Processing Systems 36 (2023).

[2] Paul Janson,  et al, A simple baseline that questions the use of pretrained models in continual learning. arXiv preprint arXiv:2210.04428, 2022. 

[3] Dipam Goswami, et al, Fecam: Exploiting the heterogeneity of class distributions in exemplar-free continual learning. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.","1. I am curious what is the difference between object-state pairs and a group of concepts describing a class? Like why limit the concepts to just object and state, there can be more concepts attached to a class. So, a class can also be described as a group of concepts and classes can then be learned incrementally with overlapping concepts from old classes.",Limitations of this work is not explicitly addressed in paper.,['No ethics review needed.'],6,4,,Yes,3,3,3,1720707016894,,,NeurIPS.cc/2024/Conference,2LRZhbTDtA,"['NeurIPS.cc/2024/Conference/Submission8122/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879219059,[],4,,,['everyone'],2LRZhbTDtA,['NeurIPS.cc/2024/Conference/Submission8122/Reviewer_x9g2'],1720707016894,1730879219059,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8122/Reviewer_x9g2']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Wang, Liyuan, et al. ""Hierarchical decomposition of prompt-based continual learning: Rethinking obscured sub-optimality."" Advances in Neural Information Processing Systems 36 (2023), referred to as [1].
2. Paul Janson, et al, ""A simple baseline that questions the use of pretrained models in continual learning."" arXiv preprint arXiv:2210.04428, 2022, referred to as [2].
3. Dipam Goswami, et al, ""Fecam: Exploiting the heterogeneity of class distributions in exemplar-free continual learning."" In Thirty-seventh Conference on Neural Information Processing Systems, 2023, referred to as [3].

These citations are suggested as relevant recent baselines or methods that the authors should consider including in their comparison or discussion.",1,"2023, 2022, 2022, 2023",A simple baseline that questions the use of pretrained models in continual learning
x48IMSe78H,"The paper propose compositional Incremental Learning to enable models to recognize state-object compositions incrementally. The paper provides two tailored datasets for composition-IL by modifying two existing datasets in the fashion domain. The paper propose a new prompt-based model comprising of multi-pool prompt learning, object-injected state prompting and generalized-mean prompt fusion. The method achieves competitive performance on the two proposed datasets.","1. The paper discusses a new direction which aims to exploit state primitives of objects for incremental classification. The authors propose a new incremental setting where objects or states can reappear in new classes in new tasks.
2. The paper provides two curated datasets in the fashion domain to study composition-IL.
3. The paper propose a new prompt-based model for composition-IL. It is nice to report HM accuracy for better evaluation.","I have major concerns with the experimental part of the paper.
1. Hyperparameters: It is very concerning that six hyperparameters are tuned on the testing set. The hyperparameter values even differ for different task splits on the same dataset. It is weird that the authors use 25 epochs for one dataset, while for the other dataset, 10 epochs for 5-task setting while 3 epochs for the 10 task setting. Even different learning rates are used for different settings on same datasets. How are these decided? It looks like everything is optimized for the test sets in all settings. This is not a fair way of doing experiments. It is acceptable if the authors fine-tune the model for one dataset and use the same parameters for all settings across different datasets (I think this is commonly done in continual learning domain). How can the proposed method be useful/practical if it needs to fine-tune so many hyper parameters on every setting using the test set to get good results?
2. Lack of experiments with random seeds: The experiments are conducted using a single random seed. The proposed method has improvements of 1% or even less in some settings. It is standard practice in CL to report results with multiple random seeds for fair evaluation and to establish the robustness of the model.
3. Competitive recent baselines like HiDe-prompt [1] are not included in the comparison.
4. Simple methods like NCM classifier [2] and Mahalanobis-distance based classifier [3] outperforms prompt methods like L2P on several datasets with first-task adaptation and no training in new tasks (using frozen model after the first task and doing continual evaluation). It would be interesting to see how these strong baseline methods work in the proposed settings.

[1] Wang, Liyuan, et al. ""Hierarchical decomposition of prompt-based continual learning: Rethinking obscured sub-optimality."" Advances in Neural Information Processing Systems 36 (2023).

[2] Paul Janson,  et al, A simple baseline that questions the use of pretrained models in continual learning. arXiv preprint arXiv:2210.04428, 2022. 

[3] Dipam Goswami, et al, Fecam: Exploiting the heterogeneity of class distributions in exemplar-free continual learning. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.","1. I am curious what is the difference between object-state pairs and a group of concepts describing a class? Like why limit the concepts to just object and state, there can be more concepts attached to a class. So, a class can also be described as a group of concepts and classes can then be learned incrementally with overlapping concepts from old classes.",Limitations of this work is not explicitly addressed in paper.,['No ethics review needed.'],6,4,,Yes,3,3,3,1720707016894,,,NeurIPS.cc/2024/Conference,2LRZhbTDtA,"['NeurIPS.cc/2024/Conference/Submission8122/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879219059,[],4,,,['everyone'],2LRZhbTDtA,['NeurIPS.cc/2024/Conference/Submission8122/Reviewer_x9g2'],1720707016894,1730879219059,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8122/Reviewer_x9g2']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Wang, Liyuan, et al. ""Hierarchical decomposition of prompt-based continual learning: Rethinking obscured sub-optimality."" Advances in Neural Information Processing Systems 36 (2023), referred to as [1].
2. Paul Janson, et al, ""A simple baseline that questions the use of pretrained models in continual learning."" arXiv preprint arXiv:2210.04428, 2022, referred to as [2].
3. Dipam Goswami, et al, ""Fecam: Exploiting the heterogeneity of class distributions in exemplar-free continual learning."" In Thirty-seventh Conference on Neural Information Processing Systems, 2023, referred to as [3].

These citations are suggested as relevant recent baselines or methods that the authors should consider including in their comparison or discussion.",1,"2023, 2022, 2022, 2023",Fecam Exploiting the heterogeneity of class distributions in exemplar-free continual learning
CH002NCzjS,"The paper presents a theoretical analysis of learning regularizers for inverse problems using a critic-based loss. By focusing on a specific family of regularizers (gauges of star-shaped bodies), amenable to theoretical analysis, the authors provide a number of theoretical insights towards existence, uniqueness within existing frameworks (based on wasserstein distance) and further extensions to f-divergences. This is further connected to the existing literature on learned regularization by considering star bodies corresponding to weakly convex regularisers.","The paper presents a very novel idea of utilising the theoretical framework of star-bodies in order to provide theoretical interpretability of critic based regularization. Given the recent interest in learned regularization, this paper opens up a number of new research directions both theoretically and numerically.","There are a few weaknesses, which in my opinion are not limiting. To be precise, the paper focuses on a specific class of regularizers (gauges of star-shaped bodies) and a specific type of critic-based loss functions (derived from variational representations of statistical distances). It would be interesting to see if the results can be extended to other classes of regularizers and loss functions.

The paper primarily investigates this class of regularizers theoretically and with very few experiments. The paper does not include any experiments to demonstrate the practical performance of the learned regularizers, and while the theoretical results are valuable, it would be helpful to see how they translate into practice. This could be of interest as future work for practitioners working on inverse problems.","The paper is very well-writen, and as such there are very few questions that I have: 

* One of the motivations, also discussed in 1.2 (and line 57), is that uniqueness of the transport potential does not hold when considering the wasserstein 1 based loss. I would like to refer the authors to arxiv.org/abs/2211.00820, as in fact (under some assumptions), this uniqueness can be shown to be unique $D_n$ almost everywhere. With this result in mind, could you explain intuitively why in Theorem 2.4, it is possible to prove uniqueness without a.e.? 

* Line 130 ""this map"" - which map is this referring to?

* I am not entirely sure what the relevance of Remark 2.8 is. In practice, rescaling the distribution destroys information from the true distribution - the critic that is desired is the one that would be operating on $D_r$ and $D_n$, and not $D_r$ and $\lambda D_n$. 

* It would be very intersting to see whether the optimal regularisers derived as minimisers of the variational objective are also optimal regulariser in the sense of Leong et al. 

*Line 50 ""about the measurements"". Clasically the measurements themselves live in a different space from the original data. For this reason Lunz et al. utilises backprojection to first map it to the same space.

* Line 29 ""ill-posed meaning that there are an infinite number ..."" - In the inverse problem literature, ill-posedness does not correspond to non-uniqueness only. I suggest referring to Hadamards definition of well-posedness. E.g. see Shumaylov et al. or Arridge, Simon, et al. ""Solving inverse problems using data-driven models."" Acta Numerica 28 (2019): 1-174.",* See weaknesses.,['No ethics review needed.'],8,3,,Yes,4,4,3,1720707567562,,,NeurIPS.cc/2024/Conference,2GQeCbhxVy,"['NeurIPS.cc/2024/Conference/Submission12741/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879576033,[],1,,,['everyone'],2GQeCbhxVy,['NeurIPS.cc/2024/Conference/Submission12741/Reviewer_kSE2'],1720707567562,1730879576033,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission12741/Reviewer_kSE2']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. arxiv.org/abs/2211.00820, which discusses the uniqueness of the transport potential under certain assumptions.
2. Hadamard's definition of well-posedness, as well as references to:
   - Shumaylov et al.
   - Arridge, Simon, et al. ""Solving inverse problems using data-driven models."" Acta Numerica 28 (2019): 1-174.
3. Leong et al., in the context of optimal regularizers.
4. Lunz et al., regarding the use of backprojection to map measurements to the same space as the original data.",1,"2022, 2019",Solving inverse problems using data-driven models
BWPeFwqtBr,"The paper proposes AlphaRec, a novel method to incorporate both knowledge from pre-trained language models and collaborative signals. Authors firstly reveal the advantages brought from pre-trained embedding model, and then propose three modules within AlphaRec. An MLP layer to transform pre-trained embedding to item-representation. A graph convolution to aggregate neighbor’s information, and the InfoNCE loss to train introduced parameters within the MLP for each dataset. Overall, the novelty of this paper lies within exploration of NLP encoded embedding on RecSys. The graph convolution and InfoNCE loss are already widely used techniques.","1. A good exploration on new direction (language-representation-based) RecSys
2. Experiments are conducted from different angles for analyzing their model.","1. Insufficient baselines.
2. Uncleared model name definition.","1. Why do authors only encode titles? There is more information within your used Amazon dataset including item descriptions.

2. I personally do not prefer un-informative model names such as the AlphaRec in this paper. Authors mentioned “This model is named AlphaRec for its originality and a series of good properties”. The reason seems so strange to me.

3. More advanced baselines are needed to compare such as the DirectAU [1]  and GraphAU [2] 

[1] Wang, C., Yu, Y., Ma, W., Zhang, M., Chen, C., Liu, Y., & Ma, S. (2022, August). Towards representation alignment and uniformity in collaborative filtering. In Proceedings of the 28th ACM SIGKDD conference on knowledge discovery and data mining (pp. 1816-1825).
[2] Yang, L., Liu, Z., Wang, C., Yang, M., Liu, X., Ma, J., & Yu, P. S. (2023, October). Graph-based alignment and uniformity for recommendation. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (pp. 4395-4399).",See Weakness.,['No ethics review needed.'],7,5,,Yes,3,3,3,1721097770741,,,NeurIPS.cc/2024/Conference,2Bef9YxSJc,"['NeurIPS.cc/2024/Conference/Submission16120/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879823853,[],3,,,['everyone'],2Bef9YxSJc,['NeurIPS.cc/2024/Conference/Submission16120/Reviewer_tJs7'],1721097770741,1730879823853,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16120/Reviewer_tJs7']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. Wang, C., Yu, Y., Ma, W., Zhang, M., Chen, C., Liu, Y., & Ma, S. (2022) - ""Towards representation alignment and uniformity in collaborative filtering"" (referred to as [1] in the review)
2. Yang, L., Liu, Z., Wang, C., Yang, M., Liu, X., Ma, J., & Yu, P. S. (2023) - ""Graph-based alignment and uniformity for recommendation"" (referred to as [2] in the review)

The reviewer recommends including these papers as baselines for comparison, implying that the authors should consider citing them in their paper.",1,"2022, 2023",Towards representation alignment and uniformity in collaborative filtering 
BWPeFwqtBr,"The paper proposes AlphaRec, a novel method to incorporate both knowledge from pre-trained language models and collaborative signals. Authors firstly reveal the advantages brought from pre-trained embedding model, and then propose three modules within AlphaRec. An MLP layer to transform pre-trained embedding to item-representation. A graph convolution to aggregate neighbor’s information, and the InfoNCE loss to train introduced parameters within the MLP for each dataset. Overall, the novelty of this paper lies within exploration of NLP encoded embedding on RecSys. The graph convolution and InfoNCE loss are already widely used techniques.","1. A good exploration on new direction (language-representation-based) RecSys
2. Experiments are conducted from different angles for analyzing their model.","1. Insufficient baselines.
2. Uncleared model name definition.","1. Why do authors only encode titles? There is more information within your used Amazon dataset including item descriptions.

2. I personally do not prefer un-informative model names such as the AlphaRec in this paper. Authors mentioned “This model is named AlphaRec for its originality and a series of good properties”. The reason seems so strange to me.

3. More advanced baselines are needed to compare such as the DirectAU [1]  and GraphAU [2] 

[1] Wang, C., Yu, Y., Ma, W., Zhang, M., Chen, C., Liu, Y., & Ma, S. (2022, August). Towards representation alignment and uniformity in collaborative filtering. In Proceedings of the 28th ACM SIGKDD conference on knowledge discovery and data mining (pp. 1816-1825).
[2] Yang, L., Liu, Z., Wang, C., Yang, M., Liu, X., Ma, J., & Yu, P. S. (2023, October). Graph-based alignment and uniformity for recommendation. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (pp. 4395-4399).",See Weakness.,['No ethics review needed.'],7,5,,Yes,3,3,3,1721097770741,,,NeurIPS.cc/2024/Conference,2Bef9YxSJc,"['NeurIPS.cc/2024/Conference/Submission16120/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879823853,[],3,,,['everyone'],2Bef9YxSJc,['NeurIPS.cc/2024/Conference/Submission16120/Reviewer_tJs7'],1721097770741,1730879823853,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16120/Reviewer_tJs7']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. Wang, C., Yu, Y., Ma, W., Zhang, M., Chen, C., Liu, Y., & Ma, S. (2022) - ""Towards representation alignment and uniformity in collaborative filtering"" (referred to as [1] in the review)
2. Yang, L., Liu, Z., Wang, C., Yang, M., Liu, X., Ma, J., & Yu, P. S. (2023) - ""Graph-based alignment and uniformity for recommendation"" (referred to as [2] in the review)

The reviewer recommends including these papers as baselines for comparison, implying that the authors should consider citing them in their paper.",1,"2022, 2023",Graph-based alignment and uniformity for recommendation
BAYkVuLtaW,"The paper shows that in-domain accuracy and Training-free NAS accuracy predictions correlate poorly with out-of-domain accuracy, while characteristics of the model such as Flops, Params and Embed-Dim (number of channels) correlate much better with out-of-domain accuracy. To do this, they train a supernet that contains all possible architectures (subnets), then they validate these subnets on 9 datasets ImageNet/C/D/P/O/A/R/Sketch/Stylaized.","They explore various ways for increasing OOD accuracy, which is most important for real-world problems. They show that conventional approaches, such as Training-free NAS or relying on in-domain accuracy, do not work. While they found that Flops, Param and Embed-dim correlated well with OOD accuracy. To do this, they introduce OoD-ViT-NAS benchmark for NAS research on ViT’s OOD generalization, that includes 3000 diverse ViT architectures which are evaluated on 9 datasets. This allows us to look for new and better approaches for finding new models structures to improve OOD accuracy.","You show that the embedding dimension has the highest impact among ViT architectural attributes, while network depth has a slight impact on OoD generalization. But the paper lacks an explanation that although embed-dim (number of channels) correlates with OOD accuracy better than depth, this does not necessarily mean that to increase OOD accuracy only embed-dim should be increased, since the computational cost and memory costs may be different for embed-dim and depth. Therefore, to create either the largest and most accurate model that fits in memory, or the most optimal model in terms of speed and accuracy, it may be optimal to increase the depth rather than embed-dim. There are also papers [1,2,3] that show that it is necessary to simultaneously increase several model parameters (depth, number of channels, resolution) in optimal proportions.

You present charts of OOD accuracy and number of parameters (Fig. 4, K19 - K24), but it would also be great to present charts of OOD-accuracy and latency, and OOD-accuracy and GPU memory consumption. Because these 3 model characteristics (OOD-accuracy, Latency, Memory consumption) are the most important for real-world problems.


1. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, Mingxing Tan, Quoc V. Le, 2019
2. EfficientNetV2: Smaller Models and Faster Training, Mingxing Tan, Quoc V. Le, 2021 
3. EfficientDet: Scalable and Efficient Object Detection, Mingxing Tan, Ruoming Pang, Quoc V. Le, 2019","- Have you tried plotting OOD-accuracy versus Latency or GPU memory consumption while increasing various model parameters such as: embed_dim, depth, MLP-ratio, num of heads, etc.? Or find correlations between ODE accuracy and these parameters, taking into account their impact on latency and memory consumption.

- Have you tried to find optimal model scaling factors (similar to works [1, 2, 3]) to increase OOD-accuracy in optimal way with respect to latency or memory consumption?


1. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, Mingxing Tan, Quoc V. Le, 2019
2. EfficientNetV2: Smaller Models and Faster Training, Mingxing Tan, Quoc V. Le, 2021 
3. EfficientDet: Scalable and Efficient Object Detection, Mingxing Tan, Ruoming Pang, Quoc V. Le, 2019","It might be worth adding to the limitations:
The results obtained on Imagenet classification datasets may not correlate with the results of real-life problems. Because Imagenet classification requires to predict the class of only one usually large object in the low resolution image without predicting its location (box, polygon or mask), whereas in real problems it is usually necessary to predict the class and position of many objects, incl. very small in high resolution image. Moreover, there is ambiguous in the Imagenet classification task, the class of which of the many objects in the image should be predicted?
Thus, a continuation of the research in this direction may be the finding of correlations, NAS approaches, new network structures, their parameters and scaling factors to achieve the highest OOD accuracy on tasks close to real ones (such as Dense prediction tasks: Segmentation, Detection, etc. ) in an optimal way with respect to latency and memory consumption.",['No ethics review needed.'],8,4,,Yes,4,3,3,1720374019786,,,NeurIPS.cc/2024/Conference,2AIwiIkE0s,"['NeurIPS.cc/2024/Conference/Submission11652/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879484126,[],1,,,['everyone'],2AIwiIkE0s,['NeurIPS.cc/2024/Conference/Submission11652/Reviewer_f7Da'],1720374019786,1730879484126,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11652/Reviewer_f7Da']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, Mingxing Tan, Quoc V. Le, 2019
2. EfficientNetV2: Smaller Models and Faster Training, Mingxing Tan, Quoc V. Le, 2021
3. EfficientDet: Scalable and Efficient Object Detection, Mingxing Tan, Ruoming Pang, Quoc V. Le, 2019

These papers are mentioned as references [1], [2], and [3] in the review, and the reviewer suggests that the authors consider the ideas presented in these papers, such as finding optimal model scaling factors, to improve the out-of-domain (OOD) accuracy of their models.",1,"2019, 2021, 2019",EfficientNet Rethinking Model Scaling for Convolutional Neural Networks 
BAYkVuLtaW,"The paper shows that in-domain accuracy and Training-free NAS accuracy predictions correlate poorly with out-of-domain accuracy, while characteristics of the model such as Flops, Params and Embed-Dim (number of channels) correlate much better with out-of-domain accuracy. To do this, they train a supernet that contains all possible architectures (subnets), then they validate these subnets on 9 datasets ImageNet/C/D/P/O/A/R/Sketch/Stylaized.","They explore various ways for increasing OOD accuracy, which is most important for real-world problems. They show that conventional approaches, such as Training-free NAS or relying on in-domain accuracy, do not work. While they found that Flops, Param and Embed-dim correlated well with OOD accuracy. To do this, they introduce OoD-ViT-NAS benchmark for NAS research on ViT’s OOD generalization, that includes 3000 diverse ViT architectures which are evaluated on 9 datasets. This allows us to look for new and better approaches for finding new models structures to improve OOD accuracy.","You show that the embedding dimension has the highest impact among ViT architectural attributes, while network depth has a slight impact on OoD generalization. But the paper lacks an explanation that although embed-dim (number of channels) correlates with OOD accuracy better than depth, this does not necessarily mean that to increase OOD accuracy only embed-dim should be increased, since the computational cost and memory costs may be different for embed-dim and depth. Therefore, to create either the largest and most accurate model that fits in memory, or the most optimal model in terms of speed and accuracy, it may be optimal to increase the depth rather than embed-dim. There are also papers [1,2,3] that show that it is necessary to simultaneously increase several model parameters (depth, number of channels, resolution) in optimal proportions.

You present charts of OOD accuracy and number of parameters (Fig. 4, K19 - K24), but it would also be great to present charts of OOD-accuracy and latency, and OOD-accuracy and GPU memory consumption. Because these 3 model characteristics (OOD-accuracy, Latency, Memory consumption) are the most important for real-world problems.


1. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, Mingxing Tan, Quoc V. Le, 2019
2. EfficientNetV2: Smaller Models and Faster Training, Mingxing Tan, Quoc V. Le, 2021 
3. EfficientDet: Scalable and Efficient Object Detection, Mingxing Tan, Ruoming Pang, Quoc V. Le, 2019","- Have you tried plotting OOD-accuracy versus Latency or GPU memory consumption while increasing various model parameters such as: embed_dim, depth, MLP-ratio, num of heads, etc.? Or find correlations between ODE accuracy and these parameters, taking into account their impact on latency and memory consumption.

- Have you tried to find optimal model scaling factors (similar to works [1, 2, 3]) to increase OOD-accuracy in optimal way with respect to latency or memory consumption?


1. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, Mingxing Tan, Quoc V. Le, 2019
2. EfficientNetV2: Smaller Models and Faster Training, Mingxing Tan, Quoc V. Le, 2021 
3. EfficientDet: Scalable and Efficient Object Detection, Mingxing Tan, Ruoming Pang, Quoc V. Le, 2019","It might be worth adding to the limitations:
The results obtained on Imagenet classification datasets may not correlate with the results of real-life problems. Because Imagenet classification requires to predict the class of only one usually large object in the low resolution image without predicting its location (box, polygon or mask), whereas in real problems it is usually necessary to predict the class and position of many objects, incl. very small in high resolution image. Moreover, there is ambiguous in the Imagenet classification task, the class of which of the many objects in the image should be predicted?
Thus, a continuation of the research in this direction may be the finding of correlations, NAS approaches, new network structures, their parameters and scaling factors to achieve the highest OOD accuracy on tasks close to real ones (such as Dense prediction tasks: Segmentation, Detection, etc. ) in an optimal way with respect to latency and memory consumption.",['No ethics review needed.'],8,4,,Yes,4,3,3,1720374019786,,,NeurIPS.cc/2024/Conference,2AIwiIkE0s,"['NeurIPS.cc/2024/Conference/Submission11652/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879484126,[],1,,,['everyone'],2AIwiIkE0s,['NeurIPS.cc/2024/Conference/Submission11652/Reviewer_f7Da'],1720374019786,1730879484126,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11652/Reviewer_f7Da']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, Mingxing Tan, Quoc V. Le, 2019
2. EfficientNetV2: Smaller Models and Faster Training, Mingxing Tan, Quoc V. Le, 2021
3. EfficientDet: Scalable and Efficient Object Detection, Mingxing Tan, Ruoming Pang, Quoc V. Le, 2019

These papers are mentioned as references [1], [2], and [3] in the review, and the reviewer suggests that the authors consider the ideas presented in these papers, such as finding optimal model scaling factors, to improve the out-of-domain (OOD) accuracy of their models.",1,"2019, 2021, 2019",EfficientNetV2 Smaller Models and Faster Training 
BAYkVuLtaW,"The paper shows that in-domain accuracy and Training-free NAS accuracy predictions correlate poorly with out-of-domain accuracy, while characteristics of the model such as Flops, Params and Embed-Dim (number of channels) correlate much better with out-of-domain accuracy. To do this, they train a supernet that contains all possible architectures (subnets), then they validate these subnets on 9 datasets ImageNet/C/D/P/O/A/R/Sketch/Stylaized.","They explore various ways for increasing OOD accuracy, which is most important for real-world problems. They show that conventional approaches, such as Training-free NAS or relying on in-domain accuracy, do not work. While they found that Flops, Param and Embed-dim correlated well with OOD accuracy. To do this, they introduce OoD-ViT-NAS benchmark for NAS research on ViT’s OOD generalization, that includes 3000 diverse ViT architectures which are evaluated on 9 datasets. This allows us to look for new and better approaches for finding new models structures to improve OOD accuracy.","You show that the embedding dimension has the highest impact among ViT architectural attributes, while network depth has a slight impact on OoD generalization. But the paper lacks an explanation that although embed-dim (number of channels) correlates with OOD accuracy better than depth, this does not necessarily mean that to increase OOD accuracy only embed-dim should be increased, since the computational cost and memory costs may be different for embed-dim and depth. Therefore, to create either the largest and most accurate model that fits in memory, or the most optimal model in terms of speed and accuracy, it may be optimal to increase the depth rather than embed-dim. There are also papers [1,2,3] that show that it is necessary to simultaneously increase several model parameters (depth, number of channels, resolution) in optimal proportions.

You present charts of OOD accuracy and number of parameters (Fig. 4, K19 - K24), but it would also be great to present charts of OOD-accuracy and latency, and OOD-accuracy and GPU memory consumption. Because these 3 model characteristics (OOD-accuracy, Latency, Memory consumption) are the most important for real-world problems.


1. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, Mingxing Tan, Quoc V. Le, 2019
2. EfficientNetV2: Smaller Models and Faster Training, Mingxing Tan, Quoc V. Le, 2021 
3. EfficientDet: Scalable and Efficient Object Detection, Mingxing Tan, Ruoming Pang, Quoc V. Le, 2019","- Have you tried plotting OOD-accuracy versus Latency or GPU memory consumption while increasing various model parameters such as: embed_dim, depth, MLP-ratio, num of heads, etc.? Or find correlations between ODE accuracy and these parameters, taking into account their impact on latency and memory consumption.

- Have you tried to find optimal model scaling factors (similar to works [1, 2, 3]) to increase OOD-accuracy in optimal way with respect to latency or memory consumption?


1. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, Mingxing Tan, Quoc V. Le, 2019
2. EfficientNetV2: Smaller Models and Faster Training, Mingxing Tan, Quoc V. Le, 2021 
3. EfficientDet: Scalable and Efficient Object Detection, Mingxing Tan, Ruoming Pang, Quoc V. Le, 2019","It might be worth adding to the limitations:
The results obtained on Imagenet classification datasets may not correlate with the results of real-life problems. Because Imagenet classification requires to predict the class of only one usually large object in the low resolution image without predicting its location (box, polygon or mask), whereas in real problems it is usually necessary to predict the class and position of many objects, incl. very small in high resolution image. Moreover, there is ambiguous in the Imagenet classification task, the class of which of the many objects in the image should be predicted?
Thus, a continuation of the research in this direction may be the finding of correlations, NAS approaches, new network structures, their parameters and scaling factors to achieve the highest OOD accuracy on tasks close to real ones (such as Dense prediction tasks: Segmentation, Detection, etc. ) in an optimal way with respect to latency and memory consumption.",['No ethics review needed.'],8,4,,Yes,4,3,3,1720374019786,,,NeurIPS.cc/2024/Conference,2AIwiIkE0s,"['NeurIPS.cc/2024/Conference/Submission11652/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879484126,[],1,,,['everyone'],2AIwiIkE0s,['NeurIPS.cc/2024/Conference/Submission11652/Reviewer_f7Da'],1720374019786,1730879484126,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11652/Reviewer_f7Da']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, Mingxing Tan, Quoc V. Le, 2019
2. EfficientNetV2: Smaller Models and Faster Training, Mingxing Tan, Quoc V. Le, 2021
3. EfficientDet: Scalable and Efficient Object Detection, Mingxing Tan, Ruoming Pang, Quoc V. Le, 2019

These papers are mentioned as references [1], [2], and [3] in the review, and the reviewer suggests that the authors consider the ideas presented in these papers, such as finding optimal model scaling factors, to improve the out-of-domain (OOD) accuracy of their models.",1,"2019, 2021, 2019",EfficientDet Scalable and Efficient Object Detection
A3B7BudD0l,"This paper investigates how to train the text-to-image model comparable to advanced models using publicly available resources. Specifically, EvolveDirector collects training data with the APIs of advanced models, and further uses a VLM to continuously refine the training dataset. The proposed VLM refinement significantly reduces the data volume needed to teach a base T2I model and improves the training efficiency.","1. The proposed framework is novel, and can significantly reduce the volume of data required to approach the SOTA text-to-image generation performance.

2. This paper investigates one interesting direction: training the base T2I model to approach the advanced models using their generated data, which can be crucial for bridging the gap between public T2I models and close-sourced T2I models. 

3. The way of utilizing VLMs is interesting and effective. The VLM dynamically maintains the training dataset to achieve efficient training.

4. Edgen shows good human evaluation performance on generation faithfulness to text prompts, especially in multi-object generation and text generation.

5. The paper is well-organized and technically clear.","1. The explanation of how to instruct VLM is not detailed. For example, how to ensure the generated text prompts can be parsed correctly and free of errors, which could introduce noise into the training data.

2. It would be better to also evaluate the final model on other benchmarks (e.g., DSG, TIFA).

3. Missing references: 
(1) DreamSync: Aligning Text-to-Image Generation with Image Understanding Feedback
(2) SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data","Typos: in line 336, “outperform” -> “outperforms”.",,['No ethics review needed.'],8,5,,Yes,4,4,4,1720820575926,,,NeurIPS.cc/2024/Conference,28bFUt6rUY,"['NeurIPS.cc/2024/Conference/Submission1029/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878673093,[],2,,,['everyone'],28bFUt6rUY,['NeurIPS.cc/2024/Conference/Submission1029/Reviewer_i5a7'],1720820575926,1730878673093,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission1029/Reviewer_i5a7']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. DreamSync: Aligning Text-to-Image Generation with Image Understanding Feedback
2. SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data

The reviewer mentions ""Missing references"" and lists these two papers, implying that the authors should consider citing them in their work.",1,,DreamSync Aligning Text-to-Image Generation with Image Understanding Feedback 
A3B7BudD0l,"This paper investigates how to train the text-to-image model comparable to advanced models using publicly available resources. Specifically, EvolveDirector collects training data with the APIs of advanced models, and further uses a VLM to continuously refine the training dataset. The proposed VLM refinement significantly reduces the data volume needed to teach a base T2I model and improves the training efficiency.","1. The proposed framework is novel, and can significantly reduce the volume of data required to approach the SOTA text-to-image generation performance.

2. This paper investigates one interesting direction: training the base T2I model to approach the advanced models using their generated data, which can be crucial for bridging the gap between public T2I models and close-sourced T2I models. 

3. The way of utilizing VLMs is interesting and effective. The VLM dynamically maintains the training dataset to achieve efficient training.

4. Edgen shows good human evaluation performance on generation faithfulness to text prompts, especially in multi-object generation and text generation.

5. The paper is well-organized and technically clear.","1. The explanation of how to instruct VLM is not detailed. For example, how to ensure the generated text prompts can be parsed correctly and free of errors, which could introduce noise into the training data.

2. It would be better to also evaluate the final model on other benchmarks (e.g., DSG, TIFA).

3. Missing references: 
(1) DreamSync: Aligning Text-to-Image Generation with Image Understanding Feedback
(2) SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data","Typos: in line 336, “outperform” -> “outperforms”.",,['No ethics review needed.'],8,5,,Yes,4,4,4,1720820575926,,,NeurIPS.cc/2024/Conference,28bFUt6rUY,"['NeurIPS.cc/2024/Conference/Submission1029/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878673093,[],2,,,['everyone'],28bFUt6rUY,['NeurIPS.cc/2024/Conference/Submission1029/Reviewer_i5a7'],1720820575926,1730878673093,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission1029/Reviewer_i5a7']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. DreamSync: Aligning Text-to-Image Generation with Image Understanding Feedback
2. SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data

The reviewer mentions ""Missing references"" and lists these two papers, implying that the authors should consider citing them in their work.",1,,SELMA Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data
I9d9L0Lv3a,"This paper focus on the semi-supervised graph domain adaptation, and introduces a new framework called TFGDA. Graph usually contains complex structure information, while existing GTL studies often overlooks the importance of structure information when extracting transferable node features. TFGDA thus proposes a novel STSA strategy to utilize the topological structures information between input and latent spaces to assist GTL. To solve the instability caused by adversarial training-based domain adaptation methods, this paper also presents an SDA strategy to reduce cross-domain node feature distributions discrepancy in the spherical space. Furthermore, an innovative mutual information-based RNC strategy is proposed to address the overfitting issue by guiding the robust clustering of unlabeled target graph nodes. Extensive experimental results show that TFGDA outperforms existing state-of-the-art methods across various transfer learning tasks, indicating its superiority and stability.","(1) The paper is well-written and has a clear structure. Compared to the widely studied unsupervised domain adaptation in GTL, the semi-supervised domain adaptation is more relevant to real-world application scenarios. Therefore, it is meaningful to explore effective solutions to address the challenges faced by semi-supervised domain adaptation. In general, the paper is quite novel and worth reading.

(2) The introduction of the STSA strategy is well-motivated. Leveraging the graph structure information to facilitate graph transfer learning is indeed an innovative attempt and shows significant transfer performance gains on multiple tasks.

(3) The SDA strategy exhibits significant superiority over existing methods in reducing node feature distributions difference. Additionally, it is an interesting idea to devise a node clustering strategy RNC from the view of mutual information. Detailed experimental results demonstrate the effectiveness of RNC in addressing the overfitting problem and enhancing model robustness. 

(4) The paper provides comprehensive experiment on multiple benchmark datasets to validate the superior transfer performance over existing state-of-the-art methods.","To make this paper more comprehensive, there are some concerns that I would like the authors to address.
(1)	This paper mainly utilizes multiple real-world academic graphs as datasets. Further exploration can be conducted on other types of graph datasets (such as real-world graph datasets), which can more effectively validate the generalizability of the proposed method.
(2)	Furthermore, I recommend the authors to include a discussion and comparison of the model’s inference efficiency in the paper. 
(3)	[Minor comment:] While the t-SNE visualization results in Figure 2 clearly show the advantage of TFGDA in reducing feature distribution discrepancy, I recommend the authors to include additional quantitative metrics to better demonstrate the transfer ability of the method, such as the {A}-distance [1].
(4)	[Minor comment:] Since the SDA strategy contains some complex mathematical details, it is recommended to add a high-level algorithm table to summarize it.

Reference:
[1] Analysis of representations for domain adaptation. (Neurips 2006).","I have some doubts and hope the authors to clarify them.
(1)	When the model performs inference on the target domain graph, is the shift parameter perturbation branch $\xi$ of RNC activated? Does the graph data flow through the regular branch or the perturbation branch before being fed into the classifier \mathcal{C} for inference?

(2)	What is the intrinsic reason for the need to introduce structure information in graph transfer learning frameworks? Is it because the structure information of the data tends to be lost as the network layers go deeper?

(3)	Some previous images based-transfer learning works [2-4] have utilized the wasserstein or the sliced wasserstein as distance metrics to minimize domain discrepancy. In the SDA strategy, why is the SSW distance better than these two distance in measuring domain differences? 

Reference:
[2] Sliced wasserstein discrepancy for unsupervised domain adaptation. (CVPR 2019).
[3] Reliable weighted optimal transport for unsupervised domain adaptation. (CVPR 2020).
[4] Deepjdot: Deep joint distribution optimal transport for unsupervised domain adaptation. (ECCV 2018).",The authors have provided clear explanations of the limitations that the proposed method may encounter in the supplementary materials. This article does not have any potential negative societal impact.,['No ethics review needed.'],7,5,,Yes,3,3,3,1719680831319,,,NeurIPS.cc/2024/Conference,26BdXIY3ik,"['NeurIPS.cc/2024/Conference/Submission504/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878647171,[],2,,,['everyone'],26BdXIY3ik,['NeurIPS.cc/2024/Conference/Submission504/Reviewer_byDA'],1719680831319,1730878647171,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission504/Reviewer_byDA']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references, including:

* [1] Analysis of representations for domain adaptation. (Neurips 2006)
* [2] Sliced wasserstein discrepancy for unsupervised domain adaptation. (CVPR 2019)
* [3] Reliable weighted optimal transport for unsupervised domain adaptation. (CVPR 2020)
* [4] Deepjdot: Deep joint distribution optimal transport for unsupervised domain adaptation. (ECCV 2018)

The reviewer is suggesting that the authors consider citing these works, particularly in the context of discussing distance metrics for measuring domain discrepancy and comparing their approach to existing methods.",1,"2006, 2019, 2020, 2018",Analysis of representations for domain adaptation 
I9d9L0Lv3a,"This paper focus on the semi-supervised graph domain adaptation, and introduces a new framework called TFGDA. Graph usually contains complex structure information, while existing GTL studies often overlooks the importance of structure information when extracting transferable node features. TFGDA thus proposes a novel STSA strategy to utilize the topological structures information between input and latent spaces to assist GTL. To solve the instability caused by adversarial training-based domain adaptation methods, this paper also presents an SDA strategy to reduce cross-domain node feature distributions discrepancy in the spherical space. Furthermore, an innovative mutual information-based RNC strategy is proposed to address the overfitting issue by guiding the robust clustering of unlabeled target graph nodes. Extensive experimental results show that TFGDA outperforms existing state-of-the-art methods across various transfer learning tasks, indicating its superiority and stability.","(1) The paper is well-written and has a clear structure. Compared to the widely studied unsupervised domain adaptation in GTL, the semi-supervised domain adaptation is more relevant to real-world application scenarios. Therefore, it is meaningful to explore effective solutions to address the challenges faced by semi-supervised domain adaptation. In general, the paper is quite novel and worth reading.

(2) The introduction of the STSA strategy is well-motivated. Leveraging the graph structure information to facilitate graph transfer learning is indeed an innovative attempt and shows significant transfer performance gains on multiple tasks.

(3) The SDA strategy exhibits significant superiority over existing methods in reducing node feature distributions difference. Additionally, it is an interesting idea to devise a node clustering strategy RNC from the view of mutual information. Detailed experimental results demonstrate the effectiveness of RNC in addressing the overfitting problem and enhancing model robustness. 

(4) The paper provides comprehensive experiment on multiple benchmark datasets to validate the superior transfer performance over existing state-of-the-art methods.","To make this paper more comprehensive, there are some concerns that I would like the authors to address.
(1)	This paper mainly utilizes multiple real-world academic graphs as datasets. Further exploration can be conducted on other types of graph datasets (such as real-world graph datasets), which can more effectively validate the generalizability of the proposed method.
(2)	Furthermore, I recommend the authors to include a discussion and comparison of the model’s inference efficiency in the paper. 
(3)	[Minor comment:] While the t-SNE visualization results in Figure 2 clearly show the advantage of TFGDA in reducing feature distribution discrepancy, I recommend the authors to include additional quantitative metrics to better demonstrate the transfer ability of the method, such as the {A}-distance [1].
(4)	[Minor comment:] Since the SDA strategy contains some complex mathematical details, it is recommended to add a high-level algorithm table to summarize it.

Reference:
[1] Analysis of representations for domain adaptation. (Neurips 2006).","I have some doubts and hope the authors to clarify them.
(1)	When the model performs inference on the target domain graph, is the shift parameter perturbation branch $\xi$ of RNC activated? Does the graph data flow through the regular branch or the perturbation branch before being fed into the classifier \mathcal{C} for inference?

(2)	What is the intrinsic reason for the need to introduce structure information in graph transfer learning frameworks? Is it because the structure information of the data tends to be lost as the network layers go deeper?

(3)	Some previous images based-transfer learning works [2-4] have utilized the wasserstein or the sliced wasserstein as distance metrics to minimize domain discrepancy. In the SDA strategy, why is the SSW distance better than these two distance in measuring domain differences? 

Reference:
[2] Sliced wasserstein discrepancy for unsupervised domain adaptation. (CVPR 2019).
[3] Reliable weighted optimal transport for unsupervised domain adaptation. (CVPR 2020).
[4] Deepjdot: Deep joint distribution optimal transport for unsupervised domain adaptation. (ECCV 2018).",The authors have provided clear explanations of the limitations that the proposed method may encounter in the supplementary materials. This article does not have any potential negative societal impact.,['No ethics review needed.'],7,5,,Yes,3,3,3,1719680831319,,,NeurIPS.cc/2024/Conference,26BdXIY3ik,"['NeurIPS.cc/2024/Conference/Submission504/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878647171,[],2,,,['everyone'],26BdXIY3ik,['NeurIPS.cc/2024/Conference/Submission504/Reviewer_byDA'],1719680831319,1730878647171,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission504/Reviewer_byDA']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references, including:

* [1] Analysis of representations for domain adaptation. (Neurips 2006)
* [2] Sliced wasserstein discrepancy for unsupervised domain adaptation. (CVPR 2019)
* [3] Reliable weighted optimal transport for unsupervised domain adaptation. (CVPR 2020)
* [4] Deepjdot: Deep joint distribution optimal transport for unsupervised domain adaptation. (ECCV 2018)

The reviewer is suggesting that the authors consider citing these works, particularly in the context of discussing distance metrics for measuring domain discrepancy and comparing their approach to existing methods.",1,"2006, 2019, 2020, 2018",Sliced wasserstein discrepancy for unsupervised domain adaptation 
I9d9L0Lv3a,"This paper focus on the semi-supervised graph domain adaptation, and introduces a new framework called TFGDA. Graph usually contains complex structure information, while existing GTL studies often overlooks the importance of structure information when extracting transferable node features. TFGDA thus proposes a novel STSA strategy to utilize the topological structures information between input and latent spaces to assist GTL. To solve the instability caused by adversarial training-based domain adaptation methods, this paper also presents an SDA strategy to reduce cross-domain node feature distributions discrepancy in the spherical space. Furthermore, an innovative mutual information-based RNC strategy is proposed to address the overfitting issue by guiding the robust clustering of unlabeled target graph nodes. Extensive experimental results show that TFGDA outperforms existing state-of-the-art methods across various transfer learning tasks, indicating its superiority and stability.","(1) The paper is well-written and has a clear structure. Compared to the widely studied unsupervised domain adaptation in GTL, the semi-supervised domain adaptation is more relevant to real-world application scenarios. Therefore, it is meaningful to explore effective solutions to address the challenges faced by semi-supervised domain adaptation. In general, the paper is quite novel and worth reading.

(2) The introduction of the STSA strategy is well-motivated. Leveraging the graph structure information to facilitate graph transfer learning is indeed an innovative attempt and shows significant transfer performance gains on multiple tasks.

(3) The SDA strategy exhibits significant superiority over existing methods in reducing node feature distributions difference. Additionally, it is an interesting idea to devise a node clustering strategy RNC from the view of mutual information. Detailed experimental results demonstrate the effectiveness of RNC in addressing the overfitting problem and enhancing model robustness. 

(4) The paper provides comprehensive experiment on multiple benchmark datasets to validate the superior transfer performance over existing state-of-the-art methods.","To make this paper more comprehensive, there are some concerns that I would like the authors to address.
(1)	This paper mainly utilizes multiple real-world academic graphs as datasets. Further exploration can be conducted on other types of graph datasets (such as real-world graph datasets), which can more effectively validate the generalizability of the proposed method.
(2)	Furthermore, I recommend the authors to include a discussion and comparison of the model’s inference efficiency in the paper. 
(3)	[Minor comment:] While the t-SNE visualization results in Figure 2 clearly show the advantage of TFGDA in reducing feature distribution discrepancy, I recommend the authors to include additional quantitative metrics to better demonstrate the transfer ability of the method, such as the {A}-distance [1].
(4)	[Minor comment:] Since the SDA strategy contains some complex mathematical details, it is recommended to add a high-level algorithm table to summarize it.

Reference:
[1] Analysis of representations for domain adaptation. (Neurips 2006).","I have some doubts and hope the authors to clarify them.
(1)	When the model performs inference on the target domain graph, is the shift parameter perturbation branch $\xi$ of RNC activated? Does the graph data flow through the regular branch or the perturbation branch before being fed into the classifier \mathcal{C} for inference?

(2)	What is the intrinsic reason for the need to introduce structure information in graph transfer learning frameworks? Is it because the structure information of the data tends to be lost as the network layers go deeper?

(3)	Some previous images based-transfer learning works [2-4] have utilized the wasserstein or the sliced wasserstein as distance metrics to minimize domain discrepancy. In the SDA strategy, why is the SSW distance better than these two distance in measuring domain differences? 

Reference:
[2] Sliced wasserstein discrepancy for unsupervised domain adaptation. (CVPR 2019).
[3] Reliable weighted optimal transport for unsupervised domain adaptation. (CVPR 2020).
[4] Deepjdot: Deep joint distribution optimal transport for unsupervised domain adaptation. (ECCV 2018).",The authors have provided clear explanations of the limitations that the proposed method may encounter in the supplementary materials. This article does not have any potential negative societal impact.,['No ethics review needed.'],7,5,,Yes,3,3,3,1719680831319,,,NeurIPS.cc/2024/Conference,26BdXIY3ik,"['NeurIPS.cc/2024/Conference/Submission504/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878647171,[],2,,,['everyone'],26BdXIY3ik,['NeurIPS.cc/2024/Conference/Submission504/Reviewer_byDA'],1719680831319,1730878647171,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission504/Reviewer_byDA']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references, including:

* [1] Analysis of representations for domain adaptation. (Neurips 2006)
* [2] Sliced wasserstein discrepancy for unsupervised domain adaptation. (CVPR 2019)
* [3] Reliable weighted optimal transport for unsupervised domain adaptation. (CVPR 2020)
* [4] Deepjdot: Deep joint distribution optimal transport for unsupervised domain adaptation. (ECCV 2018)

The reviewer is suggesting that the authors consider citing these works, particularly in the context of discussing distance metrics for measuring domain discrepancy and comparing their approach to existing methods.",1,"2006, 2019, 2020, 2018",Reliable weighted optimal transport for unsupervised domain adaptation 
I9d9L0Lv3a,"This paper focus on the semi-supervised graph domain adaptation, and introduces a new framework called TFGDA. Graph usually contains complex structure information, while existing GTL studies often overlooks the importance of structure information when extracting transferable node features. TFGDA thus proposes a novel STSA strategy to utilize the topological structures information between input and latent spaces to assist GTL. To solve the instability caused by adversarial training-based domain adaptation methods, this paper also presents an SDA strategy to reduce cross-domain node feature distributions discrepancy in the spherical space. Furthermore, an innovative mutual information-based RNC strategy is proposed to address the overfitting issue by guiding the robust clustering of unlabeled target graph nodes. Extensive experimental results show that TFGDA outperforms existing state-of-the-art methods across various transfer learning tasks, indicating its superiority and stability.","(1) The paper is well-written and has a clear structure. Compared to the widely studied unsupervised domain adaptation in GTL, the semi-supervised domain adaptation is more relevant to real-world application scenarios. Therefore, it is meaningful to explore effective solutions to address the challenges faced by semi-supervised domain adaptation. In general, the paper is quite novel and worth reading.

(2) The introduction of the STSA strategy is well-motivated. Leveraging the graph structure information to facilitate graph transfer learning is indeed an innovative attempt and shows significant transfer performance gains on multiple tasks.

(3) The SDA strategy exhibits significant superiority over existing methods in reducing node feature distributions difference. Additionally, it is an interesting idea to devise a node clustering strategy RNC from the view of mutual information. Detailed experimental results demonstrate the effectiveness of RNC in addressing the overfitting problem and enhancing model robustness. 

(4) The paper provides comprehensive experiment on multiple benchmark datasets to validate the superior transfer performance over existing state-of-the-art methods.","To make this paper more comprehensive, there are some concerns that I would like the authors to address.
(1)	This paper mainly utilizes multiple real-world academic graphs as datasets. Further exploration can be conducted on other types of graph datasets (such as real-world graph datasets), which can more effectively validate the generalizability of the proposed method.
(2)	Furthermore, I recommend the authors to include a discussion and comparison of the model’s inference efficiency in the paper. 
(3)	[Minor comment:] While the t-SNE visualization results in Figure 2 clearly show the advantage of TFGDA in reducing feature distribution discrepancy, I recommend the authors to include additional quantitative metrics to better demonstrate the transfer ability of the method, such as the {A}-distance [1].
(4)	[Minor comment:] Since the SDA strategy contains some complex mathematical details, it is recommended to add a high-level algorithm table to summarize it.

Reference:
[1] Analysis of representations for domain adaptation. (Neurips 2006).","I have some doubts and hope the authors to clarify them.
(1)	When the model performs inference on the target domain graph, is the shift parameter perturbation branch $\xi$ of RNC activated? Does the graph data flow through the regular branch or the perturbation branch before being fed into the classifier \mathcal{C} for inference?

(2)	What is the intrinsic reason for the need to introduce structure information in graph transfer learning frameworks? Is it because the structure information of the data tends to be lost as the network layers go deeper?

(3)	Some previous images based-transfer learning works [2-4] have utilized the wasserstein or the sliced wasserstein as distance metrics to minimize domain discrepancy. In the SDA strategy, why is the SSW distance better than these two distance in measuring domain differences? 

Reference:
[2] Sliced wasserstein discrepancy for unsupervised domain adaptation. (CVPR 2019).
[3] Reliable weighted optimal transport for unsupervised domain adaptation. (CVPR 2020).
[4] Deepjdot: Deep joint distribution optimal transport for unsupervised domain adaptation. (ECCV 2018).",The authors have provided clear explanations of the limitations that the proposed method may encounter in the supplementary materials. This article does not have any potential negative societal impact.,['No ethics review needed.'],7,5,,Yes,3,3,3,1719680831319,,,NeurIPS.cc/2024/Conference,26BdXIY3ik,"['NeurIPS.cc/2024/Conference/Submission504/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878647171,[],2,,,['everyone'],26BdXIY3ik,['NeurIPS.cc/2024/Conference/Submission504/Reviewer_byDA'],1719680831319,1730878647171,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission504/Reviewer_byDA']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references, including:

* [1] Analysis of representations for domain adaptation. (Neurips 2006)
* [2] Sliced wasserstein discrepancy for unsupervised domain adaptation. (CVPR 2019)
* [3] Reliable weighted optimal transport for unsupervised domain adaptation. (CVPR 2020)
* [4] Deepjdot: Deep joint distribution optimal transport for unsupervised domain adaptation. (ECCV 2018)

The reviewer is suggesting that the authors consider citing these works, particularly in the context of discussing distance metrics for measuring domain discrepancy and comparing their approach to existing methods.",1,"2006, 2019, 2020, 2018",Deepjdot Deep joint distribution optimal transport for unsupervised domain adaptation
fJFkVUFabR,"This paper proposes YOCO, a hybrid model that combines gated linear attention with standard attention (SA). The model stacks efficient self attention (ESA) in the first $L/2$ layers, succeeded by another $L/2$ cross-attention layers. 
Notably, the output of the last ESA is shared across subsequent CA layers, thereby achieving significant parameter reduction and enabling exceptional key-value (KV) cache compression, critical for optimizing inference.

Two ESA variants are evaluated: sliding window attention and a novel gated retention method, which incorporates data-driven head-wise decay over retention. 
Upon scaling YOCO to a 3-billion-parameter model trained on a corpus of 1 trillion tokens, the authors report superior performance relative to Llama-like architectures in language modeling tasks. 
They also conduct some analysis on long-seq evals and observe near-perfect performance on needle-in-haystack tests and other benchmarks like Qasper.","1. YOCO's hybrid structure delivers remarkable results in needle-in-haystack scenarios and demonstrates robust performance on retrieval-centric tasks, marking a pioneering achievement.
2. The proposed data-dependent gated-retention brings great improvement against retention.
3. By facilitating substantial KV cache compression relative to standard attention, YOCO exhibits superior retrieval capabilities compared to existing linear attention models. I'm very glad to see the results of YOCO scaling to larger sizes.","I see no obvious disadvantages of this paper; however, the manuscript would benefit from:

1) The authors should add more comparions with  exisiting linear-time / hybrid models trained on trillions of tokens, e.g., RWKV6 and TransNormer, whose checkpoints are publicly available. 
2) Despite concurrent works, I suggest the authors to add discussions with Samba [1] and Mamba2 [2] in their next version.

[1] Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling

[2] Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality","1. Some notations are confusing: 1) Regarding Eq.7, the usage of $\beta_{iB}$ suggests an accumulation effect from preceding chunks, which may mislead readers. Additionally, the notations of $\beta_{[i]}(j,k)$ appears unused. If I understand correctly, $x_{[i]}$ is a 2-d tensor while $\beta_{[i]}$ is a scalar, it could be better to use another notation to distinguish the two. 2) Eq. 8 should be $\mathrm{head}_1,\dots,\mathrm{head}_n=\dots$
2. I'm curious if the authors have tried other linear attention variants instead of gRet, e.g., Mamba, and GLA.",,['No ethics review needed.'],7,5,,Yes,3,3,3,1720699283543,,,NeurIPS.cc/2024/Conference,25Ioxw576r,"['NeurIPS.cc/2024/Conference/Submission5374/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878996058,[],1,,,['everyone'],25Ioxw576r,['NeurIPS.cc/2024/Conference/Submission5374/Reviewer_hQmr'],1720699283543,1730878996058,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5374/Reviewer_hQmr']","Yes, the peer review explicitly suggests the authors of the paper to discuss and possibly cite the following specific literature:

1. Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling
2. Mamba2: Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality

Additionally, the reviewer mentions RWKV6 and TransNormer as examples of existing linear-time/hybrid models that the authors could compare their work to. However, this is not necessarily a suggestion to cite these papers, but rather to use their publicly available checkpoints for comparison.",1,,Samba Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling
fJFkVUFabR,"This paper proposes YOCO, a hybrid model that combines gated linear attention with standard attention (SA). The model stacks efficient self attention (ESA) in the first $L/2$ layers, succeeded by another $L/2$ cross-attention layers. 
Notably, the output of the last ESA is shared across subsequent CA layers, thereby achieving significant parameter reduction and enabling exceptional key-value (KV) cache compression, critical for optimizing inference.

Two ESA variants are evaluated: sliding window attention and a novel gated retention method, which incorporates data-driven head-wise decay over retention. 
Upon scaling YOCO to a 3-billion-parameter model trained on a corpus of 1 trillion tokens, the authors report superior performance relative to Llama-like architectures in language modeling tasks. 
They also conduct some analysis on long-seq evals and observe near-perfect performance on needle-in-haystack tests and other benchmarks like Qasper.","1. YOCO's hybrid structure delivers remarkable results in needle-in-haystack scenarios and demonstrates robust performance on retrieval-centric tasks, marking a pioneering achievement.
2. The proposed data-dependent gated-retention brings great improvement against retention.
3. By facilitating substantial KV cache compression relative to standard attention, YOCO exhibits superior retrieval capabilities compared to existing linear attention models. I'm very glad to see the results of YOCO scaling to larger sizes.","I see no obvious disadvantages of this paper; however, the manuscript would benefit from:

1) The authors should add more comparions with  exisiting linear-time / hybrid models trained on trillions of tokens, e.g., RWKV6 and TransNormer, whose checkpoints are publicly available. 
2) Despite concurrent works, I suggest the authors to add discussions with Samba [1] and Mamba2 [2] in their next version.

[1] Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling

[2] Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality","1. Some notations are confusing: 1) Regarding Eq.7, the usage of $\beta_{iB}$ suggests an accumulation effect from preceding chunks, which may mislead readers. Additionally, the notations of $\beta_{[i]}(j,k)$ appears unused. If I understand correctly, $x_{[i]}$ is a 2-d tensor while $\beta_{[i]}$ is a scalar, it could be better to use another notation to distinguish the two. 2) Eq. 8 should be $\mathrm{head}_1,\dots,\mathrm{head}_n=\dots$
2. I'm curious if the authors have tried other linear attention variants instead of gRet, e.g., Mamba, and GLA.",,['No ethics review needed.'],7,5,,Yes,3,3,3,1720699283543,,,NeurIPS.cc/2024/Conference,25Ioxw576r,"['NeurIPS.cc/2024/Conference/Submission5374/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878996058,[],1,,,['everyone'],25Ioxw576r,['NeurIPS.cc/2024/Conference/Submission5374/Reviewer_hQmr'],1720699283543,1730878996058,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5374/Reviewer_hQmr']","Yes, the peer review explicitly suggests the authors of the paper to discuss and possibly cite the following specific literature:

1. Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling
2. Mamba2: Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality

Additionally, the reviewer mentions RWKV6 and TransNormer as examples of existing linear-time/hybrid models that the authors could compare their work to. However, this is not necessarily a suggestion to cite these papers, but rather to use their publicly available checkpoints for comparison.",1,,Mamba2 Transformers are SSMs Generalized Models and Efficient Algorithms Through Structured State Space Duality
ypNRxXsbHd,This paper proposes a novel online batch selection algorithm called GREedy Approximation Taylor Selection (GREATS) for training large language models (LLMs). The algorithm aims to improve training convergence speed and generalization performance by selecting informative and diverse examples for model updates. GREATS uses a principled formulation of the online batch selection problem and leverages greedy algorithms and Taylor expansions to approximate the utility of data points. This paper presents extensive experiments on various LLM tasks to demonstrate the effectiveness of GREATS in improving training performance.,"1) This paper presents a novel online batch selection algorithm that addresses the limitations of existing methods and significantly improves training convergence speed and generalization performance.
2) The algorithm is based on a principled formulation and uses innovative techniques such as greedy algorithms and Taylor expansions to approximate the utility of data points.
3) This paper provides comprehensive evaluations on various LLM tasks, demonstrating the robustness and versatility of GREATS.","1) The authors only consider MaxLoss and GradNorm as baselines, they do not compare GREATS with other state-of-the-art online batch selection methods.
2) No confidence intervals in any of the tables, which makes it hard to gauge the significance of the accuracy gains.
3) The authors only report accuracy on MMLU and TYDIQA test sets, I cannot find the results of other datasets.","Why are uniform selection and selection-via-Proxy [*1] not included as baselines?

[*1] Selection via proxy: Efficient data selection for deep learning, ICLR 2020.",The authors have addressed the limitations in the main text.,['No ethics review needed.'],6,4,,Yes,2,3,3,1719477041367,,,NeurIPS.cc/2024/Conference,232VcN8tSx,"['NeurIPS.cc/2024/Conference/Submission20576/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880121043,[],1,,,['everyone'],232VcN8tSx,['NeurIPS.cc/2024/Conference/Submission20576/Reviewer_tC7z'],1719477041367,1730880121043,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission20576/Reviewer_tC7z']","Yes, this peer review explicitly suggests the authors of the paper to cite the literature ""Selection via proxy: Efficient data selection for deep learning, ICLR 2020"" as a baseline for comparison, in addition to mentioning another baseline ""uniform selection"". The reviewer questions why these were not included as baselines, implying that they should be considered for a more comprehensive evaluation of the proposed algorithm, GREATS.",1,2020,Selection via proxy: Efficient data selection for deep learning
M4cArrxQcz,"The paper introduces a well-motivated online data selection method based on Taylor series expansions (with additional approximations) and apply it to training/fine-tuning LLMs. The paper's results show good performance improvements on fine-tuning tasks, but little gains on pre-training tasks.","The paper is very well motivated, and tackles a problem which has clear significance to large scale model training.

The problem setup is very intuitive and straightforward: select the data points now which would maximize utility after one model update step.

The paper is also relatively well written. The method is clearly derived and explained -- most/each introduced approximation is accompanied by a clear interpretation.  I most enjoyed reading section 3.2 -- splitting out the importance score of a sample and correcting it based on the scores of previously seen samples is very neat.

The paper includes several relevant experiments (most on fine-tuning) -- using a few relevant baselines. The results appear strong, in general, when compared to the selected baselines.","I gave the paper a rating of 5 mostly because of the limited evaluation. Simple baselines are just missing from the paper, e.g.: (1) a classifier to detect similarity to validation data and (2) rho loss. I would be happy to increase my rating if these baselines are added to the paper.

To clarify, regarding rho loss, I do not find the argument in line 262-263 at all convincing. In a separate pass, you can just label the training data with per token losses from a pre-trained reference model. No extra training flops needed over the ""Max Loss"" baseline.

Note that influence functions [Koh & Liang] (in the context of LLMs too [Grosse et al.]) are not discussed anywhere, even though they are closely related with the method proposed here. The difference is that influence functions look at final performance and the paper here looks at 1-step performance. It would be great to see what happens when consider n-step unrolls, i.e., and use the influence functions formulation -- of course, this could be left specifically for future work.

The runtime complexity (i.e. number of flops) of the GREATS algorithm is missing (under every condition) and is not compared to that of regular training. Indeed runtime comparisons (i.e. in seconds) are useful, they are a bit incomplete.

A minor point is that the argument in lines 28-29 is tenuous at best (""Moreover, online batch selection operates on smaller batches of data, reducing the need for cumbersome data preprocessing and enabling more efficient use of computational resources compared to static data selection methods that process the entire dataset upfront"".) It is much more convenient to pre-cache the data when training these models. At training time, one really just wants to use accelerators as efficiently as possible. 

[Koh & Liang] Understanding Black-box Predictions via Influence Functions
[Grosse] Studying Large Language Model Generalization with Influence Functions","- It is unclear when the Hessian is set to the identity in all GREATS experiments. I assume H=I always, as otherwise the runtime would blow up. Is this assumption correct?

- How did you choose the (up to 16) validation dataset points? Randomly?",The authors have moderately addressed the limitations of their work. I've pointed out what else I was expecting to see in the weaknesses section.,['No ethics review needed.'],7,4,,Yes,2,3,3,1720711941698,,,NeurIPS.cc/2024/Conference,232VcN8tSx,"['NeurIPS.cc/2024/Conference/Submission20576/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880120816,[],2,,,['everyone'],232VcN8tSx,['NeurIPS.cc/2024/Conference/Submission20576/Reviewer_SyBn'],1720711941698,1730880120816,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission20576/Reviewer_SyBn']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. [Koh & Liang] ""Understanding Black-box Predictions via Influence Functions""
2. [Grosse] ""Studying Large Language Model Generalization with Influence Functions""

The reviewer mentions that influence functions are closely related to the method proposed in the paper and suggests that the authors should discuss them, particularly in the context of looking at final performance versus 1-step performance.",1,,Understanding Black-box Predictions via Influence Functions 
M4cArrxQcz,"The paper introduces a well-motivated online data selection method based on Taylor series expansions (with additional approximations) and apply it to training/fine-tuning LLMs. The paper's results show good performance improvements on fine-tuning tasks, but little gains on pre-training tasks.","The paper is very well motivated, and tackles a problem which has clear significance to large scale model training.

The problem setup is very intuitive and straightforward: select the data points now which would maximize utility after one model update step.

The paper is also relatively well written. The method is clearly derived and explained -- most/each introduced approximation is accompanied by a clear interpretation.  I most enjoyed reading section 3.2 -- splitting out the importance score of a sample and correcting it based on the scores of previously seen samples is very neat.

The paper includes several relevant experiments (most on fine-tuning) -- using a few relevant baselines. The results appear strong, in general, when compared to the selected baselines.","I gave the paper a rating of 5 mostly because of the limited evaluation. Simple baselines are just missing from the paper, e.g.: (1) a classifier to detect similarity to validation data and (2) rho loss. I would be happy to increase my rating if these baselines are added to the paper.

To clarify, regarding rho loss, I do not find the argument in line 262-263 at all convincing. In a separate pass, you can just label the training data with per token losses from a pre-trained reference model. No extra training flops needed over the ""Max Loss"" baseline.

Note that influence functions [Koh & Liang] (in the context of LLMs too [Grosse et al.]) are not discussed anywhere, even though they are closely related with the method proposed here. The difference is that influence functions look at final performance and the paper here looks at 1-step performance. It would be great to see what happens when consider n-step unrolls, i.e., and use the influence functions formulation -- of course, this could be left specifically for future work.

The runtime complexity (i.e. number of flops) of the GREATS algorithm is missing (under every condition) and is not compared to that of regular training. Indeed runtime comparisons (i.e. in seconds) are useful, they are a bit incomplete.

A minor point is that the argument in lines 28-29 is tenuous at best (""Moreover, online batch selection operates on smaller batches of data, reducing the need for cumbersome data preprocessing and enabling more efficient use of computational resources compared to static data selection methods that process the entire dataset upfront"".) It is much more convenient to pre-cache the data when training these models. At training time, one really just wants to use accelerators as efficiently as possible. 

[Koh & Liang] Understanding Black-box Predictions via Influence Functions
[Grosse] Studying Large Language Model Generalization with Influence Functions","- It is unclear when the Hessian is set to the identity in all GREATS experiments. I assume H=I always, as otherwise the runtime would blow up. Is this assumption correct?

- How did you choose the (up to 16) validation dataset points? Randomly?",The authors have moderately addressed the limitations of their work. I've pointed out what else I was expecting to see in the weaknesses section.,['No ethics review needed.'],7,4,,Yes,2,3,3,1720711941698,,,NeurIPS.cc/2024/Conference,232VcN8tSx,"['NeurIPS.cc/2024/Conference/Submission20576/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880120816,[],2,,,['everyone'],232VcN8tSx,['NeurIPS.cc/2024/Conference/Submission20576/Reviewer_SyBn'],1720711941698,1730880120816,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission20576/Reviewer_SyBn']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. [Koh & Liang] ""Understanding Black-box Predictions via Influence Functions""
2. [Grosse] ""Studying Large Language Model Generalization with Influence Functions""

The reviewer mentions that influence functions are closely related to the method proposed in the paper and suggests that the authors should discuss them, particularly in the context of looking at final performance versus 1-step performance.",1,,Studying Large Language Model Generalization with Influence Functions
Cx54tAZ1n2,"In the paper, authors propose a novel framework, G3, for worldwide geolocalization of a given photograph anywhere on Earth. The authors address the challenges of capturing location-specific visual cues and handling variations in image data distribution across the globe. G3 utilizes a three-step process: Geo-alignment, which learns location-aware image representations, Geo-diversification, which employs multiple retrieval-augmented prompts for robust location prediction, and Geo-verification, which combines retrieved and generated location data for final prediction. The authors also introduce the MP16-Pro dataset to support location-aware visual representation learning. Experiments on the IM2GPS3k and YFCC4K datasets demonstrate the superiority of G3 over existing methods.","* All the modules in the G3 framework: Geo Alignment, Geo Diversification and Geo Verification seem logical and rational. Three kinds of embedding coming from the vision encoder are used for retrieval. LLM is used to generate a set of plausible coordinates by providing positive and negative examples.
* The method achieves superior performance over several baselines at various levels of granularity on IM2GPS3k and YFCC4K.
* Overall, the method is interesting and novel, the writing and flow of the paper is meaningful.","* The only limitation discussed is regarding the efficiency of inference. However, there is no mention of how much compute time and memory (in number) is required to geo-localize a given input image. 
* There are no concrete qualitative example of failures reported in the paper. Can the system be fooled easily? For example, if an image from Italy contains a human with a flag of The Netherlands, is the system capable of correctly geolocalizing the image? How does the RAG system along with the LLM perform in such a case?
* Limited evaluation considering the state-of-the-art. No mention of recent works such as Pigeon [1] or a GeoReasoner [2].
* Why did the authors choose to use CLIP vision encoder for extracting image features? Recent works have shown that purely image-based pretrained models such as DINO-v2 are better feature extractors than CLIP. No ablation study done for the choice of the vision encoder.
* Overall, from discussion in **L316-L333** and Figure 4, it looks like the number of references provided to LLM highly depends and varies based on the image content. The performance is highly sensitive to this hyperparameter and a single value cannot guarantee optimal performance. This can make the framework highly unreliable for practical use cases.

[1] Haas, Lukas, Michal Skreta, Silas Alberti, and Chelsea Finn. ""Pigeon: Predicting image geolocations."" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 12893-12902. 2024

[2] Li, Ling, Yu Ye, Bingchuan Jiang, and Wei Zeng. ""GeoReasoner: Geo-localization with Reasoning in Street Views using a Large Vision-Language Model."" In Forty-first International Conference on Machine Learning.","* There is only a marginal improvement in performance when including the geo-diversification step considering it is potentially the most expensive step during the inference.
* Currently, the text associated with each coordinate only includes the country and city labels. Will the performance of the framework improve by including fine-grained details such as region and/or street name?",Limitations are included but failure cases are missing.,['No ethics review needed.'],6,5,,Yes,3,3,4,1720562918014,,,NeurIPS.cc/2024/Conference,21tn63ee15,"['NeurIPS.cc/2024/Conference/Submission5376/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878996770,[],1,,,['everyone'],21tn63ee15,['NeurIPS.cc/2024/Conference/Submission5376/Reviewer_CzZb'],1720562918014,1730878996770,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5376/Reviewer_CzZb']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. ""Pigeon: Predicting image geolocations"" by Haas et al. (2024)
2. ""GeoReasoner: Geo-localization with Reasoning in Street Views using a Large Vision-Language Model"" by Li et al.

The reviewer mentions that the authors should consider including these recent works in their evaluation, as they are relevant to the topic of geolocalization and could provide a more comprehensive comparison with the state-of-the-art methods.",1,2024,Pigeon Predicting image geolocations 
Cx54tAZ1n2,"In the paper, authors propose a novel framework, G3, for worldwide geolocalization of a given photograph anywhere on Earth. The authors address the challenges of capturing location-specific visual cues and handling variations in image data distribution across the globe. G3 utilizes a three-step process: Geo-alignment, which learns location-aware image representations, Geo-diversification, which employs multiple retrieval-augmented prompts for robust location prediction, and Geo-verification, which combines retrieved and generated location data for final prediction. The authors also introduce the MP16-Pro dataset to support location-aware visual representation learning. Experiments on the IM2GPS3k and YFCC4K datasets demonstrate the superiority of G3 over existing methods.","* All the modules in the G3 framework: Geo Alignment, Geo Diversification and Geo Verification seem logical and rational. Three kinds of embedding coming from the vision encoder are used for retrieval. LLM is used to generate a set of plausible coordinates by providing positive and negative examples.
* The method achieves superior performance over several baselines at various levels of granularity on IM2GPS3k and YFCC4K.
* Overall, the method is interesting and novel, the writing and flow of the paper is meaningful.","* The only limitation discussed is regarding the efficiency of inference. However, there is no mention of how much compute time and memory (in number) is required to geo-localize a given input image. 
* There are no concrete qualitative example of failures reported in the paper. Can the system be fooled easily? For example, if an image from Italy contains a human with a flag of The Netherlands, is the system capable of correctly geolocalizing the image? How does the RAG system along with the LLM perform in such a case?
* Limited evaluation considering the state-of-the-art. No mention of recent works such as Pigeon [1] or a GeoReasoner [2].
* Why did the authors choose to use CLIP vision encoder for extracting image features? Recent works have shown that purely image-based pretrained models such as DINO-v2 are better feature extractors than CLIP. No ablation study done for the choice of the vision encoder.
* Overall, from discussion in **L316-L333** and Figure 4, it looks like the number of references provided to LLM highly depends and varies based on the image content. The performance is highly sensitive to this hyperparameter and a single value cannot guarantee optimal performance. This can make the framework highly unreliable for practical use cases.

[1] Haas, Lukas, Michal Skreta, Silas Alberti, and Chelsea Finn. ""Pigeon: Predicting image geolocations."" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 12893-12902. 2024

[2] Li, Ling, Yu Ye, Bingchuan Jiang, and Wei Zeng. ""GeoReasoner: Geo-localization with Reasoning in Street Views using a Large Vision-Language Model."" In Forty-first International Conference on Machine Learning.","* There is only a marginal improvement in performance when including the geo-diversification step considering it is potentially the most expensive step during the inference.
* Currently, the text associated with each coordinate only includes the country and city labels. Will the performance of the framework improve by including fine-grained details such as region and/or street name?",Limitations are included but failure cases are missing.,['No ethics review needed.'],6,5,,Yes,3,3,4,1720562918014,,,NeurIPS.cc/2024/Conference,21tn63ee15,"['NeurIPS.cc/2024/Conference/Submission5376/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878996770,[],1,,,['everyone'],21tn63ee15,['NeurIPS.cc/2024/Conference/Submission5376/Reviewer_CzZb'],1720562918014,1730878996770,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5376/Reviewer_CzZb']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. ""Pigeon: Predicting image geolocations"" by Haas et al. (2024)
2. ""GeoReasoner: Geo-localization with Reasoning in Street Views using a Large Vision-Language Model"" by Li et al.

The reviewer mentions that the authors should consider including these recent works in their evaluation, as they are relevant to the topic of geolocalization and could provide a more comprehensive comparison with the state-of-the-art methods.",1,2024,GeoReasoner Geo-localization with Reasoning in Street Views using a Large Vision-Language Model
vCeWl0pFpw,"This paper presents a collaborative framework for multi-drone object trajectory prediction, named DHD, which consists of two specifically designed components: the GBG module, aimed at generating more accurate BEV representations in aerial scenes, and the SISW module, which adaptively selects regions for collaborative interactions. Additionally, a simulated multi-drone collaborative observation dataset is created to demonstrate the effectiveness of the proposed DHD framework.","- This paper successfully implements an end-to-end multi-drone object trajectory prediction based purely on visual inputs and extends it to the collaborative object detection task. This work fills in the blank of end-to-end multi-drone collaborative prediction, demonstrating notable originality.
- The proposed GBG module innovatively leverages the unique inclined observations from drone perspectives as geometric priors and replaces traditional depth estimation with height estimation. These enhancements significantly improve the accuracy of BEV representations for long-range aerial observations compared to the listed baselines, such as LSS and DVDET.
- This paper presents an efficient communication strategy called SISW, which considers both the limited inter-drone communication and the prediction task's dependency on foreground and contextual information. Experimental results indicate that this design outperforms previous sparse interaction strategies like where2comm.
- A simulated dataset, ""Air-Co-Pred,"" is created to support multi-drone object trajectory prediction. The dataset enriches the available resources within the multi-drone field and can serve as a valuable benchmark for future research.","- The authors need to carefully review the paper for grammar mistakes, typos, and formatting errors. Specific issues include:
    - Line 82: BEV's full-term appears redundantly.
    - Line 119: The subscript in$ Y_{k}^{o} $ is incorrect and should be$ Y_{k}^{t_o} $.
    - Line 152: Figure reference is incorrect.
    - Line 221: ""2HZ"" is improperly formatted and should be ""2Hz.""
    - Equation 6: The subscript next to $ \Sigma $ should be $ xy $ instead of $ hw $.  
Addressing these issues will improve the paper's readability.

- The transmission volumes for various collaboration strategies in Table 2 are unclear. It would be beneficial to supplement this information to better reflect the balance between the performance improvements in prediction and the cost of collaborative interactions. Additionally, it appears that the results of DHD in Table 2 are not the best in every column, so why are they bolded?
- Please consider exploring scenarios where the number of drones varies from 1 to 4. This would help investigate the impact of drone quantity on perception enhancement and also reflect the influence of potential drone failures on performance metrics.
- In reality, extrinsic parameters are derived through computation and approximation, leading to certain biases. Please explore how the extent of extrinsic bias affects the performance of collaborative prediction.","- Could you provide more details about Air-Co-Pred, including the drone attitude settings, flight patterns, the speed of objects, etc.? Why were four drones chosen to collect data? 
- In Section 3.3, the equation regarding the derivation of the depth upper-bound is presented directly without any intermediate steps in the main text or supplementary materials. Please provide the detailed derivation process to help readers understand it better.
- The reviewer found that the proposed GBG module is highly relevant to the applications of camera intrinsics and extrinsic in UAVs. The reviewer encourages the authors to acknowledge the existence of related works and clarify the differences. 
For reference, see:  
Shen H, Lin D, Yang X, et al. Vision-Based Multi-Object Tracking through UAV Swarm[J]. IEEE Geoscience and Remote Sensing Letters, 2023.  
Pan T, Dong H, Deng B, et al. Robust Cross-Drone Multi-Target Association Using 3D Spatial Consistency[J]. IEEE Signal Processing Letters, 2023.  
- Considering the complexity of the proposed framework, could you provide additional details or code for better understanding and reproducibility?","The authors acknowledge that the current focus of this paper is on simulated environments to investigate multi-drone object trajectory prediction without considering latency and camera noise. These are reasonable limitations, and addressing them in future work would be beneficial",['No ethics review needed.'],7,5,,Yes,3,3,4,1720355566371,,,NeurIPS.cc/2024/Conference,20QgErW5zH,"['NeurIPS.cc/2024/Conference/Submission9889/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879346821,[],1,,,['everyone'],20QgErW5zH,['NeurIPS.cc/2024/Conference/Submission9889/Reviewer_vjyF'],1720355566371,1730879346821,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9889/Reviewer_vjyF']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two papers:

1. Shen H, Lin D, Yang X, et al. Vision-Based Multi-Object Tracking through UAV Swarm[J]. IEEE Geoscience and Remote Sensing Letters, 2023.
2. Pan T, Dong H, Deng B, et al. Robust Cross-Drone Multi-Target Association Using 3D Spatial Consistency[J]. IEEE Signal Processing Letters, 2023.

The reviewer encourages the authors to acknowledge the existence of these related works and clarify the differences between their proposed GBG module and these existing studies.",1,"2023, 2023",Vision-Based Multi-Object Tracking through UAV Swarm 
vCeWl0pFpw,"This paper presents a collaborative framework for multi-drone object trajectory prediction, named DHD, which consists of two specifically designed components: the GBG module, aimed at generating more accurate BEV representations in aerial scenes, and the SISW module, which adaptively selects regions for collaborative interactions. Additionally, a simulated multi-drone collaborative observation dataset is created to demonstrate the effectiveness of the proposed DHD framework.","- This paper successfully implements an end-to-end multi-drone object trajectory prediction based purely on visual inputs and extends it to the collaborative object detection task. This work fills in the blank of end-to-end multi-drone collaborative prediction, demonstrating notable originality.
- The proposed GBG module innovatively leverages the unique inclined observations from drone perspectives as geometric priors and replaces traditional depth estimation with height estimation. These enhancements significantly improve the accuracy of BEV representations for long-range aerial observations compared to the listed baselines, such as LSS and DVDET.
- This paper presents an efficient communication strategy called SISW, which considers both the limited inter-drone communication and the prediction task's dependency on foreground and contextual information. Experimental results indicate that this design outperforms previous sparse interaction strategies like where2comm.
- A simulated dataset, ""Air-Co-Pred,"" is created to support multi-drone object trajectory prediction. The dataset enriches the available resources within the multi-drone field and can serve as a valuable benchmark for future research.","- The authors need to carefully review the paper for grammar mistakes, typos, and formatting errors. Specific issues include:
    - Line 82: BEV's full-term appears redundantly.
    - Line 119: The subscript in$ Y_{k}^{o} $ is incorrect and should be$ Y_{k}^{t_o} $.
    - Line 152: Figure reference is incorrect.
    - Line 221: ""2HZ"" is improperly formatted and should be ""2Hz.""
    - Equation 6: The subscript next to $ \Sigma $ should be $ xy $ instead of $ hw $.  
Addressing these issues will improve the paper's readability.

- The transmission volumes for various collaboration strategies in Table 2 are unclear. It would be beneficial to supplement this information to better reflect the balance between the performance improvements in prediction and the cost of collaborative interactions. Additionally, it appears that the results of DHD in Table 2 are not the best in every column, so why are they bolded?
- Please consider exploring scenarios where the number of drones varies from 1 to 4. This would help investigate the impact of drone quantity on perception enhancement and also reflect the influence of potential drone failures on performance metrics.
- In reality, extrinsic parameters are derived through computation and approximation, leading to certain biases. Please explore how the extent of extrinsic bias affects the performance of collaborative prediction.","- Could you provide more details about Air-Co-Pred, including the drone attitude settings, flight patterns, the speed of objects, etc.? Why were four drones chosen to collect data? 
- In Section 3.3, the equation regarding the derivation of the depth upper-bound is presented directly without any intermediate steps in the main text or supplementary materials. Please provide the detailed derivation process to help readers understand it better.
- The reviewer found that the proposed GBG module is highly relevant to the applications of camera intrinsics and extrinsic in UAVs. The reviewer encourages the authors to acknowledge the existence of related works and clarify the differences. 
For reference, see:  
Shen H, Lin D, Yang X, et al. Vision-Based Multi-Object Tracking through UAV Swarm[J]. IEEE Geoscience and Remote Sensing Letters, 2023.  
Pan T, Dong H, Deng B, et al. Robust Cross-Drone Multi-Target Association Using 3D Spatial Consistency[J]. IEEE Signal Processing Letters, 2023.  
- Considering the complexity of the proposed framework, could you provide additional details or code for better understanding and reproducibility?","The authors acknowledge that the current focus of this paper is on simulated environments to investigate multi-drone object trajectory prediction without considering latency and camera noise. These are reasonable limitations, and addressing them in future work would be beneficial",['No ethics review needed.'],7,5,,Yes,3,3,4,1720355566371,,,NeurIPS.cc/2024/Conference,20QgErW5zH,"['NeurIPS.cc/2024/Conference/Submission9889/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879346821,[],1,,,['everyone'],20QgErW5zH,['NeurIPS.cc/2024/Conference/Submission9889/Reviewer_vjyF'],1720355566371,1730879346821,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9889/Reviewer_vjyF']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two papers:

1. Shen H, Lin D, Yang X, et al. Vision-Based Multi-Object Tracking through UAV Swarm[J]. IEEE Geoscience and Remote Sensing Letters, 2023.
2. Pan T, Dong H, Deng B, et al. Robust Cross-Drone Multi-Target Association Using 3D Spatial Consistency[J]. IEEE Signal Processing Letters, 2023.

The reviewer encourages the authors to acknowledge the existence of these related works and clarify the differences between their proposed GBG module and these existing studies.",1,"2023, 2023",Robust Cross-Drone Multi-Target Association Using 3D Spatial Consistency
JgQORS2MpL,"This paper proposes a framework, Drones Help Drones (DHD), which tackles trajectory prediction of objects in the scene. DHD consists of a Ground Prior Based Bird’s Eye View (BEV) Generation (GBG) module, which provides depth estimation from the drone to an object using ground priors to create an accurate BEV representation of the features. It also utilises Sparse Interaction via Sliding Window (SISW) to minimize the data transmission cost between drones. In addition, the authors develop a new dataset for multi-drone collaboration prediction, ""Air-Co-Pred"". The paper is interesting in the field of collaborative AI.","The paper is well-structured, referencing a well-established research stream in computer vision and collaborative object trajectory prediction. The following are some strengths of the paper:
- The research problem is clearly described with good visuals and diagrams, which aid in the explanation.
- There are several contributions, including BEV generation, sliding windows for sparse interaction, and Air-Co-Pred simulated dataset
- The paper provides both quantitative and qualitative assessments of their framework, compared to baseline and state-of-the-art, such as Who2com and Where2com. It demonstrates good improvements.
- The provided appendices are useful for further details and ablation studies.","The paper has several weaknesses:
- It investigates methods to overcome single-drone issues, such as occlusions and blurs; nevertheless, it is also important to discuss a bigger picture of their use cases, including accident prevention and path planning, in greater details with certain limitations. For example, in accident prevention, if multiple drones collaborate and predict an accident is about to happen, what can it do? Does it then communicate/inject commands over the air to the vehicle causing certain actions?
- The DHD framework consists of feature extraction, BEV, Sparse Interaction via Sliding Windows, and Trajectory Prediction. The idea of having sliding windows for sparse interaction is quite interesting; nevertheless, relying on a local coordinate system and pixel-level weight fusion can be a weak spot when it comes to real-world settings. It is also important to examine how each of the modules contributes to the overall performance in ablation studies.
- The development of Air-Co-Pred remains questionable, based on CARLA. There are indeed many CARLA-based datasets and it is important to compare your dataset with others to prevent overlappings/duplications.
- It is vital to discuss the following papers, in relation to the work:
1. Wei, S., Wei, Y., Hu, Y., Lu, Y., Zhong, Y., Chen, S., & Zhang, Y. (2024). Asynchrony-robust collaborative perception via bird's eye view flow. Advances in Neural Information Processing Systems, 36.
2. Lu, Y., Hu, Y., Zhong, Y., Wang, D., Chen, S., & Wang, Y. (2024). An extensible framework for open heterogeneous collaborative perception. arXiv preprint arXiv:2401.13964.
3. Liang, J., Jiang, L., & Hauptmann, A. (2020). Simaug: Learning robust representations from simulation for trajectory prediction. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XIII 16 (pp. 275-292). Springer International Publishing.","There are many questions to address as the following:
- With the DHD framework, given objects to track/predict, what is the optimal number of drones that need to be “watching” the object in order to produce the best prediction? Is it always the case that the more drones that have the object in view, the better the trajectory prediction? Why four collaborative drones in Air-Co-Pred? Can we get away with just 2 drones? 
- Can you explain more about why CARLA is used to simulate and produce the dataset? Has anyone attempted trajectory prediction with multiple drones in real-world settings? Is it feasible? What needs to happen before DHD can be deployed in production in the real-world setting? Maybe it can be included in a discussion section.
Is there an optimal drone height/altitude? Is 50 meters the best height value, so it’s used in the dataset?
- How often should the drones be communicating/transmitting data to each other? Is it the same as the aerial observation samples being collected (frequency of 2 Hz)? Can it be reduced to further lower transmission data?
- How does the DHD framework respond to noises, such as flight turbulence?
- What will be the performance if we turn on/off multiple components, such as BEV or Sparse Interaction? This should be included in ablation studies.
- How far are we from real-world experiments?
- What will be the impacts of your study to the field?","The authors have raised concerns about the use of simulated settings, which limit the research's practicality. It is important to develop real-world scenarios for future validations of the research.",['No ethics review needed.'],5,4,,Yes,3,3,3,1721941005598,,,NeurIPS.cc/2024/Conference,20QgErW5zH,"['NeurIPS.cc/2024/Conference/Submission9889/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879346232,[],5,,,['everyone'],20QgErW5zH,['NeurIPS.cc/2024/Conference/Submission9889/Reviewer_CzWU'],1721941005598,1730879346232,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9889/Reviewer_CzWU']","Yes, this peer review explicitly suggests the authors of the paper to cite three specific literature references:

1. Wei, S., Wei, Y., Hu, Y., Lu, Y., Zhong, Y., Chen, S., & Zhang, Y. (2024). Asynchrony-robust collaborative perception via bird's eye view flow. Advances in Neural Information Processing Systems, 36.
2. Lu, Y., Hu, Y., Zhong, Y., Wang, D., Chen, S., & Wang, Y. (2024). An extensible framework for open heterogeneous collaborative perception. arXiv preprint arXiv:2401.13964.
3. Liang, J., Jiang, L., & Hauptmann, A. (2020). Simaug: Learning robust representations from simulation for trajectory prediction. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XIII 16 (pp. 275-292). Springer International Publishing.

The reviewer mentions that it is vital to discuss these papers in relation to the work presented in the paper.",1,"2024, 2024, 2024, 2020, 2020, 2020",Asynchrony-robust collaborative perception via bird's eye view flow 
JgQORS2MpL,"This paper proposes a framework, Drones Help Drones (DHD), which tackles trajectory prediction of objects in the scene. DHD consists of a Ground Prior Based Bird’s Eye View (BEV) Generation (GBG) module, which provides depth estimation from the drone to an object using ground priors to create an accurate BEV representation of the features. It also utilises Sparse Interaction via Sliding Window (SISW) to minimize the data transmission cost between drones. In addition, the authors develop a new dataset for multi-drone collaboration prediction, ""Air-Co-Pred"". The paper is interesting in the field of collaborative AI.","The paper is well-structured, referencing a well-established research stream in computer vision and collaborative object trajectory prediction. The following are some strengths of the paper:
- The research problem is clearly described with good visuals and diagrams, which aid in the explanation.
- There are several contributions, including BEV generation, sliding windows for sparse interaction, and Air-Co-Pred simulated dataset
- The paper provides both quantitative and qualitative assessments of their framework, compared to baseline and state-of-the-art, such as Who2com and Where2com. It demonstrates good improvements.
- The provided appendices are useful for further details and ablation studies.","The paper has several weaknesses:
- It investigates methods to overcome single-drone issues, such as occlusions and blurs; nevertheless, it is also important to discuss a bigger picture of their use cases, including accident prevention and path planning, in greater details with certain limitations. For example, in accident prevention, if multiple drones collaborate and predict an accident is about to happen, what can it do? Does it then communicate/inject commands over the air to the vehicle causing certain actions?
- The DHD framework consists of feature extraction, BEV, Sparse Interaction via Sliding Windows, and Trajectory Prediction. The idea of having sliding windows for sparse interaction is quite interesting; nevertheless, relying on a local coordinate system and pixel-level weight fusion can be a weak spot when it comes to real-world settings. It is also important to examine how each of the modules contributes to the overall performance in ablation studies.
- The development of Air-Co-Pred remains questionable, based on CARLA. There are indeed many CARLA-based datasets and it is important to compare your dataset with others to prevent overlappings/duplications.
- It is vital to discuss the following papers, in relation to the work:
1. Wei, S., Wei, Y., Hu, Y., Lu, Y., Zhong, Y., Chen, S., & Zhang, Y. (2024). Asynchrony-robust collaborative perception via bird's eye view flow. Advances in Neural Information Processing Systems, 36.
2. Lu, Y., Hu, Y., Zhong, Y., Wang, D., Chen, S., & Wang, Y. (2024). An extensible framework for open heterogeneous collaborative perception. arXiv preprint arXiv:2401.13964.
3. Liang, J., Jiang, L., & Hauptmann, A. (2020). Simaug: Learning robust representations from simulation for trajectory prediction. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XIII 16 (pp. 275-292). Springer International Publishing.","There are many questions to address as the following:
- With the DHD framework, given objects to track/predict, what is the optimal number of drones that need to be “watching” the object in order to produce the best prediction? Is it always the case that the more drones that have the object in view, the better the trajectory prediction? Why four collaborative drones in Air-Co-Pred? Can we get away with just 2 drones? 
- Can you explain more about why CARLA is used to simulate and produce the dataset? Has anyone attempted trajectory prediction with multiple drones in real-world settings? Is it feasible? What needs to happen before DHD can be deployed in production in the real-world setting? Maybe it can be included in a discussion section.
Is there an optimal drone height/altitude? Is 50 meters the best height value, so it’s used in the dataset?
- How often should the drones be communicating/transmitting data to each other? Is it the same as the aerial observation samples being collected (frequency of 2 Hz)? Can it be reduced to further lower transmission data?
- How does the DHD framework respond to noises, such as flight turbulence?
- What will be the performance if we turn on/off multiple components, such as BEV or Sparse Interaction? This should be included in ablation studies.
- How far are we from real-world experiments?
- What will be the impacts of your study to the field?","The authors have raised concerns about the use of simulated settings, which limit the research's practicality. It is important to develop real-world scenarios for future validations of the research.",['No ethics review needed.'],5,4,,Yes,3,3,3,1721941005598,,,NeurIPS.cc/2024/Conference,20QgErW5zH,"['NeurIPS.cc/2024/Conference/Submission9889/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879346232,[],5,,,['everyone'],20QgErW5zH,['NeurIPS.cc/2024/Conference/Submission9889/Reviewer_CzWU'],1721941005598,1730879346232,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9889/Reviewer_CzWU']","Yes, this peer review explicitly suggests the authors of the paper to cite three specific literature references:

1. Wei, S., Wei, Y., Hu, Y., Lu, Y., Zhong, Y., Chen, S., & Zhang, Y. (2024). Asynchrony-robust collaborative perception via bird's eye view flow. Advances in Neural Information Processing Systems, 36.
2. Lu, Y., Hu, Y., Zhong, Y., Wang, D., Chen, S., & Wang, Y. (2024). An extensible framework for open heterogeneous collaborative perception. arXiv preprint arXiv:2401.13964.
3. Liang, J., Jiang, L., & Hauptmann, A. (2020). Simaug: Learning robust representations from simulation for trajectory prediction. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XIII 16 (pp. 275-292). Springer International Publishing.

The reviewer mentions that it is vital to discuss these papers in relation to the work presented in the paper.",1,"2024, 2024, 2024, 2020, 2020, 2020",An extensible framework for open heterogeneous collaborative perception 
JgQORS2MpL,"This paper proposes a framework, Drones Help Drones (DHD), which tackles trajectory prediction of objects in the scene. DHD consists of a Ground Prior Based Bird’s Eye View (BEV) Generation (GBG) module, which provides depth estimation from the drone to an object using ground priors to create an accurate BEV representation of the features. It also utilises Sparse Interaction via Sliding Window (SISW) to minimize the data transmission cost between drones. In addition, the authors develop a new dataset for multi-drone collaboration prediction, ""Air-Co-Pred"". The paper is interesting in the field of collaborative AI.","The paper is well-structured, referencing a well-established research stream in computer vision and collaborative object trajectory prediction. The following are some strengths of the paper:
- The research problem is clearly described with good visuals and diagrams, which aid in the explanation.
- There are several contributions, including BEV generation, sliding windows for sparse interaction, and Air-Co-Pred simulated dataset
- The paper provides both quantitative and qualitative assessments of their framework, compared to baseline and state-of-the-art, such as Who2com and Where2com. It demonstrates good improvements.
- The provided appendices are useful for further details and ablation studies.","The paper has several weaknesses:
- It investigates methods to overcome single-drone issues, such as occlusions and blurs; nevertheless, it is also important to discuss a bigger picture of their use cases, including accident prevention and path planning, in greater details with certain limitations. For example, in accident prevention, if multiple drones collaborate and predict an accident is about to happen, what can it do? Does it then communicate/inject commands over the air to the vehicle causing certain actions?
- The DHD framework consists of feature extraction, BEV, Sparse Interaction via Sliding Windows, and Trajectory Prediction. The idea of having sliding windows for sparse interaction is quite interesting; nevertheless, relying on a local coordinate system and pixel-level weight fusion can be a weak spot when it comes to real-world settings. It is also important to examine how each of the modules contributes to the overall performance in ablation studies.
- The development of Air-Co-Pred remains questionable, based on CARLA. There are indeed many CARLA-based datasets and it is important to compare your dataset with others to prevent overlappings/duplications.
- It is vital to discuss the following papers, in relation to the work:
1. Wei, S., Wei, Y., Hu, Y., Lu, Y., Zhong, Y., Chen, S., & Zhang, Y. (2024). Asynchrony-robust collaborative perception via bird's eye view flow. Advances in Neural Information Processing Systems, 36.
2. Lu, Y., Hu, Y., Zhong, Y., Wang, D., Chen, S., & Wang, Y. (2024). An extensible framework for open heterogeneous collaborative perception. arXiv preprint arXiv:2401.13964.
3. Liang, J., Jiang, L., & Hauptmann, A. (2020). Simaug: Learning robust representations from simulation for trajectory prediction. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XIII 16 (pp. 275-292). Springer International Publishing.","There are many questions to address as the following:
- With the DHD framework, given objects to track/predict, what is the optimal number of drones that need to be “watching” the object in order to produce the best prediction? Is it always the case that the more drones that have the object in view, the better the trajectory prediction? Why four collaborative drones in Air-Co-Pred? Can we get away with just 2 drones? 
- Can you explain more about why CARLA is used to simulate and produce the dataset? Has anyone attempted trajectory prediction with multiple drones in real-world settings? Is it feasible? What needs to happen before DHD can be deployed in production in the real-world setting? Maybe it can be included in a discussion section.
Is there an optimal drone height/altitude? Is 50 meters the best height value, so it’s used in the dataset?
- How often should the drones be communicating/transmitting data to each other? Is it the same as the aerial observation samples being collected (frequency of 2 Hz)? Can it be reduced to further lower transmission data?
- How does the DHD framework respond to noises, such as flight turbulence?
- What will be the performance if we turn on/off multiple components, such as BEV or Sparse Interaction? This should be included in ablation studies.
- How far are we from real-world experiments?
- What will be the impacts of your study to the field?","The authors have raised concerns about the use of simulated settings, which limit the research's practicality. It is important to develop real-world scenarios for future validations of the research.",['No ethics review needed.'],5,4,,Yes,3,3,3,1721941005598,,,NeurIPS.cc/2024/Conference,20QgErW5zH,"['NeurIPS.cc/2024/Conference/Submission9889/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879346232,[],5,,,['everyone'],20QgErW5zH,['NeurIPS.cc/2024/Conference/Submission9889/Reviewer_CzWU'],1721941005598,1730879346232,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9889/Reviewer_CzWU']","Yes, this peer review explicitly suggests the authors of the paper to cite three specific literature references:

1. Wei, S., Wei, Y., Hu, Y., Lu, Y., Zhong, Y., Chen, S., & Zhang, Y. (2024). Asynchrony-robust collaborative perception via bird's eye view flow. Advances in Neural Information Processing Systems, 36.
2. Lu, Y., Hu, Y., Zhong, Y., Wang, D., Chen, S., & Wang, Y. (2024). An extensible framework for open heterogeneous collaborative perception. arXiv preprint arXiv:2401.13964.
3. Liang, J., Jiang, L., & Hauptmann, A. (2020). Simaug: Learning robust representations from simulation for trajectory prediction. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XIII 16 (pp. 275-292). Springer International Publishing.

The reviewer mentions that it is vital to discuss these papers in relation to the work presented in the paper.",1,"2024, 2024, 2024, 2020, 2020, 2020",Simaug: Learning robust representations from simulation for trajectory prediction
pcBmD74X1A,"The authors provide theoretical analysis of the underfitting problem of Laplace approximation. Specifically, they show that the underfitting of Laplace approximation is due to the approximate posterior covariance is not invariant under reparameterization. Moreover, they propose a reparametrization invariant diffusion posterior to address undefitting. The method are evaluated over standard image classification benchmarks. The quality of the uncertainty for both in-distribution and out-of-distribution tasks are considered.","1. The paper provides, to my knowledge, the first theoretical justification of why Laplace approximation sufferes from underfitting: the approximate posterior covariance is not reparameterization invariance.
2. Given the theoretical analysis, the idea of reparametrization invariant posterior is natural and proves to be effective empirically.
3. The paper is easy to follow and well organized.","1. The proposed method, as mentioned by the authors as well, sufferes from more expensive computation. It would be good to report the time metric for readers to properly assess the practicability of the method.
2. The datasets considered are a bit outdated and the networks considred seem to be quite small, such that overall the performance is on the lower end (e.g. <90% acc. for CIFAR10). Recent BDL papers typically consider larger datasets (such as ImageNet) and deeper networks (e.g. [1]). Furthermore, last-layer Laplace seems to be competitive with or even outperform the proposed method in some experiments.
3. The method is tailored to improving Laplace approximation, and there is no discussion related to any other approximate inference techiques (e.g. variational inference).

References
[1] Antoran et al. Sampling-based inference for large linear models with application to linearised Laplace. ICLR 2023.",See weakness.,The authors do not address potential negative social impact since the paper is predominantly theoretical.,['No ethics review needed.'],7,3,,Yes,3,3,3,1720920919429,,,NeurIPS.cc/2024/Conference,204YOrDHny,"['NeurIPS.cc/2024/Conference/Submission18366/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879968819,[],3,,,['everyone'],204YOrDHny,['NeurIPS.cc/2024/Conference/Submission18366/Reviewer_12ke'],1720920919429,1730879968819,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18366/Reviewer_12ke']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

[1] Antoran et al. Sampling-based inference for large linear models with application to linearised Laplace. ICLR 2023.

This is mentioned in the ""weaknesses"" section of the review, where the reviewer notes that recent BDL papers typically consider larger datasets and deeper networks, and cites this specific paper as an example.",1,2023,Sampling-based inference for large linear models with application to linearised Laplace
MUmUbIOd1v,"The paper presents a new method for shape correspondence that extracts descriptors that are both smooth over the manifold and distinctive enough to find high precision point matching. One can view the presented method as an improvement over the 2D-GEM method, that, as opposed to the latter, does not use the eigenfunction of the laplacian and interacts with more the 2-hop neighborhood.  It is extensively tested on various benchmarks in the field, near-isometric and non-isometric ones, and presented promising results.","It presented a descriptor that shows improvement over previous ones. The method is well explained. The related work section is written well, and it adds an important context to the paper. Additionally it extensively tested and presented superior results in comparison to previous methods.","The new method to some extent resembles the 2D-GEM method, which limits the novelty. As presented in the limitation, since it uses the vertex neighborhood it is vulnerable to remeshing, and it counters the statements in the paper about the method usefulness in real data scenarios (overclaiming). 
Small issues: I think [1] should be referred to because of its similarly to the ideas presented in the paper, they also use alignment processing of the initial descriptors by reducing geodesic distance error.

[1] Bracha, A., et al., 2020. Shape correspondence by aligning scale-invariant LBO eigenfunctions. 3DOR: Eurographics Workshop on 3D Object Retrieval",see weaknesses,see weaknesses,['No ethics review needed.'],6,5,,Yes,2,4,3,1719479176663,,,NeurIPS.cc/2024/Conference,1ziIqFo4Tj,"['NeurIPS.cc/2024/Conference/Submission2171/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878754593,[],1,,,['everyone'],1ziIqFo4Tj,['NeurIPS.cc/2024/Conference/Submission2171/Reviewer_hBzn'],1719479176663,1730878754593,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2171/Reviewer_hBzn']","Yes, the peer review explicitly suggests that the authors of the paper should cite a specific literature, namely [1] ""Bracha, A., et al., 2020. Shape correspondence by aligning scale-invariant LBO eigenfunctions. 3DOR: Eurographics Workshop on 3D Object Retrieval"", due to its similarity to the ideas presented in the paper.",1,2020,Shape correspondence by aligning scale-invariant LBO eigenfunctions
nqNs1OE1wo,This paper proposes to make graph-level predictions via distribution comparison between node-level representations and discrete reference distributions. The authors claim that their proposed method avoids the requirements of graph pooling for graph-level tasks. and reduce the risk of information loss. Theoretical and empirical justification results are provided.,"- The authors propose a novel and simple method for graph classification and provide theoretical analysis on the generalization bound. The discussion is clear and extensive.
- The method shows advantage in time cost compared to related works.
- The authors performed extensive ablation study on the proposed method.","- Equation in L138-139 (a missing equation index?) also requires summation over nodes. The description of ""avoid graph pooling operation"" seems to be overclaimed. I suggest that the authors reconsider it.
- An ablation study on the discrimination loss and the usage of node-level representation is required. I think the main improvement in performance may be attributed to the discrimination loss. It helps the model learn distant representations for graphs of different labels in the feature space.  The performance of the proposed method should be compared with and without the discrimination loss. Besides, the authors should also implement a baseline with discrimination loss where node representations are first sum-pooling and then compared with the reference distribution.
- Minor: Latest baseline models are required for a comprehensive empirical comparison, such as graph pooling including SEP[1], GMT[2], and CoCN[3] and graph transformers including Exphormer[4], GRIT[5], and MPNN-VN[6]. Considering the time limitation and the similarity of the datasets, a comparison on part of the datasets will be sufficient.

[1] Structural entropy guided graph hierarchical pooling. ICML'22

[2] Accurate Learning of Graph Representations with Graph Multiset Pooling. ICLR'22

[3] All in a row: Compressed convolution networks for graphs. ICML'23

[4] Exphormer: Sparse Transformers for Graphs. ICML'23

[5] Graph Inductive Biases in Transformers without Message Passing. ICML'23

[6] On the Connection Between MPNN and Graph Transformer. ICML'23",Please refer to the weaknesses.,Yes. The authors describe the limited performances of the proposed method on certain datasets.,['No ethics review needed.'],6,3,,Yes,3,3,2,1720842413917,,,NeurIPS.cc/2024/Conference,1zVinhehks,"['NeurIPS.cc/2024/Conference/Submission10244/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879370968,[],3,,,['everyone'],1zVinhehks,['NeurIPS.cc/2024/Conference/Submission10244/Reviewer_5HH3'],1720842413917,1730879370968,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10244/Reviewer_5HH3']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. SEP [1] - Structural entropy guided graph hierarchical pooling (ICML'22)
2. GMT [2] - Accurate Learning of Graph Representations with Graph Multiset Pooling (ICLR'22)
3. CoCN [3] - All in a row: Compressed convolution networks for graphs (ICML'23)
4. Exphormer [4] - Exphormer: Sparse Transformers for Graphs (ICML'23)
5. GRIT [5] - Graph Inductive Biases in Transformers without Message Passing (ICML'23)
6. MPNN-VN [6] - On the Connection Between MPNN and Graph Transformer (ICML'23)

The reviewer suggests that the authors should compare their proposed method with these latest baseline models for a comprehensive empirical comparison.",1,"2022, 2022, 2023, 2023, 2023, 2023",Structural entropy guided graph hierarchical pooling 
nqNs1OE1wo,This paper proposes to make graph-level predictions via distribution comparison between node-level representations and discrete reference distributions. The authors claim that their proposed method avoids the requirements of graph pooling for graph-level tasks. and reduce the risk of information loss. Theoretical and empirical justification results are provided.,"- The authors propose a novel and simple method for graph classification and provide theoretical analysis on the generalization bound. The discussion is clear and extensive.
- The method shows advantage in time cost compared to related works.
- The authors performed extensive ablation study on the proposed method.","- Equation in L138-139 (a missing equation index?) also requires summation over nodes. The description of ""avoid graph pooling operation"" seems to be overclaimed. I suggest that the authors reconsider it.
- An ablation study on the discrimination loss and the usage of node-level representation is required. I think the main improvement in performance may be attributed to the discrimination loss. It helps the model learn distant representations for graphs of different labels in the feature space.  The performance of the proposed method should be compared with and without the discrimination loss. Besides, the authors should also implement a baseline with discrimination loss where node representations are first sum-pooling and then compared with the reference distribution.
- Minor: Latest baseline models are required for a comprehensive empirical comparison, such as graph pooling including SEP[1], GMT[2], and CoCN[3] and graph transformers including Exphormer[4], GRIT[5], and MPNN-VN[6]. Considering the time limitation and the similarity of the datasets, a comparison on part of the datasets will be sufficient.

[1] Structural entropy guided graph hierarchical pooling. ICML'22

[2] Accurate Learning of Graph Representations with Graph Multiset Pooling. ICLR'22

[3] All in a row: Compressed convolution networks for graphs. ICML'23

[4] Exphormer: Sparse Transformers for Graphs. ICML'23

[5] Graph Inductive Biases in Transformers without Message Passing. ICML'23

[6] On the Connection Between MPNN and Graph Transformer. ICML'23",Please refer to the weaknesses.,Yes. The authors describe the limited performances of the proposed method on certain datasets.,['No ethics review needed.'],6,3,,Yes,3,3,2,1720842413917,,,NeurIPS.cc/2024/Conference,1zVinhehks,"['NeurIPS.cc/2024/Conference/Submission10244/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879370968,[],3,,,['everyone'],1zVinhehks,['NeurIPS.cc/2024/Conference/Submission10244/Reviewer_5HH3'],1720842413917,1730879370968,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10244/Reviewer_5HH3']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. SEP [1] - Structural entropy guided graph hierarchical pooling (ICML'22)
2. GMT [2] - Accurate Learning of Graph Representations with Graph Multiset Pooling (ICLR'22)
3. CoCN [3] - All in a row: Compressed convolution networks for graphs (ICML'23)
4. Exphormer [4] - Exphormer: Sparse Transformers for Graphs (ICML'23)
5. GRIT [5] - Graph Inductive Biases in Transformers without Message Passing (ICML'23)
6. MPNN-VN [6] - On the Connection Between MPNN and Graph Transformer (ICML'23)

The reviewer suggests that the authors should compare their proposed method with these latest baseline models for a comprehensive empirical comparison.",1,"2022, 2022, 2023, 2023, 2023, 2023",Accurate Learning of Graph Representations with Graph Multiset Pooling 
nqNs1OE1wo,This paper proposes to make graph-level predictions via distribution comparison between node-level representations and discrete reference distributions. The authors claim that their proposed method avoids the requirements of graph pooling for graph-level tasks. and reduce the risk of information loss. Theoretical and empirical justification results are provided.,"- The authors propose a novel and simple method for graph classification and provide theoretical analysis on the generalization bound. The discussion is clear and extensive.
- The method shows advantage in time cost compared to related works.
- The authors performed extensive ablation study on the proposed method.","- Equation in L138-139 (a missing equation index?) also requires summation over nodes. The description of ""avoid graph pooling operation"" seems to be overclaimed. I suggest that the authors reconsider it.
- An ablation study on the discrimination loss and the usage of node-level representation is required. I think the main improvement in performance may be attributed to the discrimination loss. It helps the model learn distant representations for graphs of different labels in the feature space.  The performance of the proposed method should be compared with and without the discrimination loss. Besides, the authors should also implement a baseline with discrimination loss where node representations are first sum-pooling and then compared with the reference distribution.
- Minor: Latest baseline models are required for a comprehensive empirical comparison, such as graph pooling including SEP[1], GMT[2], and CoCN[3] and graph transformers including Exphormer[4], GRIT[5], and MPNN-VN[6]. Considering the time limitation and the similarity of the datasets, a comparison on part of the datasets will be sufficient.

[1] Structural entropy guided graph hierarchical pooling. ICML'22

[2] Accurate Learning of Graph Representations with Graph Multiset Pooling. ICLR'22

[3] All in a row: Compressed convolution networks for graphs. ICML'23

[4] Exphormer: Sparse Transformers for Graphs. ICML'23

[5] Graph Inductive Biases in Transformers without Message Passing. ICML'23

[6] On the Connection Between MPNN and Graph Transformer. ICML'23",Please refer to the weaknesses.,Yes. The authors describe the limited performances of the proposed method on certain datasets.,['No ethics review needed.'],6,3,,Yes,3,3,2,1720842413917,,,NeurIPS.cc/2024/Conference,1zVinhehks,"['NeurIPS.cc/2024/Conference/Submission10244/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879370968,[],3,,,['everyone'],1zVinhehks,['NeurIPS.cc/2024/Conference/Submission10244/Reviewer_5HH3'],1720842413917,1730879370968,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10244/Reviewer_5HH3']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. SEP [1] - Structural entropy guided graph hierarchical pooling (ICML'22)
2. GMT [2] - Accurate Learning of Graph Representations with Graph Multiset Pooling (ICLR'22)
3. CoCN [3] - All in a row: Compressed convolution networks for graphs (ICML'23)
4. Exphormer [4] - Exphormer: Sparse Transformers for Graphs (ICML'23)
5. GRIT [5] - Graph Inductive Biases in Transformers without Message Passing (ICML'23)
6. MPNN-VN [6] - On the Connection Between MPNN and Graph Transformer (ICML'23)

The reviewer suggests that the authors should compare their proposed method with these latest baseline models for a comprehensive empirical comparison.",1,"2022, 2022, 2023, 2023, 2023, 2023",All in a row Compressed convolution networks for graphs 
nqNs1OE1wo,This paper proposes to make graph-level predictions via distribution comparison between node-level representations and discrete reference distributions. The authors claim that their proposed method avoids the requirements of graph pooling for graph-level tasks. and reduce the risk of information loss. Theoretical and empirical justification results are provided.,"- The authors propose a novel and simple method for graph classification and provide theoretical analysis on the generalization bound. The discussion is clear and extensive.
- The method shows advantage in time cost compared to related works.
- The authors performed extensive ablation study on the proposed method.","- Equation in L138-139 (a missing equation index?) also requires summation over nodes. The description of ""avoid graph pooling operation"" seems to be overclaimed. I suggest that the authors reconsider it.
- An ablation study on the discrimination loss and the usage of node-level representation is required. I think the main improvement in performance may be attributed to the discrimination loss. It helps the model learn distant representations for graphs of different labels in the feature space.  The performance of the proposed method should be compared with and without the discrimination loss. Besides, the authors should also implement a baseline with discrimination loss where node representations are first sum-pooling and then compared with the reference distribution.
- Minor: Latest baseline models are required for a comprehensive empirical comparison, such as graph pooling including SEP[1], GMT[2], and CoCN[3] and graph transformers including Exphormer[4], GRIT[5], and MPNN-VN[6]. Considering the time limitation and the similarity of the datasets, a comparison on part of the datasets will be sufficient.

[1] Structural entropy guided graph hierarchical pooling. ICML'22

[2] Accurate Learning of Graph Representations with Graph Multiset Pooling. ICLR'22

[3] All in a row: Compressed convolution networks for graphs. ICML'23

[4] Exphormer: Sparse Transformers for Graphs. ICML'23

[5] Graph Inductive Biases in Transformers without Message Passing. ICML'23

[6] On the Connection Between MPNN and Graph Transformer. ICML'23",Please refer to the weaknesses.,Yes. The authors describe the limited performances of the proposed method on certain datasets.,['No ethics review needed.'],6,3,,Yes,3,3,2,1720842413917,,,NeurIPS.cc/2024/Conference,1zVinhehks,"['NeurIPS.cc/2024/Conference/Submission10244/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879370968,[],3,,,['everyone'],1zVinhehks,['NeurIPS.cc/2024/Conference/Submission10244/Reviewer_5HH3'],1720842413917,1730879370968,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10244/Reviewer_5HH3']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. SEP [1] - Structural entropy guided graph hierarchical pooling (ICML'22)
2. GMT [2] - Accurate Learning of Graph Representations with Graph Multiset Pooling (ICLR'22)
3. CoCN [3] - All in a row: Compressed convolution networks for graphs (ICML'23)
4. Exphormer [4] - Exphormer: Sparse Transformers for Graphs (ICML'23)
5. GRIT [5] - Graph Inductive Biases in Transformers without Message Passing (ICML'23)
6. MPNN-VN [6] - On the Connection Between MPNN and Graph Transformer (ICML'23)

The reviewer suggests that the authors should compare their proposed method with these latest baseline models for a comprehensive empirical comparison.",1,"2022, 2022, 2023, 2023, 2023, 2023",Exphormer Sparse Transformers for Graphs 
nqNs1OE1wo,This paper proposes to make graph-level predictions via distribution comparison between node-level representations and discrete reference distributions. The authors claim that their proposed method avoids the requirements of graph pooling for graph-level tasks. and reduce the risk of information loss. Theoretical and empirical justification results are provided.,"- The authors propose a novel and simple method for graph classification and provide theoretical analysis on the generalization bound. The discussion is clear and extensive.
- The method shows advantage in time cost compared to related works.
- The authors performed extensive ablation study on the proposed method.","- Equation in L138-139 (a missing equation index?) also requires summation over nodes. The description of ""avoid graph pooling operation"" seems to be overclaimed. I suggest that the authors reconsider it.
- An ablation study on the discrimination loss and the usage of node-level representation is required. I think the main improvement in performance may be attributed to the discrimination loss. It helps the model learn distant representations for graphs of different labels in the feature space.  The performance of the proposed method should be compared with and without the discrimination loss. Besides, the authors should also implement a baseline with discrimination loss where node representations are first sum-pooling and then compared with the reference distribution.
- Minor: Latest baseline models are required for a comprehensive empirical comparison, such as graph pooling including SEP[1], GMT[2], and CoCN[3] and graph transformers including Exphormer[4], GRIT[5], and MPNN-VN[6]. Considering the time limitation and the similarity of the datasets, a comparison on part of the datasets will be sufficient.

[1] Structural entropy guided graph hierarchical pooling. ICML'22

[2] Accurate Learning of Graph Representations with Graph Multiset Pooling. ICLR'22

[3] All in a row: Compressed convolution networks for graphs. ICML'23

[4] Exphormer: Sparse Transformers for Graphs. ICML'23

[5] Graph Inductive Biases in Transformers without Message Passing. ICML'23

[6] On the Connection Between MPNN and Graph Transformer. ICML'23",Please refer to the weaknesses.,Yes. The authors describe the limited performances of the proposed method on certain datasets.,['No ethics review needed.'],6,3,,Yes,3,3,2,1720842413917,,,NeurIPS.cc/2024/Conference,1zVinhehks,"['NeurIPS.cc/2024/Conference/Submission10244/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879370968,[],3,,,['everyone'],1zVinhehks,['NeurIPS.cc/2024/Conference/Submission10244/Reviewer_5HH3'],1720842413917,1730879370968,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10244/Reviewer_5HH3']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. SEP [1] - Structural entropy guided graph hierarchical pooling (ICML'22)
2. GMT [2] - Accurate Learning of Graph Representations with Graph Multiset Pooling (ICLR'22)
3. CoCN [3] - All in a row: Compressed convolution networks for graphs (ICML'23)
4. Exphormer [4] - Exphormer: Sparse Transformers for Graphs (ICML'23)
5. GRIT [5] - Graph Inductive Biases in Transformers without Message Passing (ICML'23)
6. MPNN-VN [6] - On the Connection Between MPNN and Graph Transformer (ICML'23)

The reviewer suggests that the authors should compare their proposed method with these latest baseline models for a comprehensive empirical comparison.",1,"2022, 2022, 2023, 2023, 2023, 2023",Graph Inductive Biases in Transformers without Message Passing 
nqNs1OE1wo,This paper proposes to make graph-level predictions via distribution comparison between node-level representations and discrete reference distributions. The authors claim that their proposed method avoids the requirements of graph pooling for graph-level tasks. and reduce the risk of information loss. Theoretical and empirical justification results are provided.,"- The authors propose a novel and simple method for graph classification and provide theoretical analysis on the generalization bound. The discussion is clear and extensive.
- The method shows advantage in time cost compared to related works.
- The authors performed extensive ablation study on the proposed method.","- Equation in L138-139 (a missing equation index?) also requires summation over nodes. The description of ""avoid graph pooling operation"" seems to be overclaimed. I suggest that the authors reconsider it.
- An ablation study on the discrimination loss and the usage of node-level representation is required. I think the main improvement in performance may be attributed to the discrimination loss. It helps the model learn distant representations for graphs of different labels in the feature space.  The performance of the proposed method should be compared with and without the discrimination loss. Besides, the authors should also implement a baseline with discrimination loss where node representations are first sum-pooling and then compared with the reference distribution.
- Minor: Latest baseline models are required for a comprehensive empirical comparison, such as graph pooling including SEP[1], GMT[2], and CoCN[3] and graph transformers including Exphormer[4], GRIT[5], and MPNN-VN[6]. Considering the time limitation and the similarity of the datasets, a comparison on part of the datasets will be sufficient.

[1] Structural entropy guided graph hierarchical pooling. ICML'22

[2] Accurate Learning of Graph Representations with Graph Multiset Pooling. ICLR'22

[3] All in a row: Compressed convolution networks for graphs. ICML'23

[4] Exphormer: Sparse Transformers for Graphs. ICML'23

[5] Graph Inductive Biases in Transformers without Message Passing. ICML'23

[6] On the Connection Between MPNN and Graph Transformer. ICML'23",Please refer to the weaknesses.,Yes. The authors describe the limited performances of the proposed method on certain datasets.,['No ethics review needed.'],6,3,,Yes,3,3,2,1720842413917,,,NeurIPS.cc/2024/Conference,1zVinhehks,"['NeurIPS.cc/2024/Conference/Submission10244/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879370968,[],3,,,['everyone'],1zVinhehks,['NeurIPS.cc/2024/Conference/Submission10244/Reviewer_5HH3'],1720842413917,1730879370968,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10244/Reviewer_5HH3']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. SEP [1] - Structural entropy guided graph hierarchical pooling (ICML'22)
2. GMT [2] - Accurate Learning of Graph Representations with Graph Multiset Pooling (ICLR'22)
3. CoCN [3] - All in a row: Compressed convolution networks for graphs (ICML'23)
4. Exphormer [4] - Exphormer: Sparse Transformers for Graphs (ICML'23)
5. GRIT [5] - Graph Inductive Biases in Transformers without Message Passing (ICML'23)
6. MPNN-VN [6] - On the Connection Between MPNN and Graph Transformer (ICML'23)

The reviewer suggests that the authors should compare their proposed method with these latest baseline models for a comprehensive empirical comparison.",1,"2022, 2022, 2023, 2023, 2023, 2023",On the Connection Between MPNN and Graph Transformer
SIjvDo35p8,"Building off prior work that studies the “reversal curse” in LLMs, the present paper provides additional analysis on 1) characterizing the limitations of LLMs on the reversal curse through more detailed experimentation (e.g., limitations with chain of thought prompting or providing multiple choice questions), and 2) interpreting the reasons as to why LLMs are biased towards correctly answering A is B when A is a name/proper noun. The main findings report that LLMs can improve generalization on B is A when 1) the prompt includes a multiple choice question; 2) LLMs are biased towards A (proper noun) is B (description), since this is how facts are typically represented in the training corpus; 3) This existing negative bias in LLMs cannot be mitigated by training/finetuning alone.","1)	The paper addresses a timely question
2)	The paper was, for the most part, straightforward and easy to understand.
3)	The experiments are interesting, and the effects appear strong","One of the main claims, that LLMs can disproportionately perform “NameIsDescription” correctly, is due to the fact pretraining datasets are biased towards having text in the form of NameIsDescription (i.e., A is B), but not the reverse. Despite the claim being mentioned several times, and though despite the claim being intuitive, the paper does not empirically quantify or demonstrate this that I could find. Are statistics reported of how often “A is B” is exhibited in the training documents relative to “B is A”? And is performance of the LLMs proportional to the ratio found in training documents? There seems to be some reference to Berglund et al., but this is a result of a prior paper, not the present paper. It would be helpful to quantify how biased LLMs are for A is B vs. B is A relative to the proportion they are exhibited in training data.

I found figure 3 to be confusing. What are the different colors supposed to indicate? (There’s no associated color bar.) Also, the incorrect answer of D makes it appear as if the incorrect selection was due to the tokenization of the name Graham Redwood.

There is also an issue of novelty – many of the reported results do not seem to particularly ‘novel’, perhaps because the results seem almost obvious. I think it would significantly help if the authors were to more clearly delineate their work from prior work in the Introduction, and to “signpost” exactly what the specific contributions of this work are (relative to prior work).","1. Is the finding that names are easier to trigger recall potentially due the fact that names typically have fewer number of tokens than descriptions? Prior work has shown that the token-wise MLP layer of the transformers act as key-value memories (Geva et al. 2021). If there are fewer tokens associated with a name, wouldn’t it be easier to coordinate retrieval of memories (i.e., facts) across fewer token streams, rather than to coordinate memory retrieval across the many streams that comprise of “Description” tokens?

2. Related to a weakness mentioned above: What are the statistics/proportions that show a bias in the pretraining corpus of “A is B” over “B is A”? And how does that proportion match with actual LLM performance?

3. In multiple choice question prompting, are LLMs biased towards any particular response (e.g., ‘A’, ‘B’, ‘C’, or ‘D’)? I’m curious to know if the attention weights in a decoder-only model could potentially bias the model to retrieve more facts associated with ‘D’, since it is later in the prompt.

4. I’m skeptical of the interpretation (or over-interpretation) of “information flow” by computing the average attention weights to a given token. This concern is compounded by the fact that the models they used (Llama) are decoder-only models, which, by construction, have greater attention weights towards tokens presented later in the prompt. Might this metric be confounded by this (results in Fig. 2 & 3)?

Geva, Mor, Roei Schuster, Jonathan Berant, and Omer Levy. “Transformer Feed-Forward Layers Are Key-Value Memories.” In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 5484–95. Online and Punta Cana, Dominican Republic: Association for Computational Linguistics, 2021. https://doi.org/10.18653/v1/2021.emnlp-main.446.","The authors claim that the curse of reversal can be somewhat mitigated if multiple choice questions are used. However, this appears to be a major limitation, while also being a strange suggestion – incorporating multiple choice questions assumes that the prompter knows the correct answer. Thus, in what scenario would this be helpful, aside from evaluating and adjudicating performances of multiple models?",['No ethics review needed.'],7,4,,Yes,2,3,2,1720637421329,,,NeurIPS.cc/2024/Conference,1wxFznQWhp,"['NeurIPS.cc/2024/Conference/Submission6292/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879067028,[],3,,,['everyone'],1wxFznQWhp,['NeurIPS.cc/2024/Conference/Submission6292/Reviewer_PVmx'],1720637421329,1730879067028,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission6292/Reviewer_PVmx']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, namely:

Geva, Mor, Roei Schuster, Jonathan Berant, and Omer Levy. “Transformer Feed-Forward Layers Are Key-Value Memories.” In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 5484–95. Online and Punta Cana, Dominican Republic: Association for Computational Linguistics, 2021. https://doi.org/10.18653/v1/2021.emnlp-main.446.

This citation is mentioned in question 1 of the peer review, where the reviewer references the work of Geva et al. (2021) to support their point about the token-wise MLP layer of transformers acting as key-value memories. Additionally, the reviewer also mentions Berglund et al., but this is a reference to a prior paper, not a suggestion to cite new literature.",1,"2021, 2021, 2021, 2021",Transformer Feed-Forward Layers Are Key-Value Memories
tAKkNslVVi,"The authors propose MotionBooth, a method to fine-tune a pre-trained text-to-video model on a collection of images of a specific object to enable the model to generate controlled videos of that object. Fine-tuning incorporates three losses: diffusion loss on image data, restricted to the object's region; video preservation loss, i.e diffusion loss on sample video data, to prevent overfitting to static images; subject token cross-attention loss, to improve controllability at generation time. During inference the motion of the object is controlled via editing the cross-attention maps to amplify the attention to the object tokens within the object's bounding boxes. The camera is controlled via shifting the noised latent and filling the new regions with latents sampled from the background of the original noised latent.",The problem of controllable video generation is of high significance nowadays. The method proposed in the paper is relatively simple and the demonstrated visual results confirm the improved controllability of MotionBooth over prior work. The contributions in the paper are supported with well-designed figures aiding the clarity of the presentation. The limitations of the proposed method are discussed in the appendix.,"1) **Novelty**: 
    - Similar training-free object motion control was proposed in [1] and [2] for image and video models respectively, where cross-attention amplification within object's bounding box was used to control its location in the generated frame. Similar training-free camera motion control was used in [3], where a series of noised latent shifts were used to control the global scene and camera motion. 
Discussion and comparisons with those works are missing in the paper.
    - Some missing references: [4, 5].

2) **Method**: 
    - Based on the formula for subject motion control, the attention is suppressed (set to -infinity) for all query-key pairs other than the queries from the bounding box and the keys from the object tokens. This way it seems that the rest of the prompt is ignored. Moreover, it is stated in the paper that ""the attention suppression outside the bounding box regions persists throughout the generation"". Details clarifying this are missing in the paper.

3) **Evaluation**: 
    - The paper lacks quantitative evaluation. Comparing CLIP features between the frames doesn't measure temporal consistency. Metrics like FVD, or optical flow warpping error could be better choices for this purpose.
    - Details on how exactly the metrics are calculated are missing. Formal definitions of newly introduced metrics are required for better understanding. E.g. how exactly is the flow error calculated in the case when not all the motion except for the object's motion corresponds to camera motion? Having those would help with understanding the significance of the improvements reported in the tables. 
    - The evaluation dataset consists of limited number of different object classes, mostly dogs, cats and toys. Evaluation on more general collection of object classes would better support the claims made in the paper.
    - More ablation studies would better illustrate the contributions. E.g. what would happen if the missing region in the shifted noised latent was not filled with samples from the same noised latent? Or if camera control like in [3] was used instead?

4) **Results**:
    - Figure 14 shows that bounding boxes often don't fully contain the object of interest. Given that the attention is suppressed outside of bounding boxes, this looks like a flaw in the proposed control and needs to be investigated.

[1] Ma et al., Directed diffusion: Direct control of object placement through attention guidance, AAAI 2024.

[2] Ma et al., TrailBlazer: Trajectory Control for Diffusion-Based Video Generation, arxiv 2024.

[3] Khachatryan et al., Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators, ICCV 2023.

[4] Wang et al., Boximator: Generating rich and controllable motions for video synthesis, arxiv 2024.

[5] Chen et al. Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based
Video Generation, arxiv 2024.","1) Could the authors discuss the connection between the proposed MotionBooth and the prior work with similar training-free controls? Some ablation studies would be ideal. 

2) Could the authors provide more details about their subject motion control attention suppression technique? Especially regarding the issue with attention to the prompt tokens other than the subject language tokens.

3) The authors claim that their fine-tuning is efficient (line 3 in the abstract). Could the authors provide more details on this? E.g. what is the training time to adapt the model to a new subject?",The authors have adequately addressed the limitation and the potential negative societal impact of their work.,['No ethics review needed.'],3,5,,Yes,2,3,2,1720308757804,,,NeurIPS.cc/2024/Conference,1we1V3MAHD,"['NeurIPS.cc/2024/Conference/Submission9629/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879328721,[],1,,,['everyone'],1we1V3MAHD,['NeurIPS.cc/2024/Conference/Submission9629/Reviewer_q2XJ'],1720308757804,1730879328721,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9629/Reviewer_q2XJ']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Ma et al., Directed diffusion: Direct control of object placement through attention guidance, AAAI 2024.
2. Ma et al., TrailBlazer: Trajectory Control for Diffusion-Based Video Generation, arxiv 2024.
3. Khachatryan et al., Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators, ICCV 2023.
4. Wang et al., Boximator: Generating rich and controllable motions for video synthesis, arxiv 2024.
5. Chen et al. Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based Video Generation, arxiv 2024.

The reviewer mentions that discussions and comparisons with these works are missing in the paper, and that some references are missing, implying that the authors should cite and engage with these works in their paper.",1,"2024, 2024, 2023, 2024, 2024",Directed diffusion: Direct control of object placement through attention guidance 
tAKkNslVVi,"The authors propose MotionBooth, a method to fine-tune a pre-trained text-to-video model on a collection of images of a specific object to enable the model to generate controlled videos of that object. Fine-tuning incorporates three losses: diffusion loss on image data, restricted to the object's region; video preservation loss, i.e diffusion loss on sample video data, to prevent overfitting to static images; subject token cross-attention loss, to improve controllability at generation time. During inference the motion of the object is controlled via editing the cross-attention maps to amplify the attention to the object tokens within the object's bounding boxes. The camera is controlled via shifting the noised latent and filling the new regions with latents sampled from the background of the original noised latent.",The problem of controllable video generation is of high significance nowadays. The method proposed in the paper is relatively simple and the demonstrated visual results confirm the improved controllability of MotionBooth over prior work. The contributions in the paper are supported with well-designed figures aiding the clarity of the presentation. The limitations of the proposed method are discussed in the appendix.,"1) **Novelty**: 
    - Similar training-free object motion control was proposed in [1] and [2] for image and video models respectively, where cross-attention amplification within object's bounding box was used to control its location in the generated frame. Similar training-free camera motion control was used in [3], where a series of noised latent shifts were used to control the global scene and camera motion. 
Discussion and comparisons with those works are missing in the paper.
    - Some missing references: [4, 5].

2) **Method**: 
    - Based on the formula for subject motion control, the attention is suppressed (set to -infinity) for all query-key pairs other than the queries from the bounding box and the keys from the object tokens. This way it seems that the rest of the prompt is ignored. Moreover, it is stated in the paper that ""the attention suppression outside the bounding box regions persists throughout the generation"". Details clarifying this are missing in the paper.

3) **Evaluation**: 
    - The paper lacks quantitative evaluation. Comparing CLIP features between the frames doesn't measure temporal consistency. Metrics like FVD, or optical flow warpping error could be better choices for this purpose.
    - Details on how exactly the metrics are calculated are missing. Formal definitions of newly introduced metrics are required for better understanding. E.g. how exactly is the flow error calculated in the case when not all the motion except for the object's motion corresponds to camera motion? Having those would help with understanding the significance of the improvements reported in the tables. 
    - The evaluation dataset consists of limited number of different object classes, mostly dogs, cats and toys. Evaluation on more general collection of object classes would better support the claims made in the paper.
    - More ablation studies would better illustrate the contributions. E.g. what would happen if the missing region in the shifted noised latent was not filled with samples from the same noised latent? Or if camera control like in [3] was used instead?

4) **Results**:
    - Figure 14 shows that bounding boxes often don't fully contain the object of interest. Given that the attention is suppressed outside of bounding boxes, this looks like a flaw in the proposed control and needs to be investigated.

[1] Ma et al., Directed diffusion: Direct control of object placement through attention guidance, AAAI 2024.

[2] Ma et al., TrailBlazer: Trajectory Control for Diffusion-Based Video Generation, arxiv 2024.

[3] Khachatryan et al., Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators, ICCV 2023.

[4] Wang et al., Boximator: Generating rich and controllable motions for video synthesis, arxiv 2024.

[5] Chen et al. Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based
Video Generation, arxiv 2024.","1) Could the authors discuss the connection between the proposed MotionBooth and the prior work with similar training-free controls? Some ablation studies would be ideal. 

2) Could the authors provide more details about their subject motion control attention suppression technique? Especially regarding the issue with attention to the prompt tokens other than the subject language tokens.

3) The authors claim that their fine-tuning is efficient (line 3 in the abstract). Could the authors provide more details on this? E.g. what is the training time to adapt the model to a new subject?",The authors have adequately addressed the limitation and the potential negative societal impact of their work.,['No ethics review needed.'],3,5,,Yes,2,3,2,1720308757804,,,NeurIPS.cc/2024/Conference,1we1V3MAHD,"['NeurIPS.cc/2024/Conference/Submission9629/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879328721,[],1,,,['everyone'],1we1V3MAHD,['NeurIPS.cc/2024/Conference/Submission9629/Reviewer_q2XJ'],1720308757804,1730879328721,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9629/Reviewer_q2XJ']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Ma et al., Directed diffusion: Direct control of object placement through attention guidance, AAAI 2024.
2. Ma et al., TrailBlazer: Trajectory Control for Diffusion-Based Video Generation, arxiv 2024.
3. Khachatryan et al., Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators, ICCV 2023.
4. Wang et al., Boximator: Generating rich and controllable motions for video synthesis, arxiv 2024.
5. Chen et al. Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based Video Generation, arxiv 2024.

The reviewer mentions that discussions and comparisons with these works are missing in the paper, and that some references are missing, implying that the authors should cite and engage with these works in their paper.",1,"2024, 2024, 2023, 2024, 2024",TrailBlazer: Trajectory Control for Diffusion-Based Video Generation 
tAKkNslVVi,"The authors propose MotionBooth, a method to fine-tune a pre-trained text-to-video model on a collection of images of a specific object to enable the model to generate controlled videos of that object. Fine-tuning incorporates three losses: diffusion loss on image data, restricted to the object's region; video preservation loss, i.e diffusion loss on sample video data, to prevent overfitting to static images; subject token cross-attention loss, to improve controllability at generation time. During inference the motion of the object is controlled via editing the cross-attention maps to amplify the attention to the object tokens within the object's bounding boxes. The camera is controlled via shifting the noised latent and filling the new regions with latents sampled from the background of the original noised latent.",The problem of controllable video generation is of high significance nowadays. The method proposed in the paper is relatively simple and the demonstrated visual results confirm the improved controllability of MotionBooth over prior work. The contributions in the paper are supported with well-designed figures aiding the clarity of the presentation. The limitations of the proposed method are discussed in the appendix.,"1) **Novelty**: 
    - Similar training-free object motion control was proposed in [1] and [2] for image and video models respectively, where cross-attention amplification within object's bounding box was used to control its location in the generated frame. Similar training-free camera motion control was used in [3], where a series of noised latent shifts were used to control the global scene and camera motion. 
Discussion and comparisons with those works are missing in the paper.
    - Some missing references: [4, 5].

2) **Method**: 
    - Based on the formula for subject motion control, the attention is suppressed (set to -infinity) for all query-key pairs other than the queries from the bounding box and the keys from the object tokens. This way it seems that the rest of the prompt is ignored. Moreover, it is stated in the paper that ""the attention suppression outside the bounding box regions persists throughout the generation"". Details clarifying this are missing in the paper.

3) **Evaluation**: 
    - The paper lacks quantitative evaluation. Comparing CLIP features between the frames doesn't measure temporal consistency. Metrics like FVD, or optical flow warpping error could be better choices for this purpose.
    - Details on how exactly the metrics are calculated are missing. Formal definitions of newly introduced metrics are required for better understanding. E.g. how exactly is the flow error calculated in the case when not all the motion except for the object's motion corresponds to camera motion? Having those would help with understanding the significance of the improvements reported in the tables. 
    - The evaluation dataset consists of limited number of different object classes, mostly dogs, cats and toys. Evaluation on more general collection of object classes would better support the claims made in the paper.
    - More ablation studies would better illustrate the contributions. E.g. what would happen if the missing region in the shifted noised latent was not filled with samples from the same noised latent? Or if camera control like in [3] was used instead?

4) **Results**:
    - Figure 14 shows that bounding boxes often don't fully contain the object of interest. Given that the attention is suppressed outside of bounding boxes, this looks like a flaw in the proposed control and needs to be investigated.

[1] Ma et al., Directed diffusion: Direct control of object placement through attention guidance, AAAI 2024.

[2] Ma et al., TrailBlazer: Trajectory Control for Diffusion-Based Video Generation, arxiv 2024.

[3] Khachatryan et al., Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators, ICCV 2023.

[4] Wang et al., Boximator: Generating rich and controllable motions for video synthesis, arxiv 2024.

[5] Chen et al. Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based
Video Generation, arxiv 2024.","1) Could the authors discuss the connection between the proposed MotionBooth and the prior work with similar training-free controls? Some ablation studies would be ideal. 

2) Could the authors provide more details about their subject motion control attention suppression technique? Especially regarding the issue with attention to the prompt tokens other than the subject language tokens.

3) The authors claim that their fine-tuning is efficient (line 3 in the abstract). Could the authors provide more details on this? E.g. what is the training time to adapt the model to a new subject?",The authors have adequately addressed the limitation and the potential negative societal impact of their work.,['No ethics review needed.'],3,5,,Yes,2,3,2,1720308757804,,,NeurIPS.cc/2024/Conference,1we1V3MAHD,"['NeurIPS.cc/2024/Conference/Submission9629/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879328721,[],1,,,['everyone'],1we1V3MAHD,['NeurIPS.cc/2024/Conference/Submission9629/Reviewer_q2XJ'],1720308757804,1730879328721,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9629/Reviewer_q2XJ']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Ma et al., Directed diffusion: Direct control of object placement through attention guidance, AAAI 2024.
2. Ma et al., TrailBlazer: Trajectory Control for Diffusion-Based Video Generation, arxiv 2024.
3. Khachatryan et al., Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators, ICCV 2023.
4. Wang et al., Boximator: Generating rich and controllable motions for video synthesis, arxiv 2024.
5. Chen et al. Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based Video Generation, arxiv 2024.

The reviewer mentions that discussions and comparisons with these works are missing in the paper, and that some references are missing, implying that the authors should cite and engage with these works in their paper.",1,"2024, 2024, 2023, 2024, 2024",Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators 
tAKkNslVVi,"The authors propose MotionBooth, a method to fine-tune a pre-trained text-to-video model on a collection of images of a specific object to enable the model to generate controlled videos of that object. Fine-tuning incorporates three losses: diffusion loss on image data, restricted to the object's region; video preservation loss, i.e diffusion loss on sample video data, to prevent overfitting to static images; subject token cross-attention loss, to improve controllability at generation time. During inference the motion of the object is controlled via editing the cross-attention maps to amplify the attention to the object tokens within the object's bounding boxes. The camera is controlled via shifting the noised latent and filling the new regions with latents sampled from the background of the original noised latent.",The problem of controllable video generation is of high significance nowadays. The method proposed in the paper is relatively simple and the demonstrated visual results confirm the improved controllability of MotionBooth over prior work. The contributions in the paper are supported with well-designed figures aiding the clarity of the presentation. The limitations of the proposed method are discussed in the appendix.,"1) **Novelty**: 
    - Similar training-free object motion control was proposed in [1] and [2] for image and video models respectively, where cross-attention amplification within object's bounding box was used to control its location in the generated frame. Similar training-free camera motion control was used in [3], where a series of noised latent shifts were used to control the global scene and camera motion. 
Discussion and comparisons with those works are missing in the paper.
    - Some missing references: [4, 5].

2) **Method**: 
    - Based on the formula for subject motion control, the attention is suppressed (set to -infinity) for all query-key pairs other than the queries from the bounding box and the keys from the object tokens. This way it seems that the rest of the prompt is ignored. Moreover, it is stated in the paper that ""the attention suppression outside the bounding box regions persists throughout the generation"". Details clarifying this are missing in the paper.

3) **Evaluation**: 
    - The paper lacks quantitative evaluation. Comparing CLIP features between the frames doesn't measure temporal consistency. Metrics like FVD, or optical flow warpping error could be better choices for this purpose.
    - Details on how exactly the metrics are calculated are missing. Formal definitions of newly introduced metrics are required for better understanding. E.g. how exactly is the flow error calculated in the case when not all the motion except for the object's motion corresponds to camera motion? Having those would help with understanding the significance of the improvements reported in the tables. 
    - The evaluation dataset consists of limited number of different object classes, mostly dogs, cats and toys. Evaluation on more general collection of object classes would better support the claims made in the paper.
    - More ablation studies would better illustrate the contributions. E.g. what would happen if the missing region in the shifted noised latent was not filled with samples from the same noised latent? Or if camera control like in [3] was used instead?

4) **Results**:
    - Figure 14 shows that bounding boxes often don't fully contain the object of interest. Given that the attention is suppressed outside of bounding boxes, this looks like a flaw in the proposed control and needs to be investigated.

[1] Ma et al., Directed diffusion: Direct control of object placement through attention guidance, AAAI 2024.

[2] Ma et al., TrailBlazer: Trajectory Control for Diffusion-Based Video Generation, arxiv 2024.

[3] Khachatryan et al., Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators, ICCV 2023.

[4] Wang et al., Boximator: Generating rich and controllable motions for video synthesis, arxiv 2024.

[5] Chen et al. Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based
Video Generation, arxiv 2024.","1) Could the authors discuss the connection between the proposed MotionBooth and the prior work with similar training-free controls? Some ablation studies would be ideal. 

2) Could the authors provide more details about their subject motion control attention suppression technique? Especially regarding the issue with attention to the prompt tokens other than the subject language tokens.

3) The authors claim that their fine-tuning is efficient (line 3 in the abstract). Could the authors provide more details on this? E.g. what is the training time to adapt the model to a new subject?",The authors have adequately addressed the limitation and the potential negative societal impact of their work.,['No ethics review needed.'],3,5,,Yes,2,3,2,1720308757804,,,NeurIPS.cc/2024/Conference,1we1V3MAHD,"['NeurIPS.cc/2024/Conference/Submission9629/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879328721,[],1,,,['everyone'],1we1V3MAHD,['NeurIPS.cc/2024/Conference/Submission9629/Reviewer_q2XJ'],1720308757804,1730879328721,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9629/Reviewer_q2XJ']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Ma et al., Directed diffusion: Direct control of object placement through attention guidance, AAAI 2024.
2. Ma et al., TrailBlazer: Trajectory Control for Diffusion-Based Video Generation, arxiv 2024.
3. Khachatryan et al., Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators, ICCV 2023.
4. Wang et al., Boximator: Generating rich and controllable motions for video synthesis, arxiv 2024.
5. Chen et al. Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based Video Generation, arxiv 2024.

The reviewer mentions that discussions and comparisons with these works are missing in the paper, and that some references are missing, implying that the authors should cite and engage with these works in their paper.",1,"2024, 2024, 2023, 2024, 2024",Boximator: Generating rich and controllable motions for video synthesis 
tAKkNslVVi,"The authors propose MotionBooth, a method to fine-tune a pre-trained text-to-video model on a collection of images of a specific object to enable the model to generate controlled videos of that object. Fine-tuning incorporates three losses: diffusion loss on image data, restricted to the object's region; video preservation loss, i.e diffusion loss on sample video data, to prevent overfitting to static images; subject token cross-attention loss, to improve controllability at generation time. During inference the motion of the object is controlled via editing the cross-attention maps to amplify the attention to the object tokens within the object's bounding boxes. The camera is controlled via shifting the noised latent and filling the new regions with latents sampled from the background of the original noised latent.",The problem of controllable video generation is of high significance nowadays. The method proposed in the paper is relatively simple and the demonstrated visual results confirm the improved controllability of MotionBooth over prior work. The contributions in the paper are supported with well-designed figures aiding the clarity of the presentation. The limitations of the proposed method are discussed in the appendix.,"1) **Novelty**: 
    - Similar training-free object motion control was proposed in [1] and [2] for image and video models respectively, where cross-attention amplification within object's bounding box was used to control its location in the generated frame. Similar training-free camera motion control was used in [3], where a series of noised latent shifts were used to control the global scene and camera motion. 
Discussion and comparisons with those works are missing in the paper.
    - Some missing references: [4, 5].

2) **Method**: 
    - Based on the formula for subject motion control, the attention is suppressed (set to -infinity) for all query-key pairs other than the queries from the bounding box and the keys from the object tokens. This way it seems that the rest of the prompt is ignored. Moreover, it is stated in the paper that ""the attention suppression outside the bounding box regions persists throughout the generation"". Details clarifying this are missing in the paper.

3) **Evaluation**: 
    - The paper lacks quantitative evaluation. Comparing CLIP features between the frames doesn't measure temporal consistency. Metrics like FVD, or optical flow warpping error could be better choices for this purpose.
    - Details on how exactly the metrics are calculated are missing. Formal definitions of newly introduced metrics are required for better understanding. E.g. how exactly is the flow error calculated in the case when not all the motion except for the object's motion corresponds to camera motion? Having those would help with understanding the significance of the improvements reported in the tables. 
    - The evaluation dataset consists of limited number of different object classes, mostly dogs, cats and toys. Evaluation on more general collection of object classes would better support the claims made in the paper.
    - More ablation studies would better illustrate the contributions. E.g. what would happen if the missing region in the shifted noised latent was not filled with samples from the same noised latent? Or if camera control like in [3] was used instead?

4) **Results**:
    - Figure 14 shows that bounding boxes often don't fully contain the object of interest. Given that the attention is suppressed outside of bounding boxes, this looks like a flaw in the proposed control and needs to be investigated.

[1] Ma et al., Directed diffusion: Direct control of object placement through attention guidance, AAAI 2024.

[2] Ma et al., TrailBlazer: Trajectory Control for Diffusion-Based Video Generation, arxiv 2024.

[3] Khachatryan et al., Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators, ICCV 2023.

[4] Wang et al., Boximator: Generating rich and controllable motions for video synthesis, arxiv 2024.

[5] Chen et al. Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based
Video Generation, arxiv 2024.","1) Could the authors discuss the connection between the proposed MotionBooth and the prior work with similar training-free controls? Some ablation studies would be ideal. 

2) Could the authors provide more details about their subject motion control attention suppression technique? Especially regarding the issue with attention to the prompt tokens other than the subject language tokens.

3) The authors claim that their fine-tuning is efficient (line 3 in the abstract). Could the authors provide more details on this? E.g. what is the training time to adapt the model to a new subject?",The authors have adequately addressed the limitation and the potential negative societal impact of their work.,['No ethics review needed.'],3,5,,Yes,2,3,2,1720308757804,,,NeurIPS.cc/2024/Conference,1we1V3MAHD,"['NeurIPS.cc/2024/Conference/Submission9629/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879328721,[],1,,,['everyone'],1we1V3MAHD,['NeurIPS.cc/2024/Conference/Submission9629/Reviewer_q2XJ'],1720308757804,1730879328721,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9629/Reviewer_q2XJ']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Ma et al., Directed diffusion: Direct control of object placement through attention guidance, AAAI 2024.
2. Ma et al., TrailBlazer: Trajectory Control for Diffusion-Based Video Generation, arxiv 2024.
3. Khachatryan et al., Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators, ICCV 2023.
4. Wang et al., Boximator: Generating rich and controllable motions for video synthesis, arxiv 2024.
5. Chen et al. Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based Video Generation, arxiv 2024.

The reviewer mentions that discussions and comparisons with these works are missing in the paper, and that some references are missing, implying that the authors should cite and engage with these works in their paper.",1,"2024, 2024, 2023, 2024, 2024",Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based Video Generation
IJnw5UuMz7,This paper proposes function t-SVD for multi-output regression under combinatorial shifts. Excess-risk bounds have been derived. Using simulation experiments risk bounds with combinatorial shifts has been compared with regular risk bounds.,"1) Proposal of functional t-SVD, which is a descent contribution.
2) Solid theoretical analysis","1) Lack of any real-data experiments. It is hard to understand the usefulness of the proposed method in real-world application though the theoretical contribution may be high. 
2) Lack of comparison to other related function tensor decomposition methods either by theory or experiments.","Lack of any real-world application is limitation of the paper. Since the paper is proposing a functional tensor decomposition methods, it would be useful give at least one application to understand its learning capability. Can authors provide some experiments on real-data set?

Some references such as function tensor-train is missing [1]. Can authors provide more detailed related methods?

How does the proposed method compare with other functional tensor decomposition methods? How does the theoretical results (ERM bounds) compared with any existing results?  

1 Alex Gorodetsky, Sertac Karaman, Youssef Marzouk, A continuous analogue of the tensor-train decomposition, Computer Methods in Applied Mechanics and Engineering, Volume 347, 2019, Pages 59-84,",Limitations listed but insufficient in my opinion due to any experiments with real-data.,['No ethics review needed.'],5,2,,Yes,3,2,3,1720605546852,,,NeurIPS.cc/2024/Conference,1v0BPTR3AA,"['NeurIPS.cc/2024/Conference/Submission8267/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879230227,[],2,,,['everyone'],1v0BPTR3AA,['NeurIPS.cc/2024/Conference/Submission8267/Reviewer_juWX'],1720605546852,1730879230227,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8267/Reviewer_juWX']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature, namely:

* Alex Gorodetsky, Sertac Karaman, Youssef Marzouk, ""A continuous analogue of the tensor-train decomposition"", Computer Methods in Applied Mechanics and Engineering, Volume 347, 2019, Pages 59-84, which is referred to as reference [1].",1,2019,A continuous analogue of the tensor-train decomposition
on89bwirW1,"The paper introduces a novel approach to multi-output regression (MOR) under combinatorial distribution shifts (CDS) using a generalized tensor decomposition framework. The proposed Functional t-Singular Value Decomposition (Ft-SVD) extends classical tensor SVD to infinite and continuous feature domains, providing a new perspective on handling MOR tasks under CDS. The authors present a Double-Stage Empirical Risk Minimization (ERM-DS) algorithm designed to improve prediction accuracy in the presence of CDS. Through rigorous theoretical analysis, the paper establishes performance guarantees for the proposed algorithm and demonstrates its efficacy with synthetic data experiments.","1.	Clear and Reasonable Motivation: The paper presents a clear and reasonable motivation for using tensor completion to address multi-output regression under combinatorial distribution shifts. By framing the problem as a tensor completion task, the method leverages the strengths of tensor decomposition techniques to manage the challenge of unseen feature combinations in MOR, effectively improving generalization capabilities.

2.	Solid Theoretical Analysis: The detailed proofs and theoretical guarantees offered in the paper are impressive and contribute significantly to the understanding and validation of the proposed methods. This rigorous approach ensures that the findings are well-supported and credible","1.	The paper's definition, introduction, and highlight of Combinatorial Distribution Shift (CDS) are insufficient. It is not clear why CDS poses a significant challenge in MOR and why it is important.

2.	The relevant definitions, assumptions, and proofs are presented with excessive detail, which makes it difficult for readers to grasp the core issues and contributions. A more concise and focused explanation would help in conveying the importance and difficulty of CDS in MOR.

3. The paper does not adequately discuss the existing body of work on functional tensor completion, such as [Bigoni et al., 2016], [Luo et al., 2023], and [Fang et al., 2024]. Including a more comprehensive discussion on related works and how the proposed method compares to them would provide better context and highlight the contributions more effectively. 

Ref:
- Bigoni, Daniele, Allan P. Engsig-Karup, and Youssef M. Marzouk. ""Spectral tensor-train decomposition."" SIAM Journal on Scientific Computing 38.4 (2016): A2405-A2439.

- Luo, Yisi, et al. ""Low-rank tensor function representation for multi-dimensional data recovery."" IEEE Transactions on Pattern Analysis and Machine Intelligence (2023).

- Fang, Shikai, et al. ""Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data."" arXiv preprint arXiv:2311.04829 (2023).",See weakness,See weakness,['No ethics review needed.'],6,3,,Yes,3,2,3,1720879402233,,,NeurIPS.cc/2024/Conference,1v0BPTR3AA,"['NeurIPS.cc/2024/Conference/Submission8267/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879230100,[],3,,,['everyone'],1v0BPTR3AA,['NeurIPS.cc/2024/Conference/Submission8267/Reviewer_yp2H'],1720879402233,1730879230100,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8267/Reviewer_yp2H']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature related to functional tensor completion, including:

1. Bigoni et al. (2016) - ""Spectral tensor-train decomposition""
2. Luo et al. (2023) - ""Low-rank tensor function representation for multi-dimensional data recovery""
3. Fang et al. (2024) - ""Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data""

The reviewer mentions that including a more comprehensive discussion on these related works and how the proposed method compares to them would provide better context and highlight the contributions more effectively.",1,"2016, 2023, 2024",Spectral tensor-train decomposition 
on89bwirW1,"The paper introduces a novel approach to multi-output regression (MOR) under combinatorial distribution shifts (CDS) using a generalized tensor decomposition framework. The proposed Functional t-Singular Value Decomposition (Ft-SVD) extends classical tensor SVD to infinite and continuous feature domains, providing a new perspective on handling MOR tasks under CDS. The authors present a Double-Stage Empirical Risk Minimization (ERM-DS) algorithm designed to improve prediction accuracy in the presence of CDS. Through rigorous theoretical analysis, the paper establishes performance guarantees for the proposed algorithm and demonstrates its efficacy with synthetic data experiments.","1.	Clear and Reasonable Motivation: The paper presents a clear and reasonable motivation for using tensor completion to address multi-output regression under combinatorial distribution shifts. By framing the problem as a tensor completion task, the method leverages the strengths of tensor decomposition techniques to manage the challenge of unseen feature combinations in MOR, effectively improving generalization capabilities.

2.	Solid Theoretical Analysis: The detailed proofs and theoretical guarantees offered in the paper are impressive and contribute significantly to the understanding and validation of the proposed methods. This rigorous approach ensures that the findings are well-supported and credible","1.	The paper's definition, introduction, and highlight of Combinatorial Distribution Shift (CDS) are insufficient. It is not clear why CDS poses a significant challenge in MOR and why it is important.

2.	The relevant definitions, assumptions, and proofs are presented with excessive detail, which makes it difficult for readers to grasp the core issues and contributions. A more concise and focused explanation would help in conveying the importance and difficulty of CDS in MOR.

3. The paper does not adequately discuss the existing body of work on functional tensor completion, such as [Bigoni et al., 2016], [Luo et al., 2023], and [Fang et al., 2024]. Including a more comprehensive discussion on related works and how the proposed method compares to them would provide better context and highlight the contributions more effectively. 

Ref:
- Bigoni, Daniele, Allan P. Engsig-Karup, and Youssef M. Marzouk. ""Spectral tensor-train decomposition."" SIAM Journal on Scientific Computing 38.4 (2016): A2405-A2439.

- Luo, Yisi, et al. ""Low-rank tensor function representation for multi-dimensional data recovery."" IEEE Transactions on Pattern Analysis and Machine Intelligence (2023).

- Fang, Shikai, et al. ""Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data."" arXiv preprint arXiv:2311.04829 (2023).",See weakness,See weakness,['No ethics review needed.'],6,3,,Yes,3,2,3,1720879402233,,,NeurIPS.cc/2024/Conference,1v0BPTR3AA,"['NeurIPS.cc/2024/Conference/Submission8267/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879230100,[],3,,,['everyone'],1v0BPTR3AA,['NeurIPS.cc/2024/Conference/Submission8267/Reviewer_yp2H'],1720879402233,1730879230100,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8267/Reviewer_yp2H']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature related to functional tensor completion, including:

1. Bigoni et al. (2016) - ""Spectral tensor-train decomposition""
2. Luo et al. (2023) - ""Low-rank tensor function representation for multi-dimensional data recovery""
3. Fang et al. (2024) - ""Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data""

The reviewer mentions that including a more comprehensive discussion on these related works and how the proposed method compares to them would provide better context and highlight the contributions more effectively.",1,"2016, 2023, 2024",Low-rank tensor function representation for multi-dimensional data recovery 
on89bwirW1,"The paper introduces a novel approach to multi-output regression (MOR) under combinatorial distribution shifts (CDS) using a generalized tensor decomposition framework. The proposed Functional t-Singular Value Decomposition (Ft-SVD) extends classical tensor SVD to infinite and continuous feature domains, providing a new perspective on handling MOR tasks under CDS. The authors present a Double-Stage Empirical Risk Minimization (ERM-DS) algorithm designed to improve prediction accuracy in the presence of CDS. Through rigorous theoretical analysis, the paper establishes performance guarantees for the proposed algorithm and demonstrates its efficacy with synthetic data experiments.","1.	Clear and Reasonable Motivation: The paper presents a clear and reasonable motivation for using tensor completion to address multi-output regression under combinatorial distribution shifts. By framing the problem as a tensor completion task, the method leverages the strengths of tensor decomposition techniques to manage the challenge of unseen feature combinations in MOR, effectively improving generalization capabilities.

2.	Solid Theoretical Analysis: The detailed proofs and theoretical guarantees offered in the paper are impressive and contribute significantly to the understanding and validation of the proposed methods. This rigorous approach ensures that the findings are well-supported and credible","1.	The paper's definition, introduction, and highlight of Combinatorial Distribution Shift (CDS) are insufficient. It is not clear why CDS poses a significant challenge in MOR and why it is important.

2.	The relevant definitions, assumptions, and proofs are presented with excessive detail, which makes it difficult for readers to grasp the core issues and contributions. A more concise and focused explanation would help in conveying the importance and difficulty of CDS in MOR.

3. The paper does not adequately discuss the existing body of work on functional tensor completion, such as [Bigoni et al., 2016], [Luo et al., 2023], and [Fang et al., 2024]. Including a more comprehensive discussion on related works and how the proposed method compares to them would provide better context and highlight the contributions more effectively. 

Ref:
- Bigoni, Daniele, Allan P. Engsig-Karup, and Youssef M. Marzouk. ""Spectral tensor-train decomposition."" SIAM Journal on Scientific Computing 38.4 (2016): A2405-A2439.

- Luo, Yisi, et al. ""Low-rank tensor function representation for multi-dimensional data recovery."" IEEE Transactions on Pattern Analysis and Machine Intelligence (2023).

- Fang, Shikai, et al. ""Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data."" arXiv preprint arXiv:2311.04829 (2023).",See weakness,See weakness,['No ethics review needed.'],6,3,,Yes,3,2,3,1720879402233,,,NeurIPS.cc/2024/Conference,1v0BPTR3AA,"['NeurIPS.cc/2024/Conference/Submission8267/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879230100,[],3,,,['everyone'],1v0BPTR3AA,['NeurIPS.cc/2024/Conference/Submission8267/Reviewer_yp2H'],1720879402233,1730879230100,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission8267/Reviewer_yp2H']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature related to functional tensor completion, including:

1. Bigoni et al. (2016) - ""Spectral tensor-train decomposition""
2. Luo et al. (2023) - ""Low-rank tensor function representation for multi-dimensional data recovery""
3. Fang et al. (2024) - ""Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data""

The reviewer mentions that including a more comprehensive discussion on these related works and how the proposed method compares to them would provide better context and highlight the contributions more effectively.",1,"2016, 2023, 2024",Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data
cGnPphEnTd,"The paper studies the extent to which LLMs can learn compositional generalization over skills by finetuning with suitable training examples. Based on abundant experimental results, the paper concludes that finetuning using a dataset with skill composition examples helps the model build a “meta-skill” that allows them to generalize to more complex (i.e., composition of more skills) tasks. The paper also finds that the training samples containing higher-order skill compositions are more efficient in eliciting such a meta-skill. The paper is quite easy to follow and the conclusions might inspire more interesting applications on LLM’s finetuning.","- The paper proposes a dataset that consists of examples with different selected skills for the analysis of skill composition.
- The results in this paper show that finetuning not only provides new knowledge to the LLM but also the skill of composing different skills, which potentially inspire novel applications using finetuning.
- The proposed method (although looks simple) efficiently improves the model’s performance on skill composition. The observation that the “skill-richer” data can induce the ability to compose skills faster would be very useful for practical LLM finetuning applications.","- It might be a bit hard to read the trends and compare results in the tables, visualizing some results might be helpful.","- Line 157 mentions that the data has a form of [prompt 1, answer 1, prompt 2, answer 2]. I do not quite understand why we need prompt 2 and answer 2 here. Will the analysis still hold for simple [prompt 1, answer 1] data samples?
- In line 260, the paper mentions a counter-intuitive phenomenon that the held-out performance is better than the train performance. The hypothetical explanation is that the model knows how to compose the held-out skills better than training skills. I think an experiment of switching the skill categories of the training and held-out sets can further support (or against) this hypothesis.
- The problem setting studied in this paper reminds me of the “least-to-most” prompting design [1]. This paper shows using some in-context examples of $k=1,2$ can make the model generalize to problems with large $k$. Hence I’m curious about whether combining these more complex in-context prompt designs could further improve the finetuning performance. (I think the analysis and experiment in the current submission is enough for a good paper, just point out this paper and a potential idea.)

[1] Zhou, Denny, et al. ""Least-to-most prompting enables complex reasoning in large language models."" ICLR 2023",Please refer to the question and weakness part.,['No ethics review needed.'],6,4,,Yes,3,4,3,1718759135767,,,NeurIPS.cc/2024/Conference,1sLdprsbmk,"['NeurIPS.cc/2024/Conference/Submission21185/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880167106,[],1,,,['everyone'],1sLdprsbmk,['NeurIPS.cc/2024/Conference/Submission21185/Reviewer_vwLV'],1718759135767,1730880167106,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission21185/Reviewer_vwLV']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, namely:

Zhou, Denny, et al. ""Least-to-most prompting enables complex reasoning in large language models."" ICLR 2023.

This is mentioned in the ""questions"" section of the review, where the reviewer notes that the problem setting studied in the paper reminds them of the ""least-to-most"" prompting design and suggests that combining these more complex in-context prompt designs could further improve the finetuning performance.",1,2023,Least-to-most prompting enables complex reasoning in large language models
Gp1OxGr9VU,"This article studies whether or not LLMs can be fine-tuned to compose skills for text generation. The authors generated training data from GPt-4 in the style of the Skill-Mix benchmark, asking the model to generate text about a topic while using a set of k skills (e.g., sympathy, temporal reasoning, syllogism, etc.). LlaMa-2 and Mistral-7B were then fine-tuned on this synthetic data and evaluated on their ability to generalize to combinations of novel skills, and to more combinations of skills than seen during training. Using GPT-4 as a grader, the authors find that fine-tuning substantially improves compositional generalization.","This article has a number of strengths
- addresses the important topic of compositional generalization using complex tasks
- well-written article
- technically sound
- evaluation for combining novel skills and combining novel numbers of skills
- Two graders were evaluated (GPT-4 and Claude)
- Data efficiency was also studied

This is solid work that is consistent with other recent work on ""learning to compose"" through training [1,2]. It addresses these ideas on a larger scale than in past studies and shows compelling results, especially the generalization to more complex combinations.
[1] Conklin, H., Wang, B., Smith, K., & Titov, I. (2021). Meta-learning to compositionally generalize. arXiv preprint arXiv:2106.04252.
[2] Lake, B. M., & Baroni, M. (2023). Human-like systematic generalization through a meta-learning neural network. Nature, 623(7985), 115-121.","The tasks in the Skill-Mix benchmark seem quite artificial, and difficult for people to both produce and evaluate. Only two example generations are provide in the appendix, and the first one has odd syntax in the prompt: ""The example should be a short tweet up to a few lines in the context of produce review...""

Another weakness is the use of automatic grading by GPT-4, although it seems unavoidable and they also tested another grader from Claude. Additional discussion justifying this choice and the accuracy of the grader seems warranted.",I don't have additional questions at this point.,This section is fine.,['No ethics review needed.'],7,4,,Yes,3,4,4,1720809009520,,,NeurIPS.cc/2024/Conference,1sLdprsbmk,"['NeurIPS.cc/2024/Conference/Submission21185/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880166951,[],2,,,['everyone'],1sLdprsbmk,['NeurIPS.cc/2024/Conference/Submission21185/Reviewer_4iaf'],1720809009520,1730880166951,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission21185/Reviewer_4iaf']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. Conklin, H., Wang, B., Smith, K., & Titov, I. (2021). Meta-learning to compositionally generalize. arXiv preprint arXiv:2106.04252.
2. Lake, B. M., & Baroni, M. (2023). Human-like systematic generalization through a meta-learning neural network. Nature, 623(7985), 115-121.

These references are mentioned as examples of ""other recent work on 'learning to compose' through training"" that the reviewed paper's work is consistent with.",1,"2021, 2021, 2023",Meta-learning to compositionally generalize 
Gp1OxGr9VU,"This article studies whether or not LLMs can be fine-tuned to compose skills for text generation. The authors generated training data from GPt-4 in the style of the Skill-Mix benchmark, asking the model to generate text about a topic while using a set of k skills (e.g., sympathy, temporal reasoning, syllogism, etc.). LlaMa-2 and Mistral-7B were then fine-tuned on this synthetic data and evaluated on their ability to generalize to combinations of novel skills, and to more combinations of skills than seen during training. Using GPT-4 as a grader, the authors find that fine-tuning substantially improves compositional generalization.","This article has a number of strengths
- addresses the important topic of compositional generalization using complex tasks
- well-written article
- technically sound
- evaluation for combining novel skills and combining novel numbers of skills
- Two graders were evaluated (GPT-4 and Claude)
- Data efficiency was also studied

This is solid work that is consistent with other recent work on ""learning to compose"" through training [1,2]. It addresses these ideas on a larger scale than in past studies and shows compelling results, especially the generalization to more complex combinations.
[1] Conklin, H., Wang, B., Smith, K., & Titov, I. (2021). Meta-learning to compositionally generalize. arXiv preprint arXiv:2106.04252.
[2] Lake, B. M., & Baroni, M. (2023). Human-like systematic generalization through a meta-learning neural network. Nature, 623(7985), 115-121.","The tasks in the Skill-Mix benchmark seem quite artificial, and difficult for people to both produce and evaluate. Only two example generations are provide in the appendix, and the first one has odd syntax in the prompt: ""The example should be a short tweet up to a few lines in the context of produce review...""

Another weakness is the use of automatic grading by GPT-4, although it seems unavoidable and they also tested another grader from Claude. Additional discussion justifying this choice and the accuracy of the grader seems warranted.",I don't have additional questions at this point.,This section is fine.,['No ethics review needed.'],7,4,,Yes,3,4,4,1720809009520,,,NeurIPS.cc/2024/Conference,1sLdprsbmk,"['NeurIPS.cc/2024/Conference/Submission21185/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880166951,[],2,,,['everyone'],1sLdprsbmk,['NeurIPS.cc/2024/Conference/Submission21185/Reviewer_4iaf'],1720809009520,1730880166951,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission21185/Reviewer_4iaf']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. Conklin, H., Wang, B., Smith, K., & Titov, I. (2021). Meta-learning to compositionally generalize. arXiv preprint arXiv:2106.04252.
2. Lake, B. M., & Baroni, M. (2023). Human-like systematic generalization through a meta-learning neural network. Nature, 623(7985), 115-121.

These references are mentioned as examples of ""other recent work on 'learning to compose' through training"" that the reviewed paper's work is consistent with.",1,"2021, 2021, 2023",Human-like systematic generalization through a meta-learning neural network
ntbhmiCrwQ,"The paper explores the capacity of smaller language models to learn compositional generalization from finetuning. Utilizing the Skill-Mix set-up, the study delivers comprehensive experiments to assesse how small language models can improve their performance on both in-distribution and out-of-distribution compositional tasks after finetuning on systhetic datasets regarding in-distribution easier tasks generated by GPT-4.","- The paper is well-written.
- The paper focuses on a very important topic (compositional generalization) of current LLM research.
- It's easy to understand the intuition behind the comprehensive experiments.","- The experiment pipeline is not novel and highly overlaps with the previous work [1]  .
- The paper is limited on one specific method on evaluating if language models can generalize compositionally on 'harder' tasks after finetuning on 'easier' compositional examples. There exists many other evaluation methods/metrics covered in related works that are not mentioned, including [2] and [3].
- The paper does not properly explain and support the claim made in line 64-65 and line 243-244, i.e., 

    > Instead, they are acquiring a higher-order meta-skill that allows them to generalize and apply to combine unseen skills.

    > The results suggest that its ability to compose multiple skills does not come from overfitting training data but should be perceived as learning a *meta-skill* instead. 

   This claim is very strong and needs more experimental results from other compositional tasks or theoretical justifications.

[1] Yu, Dingli, et al. ""Skill-Mix: A flexible and expandable family of evaluations for AI models."" arXiv preprint arXiv:2310.17567 (2023).

[2] Dziri, Nouha, et al. ""Faith and fate: Limits of transformers on compositionality."" Advances in Neural Information Processing Systems 36 (2024).

[3] Chen, Jiaao, et al. ""Skills-in-context prompting: Unlocking compositionality in large language models."" arXiv preprint arXiv:2308.00304 (2023).","- The skill-mix paper only released small part of topics and skills to prevent people from chasing the leaderboard, so I'm wondering if the full list of skills and topics used in this paper is the same as the original paper.
- The second-last line in Table 3 shows that Mistral-7B-Instruct-v0.2 get 0 point for Skill Fraction on $\text { SKILL-MIX }(k)$ after finetuning on $\mathcal{D}_{\text {SKILL-MIX }}(1,2)$. This seems to be a typo.
- The experimental results showing performance improvements after finetuning are unsurprised unless the author can justify if the model is indeed learning how to combine skills compositionally during finetuning.",The limitations are mentioned in the Appendix section.,['No ethics review needed.'],5,4,,Yes,2,3,3,1720849652392,,,NeurIPS.cc/2024/Conference,1sLdprsbmk,"['NeurIPS.cc/2024/Conference/Submission21185/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880166794,[],3,,,['everyone'],1sLdprsbmk,['NeurIPS.cc/2024/Conference/Submission21185/Reviewer_ZBU1'],1720849652392,1730880166794,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission21185/Reviewer_ZBU1']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. Yu, Dingli, et al. ""Skill-Mix: A flexible and expandable family of evaluations for AI models."" (referenced as [1])
2. Dziri, Nouha, et al. ""Faith and fate: Limits of transformers on compositionality."" (referenced as [2])
3. Chen, Jiaao, et al. ""Skills-in-context prompting: Unlocking compositionality in large language models."" (referenced as [3])

The reviewer mentions these references to point out that the experiment pipeline is not novel and overlaps with previous work ([1]), and that there are other evaluation methods and metrics covered in related works ([2] and [3]) that are not mentioned in the paper.",1,,Skill-Mix A flexible and expandable family of evaluations for AI models
ntbhmiCrwQ,"The paper explores the capacity of smaller language models to learn compositional generalization from finetuning. Utilizing the Skill-Mix set-up, the study delivers comprehensive experiments to assesse how small language models can improve their performance on both in-distribution and out-of-distribution compositional tasks after finetuning on systhetic datasets regarding in-distribution easier tasks generated by GPT-4.","- The paper is well-written.
- The paper focuses on a very important topic (compositional generalization) of current LLM research.
- It's easy to understand the intuition behind the comprehensive experiments.","- The experiment pipeline is not novel and highly overlaps with the previous work [1]  .
- The paper is limited on one specific method on evaluating if language models can generalize compositionally on 'harder' tasks after finetuning on 'easier' compositional examples. There exists many other evaluation methods/metrics covered in related works that are not mentioned, including [2] and [3].
- The paper does not properly explain and support the claim made in line 64-65 and line 243-244, i.e., 

    > Instead, they are acquiring a higher-order meta-skill that allows them to generalize and apply to combine unseen skills.

    > The results suggest that its ability to compose multiple skills does not come from overfitting training data but should be perceived as learning a *meta-skill* instead. 

   This claim is very strong and needs more experimental results from other compositional tasks or theoretical justifications.

[1] Yu, Dingli, et al. ""Skill-Mix: A flexible and expandable family of evaluations for AI models."" arXiv preprint arXiv:2310.17567 (2023).

[2] Dziri, Nouha, et al. ""Faith and fate: Limits of transformers on compositionality."" Advances in Neural Information Processing Systems 36 (2024).

[3] Chen, Jiaao, et al. ""Skills-in-context prompting: Unlocking compositionality in large language models."" arXiv preprint arXiv:2308.00304 (2023).","- The skill-mix paper only released small part of topics and skills to prevent people from chasing the leaderboard, so I'm wondering if the full list of skills and topics used in this paper is the same as the original paper.
- The second-last line in Table 3 shows that Mistral-7B-Instruct-v0.2 get 0 point for Skill Fraction on $\text { SKILL-MIX }(k)$ after finetuning on $\mathcal{D}_{\text {SKILL-MIX }}(1,2)$. This seems to be a typo.
- The experimental results showing performance improvements after finetuning are unsurprised unless the author can justify if the model is indeed learning how to combine skills compositionally during finetuning.",The limitations are mentioned in the Appendix section.,['No ethics review needed.'],5,4,,Yes,2,3,3,1720849652392,,,NeurIPS.cc/2024/Conference,1sLdprsbmk,"['NeurIPS.cc/2024/Conference/Submission21185/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880166794,[],3,,,['everyone'],1sLdprsbmk,['NeurIPS.cc/2024/Conference/Submission21185/Reviewer_ZBU1'],1720849652392,1730880166794,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission21185/Reviewer_ZBU1']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. Yu, Dingli, et al. ""Skill-Mix: A flexible and expandable family of evaluations for AI models."" (referenced as [1])
2. Dziri, Nouha, et al. ""Faith and fate: Limits of transformers on compositionality."" (referenced as [2])
3. Chen, Jiaao, et al. ""Skills-in-context prompting: Unlocking compositionality in large language models."" (referenced as [3])

The reviewer mentions these references to point out that the experiment pipeline is not novel and overlaps with previous work ([1]), and that there are other evaluation methods and metrics covered in related works ([2] and [3]) that are not mentioned in the paper.",1,,Faith and fate Limits of transformers on compositionality
ntbhmiCrwQ,"The paper explores the capacity of smaller language models to learn compositional generalization from finetuning. Utilizing the Skill-Mix set-up, the study delivers comprehensive experiments to assesse how small language models can improve their performance on both in-distribution and out-of-distribution compositional tasks after finetuning on systhetic datasets regarding in-distribution easier tasks generated by GPT-4.","- The paper is well-written.
- The paper focuses on a very important topic (compositional generalization) of current LLM research.
- It's easy to understand the intuition behind the comprehensive experiments.","- The experiment pipeline is not novel and highly overlaps with the previous work [1]  .
- The paper is limited on one specific method on evaluating if language models can generalize compositionally on 'harder' tasks after finetuning on 'easier' compositional examples. There exists many other evaluation methods/metrics covered in related works that are not mentioned, including [2] and [3].
- The paper does not properly explain and support the claim made in line 64-65 and line 243-244, i.e., 

    > Instead, they are acquiring a higher-order meta-skill that allows them to generalize and apply to combine unseen skills.

    > The results suggest that its ability to compose multiple skills does not come from overfitting training data but should be perceived as learning a *meta-skill* instead. 

   This claim is very strong and needs more experimental results from other compositional tasks or theoretical justifications.

[1] Yu, Dingli, et al. ""Skill-Mix: A flexible and expandable family of evaluations for AI models."" arXiv preprint arXiv:2310.17567 (2023).

[2] Dziri, Nouha, et al. ""Faith and fate: Limits of transformers on compositionality."" Advances in Neural Information Processing Systems 36 (2024).

[3] Chen, Jiaao, et al. ""Skills-in-context prompting: Unlocking compositionality in large language models."" arXiv preprint arXiv:2308.00304 (2023).","- The skill-mix paper only released small part of topics and skills to prevent people from chasing the leaderboard, so I'm wondering if the full list of skills and topics used in this paper is the same as the original paper.
- The second-last line in Table 3 shows that Mistral-7B-Instruct-v0.2 get 0 point for Skill Fraction on $\text { SKILL-MIX }(k)$ after finetuning on $\mathcal{D}_{\text {SKILL-MIX }}(1,2)$. This seems to be a typo.
- The experimental results showing performance improvements after finetuning are unsurprised unless the author can justify if the model is indeed learning how to combine skills compositionally during finetuning.",The limitations are mentioned in the Appendix section.,['No ethics review needed.'],5,4,,Yes,2,3,3,1720849652392,,,NeurIPS.cc/2024/Conference,1sLdprsbmk,"['NeurIPS.cc/2024/Conference/Submission21185/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880166794,[],3,,,['everyone'],1sLdprsbmk,['NeurIPS.cc/2024/Conference/Submission21185/Reviewer_ZBU1'],1720849652392,1730880166794,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission21185/Reviewer_ZBU1']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. Yu, Dingli, et al. ""Skill-Mix: A flexible and expandable family of evaluations for AI models."" (referenced as [1])
2. Dziri, Nouha, et al. ""Faith and fate: Limits of transformers on compositionality."" (referenced as [2])
3. Chen, Jiaao, et al. ""Skills-in-context prompting: Unlocking compositionality in large language models."" (referenced as [3])

The reviewer mentions these references to point out that the experiment pipeline is not novel and overlaps with previous work ([1]), and that there are other evaluation methods and metrics covered in related works ([2] and [3]) that are not mentioned in the paper.",1,,Skills-in-context prompting Unlocking compositionality in large language models
HzvzyLYrmt,"This paper examines the relationship between egalitarian fairness concepts and stability in federated learning, where multiple clients collaboratively train a shared model while retaining local data privacy. Egalitarian fairness promotes uniform model performance across clients, but this can reduce performance for data-rich clients, potentially causing instability, as these clients might leave for better-performing coalitions. This work employs cooperative game theory and social choice to frame FL systems as altruism coalition formation games, suggesting that core instability issues are linked to clients' altruism and their network of relationships. The authors propose optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors, suggesting that egalitarian fairness does not necessarily lead to instability.","The main strength of this paper is its comprehensive approach to analyzing federated learning under both selfish and altruistic behavior. By considering both the performance of machine learners and the game-theoretic aspects of how federated learners interact, the authors provide a well-rounded analysis of the relationship between egalitarian fairness and stability. The use of game theory and social choice theory to frame FL systems as altruism coalition formation games is particularly innovative, linking instability issues to clients' altruism and their network of relationships. The proposed optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors are a significant theoretical advancement, disproving the assumption that egalitarian fairness inevitably leads to instability. The technical correctness of the results, subject to the model assumed, further solidifies the paper's contribution to advancing the state of the art in this field. Experimental validation then convincingly supports these theoretical findings with empirical outcomes.","I'm left with some questions about the motivations for the model, though the authors do a good job motivating it with prior work. I'm also left wondering whether some results and assumptions can be generalized, as the analysis is somewhat rigid; the paper would be much stronger if some results held in greater generality. I also question the model of FL used here (FedAvg), as it simply averages over model parameters (it would be nice to see models where clients submit gradient updates rather than complete models, and also where the central authority itself optimizes for egalitarian or other fairness objectives, rather than averaging). Finally, I argue the client utilities don't fully reflect the impact of overfitting.","Clearly the FedAvg rule for $\theta$ (line 126) promotes privacy in some sense, but with modest added noise, is the mechanism differentially private?

I would argue that definition 1 is more closely related to the demographic parity concept of equalized error [10], not egalitarian fairness. I would claim that in loss contexts, egalitarian welfare (or more aptly, malfare) is simply the max over average losses of agents [8], but inequality between agents is not antithetical to egalitarian fairness, rather egalitarianism is indifferent to the performance of high performing groups so long as low performing groups cannot be improved. I suppose this is more of a terminology issue, though I do ask if an additive version of this could be explored, where error values are compared to the maximum per group error.

Lemma 1 is quite confusing to me. $\mu_{e}$ depends on i, but notation does not reflect this. By expected value of the variance, you seem to mean expected value of the raw variance, but it's not clear why I care about that quantity? Is this assuming realizability, and therefore the square here corresponds to square loss? Is the method specific to square error though? Why not work directly in terms of loss? These inferences are somewhat confirmed in section 6, though I suspect a method is not really specific to square error, and I claim a more general description in terms of generic loss and loss variance would be easier to follow.

I also think this result does not properly consider overfitting, so I don't think it's very well motivated in a machine learning context. Loss variances should be model (parameter) dependent, so if this is in terms of minimum variance, I suspect it's a reasonable lower bound, and if maximum variance is considered (and multiplied by the log of the model class cardinality or some similar capacity measure), it may be a reasonable upper bound? It's also not totally clear to me which quantities refer to distributions and which refer to data sets in this definition. I would be interested to see a more general analysis, in terms of quantities like Rademacher averages that better characterize overfitting in machine learning [1,2,5]. Some discussion of how this applies to fair learning in particular would be appreciated, especially as works like [9] show that the process of optimizing fair ML objectives has a regularizing effect and can actually reduce overfitting.

In lemmas 2,3,&4, the requirement is that this holds for all i, correct? These are a bit tricky to read, because $\mu_{e}$ depends on i, although $\sigma^{2}$ does not, and the notation does not reflect this. Moreover, it seems unfortunate that we reach the same conclusion in all three cases, is this necessary (i.e., are there counterexamples to improvement in each?).

I think these results can only be true if client distributions are drawn IID. This should be clarified in lemma 1. This is a big assumption, since I might expect friends’ distributions to be correlated (which incentivizes them to deviate, harming core stability). But I also need to ask, is the variance between distributions the sample variance or the distribution variance? I think this matters a lot, since presumably there are relatively few agents, and if the sample variance is what matters, then why can't we condition on the sample (in which case independence wouldn’t matter)?


In section 4.1, I think it would be nice to generalize this idea to define a client's utility function as some welfare function of their own value and the value of their friends. I think this would simplify the presentation, but also you would be able to use more sophisticated concepts, like weighted power-means.

Moreover, since the same result holds for purely altruistic and friendly altruistic cases, this immediately implies that the client utility functions can be the utilitarian maximum social welfare (malfare) function [6,11], and some set of weighted utilitarian welfare (malfare) functions. I suspect it could easily generalize to any weighted utilitarian welfare function. I would also be very interested to see if these results held for any unweighted power-mean welfare function, any weighted power-mean welfare function, or any Gini malfare function [6], as they do in some sense lie between welfare altruism and equal altruism, though I don't think these results follow directly from your stated lemmas.



Minor points:

149 “satisfy” should be “satisfies.” Moreover this definition feels a bit redundant with (1).

158 It seems strange to mix a sociological definition of friend with a mathematical definition. Moreover, while I am not a sociologist, it seems wrong that “friend” would be the most intimate trusted voluntary category. If so, what is a best friend, and where does that leave a partner? But is this discussion even necessary?

Perhaps definitions 2 3 and 4 can be merged to describe the coalitional game?

163 “does not exist” to “does not exist a”


171 I dislike this terminology. I would describe both types of altruism as considering different types of the welfare among friends, but I would term them “egalitarian altruism” and “utilitarian altruism,” respectively [1].","FedAvg

I don't love the FedAvg aggregation rule of line 126 (though I appreciate that the authors analyze an established model). This seems appropriate when groups train relatively similar models on their own, and the lost surface is relatively smooth. I suspect this is a decent rule when each client has the same optimal model, but due to limited sampling wouldn't identify this from their own data.

The approach seems particularly problematic for non-convex loss surfaces, or models with symmetry (e.g., neural networks or mixture models where averaging the parameters of two identical models can produce a completely different model). I’d like to see more discussion of these limitations (or generalization of the model).

However, I would like to see some consideration of other models of FL, for instance when clients send gradient updates, rather than raw model parameters. From reading the introduction, I expected the FL to be trained to incentivize egalitarian fairness, but this simple averaging rule is neither utilitarian optimal, nor is it egalitarian optimal. Works like [3] consider sampling implications for this, and biased SGD analyses [4,7] also seem appropriate to discuss, at least in related work.

Overfitting

I would also like to see some consideration of overfitting. It seems tautological that nonaltruistic agents would prefer to train their own model when only training loss is considered, and while altruism may incentivize them to share their data, there is also the non-altruistic effect of reduced overfitting. It seems this would also disincentivize the formations of small coalitions, so I would be very interested to see what impact these factors have on the work.


References:

[1] An axiomatic theory of provably-fair welfare-centric machine learning
C Cousins
Advances in Neural Information Processing Systems 34, 16610-16621

[2] Revisiting fair-PAC learning and the axioms of cardinal welfare
C Cousins
International Conference on Artificial Intelligence and Statistics, 6422-6442

[3] Jacob D Abernethy, Pranjal Awasthi, Matthäus Kleindessner, Jamie Morgenstern, Chris Russell, and Jie Zhang. Active sampling for min-max fairness. In International
Conference on Machine Learning, volume 162, 2022.

[4] A guide through the zoo of biased SGD
Y Demidovich, G Malinovsky… - Advances in Neural …, 2024 - proceedings.neurips.cc,

[5] Uncertainty and the social planner’s problem: Why sample complexity matters
C Cousins
Proceedings of the 2022 ACM Conference on Fairness, Accountability, and …

[6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
Cyrus Cousins

[7] Hu, Yifan, et al. ""Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning."" Advances in Neural Information Processing Systems 33 (2020): 2759-2770.

[8] John Rawls. A theory of justice. Harvard University Press, 1971.

[9] Cousins, Cyrus, I. Elizabeth Kumar, and Suresh Venkatasubramanian. ""To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models."" International Conference on Artificial Intelligence and Statistics. PMLR, 2024.

[10] Dwork, Cynthia, et al. ""Fairness through awareness."" Proceedings of the 3rd innovations in theoretical computer science conference. 2012.

[11] Deschamps, R., Gevers, L.: Leximin and utilitarian rules: A joint characterization. Journal of Economic Theory 17(2), 143–163 (1978)",['No ethics review needed.'],6,4,,Yes,2,3,4,1721221878048,,,NeurIPS.cc/2024/Conference,1kyc4TSOFZ,"['NeurIPS.cc/2024/Conference/Submission3661/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878866018,[],3,,,['everyone'],1kyc4TSOFZ,['NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP'],1721221878048,1730878866018,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] An axiomatic theory of provably-fair welfare-centric machine learning
2. [2] Revisiting fair-PAC learning and the axioms of cardinal welfare
3. [3] Active sampling for min-max fairness
4. [4] A guide through the zoo of biased SGD
5. [5] Uncertainty and the social planner’s problem: Why sample complexity matters
6. [6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
7. [7] Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning
8. [8] A theory of justice
9. [9] To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models
10. [10] Fairness through awareness
11. [11] Leximin and utilitarian rules: A joint characterization

These citations are provided as references to support the reviewer's comments and suggestions for improving the paper.",1,,An axiomatic theory of provably-fair welfare-centric machine learning
HzvzyLYrmt,"This paper examines the relationship between egalitarian fairness concepts and stability in federated learning, where multiple clients collaboratively train a shared model while retaining local data privacy. Egalitarian fairness promotes uniform model performance across clients, but this can reduce performance for data-rich clients, potentially causing instability, as these clients might leave for better-performing coalitions. This work employs cooperative game theory and social choice to frame FL systems as altruism coalition formation games, suggesting that core instability issues are linked to clients' altruism and their network of relationships. The authors propose optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors, suggesting that egalitarian fairness does not necessarily lead to instability.","The main strength of this paper is its comprehensive approach to analyzing federated learning under both selfish and altruistic behavior. By considering both the performance of machine learners and the game-theoretic aspects of how federated learners interact, the authors provide a well-rounded analysis of the relationship between egalitarian fairness and stability. The use of game theory and social choice theory to frame FL systems as altruism coalition formation games is particularly innovative, linking instability issues to clients' altruism and their network of relationships. The proposed optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors are a significant theoretical advancement, disproving the assumption that egalitarian fairness inevitably leads to instability. The technical correctness of the results, subject to the model assumed, further solidifies the paper's contribution to advancing the state of the art in this field. Experimental validation then convincingly supports these theoretical findings with empirical outcomes.","I'm left with some questions about the motivations for the model, though the authors do a good job motivating it with prior work. I'm also left wondering whether some results and assumptions can be generalized, as the analysis is somewhat rigid; the paper would be much stronger if some results held in greater generality. I also question the model of FL used here (FedAvg), as it simply averages over model parameters (it would be nice to see models where clients submit gradient updates rather than complete models, and also where the central authority itself optimizes for egalitarian or other fairness objectives, rather than averaging). Finally, I argue the client utilities don't fully reflect the impact of overfitting.","Clearly the FedAvg rule for $\theta$ (line 126) promotes privacy in some sense, but with modest added noise, is the mechanism differentially private?

I would argue that definition 1 is more closely related to the demographic parity concept of equalized error [10], not egalitarian fairness. I would claim that in loss contexts, egalitarian welfare (or more aptly, malfare) is simply the max over average losses of agents [8], but inequality between agents is not antithetical to egalitarian fairness, rather egalitarianism is indifferent to the performance of high performing groups so long as low performing groups cannot be improved. I suppose this is more of a terminology issue, though I do ask if an additive version of this could be explored, where error values are compared to the maximum per group error.

Lemma 1 is quite confusing to me. $\mu_{e}$ depends on i, but notation does not reflect this. By expected value of the variance, you seem to mean expected value of the raw variance, but it's not clear why I care about that quantity? Is this assuming realizability, and therefore the square here corresponds to square loss? Is the method specific to square error though? Why not work directly in terms of loss? These inferences are somewhat confirmed in section 6, though I suspect a method is not really specific to square error, and I claim a more general description in terms of generic loss and loss variance would be easier to follow.

I also think this result does not properly consider overfitting, so I don't think it's very well motivated in a machine learning context. Loss variances should be model (parameter) dependent, so if this is in terms of minimum variance, I suspect it's a reasonable lower bound, and if maximum variance is considered (and multiplied by the log of the model class cardinality or some similar capacity measure), it may be a reasonable upper bound? It's also not totally clear to me which quantities refer to distributions and which refer to data sets in this definition. I would be interested to see a more general analysis, in terms of quantities like Rademacher averages that better characterize overfitting in machine learning [1,2,5]. Some discussion of how this applies to fair learning in particular would be appreciated, especially as works like [9] show that the process of optimizing fair ML objectives has a regularizing effect and can actually reduce overfitting.

In lemmas 2,3,&4, the requirement is that this holds for all i, correct? These are a bit tricky to read, because $\mu_{e}$ depends on i, although $\sigma^{2}$ does not, and the notation does not reflect this. Moreover, it seems unfortunate that we reach the same conclusion in all three cases, is this necessary (i.e., are there counterexamples to improvement in each?).

I think these results can only be true if client distributions are drawn IID. This should be clarified in lemma 1. This is a big assumption, since I might expect friends’ distributions to be correlated (which incentivizes them to deviate, harming core stability). But I also need to ask, is the variance between distributions the sample variance or the distribution variance? I think this matters a lot, since presumably there are relatively few agents, and if the sample variance is what matters, then why can't we condition on the sample (in which case independence wouldn’t matter)?


In section 4.1, I think it would be nice to generalize this idea to define a client's utility function as some welfare function of their own value and the value of their friends. I think this would simplify the presentation, but also you would be able to use more sophisticated concepts, like weighted power-means.

Moreover, since the same result holds for purely altruistic and friendly altruistic cases, this immediately implies that the client utility functions can be the utilitarian maximum social welfare (malfare) function [6,11], and some set of weighted utilitarian welfare (malfare) functions. I suspect it could easily generalize to any weighted utilitarian welfare function. I would also be very interested to see if these results held for any unweighted power-mean welfare function, any weighted power-mean welfare function, or any Gini malfare function [6], as they do in some sense lie between welfare altruism and equal altruism, though I don't think these results follow directly from your stated lemmas.



Minor points:

149 “satisfy” should be “satisfies.” Moreover this definition feels a bit redundant with (1).

158 It seems strange to mix a sociological definition of friend with a mathematical definition. Moreover, while I am not a sociologist, it seems wrong that “friend” would be the most intimate trusted voluntary category. If so, what is a best friend, and where does that leave a partner? But is this discussion even necessary?

Perhaps definitions 2 3 and 4 can be merged to describe the coalitional game?

163 “does not exist” to “does not exist a”


171 I dislike this terminology. I would describe both types of altruism as considering different types of the welfare among friends, but I would term them “egalitarian altruism” and “utilitarian altruism,” respectively [1].","FedAvg

I don't love the FedAvg aggregation rule of line 126 (though I appreciate that the authors analyze an established model). This seems appropriate when groups train relatively similar models on their own, and the lost surface is relatively smooth. I suspect this is a decent rule when each client has the same optimal model, but due to limited sampling wouldn't identify this from their own data.

The approach seems particularly problematic for non-convex loss surfaces, or models with symmetry (e.g., neural networks or mixture models where averaging the parameters of two identical models can produce a completely different model). I’d like to see more discussion of these limitations (or generalization of the model).

However, I would like to see some consideration of other models of FL, for instance when clients send gradient updates, rather than raw model parameters. From reading the introduction, I expected the FL to be trained to incentivize egalitarian fairness, but this simple averaging rule is neither utilitarian optimal, nor is it egalitarian optimal. Works like [3] consider sampling implications for this, and biased SGD analyses [4,7] also seem appropriate to discuss, at least in related work.

Overfitting

I would also like to see some consideration of overfitting. It seems tautological that nonaltruistic agents would prefer to train their own model when only training loss is considered, and while altruism may incentivize them to share their data, there is also the non-altruistic effect of reduced overfitting. It seems this would also disincentivize the formations of small coalitions, so I would be very interested to see what impact these factors have on the work.


References:

[1] An axiomatic theory of provably-fair welfare-centric machine learning
C Cousins
Advances in Neural Information Processing Systems 34, 16610-16621

[2] Revisiting fair-PAC learning and the axioms of cardinal welfare
C Cousins
International Conference on Artificial Intelligence and Statistics, 6422-6442

[3] Jacob D Abernethy, Pranjal Awasthi, Matthäus Kleindessner, Jamie Morgenstern, Chris Russell, and Jie Zhang. Active sampling for min-max fairness. In International
Conference on Machine Learning, volume 162, 2022.

[4] A guide through the zoo of biased SGD
Y Demidovich, G Malinovsky… - Advances in Neural …, 2024 - proceedings.neurips.cc,

[5] Uncertainty and the social planner’s problem: Why sample complexity matters
C Cousins
Proceedings of the 2022 ACM Conference on Fairness, Accountability, and …

[6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
Cyrus Cousins

[7] Hu, Yifan, et al. ""Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning."" Advances in Neural Information Processing Systems 33 (2020): 2759-2770.

[8] John Rawls. A theory of justice. Harvard University Press, 1971.

[9] Cousins, Cyrus, I. Elizabeth Kumar, and Suresh Venkatasubramanian. ""To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models."" International Conference on Artificial Intelligence and Statistics. PMLR, 2024.

[10] Dwork, Cynthia, et al. ""Fairness through awareness."" Proceedings of the 3rd innovations in theoretical computer science conference. 2012.

[11] Deschamps, R., Gevers, L.: Leximin and utilitarian rules: A joint characterization. Journal of Economic Theory 17(2), 143–163 (1978)",['No ethics review needed.'],6,4,,Yes,2,3,4,1721221878048,,,NeurIPS.cc/2024/Conference,1kyc4TSOFZ,"['NeurIPS.cc/2024/Conference/Submission3661/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878866018,[],3,,,['everyone'],1kyc4TSOFZ,['NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP'],1721221878048,1730878866018,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] An axiomatic theory of provably-fair welfare-centric machine learning
2. [2] Revisiting fair-PAC learning and the axioms of cardinal welfare
3. [3] Active sampling for min-max fairness
4. [4] A guide through the zoo of biased SGD
5. [5] Uncertainty and the social planner’s problem: Why sample complexity matters
6. [6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
7. [7] Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning
8. [8] A theory of justice
9. [9] To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models
10. [10] Fairness through awareness
11. [11] Leximin and utilitarian rules: A joint characterization

These citations are provided as references to support the reviewer's comments and suggestions for improving the paper.",1,,Revisiting fair-PAC learning and the axioms of cardinal welfare
HzvzyLYrmt,"This paper examines the relationship between egalitarian fairness concepts and stability in federated learning, where multiple clients collaboratively train a shared model while retaining local data privacy. Egalitarian fairness promotes uniform model performance across clients, but this can reduce performance for data-rich clients, potentially causing instability, as these clients might leave for better-performing coalitions. This work employs cooperative game theory and social choice to frame FL systems as altruism coalition formation games, suggesting that core instability issues are linked to clients' altruism and their network of relationships. The authors propose optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors, suggesting that egalitarian fairness does not necessarily lead to instability.","The main strength of this paper is its comprehensive approach to analyzing federated learning under both selfish and altruistic behavior. By considering both the performance of machine learners and the game-theoretic aspects of how federated learners interact, the authors provide a well-rounded analysis of the relationship between egalitarian fairness and stability. The use of game theory and social choice theory to frame FL systems as altruism coalition formation games is particularly innovative, linking instability issues to clients' altruism and their network of relationships. The proposed optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors are a significant theoretical advancement, disproving the assumption that egalitarian fairness inevitably leads to instability. The technical correctness of the results, subject to the model assumed, further solidifies the paper's contribution to advancing the state of the art in this field. Experimental validation then convincingly supports these theoretical findings with empirical outcomes.","I'm left with some questions about the motivations for the model, though the authors do a good job motivating it with prior work. I'm also left wondering whether some results and assumptions can be generalized, as the analysis is somewhat rigid; the paper would be much stronger if some results held in greater generality. I also question the model of FL used here (FedAvg), as it simply averages over model parameters (it would be nice to see models where clients submit gradient updates rather than complete models, and also where the central authority itself optimizes for egalitarian or other fairness objectives, rather than averaging). Finally, I argue the client utilities don't fully reflect the impact of overfitting.","Clearly the FedAvg rule for $\theta$ (line 126) promotes privacy in some sense, but with modest added noise, is the mechanism differentially private?

I would argue that definition 1 is more closely related to the demographic parity concept of equalized error [10], not egalitarian fairness. I would claim that in loss contexts, egalitarian welfare (or more aptly, malfare) is simply the max over average losses of agents [8], but inequality between agents is not antithetical to egalitarian fairness, rather egalitarianism is indifferent to the performance of high performing groups so long as low performing groups cannot be improved. I suppose this is more of a terminology issue, though I do ask if an additive version of this could be explored, where error values are compared to the maximum per group error.

Lemma 1 is quite confusing to me. $\mu_{e}$ depends on i, but notation does not reflect this. By expected value of the variance, you seem to mean expected value of the raw variance, but it's not clear why I care about that quantity? Is this assuming realizability, and therefore the square here corresponds to square loss? Is the method specific to square error though? Why not work directly in terms of loss? These inferences are somewhat confirmed in section 6, though I suspect a method is not really specific to square error, and I claim a more general description in terms of generic loss and loss variance would be easier to follow.

I also think this result does not properly consider overfitting, so I don't think it's very well motivated in a machine learning context. Loss variances should be model (parameter) dependent, so if this is in terms of minimum variance, I suspect it's a reasonable lower bound, and if maximum variance is considered (and multiplied by the log of the model class cardinality or some similar capacity measure), it may be a reasonable upper bound? It's also not totally clear to me which quantities refer to distributions and which refer to data sets in this definition. I would be interested to see a more general analysis, in terms of quantities like Rademacher averages that better characterize overfitting in machine learning [1,2,5]. Some discussion of how this applies to fair learning in particular would be appreciated, especially as works like [9] show that the process of optimizing fair ML objectives has a regularizing effect and can actually reduce overfitting.

In lemmas 2,3,&4, the requirement is that this holds for all i, correct? These are a bit tricky to read, because $\mu_{e}$ depends on i, although $\sigma^{2}$ does not, and the notation does not reflect this. Moreover, it seems unfortunate that we reach the same conclusion in all three cases, is this necessary (i.e., are there counterexamples to improvement in each?).

I think these results can only be true if client distributions are drawn IID. This should be clarified in lemma 1. This is a big assumption, since I might expect friends’ distributions to be correlated (which incentivizes them to deviate, harming core stability). But I also need to ask, is the variance between distributions the sample variance or the distribution variance? I think this matters a lot, since presumably there are relatively few agents, and if the sample variance is what matters, then why can't we condition on the sample (in which case independence wouldn’t matter)?


In section 4.1, I think it would be nice to generalize this idea to define a client's utility function as some welfare function of their own value and the value of their friends. I think this would simplify the presentation, but also you would be able to use more sophisticated concepts, like weighted power-means.

Moreover, since the same result holds for purely altruistic and friendly altruistic cases, this immediately implies that the client utility functions can be the utilitarian maximum social welfare (malfare) function [6,11], and some set of weighted utilitarian welfare (malfare) functions. I suspect it could easily generalize to any weighted utilitarian welfare function. I would also be very interested to see if these results held for any unweighted power-mean welfare function, any weighted power-mean welfare function, or any Gini malfare function [6], as they do in some sense lie between welfare altruism and equal altruism, though I don't think these results follow directly from your stated lemmas.



Minor points:

149 “satisfy” should be “satisfies.” Moreover this definition feels a bit redundant with (1).

158 It seems strange to mix a sociological definition of friend with a mathematical definition. Moreover, while I am not a sociologist, it seems wrong that “friend” would be the most intimate trusted voluntary category. If so, what is a best friend, and where does that leave a partner? But is this discussion even necessary?

Perhaps definitions 2 3 and 4 can be merged to describe the coalitional game?

163 “does not exist” to “does not exist a”


171 I dislike this terminology. I would describe both types of altruism as considering different types of the welfare among friends, but I would term them “egalitarian altruism” and “utilitarian altruism,” respectively [1].","FedAvg

I don't love the FedAvg aggregation rule of line 126 (though I appreciate that the authors analyze an established model). This seems appropriate when groups train relatively similar models on their own, and the lost surface is relatively smooth. I suspect this is a decent rule when each client has the same optimal model, but due to limited sampling wouldn't identify this from their own data.

The approach seems particularly problematic for non-convex loss surfaces, or models with symmetry (e.g., neural networks or mixture models where averaging the parameters of two identical models can produce a completely different model). I’d like to see more discussion of these limitations (or generalization of the model).

However, I would like to see some consideration of other models of FL, for instance when clients send gradient updates, rather than raw model parameters. From reading the introduction, I expected the FL to be trained to incentivize egalitarian fairness, but this simple averaging rule is neither utilitarian optimal, nor is it egalitarian optimal. Works like [3] consider sampling implications for this, and biased SGD analyses [4,7] also seem appropriate to discuss, at least in related work.

Overfitting

I would also like to see some consideration of overfitting. It seems tautological that nonaltruistic agents would prefer to train their own model when only training loss is considered, and while altruism may incentivize them to share their data, there is also the non-altruistic effect of reduced overfitting. It seems this would also disincentivize the formations of small coalitions, so I would be very interested to see what impact these factors have on the work.


References:

[1] An axiomatic theory of provably-fair welfare-centric machine learning
C Cousins
Advances in Neural Information Processing Systems 34, 16610-16621

[2] Revisiting fair-PAC learning and the axioms of cardinal welfare
C Cousins
International Conference on Artificial Intelligence and Statistics, 6422-6442

[3] Jacob D Abernethy, Pranjal Awasthi, Matthäus Kleindessner, Jamie Morgenstern, Chris Russell, and Jie Zhang. Active sampling for min-max fairness. In International
Conference on Machine Learning, volume 162, 2022.

[4] A guide through the zoo of biased SGD
Y Demidovich, G Malinovsky… - Advances in Neural …, 2024 - proceedings.neurips.cc,

[5] Uncertainty and the social planner’s problem: Why sample complexity matters
C Cousins
Proceedings of the 2022 ACM Conference on Fairness, Accountability, and …

[6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
Cyrus Cousins

[7] Hu, Yifan, et al. ""Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning."" Advances in Neural Information Processing Systems 33 (2020): 2759-2770.

[8] John Rawls. A theory of justice. Harvard University Press, 1971.

[9] Cousins, Cyrus, I. Elizabeth Kumar, and Suresh Venkatasubramanian. ""To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models."" International Conference on Artificial Intelligence and Statistics. PMLR, 2024.

[10] Dwork, Cynthia, et al. ""Fairness through awareness."" Proceedings of the 3rd innovations in theoretical computer science conference. 2012.

[11] Deschamps, R., Gevers, L.: Leximin and utilitarian rules: A joint characterization. Journal of Economic Theory 17(2), 143–163 (1978)",['No ethics review needed.'],6,4,,Yes,2,3,4,1721221878048,,,NeurIPS.cc/2024/Conference,1kyc4TSOFZ,"['NeurIPS.cc/2024/Conference/Submission3661/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878866018,[],3,,,['everyone'],1kyc4TSOFZ,['NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP'],1721221878048,1730878866018,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] An axiomatic theory of provably-fair welfare-centric machine learning
2. [2] Revisiting fair-PAC learning and the axioms of cardinal welfare
3. [3] Active sampling for min-max fairness
4. [4] A guide through the zoo of biased SGD
5. [5] Uncertainty and the social planner’s problem: Why sample complexity matters
6. [6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
7. [7] Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning
8. [8] A theory of justice
9. [9] To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models
10. [10] Fairness through awareness
11. [11] Leximin and utilitarian rules: A joint characterization

These citations are provided as references to support the reviewer's comments and suggestions for improving the paper.",1,,Active sampling for min-max fairness
HzvzyLYrmt,"This paper examines the relationship between egalitarian fairness concepts and stability in federated learning, where multiple clients collaboratively train a shared model while retaining local data privacy. Egalitarian fairness promotes uniform model performance across clients, but this can reduce performance for data-rich clients, potentially causing instability, as these clients might leave for better-performing coalitions. This work employs cooperative game theory and social choice to frame FL systems as altruism coalition formation games, suggesting that core instability issues are linked to clients' altruism and their network of relationships. The authors propose optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors, suggesting that egalitarian fairness does not necessarily lead to instability.","The main strength of this paper is its comprehensive approach to analyzing federated learning under both selfish and altruistic behavior. By considering both the performance of machine learners and the game-theoretic aspects of how federated learners interact, the authors provide a well-rounded analysis of the relationship between egalitarian fairness and stability. The use of game theory and social choice theory to frame FL systems as altruism coalition formation games is particularly innovative, linking instability issues to clients' altruism and their network of relationships. The proposed optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors are a significant theoretical advancement, disproving the assumption that egalitarian fairness inevitably leads to instability. The technical correctness of the results, subject to the model assumed, further solidifies the paper's contribution to advancing the state of the art in this field. Experimental validation then convincingly supports these theoretical findings with empirical outcomes.","I'm left with some questions about the motivations for the model, though the authors do a good job motivating it with prior work. I'm also left wondering whether some results and assumptions can be generalized, as the analysis is somewhat rigid; the paper would be much stronger if some results held in greater generality. I also question the model of FL used here (FedAvg), as it simply averages over model parameters (it would be nice to see models where clients submit gradient updates rather than complete models, and also where the central authority itself optimizes for egalitarian or other fairness objectives, rather than averaging). Finally, I argue the client utilities don't fully reflect the impact of overfitting.","Clearly the FedAvg rule for $\theta$ (line 126) promotes privacy in some sense, but with modest added noise, is the mechanism differentially private?

I would argue that definition 1 is more closely related to the demographic parity concept of equalized error [10], not egalitarian fairness. I would claim that in loss contexts, egalitarian welfare (or more aptly, malfare) is simply the max over average losses of agents [8], but inequality between agents is not antithetical to egalitarian fairness, rather egalitarianism is indifferent to the performance of high performing groups so long as low performing groups cannot be improved. I suppose this is more of a terminology issue, though I do ask if an additive version of this could be explored, where error values are compared to the maximum per group error.

Lemma 1 is quite confusing to me. $\mu_{e}$ depends on i, but notation does not reflect this. By expected value of the variance, you seem to mean expected value of the raw variance, but it's not clear why I care about that quantity? Is this assuming realizability, and therefore the square here corresponds to square loss? Is the method specific to square error though? Why not work directly in terms of loss? These inferences are somewhat confirmed in section 6, though I suspect a method is not really specific to square error, and I claim a more general description in terms of generic loss and loss variance would be easier to follow.

I also think this result does not properly consider overfitting, so I don't think it's very well motivated in a machine learning context. Loss variances should be model (parameter) dependent, so if this is in terms of minimum variance, I suspect it's a reasonable lower bound, and if maximum variance is considered (and multiplied by the log of the model class cardinality or some similar capacity measure), it may be a reasonable upper bound? It's also not totally clear to me which quantities refer to distributions and which refer to data sets in this definition. I would be interested to see a more general analysis, in terms of quantities like Rademacher averages that better characterize overfitting in machine learning [1,2,5]. Some discussion of how this applies to fair learning in particular would be appreciated, especially as works like [9] show that the process of optimizing fair ML objectives has a regularizing effect and can actually reduce overfitting.

In lemmas 2,3,&4, the requirement is that this holds for all i, correct? These are a bit tricky to read, because $\mu_{e}$ depends on i, although $\sigma^{2}$ does not, and the notation does not reflect this. Moreover, it seems unfortunate that we reach the same conclusion in all three cases, is this necessary (i.e., are there counterexamples to improvement in each?).

I think these results can only be true if client distributions are drawn IID. This should be clarified in lemma 1. This is a big assumption, since I might expect friends’ distributions to be correlated (which incentivizes them to deviate, harming core stability). But I also need to ask, is the variance between distributions the sample variance or the distribution variance? I think this matters a lot, since presumably there are relatively few agents, and if the sample variance is what matters, then why can't we condition on the sample (in which case independence wouldn’t matter)?


In section 4.1, I think it would be nice to generalize this idea to define a client's utility function as some welfare function of their own value and the value of their friends. I think this would simplify the presentation, but also you would be able to use more sophisticated concepts, like weighted power-means.

Moreover, since the same result holds for purely altruistic and friendly altruistic cases, this immediately implies that the client utility functions can be the utilitarian maximum social welfare (malfare) function [6,11], and some set of weighted utilitarian welfare (malfare) functions. I suspect it could easily generalize to any weighted utilitarian welfare function. I would also be very interested to see if these results held for any unweighted power-mean welfare function, any weighted power-mean welfare function, or any Gini malfare function [6], as they do in some sense lie between welfare altruism and equal altruism, though I don't think these results follow directly from your stated lemmas.



Minor points:

149 “satisfy” should be “satisfies.” Moreover this definition feels a bit redundant with (1).

158 It seems strange to mix a sociological definition of friend with a mathematical definition. Moreover, while I am not a sociologist, it seems wrong that “friend” would be the most intimate trusted voluntary category. If so, what is a best friend, and where does that leave a partner? But is this discussion even necessary?

Perhaps definitions 2 3 and 4 can be merged to describe the coalitional game?

163 “does not exist” to “does not exist a”


171 I dislike this terminology. I would describe both types of altruism as considering different types of the welfare among friends, but I would term them “egalitarian altruism” and “utilitarian altruism,” respectively [1].","FedAvg

I don't love the FedAvg aggregation rule of line 126 (though I appreciate that the authors analyze an established model). This seems appropriate when groups train relatively similar models on their own, and the lost surface is relatively smooth. I suspect this is a decent rule when each client has the same optimal model, but due to limited sampling wouldn't identify this from their own data.

The approach seems particularly problematic for non-convex loss surfaces, or models with symmetry (e.g., neural networks or mixture models where averaging the parameters of two identical models can produce a completely different model). I’d like to see more discussion of these limitations (or generalization of the model).

However, I would like to see some consideration of other models of FL, for instance when clients send gradient updates, rather than raw model parameters. From reading the introduction, I expected the FL to be trained to incentivize egalitarian fairness, but this simple averaging rule is neither utilitarian optimal, nor is it egalitarian optimal. Works like [3] consider sampling implications for this, and biased SGD analyses [4,7] also seem appropriate to discuss, at least in related work.

Overfitting

I would also like to see some consideration of overfitting. It seems tautological that nonaltruistic agents would prefer to train their own model when only training loss is considered, and while altruism may incentivize them to share their data, there is also the non-altruistic effect of reduced overfitting. It seems this would also disincentivize the formations of small coalitions, so I would be very interested to see what impact these factors have on the work.


References:

[1] An axiomatic theory of provably-fair welfare-centric machine learning
C Cousins
Advances in Neural Information Processing Systems 34, 16610-16621

[2] Revisiting fair-PAC learning and the axioms of cardinal welfare
C Cousins
International Conference on Artificial Intelligence and Statistics, 6422-6442

[3] Jacob D Abernethy, Pranjal Awasthi, Matthäus Kleindessner, Jamie Morgenstern, Chris Russell, and Jie Zhang. Active sampling for min-max fairness. In International
Conference on Machine Learning, volume 162, 2022.

[4] A guide through the zoo of biased SGD
Y Demidovich, G Malinovsky… - Advances in Neural …, 2024 - proceedings.neurips.cc,

[5] Uncertainty and the social planner’s problem: Why sample complexity matters
C Cousins
Proceedings of the 2022 ACM Conference on Fairness, Accountability, and …

[6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
Cyrus Cousins

[7] Hu, Yifan, et al. ""Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning."" Advances in Neural Information Processing Systems 33 (2020): 2759-2770.

[8] John Rawls. A theory of justice. Harvard University Press, 1971.

[9] Cousins, Cyrus, I. Elizabeth Kumar, and Suresh Venkatasubramanian. ""To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models."" International Conference on Artificial Intelligence and Statistics. PMLR, 2024.

[10] Dwork, Cynthia, et al. ""Fairness through awareness."" Proceedings of the 3rd innovations in theoretical computer science conference. 2012.

[11] Deschamps, R., Gevers, L.: Leximin and utilitarian rules: A joint characterization. Journal of Economic Theory 17(2), 143–163 (1978)",['No ethics review needed.'],6,4,,Yes,2,3,4,1721221878048,,,NeurIPS.cc/2024/Conference,1kyc4TSOFZ,"['NeurIPS.cc/2024/Conference/Submission3661/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878866018,[],3,,,['everyone'],1kyc4TSOFZ,['NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP'],1721221878048,1730878866018,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] An axiomatic theory of provably-fair welfare-centric machine learning
2. [2] Revisiting fair-PAC learning and the axioms of cardinal welfare
3. [3] Active sampling for min-max fairness
4. [4] A guide through the zoo of biased SGD
5. [5] Uncertainty and the social planner’s problem: Why sample complexity matters
6. [6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
7. [7] Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning
8. [8] A theory of justice
9. [9] To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models
10. [10] Fairness through awareness
11. [11] Leximin and utilitarian rules: A joint characterization

These citations are provided as references to support the reviewer's comments and suggestions for improving the paper.",1,,A guide through the zoo of biased SGD
HzvzyLYrmt,"This paper examines the relationship between egalitarian fairness concepts and stability in federated learning, where multiple clients collaboratively train a shared model while retaining local data privacy. Egalitarian fairness promotes uniform model performance across clients, but this can reduce performance for data-rich clients, potentially causing instability, as these clients might leave for better-performing coalitions. This work employs cooperative game theory and social choice to frame FL systems as altruism coalition formation games, suggesting that core instability issues are linked to clients' altruism and their network of relationships. The authors propose optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors, suggesting that egalitarian fairness does not necessarily lead to instability.","The main strength of this paper is its comprehensive approach to analyzing federated learning under both selfish and altruistic behavior. By considering both the performance of machine learners and the game-theoretic aspects of how federated learners interact, the authors provide a well-rounded analysis of the relationship between egalitarian fairness and stability. The use of game theory and social choice theory to frame FL systems as altruism coalition formation games is particularly innovative, linking instability issues to clients' altruism and their network of relationships. The proposed optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors are a significant theoretical advancement, disproving the assumption that egalitarian fairness inevitably leads to instability. The technical correctness of the results, subject to the model assumed, further solidifies the paper's contribution to advancing the state of the art in this field. Experimental validation then convincingly supports these theoretical findings with empirical outcomes.","I'm left with some questions about the motivations for the model, though the authors do a good job motivating it with prior work. I'm also left wondering whether some results and assumptions can be generalized, as the analysis is somewhat rigid; the paper would be much stronger if some results held in greater generality. I also question the model of FL used here (FedAvg), as it simply averages over model parameters (it would be nice to see models where clients submit gradient updates rather than complete models, and also where the central authority itself optimizes for egalitarian or other fairness objectives, rather than averaging). Finally, I argue the client utilities don't fully reflect the impact of overfitting.","Clearly the FedAvg rule for $\theta$ (line 126) promotes privacy in some sense, but with modest added noise, is the mechanism differentially private?

I would argue that definition 1 is more closely related to the demographic parity concept of equalized error [10], not egalitarian fairness. I would claim that in loss contexts, egalitarian welfare (or more aptly, malfare) is simply the max over average losses of agents [8], but inequality between agents is not antithetical to egalitarian fairness, rather egalitarianism is indifferent to the performance of high performing groups so long as low performing groups cannot be improved. I suppose this is more of a terminology issue, though I do ask if an additive version of this could be explored, where error values are compared to the maximum per group error.

Lemma 1 is quite confusing to me. $\mu_{e}$ depends on i, but notation does not reflect this. By expected value of the variance, you seem to mean expected value of the raw variance, but it's not clear why I care about that quantity? Is this assuming realizability, and therefore the square here corresponds to square loss? Is the method specific to square error though? Why not work directly in terms of loss? These inferences are somewhat confirmed in section 6, though I suspect a method is not really specific to square error, and I claim a more general description in terms of generic loss and loss variance would be easier to follow.

I also think this result does not properly consider overfitting, so I don't think it's very well motivated in a machine learning context. Loss variances should be model (parameter) dependent, so if this is in terms of minimum variance, I suspect it's a reasonable lower bound, and if maximum variance is considered (and multiplied by the log of the model class cardinality or some similar capacity measure), it may be a reasonable upper bound? It's also not totally clear to me which quantities refer to distributions and which refer to data sets in this definition. I would be interested to see a more general analysis, in terms of quantities like Rademacher averages that better characterize overfitting in machine learning [1,2,5]. Some discussion of how this applies to fair learning in particular would be appreciated, especially as works like [9] show that the process of optimizing fair ML objectives has a regularizing effect and can actually reduce overfitting.

In lemmas 2,3,&4, the requirement is that this holds for all i, correct? These are a bit tricky to read, because $\mu_{e}$ depends on i, although $\sigma^{2}$ does not, and the notation does not reflect this. Moreover, it seems unfortunate that we reach the same conclusion in all three cases, is this necessary (i.e., are there counterexamples to improvement in each?).

I think these results can only be true if client distributions are drawn IID. This should be clarified in lemma 1. This is a big assumption, since I might expect friends’ distributions to be correlated (which incentivizes them to deviate, harming core stability). But I also need to ask, is the variance between distributions the sample variance or the distribution variance? I think this matters a lot, since presumably there are relatively few agents, and if the sample variance is what matters, then why can't we condition on the sample (in which case independence wouldn’t matter)?


In section 4.1, I think it would be nice to generalize this idea to define a client's utility function as some welfare function of their own value and the value of their friends. I think this would simplify the presentation, but also you would be able to use more sophisticated concepts, like weighted power-means.

Moreover, since the same result holds for purely altruistic and friendly altruistic cases, this immediately implies that the client utility functions can be the utilitarian maximum social welfare (malfare) function [6,11], and some set of weighted utilitarian welfare (malfare) functions. I suspect it could easily generalize to any weighted utilitarian welfare function. I would also be very interested to see if these results held for any unweighted power-mean welfare function, any weighted power-mean welfare function, or any Gini malfare function [6], as they do in some sense lie between welfare altruism and equal altruism, though I don't think these results follow directly from your stated lemmas.



Minor points:

149 “satisfy” should be “satisfies.” Moreover this definition feels a bit redundant with (1).

158 It seems strange to mix a sociological definition of friend with a mathematical definition. Moreover, while I am not a sociologist, it seems wrong that “friend” would be the most intimate trusted voluntary category. If so, what is a best friend, and where does that leave a partner? But is this discussion even necessary?

Perhaps definitions 2 3 and 4 can be merged to describe the coalitional game?

163 “does not exist” to “does not exist a”


171 I dislike this terminology. I would describe both types of altruism as considering different types of the welfare among friends, but I would term them “egalitarian altruism” and “utilitarian altruism,” respectively [1].","FedAvg

I don't love the FedAvg aggregation rule of line 126 (though I appreciate that the authors analyze an established model). This seems appropriate when groups train relatively similar models on their own, and the lost surface is relatively smooth. I suspect this is a decent rule when each client has the same optimal model, but due to limited sampling wouldn't identify this from their own data.

The approach seems particularly problematic for non-convex loss surfaces, or models with symmetry (e.g., neural networks or mixture models where averaging the parameters of two identical models can produce a completely different model). I’d like to see more discussion of these limitations (or generalization of the model).

However, I would like to see some consideration of other models of FL, for instance when clients send gradient updates, rather than raw model parameters. From reading the introduction, I expected the FL to be trained to incentivize egalitarian fairness, but this simple averaging rule is neither utilitarian optimal, nor is it egalitarian optimal. Works like [3] consider sampling implications for this, and biased SGD analyses [4,7] also seem appropriate to discuss, at least in related work.

Overfitting

I would also like to see some consideration of overfitting. It seems tautological that nonaltruistic agents would prefer to train their own model when only training loss is considered, and while altruism may incentivize them to share their data, there is also the non-altruistic effect of reduced overfitting. It seems this would also disincentivize the formations of small coalitions, so I would be very interested to see what impact these factors have on the work.


References:

[1] An axiomatic theory of provably-fair welfare-centric machine learning
C Cousins
Advances in Neural Information Processing Systems 34, 16610-16621

[2] Revisiting fair-PAC learning and the axioms of cardinal welfare
C Cousins
International Conference on Artificial Intelligence and Statistics, 6422-6442

[3] Jacob D Abernethy, Pranjal Awasthi, Matthäus Kleindessner, Jamie Morgenstern, Chris Russell, and Jie Zhang. Active sampling for min-max fairness. In International
Conference on Machine Learning, volume 162, 2022.

[4] A guide through the zoo of biased SGD
Y Demidovich, G Malinovsky… - Advances in Neural …, 2024 - proceedings.neurips.cc,

[5] Uncertainty and the social planner’s problem: Why sample complexity matters
C Cousins
Proceedings of the 2022 ACM Conference on Fairness, Accountability, and …

[6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
Cyrus Cousins

[7] Hu, Yifan, et al. ""Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning."" Advances in Neural Information Processing Systems 33 (2020): 2759-2770.

[8] John Rawls. A theory of justice. Harvard University Press, 1971.

[9] Cousins, Cyrus, I. Elizabeth Kumar, and Suresh Venkatasubramanian. ""To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models."" International Conference on Artificial Intelligence and Statistics. PMLR, 2024.

[10] Dwork, Cynthia, et al. ""Fairness through awareness."" Proceedings of the 3rd innovations in theoretical computer science conference. 2012.

[11] Deschamps, R., Gevers, L.: Leximin and utilitarian rules: A joint characterization. Journal of Economic Theory 17(2), 143–163 (1978)",['No ethics review needed.'],6,4,,Yes,2,3,4,1721221878048,,,NeurIPS.cc/2024/Conference,1kyc4TSOFZ,"['NeurIPS.cc/2024/Conference/Submission3661/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878866018,[],3,,,['everyone'],1kyc4TSOFZ,['NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP'],1721221878048,1730878866018,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] An axiomatic theory of provably-fair welfare-centric machine learning
2. [2] Revisiting fair-PAC learning and the axioms of cardinal welfare
3. [3] Active sampling for min-max fairness
4. [4] A guide through the zoo of biased SGD
5. [5] Uncertainty and the social planner’s problem: Why sample complexity matters
6. [6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
7. [7] Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning
8. [8] A theory of justice
9. [9] To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models
10. [10] Fairness through awareness
11. [11] Leximin and utilitarian rules: A joint characterization

These citations are provided as references to support the reviewer's comments and suggestions for improving the paper.",1,,Uncertainty and the social planner’s problem Why sample complexity matters
HzvzyLYrmt,"This paper examines the relationship between egalitarian fairness concepts and stability in federated learning, where multiple clients collaboratively train a shared model while retaining local data privacy. Egalitarian fairness promotes uniform model performance across clients, but this can reduce performance for data-rich clients, potentially causing instability, as these clients might leave for better-performing coalitions. This work employs cooperative game theory and social choice to frame FL systems as altruism coalition formation games, suggesting that core instability issues are linked to clients' altruism and their network of relationships. The authors propose optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors, suggesting that egalitarian fairness does not necessarily lead to instability.","The main strength of this paper is its comprehensive approach to analyzing federated learning under both selfish and altruistic behavior. By considering both the performance of machine learners and the game-theoretic aspects of how federated learners interact, the authors provide a well-rounded analysis of the relationship between egalitarian fairness and stability. The use of game theory and social choice theory to frame FL systems as altruism coalition formation games is particularly innovative, linking instability issues to clients' altruism and their network of relationships. The proposed optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors are a significant theoretical advancement, disproving the assumption that egalitarian fairness inevitably leads to instability. The technical correctness of the results, subject to the model assumed, further solidifies the paper's contribution to advancing the state of the art in this field. Experimental validation then convincingly supports these theoretical findings with empirical outcomes.","I'm left with some questions about the motivations for the model, though the authors do a good job motivating it with prior work. I'm also left wondering whether some results and assumptions can be generalized, as the analysis is somewhat rigid; the paper would be much stronger if some results held in greater generality. I also question the model of FL used here (FedAvg), as it simply averages over model parameters (it would be nice to see models where clients submit gradient updates rather than complete models, and also where the central authority itself optimizes for egalitarian or other fairness objectives, rather than averaging). Finally, I argue the client utilities don't fully reflect the impact of overfitting.","Clearly the FedAvg rule for $\theta$ (line 126) promotes privacy in some sense, but with modest added noise, is the mechanism differentially private?

I would argue that definition 1 is more closely related to the demographic parity concept of equalized error [10], not egalitarian fairness. I would claim that in loss contexts, egalitarian welfare (or more aptly, malfare) is simply the max over average losses of agents [8], but inequality between agents is not antithetical to egalitarian fairness, rather egalitarianism is indifferent to the performance of high performing groups so long as low performing groups cannot be improved. I suppose this is more of a terminology issue, though I do ask if an additive version of this could be explored, where error values are compared to the maximum per group error.

Lemma 1 is quite confusing to me. $\mu_{e}$ depends on i, but notation does not reflect this. By expected value of the variance, you seem to mean expected value of the raw variance, but it's not clear why I care about that quantity? Is this assuming realizability, and therefore the square here corresponds to square loss? Is the method specific to square error though? Why not work directly in terms of loss? These inferences are somewhat confirmed in section 6, though I suspect a method is not really specific to square error, and I claim a more general description in terms of generic loss and loss variance would be easier to follow.

I also think this result does not properly consider overfitting, so I don't think it's very well motivated in a machine learning context. Loss variances should be model (parameter) dependent, so if this is in terms of minimum variance, I suspect it's a reasonable lower bound, and if maximum variance is considered (and multiplied by the log of the model class cardinality or some similar capacity measure), it may be a reasonable upper bound? It's also not totally clear to me which quantities refer to distributions and which refer to data sets in this definition. I would be interested to see a more general analysis, in terms of quantities like Rademacher averages that better characterize overfitting in machine learning [1,2,5]. Some discussion of how this applies to fair learning in particular would be appreciated, especially as works like [9] show that the process of optimizing fair ML objectives has a regularizing effect and can actually reduce overfitting.

In lemmas 2,3,&4, the requirement is that this holds for all i, correct? These are a bit tricky to read, because $\mu_{e}$ depends on i, although $\sigma^{2}$ does not, and the notation does not reflect this. Moreover, it seems unfortunate that we reach the same conclusion in all three cases, is this necessary (i.e., are there counterexamples to improvement in each?).

I think these results can only be true if client distributions are drawn IID. This should be clarified in lemma 1. This is a big assumption, since I might expect friends’ distributions to be correlated (which incentivizes them to deviate, harming core stability). But I also need to ask, is the variance between distributions the sample variance or the distribution variance? I think this matters a lot, since presumably there are relatively few agents, and if the sample variance is what matters, then why can't we condition on the sample (in which case independence wouldn’t matter)?


In section 4.1, I think it would be nice to generalize this idea to define a client's utility function as some welfare function of their own value and the value of their friends. I think this would simplify the presentation, but also you would be able to use more sophisticated concepts, like weighted power-means.

Moreover, since the same result holds for purely altruistic and friendly altruistic cases, this immediately implies that the client utility functions can be the utilitarian maximum social welfare (malfare) function [6,11], and some set of weighted utilitarian welfare (malfare) functions. I suspect it could easily generalize to any weighted utilitarian welfare function. I would also be very interested to see if these results held for any unweighted power-mean welfare function, any weighted power-mean welfare function, or any Gini malfare function [6], as they do in some sense lie between welfare altruism and equal altruism, though I don't think these results follow directly from your stated lemmas.



Minor points:

149 “satisfy” should be “satisfies.” Moreover this definition feels a bit redundant with (1).

158 It seems strange to mix a sociological definition of friend with a mathematical definition. Moreover, while I am not a sociologist, it seems wrong that “friend” would be the most intimate trusted voluntary category. If so, what is a best friend, and where does that leave a partner? But is this discussion even necessary?

Perhaps definitions 2 3 and 4 can be merged to describe the coalitional game?

163 “does not exist” to “does not exist a”


171 I dislike this terminology. I would describe both types of altruism as considering different types of the welfare among friends, but I would term them “egalitarian altruism” and “utilitarian altruism,” respectively [1].","FedAvg

I don't love the FedAvg aggregation rule of line 126 (though I appreciate that the authors analyze an established model). This seems appropriate when groups train relatively similar models on their own, and the lost surface is relatively smooth. I suspect this is a decent rule when each client has the same optimal model, but due to limited sampling wouldn't identify this from their own data.

The approach seems particularly problematic for non-convex loss surfaces, or models with symmetry (e.g., neural networks or mixture models where averaging the parameters of two identical models can produce a completely different model). I’d like to see more discussion of these limitations (or generalization of the model).

However, I would like to see some consideration of other models of FL, for instance when clients send gradient updates, rather than raw model parameters. From reading the introduction, I expected the FL to be trained to incentivize egalitarian fairness, but this simple averaging rule is neither utilitarian optimal, nor is it egalitarian optimal. Works like [3] consider sampling implications for this, and biased SGD analyses [4,7] also seem appropriate to discuss, at least in related work.

Overfitting

I would also like to see some consideration of overfitting. It seems tautological that nonaltruistic agents would prefer to train their own model when only training loss is considered, and while altruism may incentivize them to share their data, there is also the non-altruistic effect of reduced overfitting. It seems this would also disincentivize the formations of small coalitions, so I would be very interested to see what impact these factors have on the work.


References:

[1] An axiomatic theory of provably-fair welfare-centric machine learning
C Cousins
Advances in Neural Information Processing Systems 34, 16610-16621

[2] Revisiting fair-PAC learning and the axioms of cardinal welfare
C Cousins
International Conference on Artificial Intelligence and Statistics, 6422-6442

[3] Jacob D Abernethy, Pranjal Awasthi, Matthäus Kleindessner, Jamie Morgenstern, Chris Russell, and Jie Zhang. Active sampling for min-max fairness. In International
Conference on Machine Learning, volume 162, 2022.

[4] A guide through the zoo of biased SGD
Y Demidovich, G Malinovsky… - Advances in Neural …, 2024 - proceedings.neurips.cc,

[5] Uncertainty and the social planner’s problem: Why sample complexity matters
C Cousins
Proceedings of the 2022 ACM Conference on Fairness, Accountability, and …

[6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
Cyrus Cousins

[7] Hu, Yifan, et al. ""Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning."" Advances in Neural Information Processing Systems 33 (2020): 2759-2770.

[8] John Rawls. A theory of justice. Harvard University Press, 1971.

[9] Cousins, Cyrus, I. Elizabeth Kumar, and Suresh Venkatasubramanian. ""To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models."" International Conference on Artificial Intelligence and Statistics. PMLR, 2024.

[10] Dwork, Cynthia, et al. ""Fairness through awareness."" Proceedings of the 3rd innovations in theoretical computer science conference. 2012.

[11] Deschamps, R., Gevers, L.: Leximin and utilitarian rules: A joint characterization. Journal of Economic Theory 17(2), 143–163 (1978)",['No ethics review needed.'],6,4,,Yes,2,3,4,1721221878048,,,NeurIPS.cc/2024/Conference,1kyc4TSOFZ,"['NeurIPS.cc/2024/Conference/Submission3661/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878866018,[],3,,,['everyone'],1kyc4TSOFZ,['NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP'],1721221878048,1730878866018,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] An axiomatic theory of provably-fair welfare-centric machine learning
2. [2] Revisiting fair-PAC learning and the axioms of cardinal welfare
3. [3] Active sampling for min-max fairness
4. [4] A guide through the zoo of biased SGD
5. [5] Uncertainty and the social planner’s problem: Why sample complexity matters
6. [6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
7. [7] Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning
8. [8] A theory of justice
9. [9] To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models
10. [10] Fairness through awareness
11. [11] Leximin and utilitarian rules: A joint characterization

These citations are provided as references to support the reviewer's comments and suggestions for improving the paper.",1,,Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
HzvzyLYrmt,"This paper examines the relationship between egalitarian fairness concepts and stability in federated learning, where multiple clients collaboratively train a shared model while retaining local data privacy. Egalitarian fairness promotes uniform model performance across clients, but this can reduce performance for data-rich clients, potentially causing instability, as these clients might leave for better-performing coalitions. This work employs cooperative game theory and social choice to frame FL systems as altruism coalition formation games, suggesting that core instability issues are linked to clients' altruism and their network of relationships. The authors propose optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors, suggesting that egalitarian fairness does not necessarily lead to instability.","The main strength of this paper is its comprehensive approach to analyzing federated learning under both selfish and altruistic behavior. By considering both the performance of machine learners and the game-theoretic aspects of how federated learners interact, the authors provide a well-rounded analysis of the relationship between egalitarian fairness and stability. The use of game theory and social choice theory to frame FL systems as altruism coalition formation games is particularly innovative, linking instability issues to clients' altruism and their network of relationships. The proposed optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors are a significant theoretical advancement, disproving the assumption that egalitarian fairness inevitably leads to instability. The technical correctness of the results, subject to the model assumed, further solidifies the paper's contribution to advancing the state of the art in this field. Experimental validation then convincingly supports these theoretical findings with empirical outcomes.","I'm left with some questions about the motivations for the model, though the authors do a good job motivating it with prior work. I'm also left wondering whether some results and assumptions can be generalized, as the analysis is somewhat rigid; the paper would be much stronger if some results held in greater generality. I also question the model of FL used here (FedAvg), as it simply averages over model parameters (it would be nice to see models where clients submit gradient updates rather than complete models, and also where the central authority itself optimizes for egalitarian or other fairness objectives, rather than averaging). Finally, I argue the client utilities don't fully reflect the impact of overfitting.","Clearly the FedAvg rule for $\theta$ (line 126) promotes privacy in some sense, but with modest added noise, is the mechanism differentially private?

I would argue that definition 1 is more closely related to the demographic parity concept of equalized error [10], not egalitarian fairness. I would claim that in loss contexts, egalitarian welfare (or more aptly, malfare) is simply the max over average losses of agents [8], but inequality between agents is not antithetical to egalitarian fairness, rather egalitarianism is indifferent to the performance of high performing groups so long as low performing groups cannot be improved. I suppose this is more of a terminology issue, though I do ask if an additive version of this could be explored, where error values are compared to the maximum per group error.

Lemma 1 is quite confusing to me. $\mu_{e}$ depends on i, but notation does not reflect this. By expected value of the variance, you seem to mean expected value of the raw variance, but it's not clear why I care about that quantity? Is this assuming realizability, and therefore the square here corresponds to square loss? Is the method specific to square error though? Why not work directly in terms of loss? These inferences are somewhat confirmed in section 6, though I suspect a method is not really specific to square error, and I claim a more general description in terms of generic loss and loss variance would be easier to follow.

I also think this result does not properly consider overfitting, so I don't think it's very well motivated in a machine learning context. Loss variances should be model (parameter) dependent, so if this is in terms of minimum variance, I suspect it's a reasonable lower bound, and if maximum variance is considered (and multiplied by the log of the model class cardinality or some similar capacity measure), it may be a reasonable upper bound? It's also not totally clear to me which quantities refer to distributions and which refer to data sets in this definition. I would be interested to see a more general analysis, in terms of quantities like Rademacher averages that better characterize overfitting in machine learning [1,2,5]. Some discussion of how this applies to fair learning in particular would be appreciated, especially as works like [9] show that the process of optimizing fair ML objectives has a regularizing effect and can actually reduce overfitting.

In lemmas 2,3,&4, the requirement is that this holds for all i, correct? These are a bit tricky to read, because $\mu_{e}$ depends on i, although $\sigma^{2}$ does not, and the notation does not reflect this. Moreover, it seems unfortunate that we reach the same conclusion in all three cases, is this necessary (i.e., are there counterexamples to improvement in each?).

I think these results can only be true if client distributions are drawn IID. This should be clarified in lemma 1. This is a big assumption, since I might expect friends’ distributions to be correlated (which incentivizes them to deviate, harming core stability). But I also need to ask, is the variance between distributions the sample variance or the distribution variance? I think this matters a lot, since presumably there are relatively few agents, and if the sample variance is what matters, then why can't we condition on the sample (in which case independence wouldn’t matter)?


In section 4.1, I think it would be nice to generalize this idea to define a client's utility function as some welfare function of their own value and the value of their friends. I think this would simplify the presentation, but also you would be able to use more sophisticated concepts, like weighted power-means.

Moreover, since the same result holds for purely altruistic and friendly altruistic cases, this immediately implies that the client utility functions can be the utilitarian maximum social welfare (malfare) function [6,11], and some set of weighted utilitarian welfare (malfare) functions. I suspect it could easily generalize to any weighted utilitarian welfare function. I would also be very interested to see if these results held for any unweighted power-mean welfare function, any weighted power-mean welfare function, or any Gini malfare function [6], as they do in some sense lie between welfare altruism and equal altruism, though I don't think these results follow directly from your stated lemmas.



Minor points:

149 “satisfy” should be “satisfies.” Moreover this definition feels a bit redundant with (1).

158 It seems strange to mix a sociological definition of friend with a mathematical definition. Moreover, while I am not a sociologist, it seems wrong that “friend” would be the most intimate trusted voluntary category. If so, what is a best friend, and where does that leave a partner? But is this discussion even necessary?

Perhaps definitions 2 3 and 4 can be merged to describe the coalitional game?

163 “does not exist” to “does not exist a”


171 I dislike this terminology. I would describe both types of altruism as considering different types of the welfare among friends, but I would term them “egalitarian altruism” and “utilitarian altruism,” respectively [1].","FedAvg

I don't love the FedAvg aggregation rule of line 126 (though I appreciate that the authors analyze an established model). This seems appropriate when groups train relatively similar models on their own, and the lost surface is relatively smooth. I suspect this is a decent rule when each client has the same optimal model, but due to limited sampling wouldn't identify this from their own data.

The approach seems particularly problematic for non-convex loss surfaces, or models with symmetry (e.g., neural networks or mixture models where averaging the parameters of two identical models can produce a completely different model). I’d like to see more discussion of these limitations (or generalization of the model).

However, I would like to see some consideration of other models of FL, for instance when clients send gradient updates, rather than raw model parameters. From reading the introduction, I expected the FL to be trained to incentivize egalitarian fairness, but this simple averaging rule is neither utilitarian optimal, nor is it egalitarian optimal. Works like [3] consider sampling implications for this, and biased SGD analyses [4,7] also seem appropriate to discuss, at least in related work.

Overfitting

I would also like to see some consideration of overfitting. It seems tautological that nonaltruistic agents would prefer to train their own model when only training loss is considered, and while altruism may incentivize them to share their data, there is also the non-altruistic effect of reduced overfitting. It seems this would also disincentivize the formations of small coalitions, so I would be very interested to see what impact these factors have on the work.


References:

[1] An axiomatic theory of provably-fair welfare-centric machine learning
C Cousins
Advances in Neural Information Processing Systems 34, 16610-16621

[2] Revisiting fair-PAC learning and the axioms of cardinal welfare
C Cousins
International Conference on Artificial Intelligence and Statistics, 6422-6442

[3] Jacob D Abernethy, Pranjal Awasthi, Matthäus Kleindessner, Jamie Morgenstern, Chris Russell, and Jie Zhang. Active sampling for min-max fairness. In International
Conference on Machine Learning, volume 162, 2022.

[4] A guide through the zoo of biased SGD
Y Demidovich, G Malinovsky… - Advances in Neural …, 2024 - proceedings.neurips.cc,

[5] Uncertainty and the social planner’s problem: Why sample complexity matters
C Cousins
Proceedings of the 2022 ACM Conference on Fairness, Accountability, and …

[6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
Cyrus Cousins

[7] Hu, Yifan, et al. ""Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning."" Advances in Neural Information Processing Systems 33 (2020): 2759-2770.

[8] John Rawls. A theory of justice. Harvard University Press, 1971.

[9] Cousins, Cyrus, I. Elizabeth Kumar, and Suresh Venkatasubramanian. ""To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models."" International Conference on Artificial Intelligence and Statistics. PMLR, 2024.

[10] Dwork, Cynthia, et al. ""Fairness through awareness."" Proceedings of the 3rd innovations in theoretical computer science conference. 2012.

[11] Deschamps, R., Gevers, L.: Leximin and utilitarian rules: A joint characterization. Journal of Economic Theory 17(2), 143–163 (1978)",['No ethics review needed.'],6,4,,Yes,2,3,4,1721221878048,,,NeurIPS.cc/2024/Conference,1kyc4TSOFZ,"['NeurIPS.cc/2024/Conference/Submission3661/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878866018,[],3,,,['everyone'],1kyc4TSOFZ,['NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP'],1721221878048,1730878866018,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] An axiomatic theory of provably-fair welfare-centric machine learning
2. [2] Revisiting fair-PAC learning and the axioms of cardinal welfare
3. [3] Active sampling for min-max fairness
4. [4] A guide through the zoo of biased SGD
5. [5] Uncertainty and the social planner’s problem: Why sample complexity matters
6. [6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
7. [7] Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning
8. [8] A theory of justice
9. [9] To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models
10. [10] Fairness through awareness
11. [11] Leximin and utilitarian rules: A joint characterization

These citations are provided as references to support the reviewer's comments and suggestions for improving the paper.",1,,Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning
HzvzyLYrmt,"This paper examines the relationship between egalitarian fairness concepts and stability in federated learning, where multiple clients collaboratively train a shared model while retaining local data privacy. Egalitarian fairness promotes uniform model performance across clients, but this can reduce performance for data-rich clients, potentially causing instability, as these clients might leave for better-performing coalitions. This work employs cooperative game theory and social choice to frame FL systems as altruism coalition formation games, suggesting that core instability issues are linked to clients' altruism and their network of relationships. The authors propose optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors, suggesting that egalitarian fairness does not necessarily lead to instability.","The main strength of this paper is its comprehensive approach to analyzing federated learning under both selfish and altruistic behavior. By considering both the performance of machine learners and the game-theoretic aspects of how federated learners interact, the authors provide a well-rounded analysis of the relationship between egalitarian fairness and stability. The use of game theory and social choice theory to frame FL systems as altruism coalition formation games is particularly innovative, linking instability issues to clients' altruism and their network of relationships. The proposed optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors are a significant theoretical advancement, disproving the assumption that egalitarian fairness inevitably leads to instability. The technical correctness of the results, subject to the model assumed, further solidifies the paper's contribution to advancing the state of the art in this field. Experimental validation then convincingly supports these theoretical findings with empirical outcomes.","I'm left with some questions about the motivations for the model, though the authors do a good job motivating it with prior work. I'm also left wondering whether some results and assumptions can be generalized, as the analysis is somewhat rigid; the paper would be much stronger if some results held in greater generality. I also question the model of FL used here (FedAvg), as it simply averages over model parameters (it would be nice to see models where clients submit gradient updates rather than complete models, and also where the central authority itself optimizes for egalitarian or other fairness objectives, rather than averaging). Finally, I argue the client utilities don't fully reflect the impact of overfitting.","Clearly the FedAvg rule for $\theta$ (line 126) promotes privacy in some sense, but with modest added noise, is the mechanism differentially private?

I would argue that definition 1 is more closely related to the demographic parity concept of equalized error [10], not egalitarian fairness. I would claim that in loss contexts, egalitarian welfare (or more aptly, malfare) is simply the max over average losses of agents [8], but inequality between agents is not antithetical to egalitarian fairness, rather egalitarianism is indifferent to the performance of high performing groups so long as low performing groups cannot be improved. I suppose this is more of a terminology issue, though I do ask if an additive version of this could be explored, where error values are compared to the maximum per group error.

Lemma 1 is quite confusing to me. $\mu_{e}$ depends on i, but notation does not reflect this. By expected value of the variance, you seem to mean expected value of the raw variance, but it's not clear why I care about that quantity? Is this assuming realizability, and therefore the square here corresponds to square loss? Is the method specific to square error though? Why not work directly in terms of loss? These inferences are somewhat confirmed in section 6, though I suspect a method is not really specific to square error, and I claim a more general description in terms of generic loss and loss variance would be easier to follow.

I also think this result does not properly consider overfitting, so I don't think it's very well motivated in a machine learning context. Loss variances should be model (parameter) dependent, so if this is in terms of minimum variance, I suspect it's a reasonable lower bound, and if maximum variance is considered (and multiplied by the log of the model class cardinality or some similar capacity measure), it may be a reasonable upper bound? It's also not totally clear to me which quantities refer to distributions and which refer to data sets in this definition. I would be interested to see a more general analysis, in terms of quantities like Rademacher averages that better characterize overfitting in machine learning [1,2,5]. Some discussion of how this applies to fair learning in particular would be appreciated, especially as works like [9] show that the process of optimizing fair ML objectives has a regularizing effect and can actually reduce overfitting.

In lemmas 2,3,&4, the requirement is that this holds for all i, correct? These are a bit tricky to read, because $\mu_{e}$ depends on i, although $\sigma^{2}$ does not, and the notation does not reflect this. Moreover, it seems unfortunate that we reach the same conclusion in all three cases, is this necessary (i.e., are there counterexamples to improvement in each?).

I think these results can only be true if client distributions are drawn IID. This should be clarified in lemma 1. This is a big assumption, since I might expect friends’ distributions to be correlated (which incentivizes them to deviate, harming core stability). But I also need to ask, is the variance between distributions the sample variance or the distribution variance? I think this matters a lot, since presumably there are relatively few agents, and if the sample variance is what matters, then why can't we condition on the sample (in which case independence wouldn’t matter)?


In section 4.1, I think it would be nice to generalize this idea to define a client's utility function as some welfare function of their own value and the value of their friends. I think this would simplify the presentation, but also you would be able to use more sophisticated concepts, like weighted power-means.

Moreover, since the same result holds for purely altruistic and friendly altruistic cases, this immediately implies that the client utility functions can be the utilitarian maximum social welfare (malfare) function [6,11], and some set of weighted utilitarian welfare (malfare) functions. I suspect it could easily generalize to any weighted utilitarian welfare function. I would also be very interested to see if these results held for any unweighted power-mean welfare function, any weighted power-mean welfare function, or any Gini malfare function [6], as they do in some sense lie between welfare altruism and equal altruism, though I don't think these results follow directly from your stated lemmas.



Minor points:

149 “satisfy” should be “satisfies.” Moreover this definition feels a bit redundant with (1).

158 It seems strange to mix a sociological definition of friend with a mathematical definition. Moreover, while I am not a sociologist, it seems wrong that “friend” would be the most intimate trusted voluntary category. If so, what is a best friend, and where does that leave a partner? But is this discussion even necessary?

Perhaps definitions 2 3 and 4 can be merged to describe the coalitional game?

163 “does not exist” to “does not exist a”


171 I dislike this terminology. I would describe both types of altruism as considering different types of the welfare among friends, but I would term them “egalitarian altruism” and “utilitarian altruism,” respectively [1].","FedAvg

I don't love the FedAvg aggregation rule of line 126 (though I appreciate that the authors analyze an established model). This seems appropriate when groups train relatively similar models on their own, and the lost surface is relatively smooth. I suspect this is a decent rule when each client has the same optimal model, but due to limited sampling wouldn't identify this from their own data.

The approach seems particularly problematic for non-convex loss surfaces, or models with symmetry (e.g., neural networks or mixture models where averaging the parameters of two identical models can produce a completely different model). I’d like to see more discussion of these limitations (or generalization of the model).

However, I would like to see some consideration of other models of FL, for instance when clients send gradient updates, rather than raw model parameters. From reading the introduction, I expected the FL to be trained to incentivize egalitarian fairness, but this simple averaging rule is neither utilitarian optimal, nor is it egalitarian optimal. Works like [3] consider sampling implications for this, and biased SGD analyses [4,7] also seem appropriate to discuss, at least in related work.

Overfitting

I would also like to see some consideration of overfitting. It seems tautological that nonaltruistic agents would prefer to train their own model when only training loss is considered, and while altruism may incentivize them to share their data, there is also the non-altruistic effect of reduced overfitting. It seems this would also disincentivize the formations of small coalitions, so I would be very interested to see what impact these factors have on the work.


References:

[1] An axiomatic theory of provably-fair welfare-centric machine learning
C Cousins
Advances in Neural Information Processing Systems 34, 16610-16621

[2] Revisiting fair-PAC learning and the axioms of cardinal welfare
C Cousins
International Conference on Artificial Intelligence and Statistics, 6422-6442

[3] Jacob D Abernethy, Pranjal Awasthi, Matthäus Kleindessner, Jamie Morgenstern, Chris Russell, and Jie Zhang. Active sampling for min-max fairness. In International
Conference on Machine Learning, volume 162, 2022.

[4] A guide through the zoo of biased SGD
Y Demidovich, G Malinovsky… - Advances in Neural …, 2024 - proceedings.neurips.cc,

[5] Uncertainty and the social planner’s problem: Why sample complexity matters
C Cousins
Proceedings of the 2022 ACM Conference on Fairness, Accountability, and …

[6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
Cyrus Cousins

[7] Hu, Yifan, et al. ""Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning."" Advances in Neural Information Processing Systems 33 (2020): 2759-2770.

[8] John Rawls. A theory of justice. Harvard University Press, 1971.

[9] Cousins, Cyrus, I. Elizabeth Kumar, and Suresh Venkatasubramanian. ""To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models."" International Conference on Artificial Intelligence and Statistics. PMLR, 2024.

[10] Dwork, Cynthia, et al. ""Fairness through awareness."" Proceedings of the 3rd innovations in theoretical computer science conference. 2012.

[11] Deschamps, R., Gevers, L.: Leximin and utilitarian rules: A joint characterization. Journal of Economic Theory 17(2), 143–163 (1978)",['No ethics review needed.'],6,4,,Yes,2,3,4,1721221878048,,,NeurIPS.cc/2024/Conference,1kyc4TSOFZ,"['NeurIPS.cc/2024/Conference/Submission3661/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878866018,[],3,,,['everyone'],1kyc4TSOFZ,['NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP'],1721221878048,1730878866018,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] An axiomatic theory of provably-fair welfare-centric machine learning
2. [2] Revisiting fair-PAC learning and the axioms of cardinal welfare
3. [3] Active sampling for min-max fairness
4. [4] A guide through the zoo of biased SGD
5. [5] Uncertainty and the social planner’s problem: Why sample complexity matters
6. [6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
7. [7] Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning
8. [8] A theory of justice
9. [9] To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models
10. [10] Fairness through awareness
11. [11] Leximin and utilitarian rules: A joint characterization

These citations are provided as references to support the reviewer's comments and suggestions for improving the paper.",1,,A theory of justice
HzvzyLYrmt,"This paper examines the relationship between egalitarian fairness concepts and stability in federated learning, where multiple clients collaboratively train a shared model while retaining local data privacy. Egalitarian fairness promotes uniform model performance across clients, but this can reduce performance for data-rich clients, potentially causing instability, as these clients might leave for better-performing coalitions. This work employs cooperative game theory and social choice to frame FL systems as altruism coalition formation games, suggesting that core instability issues are linked to clients' altruism and their network of relationships. The authors propose optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors, suggesting that egalitarian fairness does not necessarily lead to instability.","The main strength of this paper is its comprehensive approach to analyzing federated learning under both selfish and altruistic behavior. By considering both the performance of machine learners and the game-theoretic aspects of how federated learners interact, the authors provide a well-rounded analysis of the relationship between egalitarian fairness and stability. The use of game theory and social choice theory to frame FL systems as altruism coalition formation games is particularly innovative, linking instability issues to clients' altruism and their network of relationships. The proposed optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors are a significant theoretical advancement, disproving the assumption that egalitarian fairness inevitably leads to instability. The technical correctness of the results, subject to the model assumed, further solidifies the paper's contribution to advancing the state of the art in this field. Experimental validation then convincingly supports these theoretical findings with empirical outcomes.","I'm left with some questions about the motivations for the model, though the authors do a good job motivating it with prior work. I'm also left wondering whether some results and assumptions can be generalized, as the analysis is somewhat rigid; the paper would be much stronger if some results held in greater generality. I also question the model of FL used here (FedAvg), as it simply averages over model parameters (it would be nice to see models where clients submit gradient updates rather than complete models, and also where the central authority itself optimizes for egalitarian or other fairness objectives, rather than averaging). Finally, I argue the client utilities don't fully reflect the impact of overfitting.","Clearly the FedAvg rule for $\theta$ (line 126) promotes privacy in some sense, but with modest added noise, is the mechanism differentially private?

I would argue that definition 1 is more closely related to the demographic parity concept of equalized error [10], not egalitarian fairness. I would claim that in loss contexts, egalitarian welfare (or more aptly, malfare) is simply the max over average losses of agents [8], but inequality between agents is not antithetical to egalitarian fairness, rather egalitarianism is indifferent to the performance of high performing groups so long as low performing groups cannot be improved. I suppose this is more of a terminology issue, though I do ask if an additive version of this could be explored, where error values are compared to the maximum per group error.

Lemma 1 is quite confusing to me. $\mu_{e}$ depends on i, but notation does not reflect this. By expected value of the variance, you seem to mean expected value of the raw variance, but it's not clear why I care about that quantity? Is this assuming realizability, and therefore the square here corresponds to square loss? Is the method specific to square error though? Why not work directly in terms of loss? These inferences are somewhat confirmed in section 6, though I suspect a method is not really specific to square error, and I claim a more general description in terms of generic loss and loss variance would be easier to follow.

I also think this result does not properly consider overfitting, so I don't think it's very well motivated in a machine learning context. Loss variances should be model (parameter) dependent, so if this is in terms of minimum variance, I suspect it's a reasonable lower bound, and if maximum variance is considered (and multiplied by the log of the model class cardinality or some similar capacity measure), it may be a reasonable upper bound? It's also not totally clear to me which quantities refer to distributions and which refer to data sets in this definition. I would be interested to see a more general analysis, in terms of quantities like Rademacher averages that better characterize overfitting in machine learning [1,2,5]. Some discussion of how this applies to fair learning in particular would be appreciated, especially as works like [9] show that the process of optimizing fair ML objectives has a regularizing effect and can actually reduce overfitting.

In lemmas 2,3,&4, the requirement is that this holds for all i, correct? These are a bit tricky to read, because $\mu_{e}$ depends on i, although $\sigma^{2}$ does not, and the notation does not reflect this. Moreover, it seems unfortunate that we reach the same conclusion in all three cases, is this necessary (i.e., are there counterexamples to improvement in each?).

I think these results can only be true if client distributions are drawn IID. This should be clarified in lemma 1. This is a big assumption, since I might expect friends’ distributions to be correlated (which incentivizes them to deviate, harming core stability). But I also need to ask, is the variance between distributions the sample variance or the distribution variance? I think this matters a lot, since presumably there are relatively few agents, and if the sample variance is what matters, then why can't we condition on the sample (in which case independence wouldn’t matter)?


In section 4.1, I think it would be nice to generalize this idea to define a client's utility function as some welfare function of their own value and the value of their friends. I think this would simplify the presentation, but also you would be able to use more sophisticated concepts, like weighted power-means.

Moreover, since the same result holds for purely altruistic and friendly altruistic cases, this immediately implies that the client utility functions can be the utilitarian maximum social welfare (malfare) function [6,11], and some set of weighted utilitarian welfare (malfare) functions. I suspect it could easily generalize to any weighted utilitarian welfare function. I would also be very interested to see if these results held for any unweighted power-mean welfare function, any weighted power-mean welfare function, or any Gini malfare function [6], as they do in some sense lie between welfare altruism and equal altruism, though I don't think these results follow directly from your stated lemmas.



Minor points:

149 “satisfy” should be “satisfies.” Moreover this definition feels a bit redundant with (1).

158 It seems strange to mix a sociological definition of friend with a mathematical definition. Moreover, while I am not a sociologist, it seems wrong that “friend” would be the most intimate trusted voluntary category. If so, what is a best friend, and where does that leave a partner? But is this discussion even necessary?

Perhaps definitions 2 3 and 4 can be merged to describe the coalitional game?

163 “does not exist” to “does not exist a”


171 I dislike this terminology. I would describe both types of altruism as considering different types of the welfare among friends, but I would term them “egalitarian altruism” and “utilitarian altruism,” respectively [1].","FedAvg

I don't love the FedAvg aggregation rule of line 126 (though I appreciate that the authors analyze an established model). This seems appropriate when groups train relatively similar models on their own, and the lost surface is relatively smooth. I suspect this is a decent rule when each client has the same optimal model, but due to limited sampling wouldn't identify this from their own data.

The approach seems particularly problematic for non-convex loss surfaces, or models with symmetry (e.g., neural networks or mixture models where averaging the parameters of two identical models can produce a completely different model). I’d like to see more discussion of these limitations (or generalization of the model).

However, I would like to see some consideration of other models of FL, for instance when clients send gradient updates, rather than raw model parameters. From reading the introduction, I expected the FL to be trained to incentivize egalitarian fairness, but this simple averaging rule is neither utilitarian optimal, nor is it egalitarian optimal. Works like [3] consider sampling implications for this, and biased SGD analyses [4,7] also seem appropriate to discuss, at least in related work.

Overfitting

I would also like to see some consideration of overfitting. It seems tautological that nonaltruistic agents would prefer to train their own model when only training loss is considered, and while altruism may incentivize them to share their data, there is also the non-altruistic effect of reduced overfitting. It seems this would also disincentivize the formations of small coalitions, so I would be very interested to see what impact these factors have on the work.


References:

[1] An axiomatic theory of provably-fair welfare-centric machine learning
C Cousins
Advances in Neural Information Processing Systems 34, 16610-16621

[2] Revisiting fair-PAC learning and the axioms of cardinal welfare
C Cousins
International Conference on Artificial Intelligence and Statistics, 6422-6442

[3] Jacob D Abernethy, Pranjal Awasthi, Matthäus Kleindessner, Jamie Morgenstern, Chris Russell, and Jie Zhang. Active sampling for min-max fairness. In International
Conference on Machine Learning, volume 162, 2022.

[4] A guide through the zoo of biased SGD
Y Demidovich, G Malinovsky… - Advances in Neural …, 2024 - proceedings.neurips.cc,

[5] Uncertainty and the social planner’s problem: Why sample complexity matters
C Cousins
Proceedings of the 2022 ACM Conference on Fairness, Accountability, and …

[6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
Cyrus Cousins

[7] Hu, Yifan, et al. ""Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning."" Advances in Neural Information Processing Systems 33 (2020): 2759-2770.

[8] John Rawls. A theory of justice. Harvard University Press, 1971.

[9] Cousins, Cyrus, I. Elizabeth Kumar, and Suresh Venkatasubramanian. ""To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models."" International Conference on Artificial Intelligence and Statistics. PMLR, 2024.

[10] Dwork, Cynthia, et al. ""Fairness through awareness."" Proceedings of the 3rd innovations in theoretical computer science conference. 2012.

[11] Deschamps, R., Gevers, L.: Leximin and utilitarian rules: A joint characterization. Journal of Economic Theory 17(2), 143–163 (1978)",['No ethics review needed.'],6,4,,Yes,2,3,4,1721221878048,,,NeurIPS.cc/2024/Conference,1kyc4TSOFZ,"['NeurIPS.cc/2024/Conference/Submission3661/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878866018,[],3,,,['everyone'],1kyc4TSOFZ,['NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP'],1721221878048,1730878866018,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] An axiomatic theory of provably-fair welfare-centric machine learning
2. [2] Revisiting fair-PAC learning and the axioms of cardinal welfare
3. [3] Active sampling for min-max fairness
4. [4] A guide through the zoo of biased SGD
5. [5] Uncertainty and the social planner’s problem: Why sample complexity matters
6. [6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
7. [7] Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning
8. [8] A theory of justice
9. [9] To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models
10. [10] Fairness through awareness
11. [11] Leximin and utilitarian rules: A joint characterization

These citations are provided as references to support the reviewer's comments and suggestions for improving the paper.",1,,To Pool or Not To Pool Analyzing the Regularizing Effects of Group-Fair Training on Shared Models
HzvzyLYrmt,"This paper examines the relationship between egalitarian fairness concepts and stability in federated learning, where multiple clients collaboratively train a shared model while retaining local data privacy. Egalitarian fairness promotes uniform model performance across clients, but this can reduce performance for data-rich clients, potentially causing instability, as these clients might leave for better-performing coalitions. This work employs cooperative game theory and social choice to frame FL systems as altruism coalition formation games, suggesting that core instability issues are linked to clients' altruism and their network of relationships. The authors propose optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors, suggesting that egalitarian fairness does not necessarily lead to instability.","The main strength of this paper is its comprehensive approach to analyzing federated learning under both selfish and altruistic behavior. By considering both the performance of machine learners and the game-theoretic aspects of how federated learners interact, the authors provide a well-rounded analysis of the relationship between egalitarian fairness and stability. The use of game theory and social choice theory to frame FL systems as altruism coalition formation games is particularly innovative, linking instability issues to clients' altruism and their network of relationships. The proposed optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors are a significant theoretical advancement, disproving the assumption that egalitarian fairness inevitably leads to instability. The technical correctness of the results, subject to the model assumed, further solidifies the paper's contribution to advancing the state of the art in this field. Experimental validation then convincingly supports these theoretical findings with empirical outcomes.","I'm left with some questions about the motivations for the model, though the authors do a good job motivating it with prior work. I'm also left wondering whether some results and assumptions can be generalized, as the analysis is somewhat rigid; the paper would be much stronger if some results held in greater generality. I also question the model of FL used here (FedAvg), as it simply averages over model parameters (it would be nice to see models where clients submit gradient updates rather than complete models, and also where the central authority itself optimizes for egalitarian or other fairness objectives, rather than averaging). Finally, I argue the client utilities don't fully reflect the impact of overfitting.","Clearly the FedAvg rule for $\theta$ (line 126) promotes privacy in some sense, but with modest added noise, is the mechanism differentially private?

I would argue that definition 1 is more closely related to the demographic parity concept of equalized error [10], not egalitarian fairness. I would claim that in loss contexts, egalitarian welfare (or more aptly, malfare) is simply the max over average losses of agents [8], but inequality between agents is not antithetical to egalitarian fairness, rather egalitarianism is indifferent to the performance of high performing groups so long as low performing groups cannot be improved. I suppose this is more of a terminology issue, though I do ask if an additive version of this could be explored, where error values are compared to the maximum per group error.

Lemma 1 is quite confusing to me. $\mu_{e}$ depends on i, but notation does not reflect this. By expected value of the variance, you seem to mean expected value of the raw variance, but it's not clear why I care about that quantity? Is this assuming realizability, and therefore the square here corresponds to square loss? Is the method specific to square error though? Why not work directly in terms of loss? These inferences are somewhat confirmed in section 6, though I suspect a method is not really specific to square error, and I claim a more general description in terms of generic loss and loss variance would be easier to follow.

I also think this result does not properly consider overfitting, so I don't think it's very well motivated in a machine learning context. Loss variances should be model (parameter) dependent, so if this is in terms of minimum variance, I suspect it's a reasonable lower bound, and if maximum variance is considered (and multiplied by the log of the model class cardinality or some similar capacity measure), it may be a reasonable upper bound? It's also not totally clear to me which quantities refer to distributions and which refer to data sets in this definition. I would be interested to see a more general analysis, in terms of quantities like Rademacher averages that better characterize overfitting in machine learning [1,2,5]. Some discussion of how this applies to fair learning in particular would be appreciated, especially as works like [9] show that the process of optimizing fair ML objectives has a regularizing effect and can actually reduce overfitting.

In lemmas 2,3,&4, the requirement is that this holds for all i, correct? These are a bit tricky to read, because $\mu_{e}$ depends on i, although $\sigma^{2}$ does not, and the notation does not reflect this. Moreover, it seems unfortunate that we reach the same conclusion in all three cases, is this necessary (i.e., are there counterexamples to improvement in each?).

I think these results can only be true if client distributions are drawn IID. This should be clarified in lemma 1. This is a big assumption, since I might expect friends’ distributions to be correlated (which incentivizes them to deviate, harming core stability). But I also need to ask, is the variance between distributions the sample variance or the distribution variance? I think this matters a lot, since presumably there are relatively few agents, and if the sample variance is what matters, then why can't we condition on the sample (in which case independence wouldn’t matter)?


In section 4.1, I think it would be nice to generalize this idea to define a client's utility function as some welfare function of their own value and the value of their friends. I think this would simplify the presentation, but also you would be able to use more sophisticated concepts, like weighted power-means.

Moreover, since the same result holds for purely altruistic and friendly altruistic cases, this immediately implies that the client utility functions can be the utilitarian maximum social welfare (malfare) function [6,11], and some set of weighted utilitarian welfare (malfare) functions. I suspect it could easily generalize to any weighted utilitarian welfare function. I would also be very interested to see if these results held for any unweighted power-mean welfare function, any weighted power-mean welfare function, or any Gini malfare function [6], as they do in some sense lie between welfare altruism and equal altruism, though I don't think these results follow directly from your stated lemmas.



Minor points:

149 “satisfy” should be “satisfies.” Moreover this definition feels a bit redundant with (1).

158 It seems strange to mix a sociological definition of friend with a mathematical definition. Moreover, while I am not a sociologist, it seems wrong that “friend” would be the most intimate trusted voluntary category. If so, what is a best friend, and where does that leave a partner? But is this discussion even necessary?

Perhaps definitions 2 3 and 4 can be merged to describe the coalitional game?

163 “does not exist” to “does not exist a”


171 I dislike this terminology. I would describe both types of altruism as considering different types of the welfare among friends, but I would term them “egalitarian altruism” and “utilitarian altruism,” respectively [1].","FedAvg

I don't love the FedAvg aggregation rule of line 126 (though I appreciate that the authors analyze an established model). This seems appropriate when groups train relatively similar models on their own, and the lost surface is relatively smooth. I suspect this is a decent rule when each client has the same optimal model, but due to limited sampling wouldn't identify this from their own data.

The approach seems particularly problematic for non-convex loss surfaces, or models with symmetry (e.g., neural networks or mixture models where averaging the parameters of two identical models can produce a completely different model). I’d like to see more discussion of these limitations (or generalization of the model).

However, I would like to see some consideration of other models of FL, for instance when clients send gradient updates, rather than raw model parameters. From reading the introduction, I expected the FL to be trained to incentivize egalitarian fairness, but this simple averaging rule is neither utilitarian optimal, nor is it egalitarian optimal. Works like [3] consider sampling implications for this, and biased SGD analyses [4,7] also seem appropriate to discuss, at least in related work.

Overfitting

I would also like to see some consideration of overfitting. It seems tautological that nonaltruistic agents would prefer to train their own model when only training loss is considered, and while altruism may incentivize them to share their data, there is also the non-altruistic effect of reduced overfitting. It seems this would also disincentivize the formations of small coalitions, so I would be very interested to see what impact these factors have on the work.


References:

[1] An axiomatic theory of provably-fair welfare-centric machine learning
C Cousins
Advances in Neural Information Processing Systems 34, 16610-16621

[2] Revisiting fair-PAC learning and the axioms of cardinal welfare
C Cousins
International Conference on Artificial Intelligence and Statistics, 6422-6442

[3] Jacob D Abernethy, Pranjal Awasthi, Matthäus Kleindessner, Jamie Morgenstern, Chris Russell, and Jie Zhang. Active sampling for min-max fairness. In International
Conference on Machine Learning, volume 162, 2022.

[4] A guide through the zoo of biased SGD
Y Demidovich, G Malinovsky… - Advances in Neural …, 2024 - proceedings.neurips.cc,

[5] Uncertainty and the social planner’s problem: Why sample complexity matters
C Cousins
Proceedings of the 2022 ACM Conference on Fairness, Accountability, and …

[6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
Cyrus Cousins

[7] Hu, Yifan, et al. ""Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning."" Advances in Neural Information Processing Systems 33 (2020): 2759-2770.

[8] John Rawls. A theory of justice. Harvard University Press, 1971.

[9] Cousins, Cyrus, I. Elizabeth Kumar, and Suresh Venkatasubramanian. ""To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models."" International Conference on Artificial Intelligence and Statistics. PMLR, 2024.

[10] Dwork, Cynthia, et al. ""Fairness through awareness."" Proceedings of the 3rd innovations in theoretical computer science conference. 2012.

[11] Deschamps, R., Gevers, L.: Leximin and utilitarian rules: A joint characterization. Journal of Economic Theory 17(2), 143–163 (1978)",['No ethics review needed.'],6,4,,Yes,2,3,4,1721221878048,,,NeurIPS.cc/2024/Conference,1kyc4TSOFZ,"['NeurIPS.cc/2024/Conference/Submission3661/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878866018,[],3,,,['everyone'],1kyc4TSOFZ,['NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP'],1721221878048,1730878866018,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] An axiomatic theory of provably-fair welfare-centric machine learning
2. [2] Revisiting fair-PAC learning and the axioms of cardinal welfare
3. [3] Active sampling for min-max fairness
4. [4] A guide through the zoo of biased SGD
5. [5] Uncertainty and the social planner’s problem: Why sample complexity matters
6. [6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
7. [7] Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning
8. [8] A theory of justice
9. [9] To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models
10. [10] Fairness through awareness
11. [11] Leximin and utilitarian rules: A joint characterization

These citations are provided as references to support the reviewer's comments and suggestions for improving the paper.",1,,Fairness through awareness
HzvzyLYrmt,"This paper examines the relationship between egalitarian fairness concepts and stability in federated learning, where multiple clients collaboratively train a shared model while retaining local data privacy. Egalitarian fairness promotes uniform model performance across clients, but this can reduce performance for data-rich clients, potentially causing instability, as these clients might leave for better-performing coalitions. This work employs cooperative game theory and social choice to frame FL systems as altruism coalition formation games, suggesting that core instability issues are linked to clients' altruism and their network of relationships. The authors propose optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors, suggesting that egalitarian fairness does not necessarily lead to instability.","The main strength of this paper is its comprehensive approach to analyzing federated learning under both selfish and altruistic behavior. By considering both the performance of machine learners and the game-theoretic aspects of how federated learners interact, the authors provide a well-rounded analysis of the relationship between egalitarian fairness and stability. The use of game theory and social choice theory to frame FL systems as altruism coalition formation games is particularly innovative, linking instability issues to clients' altruism and their network of relationships. The proposed optimal egalitarian fairness bounds that maintain core stability under various altruistic behaviors are a significant theoretical advancement, disproving the assumption that egalitarian fairness inevitably leads to instability. The technical correctness of the results, subject to the model assumed, further solidifies the paper's contribution to advancing the state of the art in this field. Experimental validation then convincingly supports these theoretical findings with empirical outcomes.","I'm left with some questions about the motivations for the model, though the authors do a good job motivating it with prior work. I'm also left wondering whether some results and assumptions can be generalized, as the analysis is somewhat rigid; the paper would be much stronger if some results held in greater generality. I also question the model of FL used here (FedAvg), as it simply averages over model parameters (it would be nice to see models where clients submit gradient updates rather than complete models, and also where the central authority itself optimizes for egalitarian or other fairness objectives, rather than averaging). Finally, I argue the client utilities don't fully reflect the impact of overfitting.","Clearly the FedAvg rule for $\theta$ (line 126) promotes privacy in some sense, but with modest added noise, is the mechanism differentially private?

I would argue that definition 1 is more closely related to the demographic parity concept of equalized error [10], not egalitarian fairness. I would claim that in loss contexts, egalitarian welfare (or more aptly, malfare) is simply the max over average losses of agents [8], but inequality between agents is not antithetical to egalitarian fairness, rather egalitarianism is indifferent to the performance of high performing groups so long as low performing groups cannot be improved. I suppose this is more of a terminology issue, though I do ask if an additive version of this could be explored, where error values are compared to the maximum per group error.

Lemma 1 is quite confusing to me. $\mu_{e}$ depends on i, but notation does not reflect this. By expected value of the variance, you seem to mean expected value of the raw variance, but it's not clear why I care about that quantity? Is this assuming realizability, and therefore the square here corresponds to square loss? Is the method specific to square error though? Why not work directly in terms of loss? These inferences are somewhat confirmed in section 6, though I suspect a method is not really specific to square error, and I claim a more general description in terms of generic loss and loss variance would be easier to follow.

I also think this result does not properly consider overfitting, so I don't think it's very well motivated in a machine learning context. Loss variances should be model (parameter) dependent, so if this is in terms of minimum variance, I suspect it's a reasonable lower bound, and if maximum variance is considered (and multiplied by the log of the model class cardinality or some similar capacity measure), it may be a reasonable upper bound? It's also not totally clear to me which quantities refer to distributions and which refer to data sets in this definition. I would be interested to see a more general analysis, in terms of quantities like Rademacher averages that better characterize overfitting in machine learning [1,2,5]. Some discussion of how this applies to fair learning in particular would be appreciated, especially as works like [9] show that the process of optimizing fair ML objectives has a regularizing effect and can actually reduce overfitting.

In lemmas 2,3,&4, the requirement is that this holds for all i, correct? These are a bit tricky to read, because $\mu_{e}$ depends on i, although $\sigma^{2}$ does not, and the notation does not reflect this. Moreover, it seems unfortunate that we reach the same conclusion in all three cases, is this necessary (i.e., are there counterexamples to improvement in each?).

I think these results can only be true if client distributions are drawn IID. This should be clarified in lemma 1. This is a big assumption, since I might expect friends’ distributions to be correlated (which incentivizes them to deviate, harming core stability). But I also need to ask, is the variance between distributions the sample variance or the distribution variance? I think this matters a lot, since presumably there are relatively few agents, and if the sample variance is what matters, then why can't we condition on the sample (in which case independence wouldn’t matter)?


In section 4.1, I think it would be nice to generalize this idea to define a client's utility function as some welfare function of their own value and the value of their friends. I think this would simplify the presentation, but also you would be able to use more sophisticated concepts, like weighted power-means.

Moreover, since the same result holds for purely altruistic and friendly altruistic cases, this immediately implies that the client utility functions can be the utilitarian maximum social welfare (malfare) function [6,11], and some set of weighted utilitarian welfare (malfare) functions. I suspect it could easily generalize to any weighted utilitarian welfare function. I would also be very interested to see if these results held for any unweighted power-mean welfare function, any weighted power-mean welfare function, or any Gini malfare function [6], as they do in some sense lie between welfare altruism and equal altruism, though I don't think these results follow directly from your stated lemmas.



Minor points:

149 “satisfy” should be “satisfies.” Moreover this definition feels a bit redundant with (1).

158 It seems strange to mix a sociological definition of friend with a mathematical definition. Moreover, while I am not a sociologist, it seems wrong that “friend” would be the most intimate trusted voluntary category. If so, what is a best friend, and where does that leave a partner? But is this discussion even necessary?

Perhaps definitions 2 3 and 4 can be merged to describe the coalitional game?

163 “does not exist” to “does not exist a”


171 I dislike this terminology. I would describe both types of altruism as considering different types of the welfare among friends, but I would term them “egalitarian altruism” and “utilitarian altruism,” respectively [1].","FedAvg

I don't love the FedAvg aggregation rule of line 126 (though I appreciate that the authors analyze an established model). This seems appropriate when groups train relatively similar models on their own, and the lost surface is relatively smooth. I suspect this is a decent rule when each client has the same optimal model, but due to limited sampling wouldn't identify this from their own data.

The approach seems particularly problematic for non-convex loss surfaces, or models with symmetry (e.g., neural networks or mixture models where averaging the parameters of two identical models can produce a completely different model). I’d like to see more discussion of these limitations (or generalization of the model).

However, I would like to see some consideration of other models of FL, for instance when clients send gradient updates, rather than raw model parameters. From reading the introduction, I expected the FL to be trained to incentivize egalitarian fairness, but this simple averaging rule is neither utilitarian optimal, nor is it egalitarian optimal. Works like [3] consider sampling implications for this, and biased SGD analyses [4,7] also seem appropriate to discuss, at least in related work.

Overfitting

I would also like to see some consideration of overfitting. It seems tautological that nonaltruistic agents would prefer to train their own model when only training loss is considered, and while altruism may incentivize them to share their data, there is also the non-altruistic effect of reduced overfitting. It seems this would also disincentivize the formations of small coalitions, so I would be very interested to see what impact these factors have on the work.


References:

[1] An axiomatic theory of provably-fair welfare-centric machine learning
C Cousins
Advances in Neural Information Processing Systems 34, 16610-16621

[2] Revisiting fair-PAC learning and the axioms of cardinal welfare
C Cousins
International Conference on Artificial Intelligence and Statistics, 6422-6442

[3] Jacob D Abernethy, Pranjal Awasthi, Matthäus Kleindessner, Jamie Morgenstern, Chris Russell, and Jie Zhang. Active sampling for min-max fairness. In International
Conference on Machine Learning, volume 162, 2022.

[4] A guide through the zoo of biased SGD
Y Demidovich, G Malinovsky… - Advances in Neural …, 2024 - proceedings.neurips.cc,

[5] Uncertainty and the social planner’s problem: Why sample complexity matters
C Cousins
Proceedings of the 2022 ACM Conference on Fairness, Accountability, and …

[6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
Cyrus Cousins

[7] Hu, Yifan, et al. ""Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning."" Advances in Neural Information Processing Systems 33 (2020): 2759-2770.

[8] John Rawls. A theory of justice. Harvard University Press, 1971.

[9] Cousins, Cyrus, I. Elizabeth Kumar, and Suresh Venkatasubramanian. ""To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models."" International Conference on Artificial Intelligence and Statistics. PMLR, 2024.

[10] Dwork, Cynthia, et al. ""Fairness through awareness."" Proceedings of the 3rd innovations in theoretical computer science conference. 2012.

[11] Deschamps, R., Gevers, L.: Leximin and utilitarian rules: A joint characterization. Journal of Economic Theory 17(2), 143–163 (1978)",['No ethics review needed.'],6,4,,Yes,2,3,4,1721221878048,,,NeurIPS.cc/2024/Conference,1kyc4TSOFZ,"['NeurIPS.cc/2024/Conference/Submission3661/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878866018,[],3,,,['everyone'],1kyc4TSOFZ,['NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP'],1721221878048,1730878866018,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3661/Reviewer_CtFP']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. [1] An axiomatic theory of provably-fair welfare-centric machine learning
2. [2] Revisiting fair-PAC learning and the axioms of cardinal welfare
3. [3] Active sampling for min-max fairness
4. [4] A guide through the zoo of biased SGD
5. [5] Uncertainty and the social planner’s problem: Why sample complexity matters
6. [6] Algorithms and Analysis for Optimizing Robust Objectives in Fair Machine Learning
7. [7] Biased stochastic first-order methods for conditional stochastic optimization and applications in meta learning
8. [8] A theory of justice
9. [9] To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models
10. [10] Fairness through awareness
11. [11] Leximin and utilitarian rules: A joint characterization

These citations are provided as references to support the reviewer's comments and suggestions for improving the paper.",1,,Leximin and utilitarian rules A joint characterization
JhJhBvOYVq,"This paper explores enhancing flow-based generative models for image generation by accelerating the sampling process while maintaining or improving image quality. The key contribution, FlowTurbo, is a new framework that introduces a lightweight velocity refiner to adjust velocity predictions during sampling, reducing computational costs. Additionally, techniques like pseudo correctors and sample-aware compilation further optimize the sampling speed. The results show significant acceleration in image generation tasks with improved FID scores, establishing a new benchmark for real-time image generation.","Overall I find that the writing is clear, concise, and well-structured, making it easy for readers to follow the arguments and understand the key points. This paper starts from the distinct features of flow models and naturally proposes corresponding solutions. Comprehensive ablations validate the effectiveness of the proposed methods.","- The design of three types of blocks in sampling is somewhat confusing to me. Why do you have to use these types of blocks and arrange them in this order? Do you have to empirically decide the order and numbers of these blocks for each task/domain/model?
- The visualization in Figure 1 is interesting. However, visualizing the discretization error or curvature [1] during sampling seems to be a more suitable and accurate method.
- Some important related works [1,2], tailored for flow models, should be discussed and compared.

[1] Nguyen, Bao, Binh Nguyen, and Viet Anh Nguyen. ""Bellman optimal step-size straightening of flow-matching models."" *arXiv preprint arXiv:2312.16414* (2023).

[2] Shaul, Neta, et al. ""Bespoke Non-Stationary Solvers for Fast Sampling of Diffusion and Flow Models."" *arXiv preprint arXiv:2403.01329* (2024).","If I understand correctly, the proposed method can be applied to diffusion models as well. (Although Figure 1 illustrates flow models may be more suitable.) Have you tested the results on diffusion models like SD or PixArt?",Yes.,['No ethics review needed.'],6,4,,Yes,3,3,3,1720754909812,,,NeurIPS.cc/2024/Conference,1jG5ngXVs3,"['NeurIPS.cc/2024/Conference/Submission1386/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878698061,[],2,,,['everyone'],1jG5ngXVs3,['NeurIPS.cc/2024/Conference/Submission1386/Reviewer_RYd7'],1720754909812,1730878698061,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission1386/Reviewer_RYd7']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. Nguyen, Bao, Binh Nguyen, and Viet Anh Nguyen. ""Bellman optimal step-size straightening of flow-matching models."" arXiv preprint arXiv:2312.16414 (2023).
2. Shaul, Neta, et al. ""Bespoke Non-Stationary Solvers for Fast Sampling of Diffusion and Flow Models."" arXiv preprint arXiv:2403.01329 (2024).

The reviewer mentions that these related works, tailored for flow models, should be discussed and compared in the paper.",1,"2023, 2023, 2024, 2024",Bellman optimal step-size straightening of flow-matching models 
JhJhBvOYVq,"This paper explores enhancing flow-based generative models for image generation by accelerating the sampling process while maintaining or improving image quality. The key contribution, FlowTurbo, is a new framework that introduces a lightweight velocity refiner to adjust velocity predictions during sampling, reducing computational costs. Additionally, techniques like pseudo correctors and sample-aware compilation further optimize the sampling speed. The results show significant acceleration in image generation tasks with improved FID scores, establishing a new benchmark for real-time image generation.","Overall I find that the writing is clear, concise, and well-structured, making it easy for readers to follow the arguments and understand the key points. This paper starts from the distinct features of flow models and naturally proposes corresponding solutions. Comprehensive ablations validate the effectiveness of the proposed methods.","- The design of three types of blocks in sampling is somewhat confusing to me. Why do you have to use these types of blocks and arrange them in this order? Do you have to empirically decide the order and numbers of these blocks for each task/domain/model?
- The visualization in Figure 1 is interesting. However, visualizing the discretization error or curvature [1] during sampling seems to be a more suitable and accurate method.
- Some important related works [1,2], tailored for flow models, should be discussed and compared.

[1] Nguyen, Bao, Binh Nguyen, and Viet Anh Nguyen. ""Bellman optimal step-size straightening of flow-matching models."" *arXiv preprint arXiv:2312.16414* (2023).

[2] Shaul, Neta, et al. ""Bespoke Non-Stationary Solvers for Fast Sampling of Diffusion and Flow Models."" *arXiv preprint arXiv:2403.01329* (2024).","If I understand correctly, the proposed method can be applied to diffusion models as well. (Although Figure 1 illustrates flow models may be more suitable.) Have you tested the results on diffusion models like SD or PixArt?",Yes.,['No ethics review needed.'],6,4,,Yes,3,3,3,1720754909812,,,NeurIPS.cc/2024/Conference,1jG5ngXVs3,"['NeurIPS.cc/2024/Conference/Submission1386/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878698061,[],2,,,['everyone'],1jG5ngXVs3,['NeurIPS.cc/2024/Conference/Submission1386/Reviewer_RYd7'],1720754909812,1730878698061,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission1386/Reviewer_RYd7']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. Nguyen, Bao, Binh Nguyen, and Viet Anh Nguyen. ""Bellman optimal step-size straightening of flow-matching models."" arXiv preprint arXiv:2312.16414 (2023).
2. Shaul, Neta, et al. ""Bespoke Non-Stationary Solvers for Fast Sampling of Diffusion and Flow Models."" arXiv preprint arXiv:2403.01329 (2024).

The reviewer mentions that these related works, tailored for flow models, should be discussed and compared in the paper.",1,"2023, 2023, 2024, 2024",Bespoke Non-Stationary Solvers for Fast Sampling of Diffusion and Flow Models
rLRWNJcjrE,"The paper presents an innovative framework for enhancing the discussion capabilities of language agents in the game ""One Night Ultimate Werewolf"" (ONUW) using reinforcement learning (RL). The authors propose a multi-phase extensive-form Bayesian game formulation for ONUW, analyze perfect Bayesian equilibria in both discussion and non-discussion scenarios, and develop an RL-trained discussion policy. Experimental results demonstrate the effectiveness and generalizability of the framework across various game settings.","1. The theoretical analysis of the game, including the formulation as a Bayesian game and the derivation of equilibria, is thorough and well-executed. The experimental design is robust, utilizing state-of-the-art LLMs and a novel RL training methodology.

2. The paper is well-structured and clearly written. The authors provide detailed explanations of the game mechanics, the theoretical framework, and the RL training process, which make the complex content accessible to readers.","1. Comparison with Related Work: While the paper provides an innovative approach to using RL and LLMs in the Werewolf game, there is a need for a more detailed comparison with closely related works, particularly those combining LLMs with reinforcement learning strategies. For instance:
Xu et al. (2023) [1] also explore strategic play in the Werewolf game using language agents trained with reinforcement learning. A comparative analysis highlighting what differentiates the current approach from Xu et al.'s methodology would clarify the novelty and the specific advancements made.
Wu et al. (2024) [2] utilize offline RL and a dataset-driven approach to enhance reasoning in LLMs within the same game context. Discussing how the methodologies differ, especially in terms of model training, dataset utilization, and resultant agent behavior, would strengthen the current work's positioning within the field.

2. Lack of Human Evaluation: The experimental section primarily focuses on win rates to demonstrate the effectiveness of the proposed framework. However, Werewolf (ONUW) involves complex human interactions and strategic discussions that might not be fully captured by win rates alone. The game's social and psychological aspects, such as bluffing and persuasion, are crucial:
It would be beneficial to include human evaluations to assess the quality of the AI's gameplay and its ability to mimic human-like strategic discussions. This could involve subjective assessments from experienced human players regarding the AI's ability to integrate seamlessly into human gameplay, its strategic depth, and its communication effectiveness.

LLM+RL：[1] Zelai Xu, Chao Yu, Fei Fang, Yu Wang, and Yi Wu. Language agents with reinforcement learning for strategic play in the werewolf game. arXiv preprint arXiv:2310.18940, 2023.
LLM+offline RL, dataset: [2] S Wu, L Zhu, T Yang, S Xu, Q Fu, Y Wei, H Fu, Enhance reasoning for large language models in the game werewolf.  arXiv preprint arXiv:2402.02330, 2024

3. Dataset Size and Composition: Detailed information on the size and composition of the dataset used for offline RL is necessary. Understanding the diversity and representativeness of the game logs in the dataset would help in assessing the potential generalizability and robustness of the trained models. This includes the number of game sessions, variety of player strategies, and the range of game outcomes included.","1. Detailed Comparison with [1] and [2]: Can the authors provide a more detailed comparison of their work with the approaches in [1] Zelai Xu et al., 2023, and [2] S Wu et al., 2024? Specifically, how does the integration of RL and LLMs in your framework differ from these studies in terms of model architecture, training processes, and performance metrics?

2. Human-Like Gameplay Evaluation: Given the social and psychological complexities of the ONUW game, how do the authors plan to evaluate the AI's performance in terms of human-like behavior and strategic discussion quality? Are there plans to incorporate human player evaluations, and if so, what methodologies would be used to assess the AI's gameplay against human strategies and interactions?

3. The authors note ""we additionally contribute a dataset featuring players employing various discussion tactics in the ONUW
game. "". Where is the dataset, can the authors opensouce the dataset?

4. Clarification on Offline RL Implementation: The paper mentions the use of offline RL due to the slow interaction with LLMs, but it lacks specific details on how the LLM embeddings are handled within the offline RL framework. Are the state embeddings used by the discussion policy generated by running LLMs on the offline dataset prior to training? If so, how is the freshness and relevance of these embeddings ensured over iterations of RL training?","The authors should consider expanding the discussion on the limitations related to the discretization of discussion tactics and the potential over-reliance on specific datasets. Suggestions for future work could include exploring methods for dynamic tactic generation or adjustment based on real-time gameplay feedback, which could help in developing more adaptable and robust AI agents for complex communication games. Additionally, addressing the computational demands and proposing more resource-efficient models could make the technology more accessible for broader applications.",['No ethics review needed.'],4,4,,Yes,2,3,3,1721010386312,,,NeurIPS.cc/2024/Conference,1f82rnwCbl,"['NeurIPS.cc/2024/Conference/Submission9801/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879339449,[],4,,,['everyone'],1f82rnwCbl,['NeurIPS.cc/2024/Conference/Submission9801/Reviewer_uoU5'],1721010386312,1730879339449,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9801/Reviewer_uoU5']","Yes, this peer review explicitly suggests the authors of the paper to cite and compare their work with two specific literature:

1. Xu et al. (2023) [1] - ""Language agents with reinforcement learning for strategic play in the werewolf game.""
2. Wu et al. (2024) [2] - ""Enhance reasoning for large language models in the game werewolf.""

The reviewer asks the authors to provide a more detailed comparison of their work with these studies, specifically in terms of model architecture, training processes, and performance metrics.",1,"2023, 2024",Language agents with reinforcement learning for strategic play in the werewolf game
rLRWNJcjrE,"The paper presents an innovative framework for enhancing the discussion capabilities of language agents in the game ""One Night Ultimate Werewolf"" (ONUW) using reinforcement learning (RL). The authors propose a multi-phase extensive-form Bayesian game formulation for ONUW, analyze perfect Bayesian equilibria in both discussion and non-discussion scenarios, and develop an RL-trained discussion policy. Experimental results demonstrate the effectiveness and generalizability of the framework across various game settings.","1. The theoretical analysis of the game, including the formulation as a Bayesian game and the derivation of equilibria, is thorough and well-executed. The experimental design is robust, utilizing state-of-the-art LLMs and a novel RL training methodology.

2. The paper is well-structured and clearly written. The authors provide detailed explanations of the game mechanics, the theoretical framework, and the RL training process, which make the complex content accessible to readers.","1. Comparison with Related Work: While the paper provides an innovative approach to using RL and LLMs in the Werewolf game, there is a need for a more detailed comparison with closely related works, particularly those combining LLMs with reinforcement learning strategies. For instance:
Xu et al. (2023) [1] also explore strategic play in the Werewolf game using language agents trained with reinforcement learning. A comparative analysis highlighting what differentiates the current approach from Xu et al.'s methodology would clarify the novelty and the specific advancements made.
Wu et al. (2024) [2] utilize offline RL and a dataset-driven approach to enhance reasoning in LLMs within the same game context. Discussing how the methodologies differ, especially in terms of model training, dataset utilization, and resultant agent behavior, would strengthen the current work's positioning within the field.

2. Lack of Human Evaluation: The experimental section primarily focuses on win rates to demonstrate the effectiveness of the proposed framework. However, Werewolf (ONUW) involves complex human interactions and strategic discussions that might not be fully captured by win rates alone. The game's social and psychological aspects, such as bluffing and persuasion, are crucial:
It would be beneficial to include human evaluations to assess the quality of the AI's gameplay and its ability to mimic human-like strategic discussions. This could involve subjective assessments from experienced human players regarding the AI's ability to integrate seamlessly into human gameplay, its strategic depth, and its communication effectiveness.

LLM+RL：[1] Zelai Xu, Chao Yu, Fei Fang, Yu Wang, and Yi Wu. Language agents with reinforcement learning for strategic play in the werewolf game. arXiv preprint arXiv:2310.18940, 2023.
LLM+offline RL, dataset: [2] S Wu, L Zhu, T Yang, S Xu, Q Fu, Y Wei, H Fu, Enhance reasoning for large language models in the game werewolf.  arXiv preprint arXiv:2402.02330, 2024

3. Dataset Size and Composition: Detailed information on the size and composition of the dataset used for offline RL is necessary. Understanding the diversity and representativeness of the game logs in the dataset would help in assessing the potential generalizability and robustness of the trained models. This includes the number of game sessions, variety of player strategies, and the range of game outcomes included.","1. Detailed Comparison with [1] and [2]: Can the authors provide a more detailed comparison of their work with the approaches in [1] Zelai Xu et al., 2023, and [2] S Wu et al., 2024? Specifically, how does the integration of RL and LLMs in your framework differ from these studies in terms of model architecture, training processes, and performance metrics?

2. Human-Like Gameplay Evaluation: Given the social and psychological complexities of the ONUW game, how do the authors plan to evaluate the AI's performance in terms of human-like behavior and strategic discussion quality? Are there plans to incorporate human player evaluations, and if so, what methodologies would be used to assess the AI's gameplay against human strategies and interactions?

3. The authors note ""we additionally contribute a dataset featuring players employing various discussion tactics in the ONUW
game. "". Where is the dataset, can the authors opensouce the dataset?

4. Clarification on Offline RL Implementation: The paper mentions the use of offline RL due to the slow interaction with LLMs, but it lacks specific details on how the LLM embeddings are handled within the offline RL framework. Are the state embeddings used by the discussion policy generated by running LLMs on the offline dataset prior to training? If so, how is the freshness and relevance of these embeddings ensured over iterations of RL training?","The authors should consider expanding the discussion on the limitations related to the discretization of discussion tactics and the potential over-reliance on specific datasets. Suggestions for future work could include exploring methods for dynamic tactic generation or adjustment based on real-time gameplay feedback, which could help in developing more adaptable and robust AI agents for complex communication games. Additionally, addressing the computational demands and proposing more resource-efficient models could make the technology more accessible for broader applications.",['No ethics review needed.'],4,4,,Yes,2,3,3,1721010386312,,,NeurIPS.cc/2024/Conference,1f82rnwCbl,"['NeurIPS.cc/2024/Conference/Submission9801/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879339449,[],4,,,['everyone'],1f82rnwCbl,['NeurIPS.cc/2024/Conference/Submission9801/Reviewer_uoU5'],1721010386312,1730879339449,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9801/Reviewer_uoU5']","Yes, this peer review explicitly suggests the authors of the paper to cite and compare their work with two specific literature:

1. Xu et al. (2023) [1] - ""Language agents with reinforcement learning for strategic play in the werewolf game.""
2. Wu et al. (2024) [2] - ""Enhance reasoning for large language models in the game werewolf.""

The reviewer asks the authors to provide a more detailed comparison of their work with these studies, specifically in terms of model architecture, training processes, and performance metrics.",1,"2023, 2024",Enhance reasoning for large language models in the game werewolf
pBJvGiqFyW,"This paper presents a comprehensive benchmark for instructional image editing. The benchmark contains a high-quality dataset with over 2000 images and 4000 instructions. In addition, the benchmark presents a new evaluation pipeline that leverages GPT to act as the judge to validate the performance of different instructional image editing methods. Within the evaluation, there are two major factor groups considering both high-level and low-level editing.","Due to the lack of high-quality benchmarks in image editing, this work fills the gap and is of great significance to the community. The evaluation pipeline is reasonable and clear to follow. The idea of using multimodal large language models to evaluate image editing results is interesting. The overall presentation is clear.","1. The provided Google Drive link cannot be opened, making the benchmark images inaccessible for review.

2. Image editing evaluation remains a challenge due to few benchmarks. However, the authors ignore comparing their work with a related work [1] due to similar technical pipelines used with that work. Both this and that work first perform human collection, then automated evaluation using GPT, then human evaluation, and then alignment evaluation. The authors should explain the missing comparison.

3. In the high-level editing, the authors did not discuss the evaluation dimension of action change or shape and size change, which are also quite essential editing types.

[1] Diffusion Model-Based Image Editing: A Survey. https://arxiv.org/abs/2402.17525","I am confused about the definition of low-level image editing, which is actually restoration and enhancement. 

First, low-level restoration tasks usually involve fine-grained operations with rich details. Can GPT really see the slight difference when two similar restored results only vary slightly in terms of visual observation or PSNR evaluation? 

Second, many editing methods are not designed for low-level vision tasks. It is not appropriate to use them to perform these tasks. The authors should check more methods specially designed for these tasks.

I hope the authors can perform additional experiments to address the above concerns. For example, for low-light image enhancement, using two leading methods (such as [2] and [3]) to enhance one image with similar outputs visually (or similar PSNR) and then using GPT for evaluation.

[2] Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement (https://arxiv.org/abs/2303.06705)

[3] Low-Light Image Enhancement with Wavelet-based Diffusion Models (https://arxiv.org/abs/2306.00306)",The paper should be submitted to the NeurIPS Dataset and Benchmark track.,['No ethics review needed.'],6,5,,Yes,2,3,2,1719540263061,,,NeurIPS.cc/2024/Conference,1dpmeH6IHa,"['NeurIPS.cc/2024/Conference/Submission136/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878626440,[],1,,,['everyone'],1dpmeH6IHa,['NeurIPS.cc/2024/Conference/Submission136/Reviewer_HHca'],1719540263061,1730878626440,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission136/Reviewer_HHca']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two specific papers:

1. [1] Diffusion Model-Based Image Editing: A Survey (https://arxiv.org/abs/2402.17525)
2. [2] Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement (https://arxiv.org/abs/2303.06705)
3. [3] Low-Light Image Enhancement with Wavelet-based Diffusion Models (https://arxiv.org/abs/2306.00306)

The reviewer suggests that the authors should compare their work with [1] and use [2] and [3] as examples for additional experiments to address the concerns raised.",1,"2024, 2023, 2023",Diffusion Model-Based Image Editing A Survey 
pBJvGiqFyW,"This paper presents a comprehensive benchmark for instructional image editing. The benchmark contains a high-quality dataset with over 2000 images and 4000 instructions. In addition, the benchmark presents a new evaluation pipeline that leverages GPT to act as the judge to validate the performance of different instructional image editing methods. Within the evaluation, there are two major factor groups considering both high-level and low-level editing.","Due to the lack of high-quality benchmarks in image editing, this work fills the gap and is of great significance to the community. The evaluation pipeline is reasonable and clear to follow. The idea of using multimodal large language models to evaluate image editing results is interesting. The overall presentation is clear.","1. The provided Google Drive link cannot be opened, making the benchmark images inaccessible for review.

2. Image editing evaluation remains a challenge due to few benchmarks. However, the authors ignore comparing their work with a related work [1] due to similar technical pipelines used with that work. Both this and that work first perform human collection, then automated evaluation using GPT, then human evaluation, and then alignment evaluation. The authors should explain the missing comparison.

3. In the high-level editing, the authors did not discuss the evaluation dimension of action change or shape and size change, which are also quite essential editing types.

[1] Diffusion Model-Based Image Editing: A Survey. https://arxiv.org/abs/2402.17525","I am confused about the definition of low-level image editing, which is actually restoration and enhancement. 

First, low-level restoration tasks usually involve fine-grained operations with rich details. Can GPT really see the slight difference when two similar restored results only vary slightly in terms of visual observation or PSNR evaluation? 

Second, many editing methods are not designed for low-level vision tasks. It is not appropriate to use them to perform these tasks. The authors should check more methods specially designed for these tasks.

I hope the authors can perform additional experiments to address the above concerns. For example, for low-light image enhancement, using two leading methods (such as [2] and [3]) to enhance one image with similar outputs visually (or similar PSNR) and then using GPT for evaluation.

[2] Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement (https://arxiv.org/abs/2303.06705)

[3] Low-Light Image Enhancement with Wavelet-based Diffusion Models (https://arxiv.org/abs/2306.00306)",The paper should be submitted to the NeurIPS Dataset and Benchmark track.,['No ethics review needed.'],6,5,,Yes,2,3,2,1719540263061,,,NeurIPS.cc/2024/Conference,1dpmeH6IHa,"['NeurIPS.cc/2024/Conference/Submission136/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878626440,[],1,,,['everyone'],1dpmeH6IHa,['NeurIPS.cc/2024/Conference/Submission136/Reviewer_HHca'],1719540263061,1730878626440,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission136/Reviewer_HHca']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two specific papers:

1. [1] Diffusion Model-Based Image Editing: A Survey (https://arxiv.org/abs/2402.17525)
2. [2] Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement (https://arxiv.org/abs/2303.06705)
3. [3] Low-Light Image Enhancement with Wavelet-based Diffusion Models (https://arxiv.org/abs/2306.00306)

The reviewer suggests that the authors should compare their work with [1] and use [2] and [3] as examples for additional experiments to address the concerns raised.",1,"2024, 2023, 2023",Retinexformer One-stage Retinex-based Transformer for Low-light Image Enhancement 
pBJvGiqFyW,"This paper presents a comprehensive benchmark for instructional image editing. The benchmark contains a high-quality dataset with over 2000 images and 4000 instructions. In addition, the benchmark presents a new evaluation pipeline that leverages GPT to act as the judge to validate the performance of different instructional image editing methods. Within the evaluation, there are two major factor groups considering both high-level and low-level editing.","Due to the lack of high-quality benchmarks in image editing, this work fills the gap and is of great significance to the community. The evaluation pipeline is reasonable and clear to follow. The idea of using multimodal large language models to evaluate image editing results is interesting. The overall presentation is clear.","1. The provided Google Drive link cannot be opened, making the benchmark images inaccessible for review.

2. Image editing evaluation remains a challenge due to few benchmarks. However, the authors ignore comparing their work with a related work [1] due to similar technical pipelines used with that work. Both this and that work first perform human collection, then automated evaluation using GPT, then human evaluation, and then alignment evaluation. The authors should explain the missing comparison.

3. In the high-level editing, the authors did not discuss the evaluation dimension of action change or shape and size change, which are also quite essential editing types.

[1] Diffusion Model-Based Image Editing: A Survey. https://arxiv.org/abs/2402.17525","I am confused about the definition of low-level image editing, which is actually restoration and enhancement. 

First, low-level restoration tasks usually involve fine-grained operations with rich details. Can GPT really see the slight difference when two similar restored results only vary slightly in terms of visual observation or PSNR evaluation? 

Second, many editing methods are not designed for low-level vision tasks. It is not appropriate to use them to perform these tasks. The authors should check more methods specially designed for these tasks.

I hope the authors can perform additional experiments to address the above concerns. For example, for low-light image enhancement, using two leading methods (such as [2] and [3]) to enhance one image with similar outputs visually (or similar PSNR) and then using GPT for evaluation.

[2] Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement (https://arxiv.org/abs/2303.06705)

[3] Low-Light Image Enhancement with Wavelet-based Diffusion Models (https://arxiv.org/abs/2306.00306)",The paper should be submitted to the NeurIPS Dataset and Benchmark track.,['No ethics review needed.'],6,5,,Yes,2,3,2,1719540263061,,,NeurIPS.cc/2024/Conference,1dpmeH6IHa,"['NeurIPS.cc/2024/Conference/Submission136/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878626440,[],1,,,['everyone'],1dpmeH6IHa,['NeurIPS.cc/2024/Conference/Submission136/Reviewer_HHca'],1719540263061,1730878626440,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission136/Reviewer_HHca']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two specific papers:

1. [1] Diffusion Model-Based Image Editing: A Survey (https://arxiv.org/abs/2402.17525)
2. [2] Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement (https://arxiv.org/abs/2303.06705)
3. [3] Low-Light Image Enhancement with Wavelet-based Diffusion Models (https://arxiv.org/abs/2306.00306)

The reviewer suggests that the authors should compare their work with [1] and use [2] and [3] as examples for additional experiments to address the concerns raised.",1,"2024, 2023, 2023",Low-Light Image Enhancement with Wavelet-based Diffusion Models
rbKzNL1O7f,"This paper studied an extension of multi-armed bandit problem by introducing infinitely many arms and generalized rotting constraints. It provides explicit regret lower bounds and proposes an algorithm with regret upper bound matching the lower bound when $\beta \geq 1$. It has been claimed that closing the gap between the lower and upper bounds when $\beta \in (0,1) $ remains an open problem.","- Extending the multi-armed bandit problem to infinitely many arms with rotting mean rewards is feasible in many real-world applications. Solid theoretical analyses and empirical results are presented to justify the proposed solution.

- The paper in general is well-written and easy to follow.  Since I have not checked the supplementary material step by step, I can not guarantee the correctness of the proofs, but the theoretical results make sense to me.","- The paper could be viewed as an extension of [1], and the impact of the paper might not be extremely significant. As mentioned in the paper, when $\beta \in (0,1)$, the proposed algorithm can not be proved near optimal at the current stage. The theoretical result could be more impactful if this issue can be solved.

[1] Jung-hun Kim, Milan Vojnovic, and Se-Young Yun. Rotting infinitely many-armed bandits. ICML, pages 11229–11254. PMLR, 2022.

- When the environment parameters $\beta, V_T,$ and $S_T$ are unknown, a significant amount of additional regret is generated with proposed Algorithm 2. 

- The paper could benefit from a more extensive experiment study. For example, the algorithm performances can be compared under different rotting processes (perhaps by varying the rotting rate and adding randomness).","The following questions are raised simply for discussion. There is no need to address them in the paper.

- Why the rotting budget $V_T$ and $S_T$ are defined for all selected arms? I would imagine it can fit better with real-world problems to treat the rotting process for each arm independently. Saying if an arm is selected $N$ times, the rotting budget is $f(N)$ where $f$ is a nondecreasing function.

- Corresponding to my second point in Weakness, is it possible to address the unknown parameters without incurring large additional regret? Can the methodology in the following paper [2] be applied in this paper to address the nonstationary rotting rewards? Can $\beta$ be estimated by selecting multiple new arms?

[2] Chen, Yifang, et al. ""A new algorithm for non-stationary contextual bandits: Efficient, optimal and parameter-free."" Conference on Learning Theory. PMLR, 2019.",The authors adequately addressed the limitations.,['No ethics review needed.'],6,4,,Yes,2,3,3,1719859937831,,,NeurIPS.cc/2024/Conference,1cXdndzkxU,"['NeurIPS.cc/2024/Conference/Submission2328/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878767969,[],1,,,['everyone'],1cXdndzkxU,['NeurIPS.cc/2024/Conference/Submission2328/Reviewer_WSKL'],1719859937831,1730878767969,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2328/Reviewer_WSKL']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. [1] Jung-hun Kim, Milan Vojnovic, and Se-Young Yun. Rotting infinitely many-armed bandits. ICML, pages 11229–11254. PMLR, 2022.
2. [2] Chen, Yifang, et al. ""A new algorithm for non-stationary contextual bandits: Efficient, optimal and parameter-free."" Conference on Learning Theory. PMLR, 2019.

The reviewer mentions these papers in the context of comparing the current paper's work to existing research and suggesting potential methods to address the open problem of unknown parameters.",1,"2022, 2019",Rotting infinitely many-armed bandits 
rbKzNL1O7f,"This paper studied an extension of multi-armed bandit problem by introducing infinitely many arms and generalized rotting constraints. It provides explicit regret lower bounds and proposes an algorithm with regret upper bound matching the lower bound when $\beta \geq 1$. It has been claimed that closing the gap between the lower and upper bounds when $\beta \in (0,1) $ remains an open problem.","- Extending the multi-armed bandit problem to infinitely many arms with rotting mean rewards is feasible in many real-world applications. Solid theoretical analyses and empirical results are presented to justify the proposed solution.

- The paper in general is well-written and easy to follow.  Since I have not checked the supplementary material step by step, I can not guarantee the correctness of the proofs, but the theoretical results make sense to me.","- The paper could be viewed as an extension of [1], and the impact of the paper might not be extremely significant. As mentioned in the paper, when $\beta \in (0,1)$, the proposed algorithm can not be proved near optimal at the current stage. The theoretical result could be more impactful if this issue can be solved.

[1] Jung-hun Kim, Milan Vojnovic, and Se-Young Yun. Rotting infinitely many-armed bandits. ICML, pages 11229–11254. PMLR, 2022.

- When the environment parameters $\beta, V_T,$ and $S_T$ are unknown, a significant amount of additional regret is generated with proposed Algorithm 2. 

- The paper could benefit from a more extensive experiment study. For example, the algorithm performances can be compared under different rotting processes (perhaps by varying the rotting rate and adding randomness).","The following questions are raised simply for discussion. There is no need to address them in the paper.

- Why the rotting budget $V_T$ and $S_T$ are defined for all selected arms? I would imagine it can fit better with real-world problems to treat the rotting process for each arm independently. Saying if an arm is selected $N$ times, the rotting budget is $f(N)$ where $f$ is a nondecreasing function.

- Corresponding to my second point in Weakness, is it possible to address the unknown parameters without incurring large additional regret? Can the methodology in the following paper [2] be applied in this paper to address the nonstationary rotting rewards? Can $\beta$ be estimated by selecting multiple new arms?

[2] Chen, Yifang, et al. ""A new algorithm for non-stationary contextual bandits: Efficient, optimal and parameter-free."" Conference on Learning Theory. PMLR, 2019.",The authors adequately addressed the limitations.,['No ethics review needed.'],6,4,,Yes,2,3,3,1719859937831,,,NeurIPS.cc/2024/Conference,1cXdndzkxU,"['NeurIPS.cc/2024/Conference/Submission2328/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878767969,[],1,,,['everyone'],1cXdndzkxU,['NeurIPS.cc/2024/Conference/Submission2328/Reviewer_WSKL'],1719859937831,1730878767969,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission2328/Reviewer_WSKL']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. [1] Jung-hun Kim, Milan Vojnovic, and Se-Young Yun. Rotting infinitely many-armed bandits. ICML, pages 11229–11254. PMLR, 2022.
2. [2] Chen, Yifang, et al. ""A new algorithm for non-stationary contextual bandits: Efficient, optimal and parameter-free."" Conference on Learning Theory. PMLR, 2019.

The reviewer mentions these papers in the context of comparing the current paper's work to existing research and suggesting potential methods to address the open problem of unknown parameters.",1,"2022, 2019",A new algorithm for non-stationary contextual bandits Efficient optimal and parameter-free
f223m55xTv,"The paper tackles the problem of single-shot fine-tuning of text-to-image models for diverse subject-driven renditions. It first discusses the problem of image-text alignment present in the few-shot fine-tuning paradigm for text-to-image models. It then presents FineStyle. More specifically, it introduces 

* a novel data augmentation technique to synthetically increase the number of image-text pairs from just a single pair
* concept-oriented masking during the (parameter-efficient) fine-tuning phase","* The paper identifies the problems present in the existing few-shot fine-tuning frameworks for text-to-image models. 
* The proposed method is simple and is well demonstrated. 
* The derivation of segmentation maps from cross-attention maps for concept-oriented masking is beautiful.","* Minimal details available on the pre-trained model being used. The paper just mentions MUSE. It didn't mention its capacity. Similarly, it didn't provide any details on the VQGAN being used. 
* Lack of references provided to the works that leverage parameter-efficient fine-tuning for controlled generation in the domain of text-to-image models. Some examples include [1], [2], and [3]. I believe this is relevant since the authors use parameter-efficient fine-tuning as well. 
* FineStyle was demonstrated for masked models like MUSE. But the image generation community doesn't use MUSE that much. So, I am a little concerned about its adoption at scale. It would be very nice if the authors could also showcase some results obtained from applying FineStyle to open text-to-image models such as [4] and [5]. 
* Timing information would have been nice to include as this study aims to avoid the limitations of the iterative fine-tuning scheme introduced in StyleDrop. 

## References

[1] https://github.com/cloneofsimo/lora

[2] Using LoRA for Efficient Stable Diffusion Fine-Tuning, https://huggingface.co/blog/lora

[3] Implicit Style-Content Separation using B-LoRA, https://arxiv.org/abs/2403.14572

[4] SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis, https://arxiv.org/abs/2307.01952

[5] PixArt-Σ: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation, https://arxiv.org/abs/2403.04692","## Suggestions

* Could the Figure 1 be modified as follows? Each row would have a starting image (style image can be overlapped on it as it is currently), and their variants would be obtained by testing different aspects such as color, compositionality, etc. 
* Figure 1 could also hint about the augmentation scheme being used to upscale the dataset. Just writing a single image-text pair (as is the case right now) doesn't sound technically right, especially after reading the nice data augmentation introduced in the paper. 
* In Figure 2, for the bottom row, the content leakage isn't very evident to my eyes. Is it possible to include a stronger example that immediately establishes the point, like the former row? 
* I included this point in the ""Weaknesses"" too but for clarity, I will include it here as well. The parameter-efficient fine-tuning scheme sounds extremely similar to LoRA [1]. It might be worth clarifying the differences if there are any. Additionally, I think it would be sensible to include the concurrent works that make use of parameter-efficient fine-tuning in the context of text-to-image generation (provided some references in ""Weaknesses""). 
* 

## Questions

* There is human evaluation involved yet checklist pts. 14 and 15 are written as NA. Is this expected? 
* Is using the pre-trained MUSE model sufficient to extract the segmentation maps from images coming from non-natural domains? If so, it might be worth mentioning it with a few examples. 
* Could the image-text misalignment problem be mitigated if the text encoder was also fine-tuned? Since MUSE uses T5-xxl and it already supports longer prompts, I believe this is worth trying to compare. Additionally, T5-xxl displays fine-grained understanding of text, as shown in Imagen [2]. 
* Is FineStyle particularly effective for style images with multiple concepts? How about simple style images? 
* 145 - 151: I like the approach. However, it appears tedious. Have the authors explored automating this using an LLM? If so, I would appreciate some results. 
* Have the authors tried using/re-purposing the prior-preservation loss introduced in DreamBooth [3] in eqn. 4?
* As per equation 4, it seems like we need to keep two models in memory for sampling. This appears to be memory-expensive. Or do the authors just use one base model and enable and disable the adapter layers when needed (reference [4])?  
* In Figure 4, in the last row, ""Christmas decoration"" is still present in the first example. Why is that? Is that a failure case?  
* How is the notion of ""unwanted concepts"" implemented in practice with FineStyle? Is it similar to negative prompting (implemented through classifier-free guidance)? 

## References

[1] LoRA: Low-Rank Adaptation of Large Language Models, https://arxiv.org/abs/2106.09685. 

[2] Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding, https://arxiv.org/abs/2205.11487. 

[3] DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation, https://arxiv.org/abs/2208.12242. 

[4] StackLLaMA: A hands-on guide to train LLaMA with RLHF, https://huggingface.co/blog/stackllama#reinforcement-learning-from-human-feedback.",No comment here.,['No ethics review needed.'],6,5,,Yes,3,3,4,1719142717860,,,NeurIPS.cc/2024/Conference,1SmXUGzrH8,"['NeurIPS.cc/2024/Conference/Submission13859/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879666668,[],1,,,['everyone'],1SmXUGzrH8,['NeurIPS.cc/2024/Conference/Submission13859/Reviewer_PDcY'],1719142717860,1730879666668,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission13859/Reviewer_PDcY']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

* [1], [2], and [3] in the ""Weaknesses"" section, which are related to parameter-efficient fine-tuning for controlled generation in the domain of text-to-image models.
* The references provided in the ""Suggestions"" and ""Questions"" sections, such as [1] (LoRA), [2] (Imagen), [3] (DreamBooth), and [4] (StackLLaMA), which are relevant to the proposed method and its potential connections to existing works.

The reviewer mentions that it would be ""sensible to include the concurrent works that make use of parameter-efficient fine-tuning in the context of text-to-image generation"" and suggests citing specific papers, implying that the authors should consider adding these references to their paper.",1,,LoRA 
f223m55xTv,"The paper tackles the problem of single-shot fine-tuning of text-to-image models for diverse subject-driven renditions. It first discusses the problem of image-text alignment present in the few-shot fine-tuning paradigm for text-to-image models. It then presents FineStyle. More specifically, it introduces 

* a novel data augmentation technique to synthetically increase the number of image-text pairs from just a single pair
* concept-oriented masking during the (parameter-efficient) fine-tuning phase","* The paper identifies the problems present in the existing few-shot fine-tuning frameworks for text-to-image models. 
* The proposed method is simple and is well demonstrated. 
* The derivation of segmentation maps from cross-attention maps for concept-oriented masking is beautiful.","* Minimal details available on the pre-trained model being used. The paper just mentions MUSE. It didn't mention its capacity. Similarly, it didn't provide any details on the VQGAN being used. 
* Lack of references provided to the works that leverage parameter-efficient fine-tuning for controlled generation in the domain of text-to-image models. Some examples include [1], [2], and [3]. I believe this is relevant since the authors use parameter-efficient fine-tuning as well. 
* FineStyle was demonstrated for masked models like MUSE. But the image generation community doesn't use MUSE that much. So, I am a little concerned about its adoption at scale. It would be very nice if the authors could also showcase some results obtained from applying FineStyle to open text-to-image models such as [4] and [5]. 
* Timing information would have been nice to include as this study aims to avoid the limitations of the iterative fine-tuning scheme introduced in StyleDrop. 

## References

[1] https://github.com/cloneofsimo/lora

[2] Using LoRA for Efficient Stable Diffusion Fine-Tuning, https://huggingface.co/blog/lora

[3] Implicit Style-Content Separation using B-LoRA, https://arxiv.org/abs/2403.14572

[4] SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis, https://arxiv.org/abs/2307.01952

[5] PixArt-Σ: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation, https://arxiv.org/abs/2403.04692","## Suggestions

* Could the Figure 1 be modified as follows? Each row would have a starting image (style image can be overlapped on it as it is currently), and their variants would be obtained by testing different aspects such as color, compositionality, etc. 
* Figure 1 could also hint about the augmentation scheme being used to upscale the dataset. Just writing a single image-text pair (as is the case right now) doesn't sound technically right, especially after reading the nice data augmentation introduced in the paper. 
* In Figure 2, for the bottom row, the content leakage isn't very evident to my eyes. Is it possible to include a stronger example that immediately establishes the point, like the former row? 
* I included this point in the ""Weaknesses"" too but for clarity, I will include it here as well. The parameter-efficient fine-tuning scheme sounds extremely similar to LoRA [1]. It might be worth clarifying the differences if there are any. Additionally, I think it would be sensible to include the concurrent works that make use of parameter-efficient fine-tuning in the context of text-to-image generation (provided some references in ""Weaknesses""). 
* 

## Questions

* There is human evaluation involved yet checklist pts. 14 and 15 are written as NA. Is this expected? 
* Is using the pre-trained MUSE model sufficient to extract the segmentation maps from images coming from non-natural domains? If so, it might be worth mentioning it with a few examples. 
* Could the image-text misalignment problem be mitigated if the text encoder was also fine-tuned? Since MUSE uses T5-xxl and it already supports longer prompts, I believe this is worth trying to compare. Additionally, T5-xxl displays fine-grained understanding of text, as shown in Imagen [2]. 
* Is FineStyle particularly effective for style images with multiple concepts? How about simple style images? 
* 145 - 151: I like the approach. However, it appears tedious. Have the authors explored automating this using an LLM? If so, I would appreciate some results. 
* Have the authors tried using/re-purposing the prior-preservation loss introduced in DreamBooth [3] in eqn. 4?
* As per equation 4, it seems like we need to keep two models in memory for sampling. This appears to be memory-expensive. Or do the authors just use one base model and enable and disable the adapter layers when needed (reference [4])?  
* In Figure 4, in the last row, ""Christmas decoration"" is still present in the first example. Why is that? Is that a failure case?  
* How is the notion of ""unwanted concepts"" implemented in practice with FineStyle? Is it similar to negative prompting (implemented through classifier-free guidance)? 

## References

[1] LoRA: Low-Rank Adaptation of Large Language Models, https://arxiv.org/abs/2106.09685. 

[2] Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding, https://arxiv.org/abs/2205.11487. 

[3] DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation, https://arxiv.org/abs/2208.12242. 

[4] StackLLaMA: A hands-on guide to train LLaMA with RLHF, https://huggingface.co/blog/stackllama#reinforcement-learning-from-human-feedback.",No comment here.,['No ethics review needed.'],6,5,,Yes,3,3,4,1719142717860,,,NeurIPS.cc/2024/Conference,1SmXUGzrH8,"['NeurIPS.cc/2024/Conference/Submission13859/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879666668,[],1,,,['everyone'],1SmXUGzrH8,['NeurIPS.cc/2024/Conference/Submission13859/Reviewer_PDcY'],1719142717860,1730879666668,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission13859/Reviewer_PDcY']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

* [1], [2], and [3] in the ""Weaknesses"" section, which are related to parameter-efficient fine-tuning for controlled generation in the domain of text-to-image models.
* The references provided in the ""Suggestions"" and ""Questions"" sections, such as [1] (LoRA), [2] (Imagen), [3] (DreamBooth), and [4] (StackLLaMA), which are relevant to the proposed method and its potential connections to existing works.

The reviewer mentions that it would be ""sensible to include the concurrent works that make use of parameter-efficient fine-tuning in the context of text-to-image generation"" and suggests citing specific papers, implying that the authors should consider adding these references to their paper.",1,,Imagen 
f223m55xTv,"The paper tackles the problem of single-shot fine-tuning of text-to-image models for diverse subject-driven renditions. It first discusses the problem of image-text alignment present in the few-shot fine-tuning paradigm for text-to-image models. It then presents FineStyle. More specifically, it introduces 

* a novel data augmentation technique to synthetically increase the number of image-text pairs from just a single pair
* concept-oriented masking during the (parameter-efficient) fine-tuning phase","* The paper identifies the problems present in the existing few-shot fine-tuning frameworks for text-to-image models. 
* The proposed method is simple and is well demonstrated. 
* The derivation of segmentation maps from cross-attention maps for concept-oriented masking is beautiful.","* Minimal details available on the pre-trained model being used. The paper just mentions MUSE. It didn't mention its capacity. Similarly, it didn't provide any details on the VQGAN being used. 
* Lack of references provided to the works that leverage parameter-efficient fine-tuning for controlled generation in the domain of text-to-image models. Some examples include [1], [2], and [3]. I believe this is relevant since the authors use parameter-efficient fine-tuning as well. 
* FineStyle was demonstrated for masked models like MUSE. But the image generation community doesn't use MUSE that much. So, I am a little concerned about its adoption at scale. It would be very nice if the authors could also showcase some results obtained from applying FineStyle to open text-to-image models such as [4] and [5]. 
* Timing information would have been nice to include as this study aims to avoid the limitations of the iterative fine-tuning scheme introduced in StyleDrop. 

## References

[1] https://github.com/cloneofsimo/lora

[2] Using LoRA for Efficient Stable Diffusion Fine-Tuning, https://huggingface.co/blog/lora

[3] Implicit Style-Content Separation using B-LoRA, https://arxiv.org/abs/2403.14572

[4] SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis, https://arxiv.org/abs/2307.01952

[5] PixArt-Σ: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation, https://arxiv.org/abs/2403.04692","## Suggestions

* Could the Figure 1 be modified as follows? Each row would have a starting image (style image can be overlapped on it as it is currently), and their variants would be obtained by testing different aspects such as color, compositionality, etc. 
* Figure 1 could also hint about the augmentation scheme being used to upscale the dataset. Just writing a single image-text pair (as is the case right now) doesn't sound technically right, especially after reading the nice data augmentation introduced in the paper. 
* In Figure 2, for the bottom row, the content leakage isn't very evident to my eyes. Is it possible to include a stronger example that immediately establishes the point, like the former row? 
* I included this point in the ""Weaknesses"" too but for clarity, I will include it here as well. The parameter-efficient fine-tuning scheme sounds extremely similar to LoRA [1]. It might be worth clarifying the differences if there are any. Additionally, I think it would be sensible to include the concurrent works that make use of parameter-efficient fine-tuning in the context of text-to-image generation (provided some references in ""Weaknesses""). 
* 

## Questions

* There is human evaluation involved yet checklist pts. 14 and 15 are written as NA. Is this expected? 
* Is using the pre-trained MUSE model sufficient to extract the segmentation maps from images coming from non-natural domains? If so, it might be worth mentioning it with a few examples. 
* Could the image-text misalignment problem be mitigated if the text encoder was also fine-tuned? Since MUSE uses T5-xxl and it already supports longer prompts, I believe this is worth trying to compare. Additionally, T5-xxl displays fine-grained understanding of text, as shown in Imagen [2]. 
* Is FineStyle particularly effective for style images with multiple concepts? How about simple style images? 
* 145 - 151: I like the approach. However, it appears tedious. Have the authors explored automating this using an LLM? If so, I would appreciate some results. 
* Have the authors tried using/re-purposing the prior-preservation loss introduced in DreamBooth [3] in eqn. 4?
* As per equation 4, it seems like we need to keep two models in memory for sampling. This appears to be memory-expensive. Or do the authors just use one base model and enable and disable the adapter layers when needed (reference [4])?  
* In Figure 4, in the last row, ""Christmas decoration"" is still present in the first example. Why is that? Is that a failure case?  
* How is the notion of ""unwanted concepts"" implemented in practice with FineStyle? Is it similar to negative prompting (implemented through classifier-free guidance)? 

## References

[1] LoRA: Low-Rank Adaptation of Large Language Models, https://arxiv.org/abs/2106.09685. 

[2] Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding, https://arxiv.org/abs/2205.11487. 

[3] DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation, https://arxiv.org/abs/2208.12242. 

[4] StackLLaMA: A hands-on guide to train LLaMA with RLHF, https://huggingface.co/blog/stackllama#reinforcement-learning-from-human-feedback.",No comment here.,['No ethics review needed.'],6,5,,Yes,3,3,4,1719142717860,,,NeurIPS.cc/2024/Conference,1SmXUGzrH8,"['NeurIPS.cc/2024/Conference/Submission13859/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879666668,[],1,,,['everyone'],1SmXUGzrH8,['NeurIPS.cc/2024/Conference/Submission13859/Reviewer_PDcY'],1719142717860,1730879666668,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission13859/Reviewer_PDcY']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

* [1], [2], and [3] in the ""Weaknesses"" section, which are related to parameter-efficient fine-tuning for controlled generation in the domain of text-to-image models.
* The references provided in the ""Suggestions"" and ""Questions"" sections, such as [1] (LoRA), [2] (Imagen), [3] (DreamBooth), and [4] (StackLLaMA), which are relevant to the proposed method and its potential connections to existing works.

The reviewer mentions that it would be ""sensible to include the concurrent works that make use of parameter-efficient fine-tuning in the context of text-to-image generation"" and suggests citing specific papers, implying that the authors should consider adding these references to their paper.",1,,DreamBooth 
f223m55xTv,"The paper tackles the problem of single-shot fine-tuning of text-to-image models for diverse subject-driven renditions. It first discusses the problem of image-text alignment present in the few-shot fine-tuning paradigm for text-to-image models. It then presents FineStyle. More specifically, it introduces 

* a novel data augmentation technique to synthetically increase the number of image-text pairs from just a single pair
* concept-oriented masking during the (parameter-efficient) fine-tuning phase","* The paper identifies the problems present in the existing few-shot fine-tuning frameworks for text-to-image models. 
* The proposed method is simple and is well demonstrated. 
* The derivation of segmentation maps from cross-attention maps for concept-oriented masking is beautiful.","* Minimal details available on the pre-trained model being used. The paper just mentions MUSE. It didn't mention its capacity. Similarly, it didn't provide any details on the VQGAN being used. 
* Lack of references provided to the works that leverage parameter-efficient fine-tuning for controlled generation in the domain of text-to-image models. Some examples include [1], [2], and [3]. I believe this is relevant since the authors use parameter-efficient fine-tuning as well. 
* FineStyle was demonstrated for masked models like MUSE. But the image generation community doesn't use MUSE that much. So, I am a little concerned about its adoption at scale. It would be very nice if the authors could also showcase some results obtained from applying FineStyle to open text-to-image models such as [4] and [5]. 
* Timing information would have been nice to include as this study aims to avoid the limitations of the iterative fine-tuning scheme introduced in StyleDrop. 

## References

[1] https://github.com/cloneofsimo/lora

[2] Using LoRA for Efficient Stable Diffusion Fine-Tuning, https://huggingface.co/blog/lora

[3] Implicit Style-Content Separation using B-LoRA, https://arxiv.org/abs/2403.14572

[4] SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis, https://arxiv.org/abs/2307.01952

[5] PixArt-Σ: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation, https://arxiv.org/abs/2403.04692","## Suggestions

* Could the Figure 1 be modified as follows? Each row would have a starting image (style image can be overlapped on it as it is currently), and their variants would be obtained by testing different aspects such as color, compositionality, etc. 
* Figure 1 could also hint about the augmentation scheme being used to upscale the dataset. Just writing a single image-text pair (as is the case right now) doesn't sound technically right, especially after reading the nice data augmentation introduced in the paper. 
* In Figure 2, for the bottom row, the content leakage isn't very evident to my eyes. Is it possible to include a stronger example that immediately establishes the point, like the former row? 
* I included this point in the ""Weaknesses"" too but for clarity, I will include it here as well. The parameter-efficient fine-tuning scheme sounds extremely similar to LoRA [1]. It might be worth clarifying the differences if there are any. Additionally, I think it would be sensible to include the concurrent works that make use of parameter-efficient fine-tuning in the context of text-to-image generation (provided some references in ""Weaknesses""). 
* 

## Questions

* There is human evaluation involved yet checklist pts. 14 and 15 are written as NA. Is this expected? 
* Is using the pre-trained MUSE model sufficient to extract the segmentation maps from images coming from non-natural domains? If so, it might be worth mentioning it with a few examples. 
* Could the image-text misalignment problem be mitigated if the text encoder was also fine-tuned? Since MUSE uses T5-xxl and it already supports longer prompts, I believe this is worth trying to compare. Additionally, T5-xxl displays fine-grained understanding of text, as shown in Imagen [2]. 
* Is FineStyle particularly effective for style images with multiple concepts? How about simple style images? 
* 145 - 151: I like the approach. However, it appears tedious. Have the authors explored automating this using an LLM? If so, I would appreciate some results. 
* Have the authors tried using/re-purposing the prior-preservation loss introduced in DreamBooth [3] in eqn. 4?
* As per equation 4, it seems like we need to keep two models in memory for sampling. This appears to be memory-expensive. Or do the authors just use one base model and enable and disable the adapter layers when needed (reference [4])?  
* In Figure 4, in the last row, ""Christmas decoration"" is still present in the first example. Why is that? Is that a failure case?  
* How is the notion of ""unwanted concepts"" implemented in practice with FineStyle? Is it similar to negative prompting (implemented through classifier-free guidance)? 

## References

[1] LoRA: Low-Rank Adaptation of Large Language Models, https://arxiv.org/abs/2106.09685. 

[2] Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding, https://arxiv.org/abs/2205.11487. 

[3] DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation, https://arxiv.org/abs/2208.12242. 

[4] StackLLaMA: A hands-on guide to train LLaMA with RLHF, https://huggingface.co/blog/stackllama#reinforcement-learning-from-human-feedback.",No comment here.,['No ethics review needed.'],6,5,,Yes,3,3,4,1719142717860,,,NeurIPS.cc/2024/Conference,1SmXUGzrH8,"['NeurIPS.cc/2024/Conference/Submission13859/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879666668,[],1,,,['everyone'],1SmXUGzrH8,['NeurIPS.cc/2024/Conference/Submission13859/Reviewer_PDcY'],1719142717860,1730879666668,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission13859/Reviewer_PDcY']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

* [1], [2], and [3] in the ""Weaknesses"" section, which are related to parameter-efficient fine-tuning for controlled generation in the domain of text-to-image models.
* The references provided in the ""Suggestions"" and ""Questions"" sections, such as [1] (LoRA), [2] (Imagen), [3] (DreamBooth), and [4] (StackLLaMA), which are relevant to the proposed method and its potential connections to existing works.

The reviewer mentions that it would be ""sensible to include the concurrent works that make use of parameter-efficient fine-tuning in the context of text-to-image generation"" and suggests citing specific papers, implying that the authors should consider adding these references to their paper.",1,,StackLLaMA
YANLuWunFf,This paper proposes a few-shot fine-tuning paradigm called FineStyle for controllability-enhanced style personalization that requires only a single reference image. A concept-oriented data scaling scheme and a parameter-efficient adapter are two key components of the proposed method to achieve this goal.,"1. This paper is well-motivated and well-organized.
2. This idea of scaling the number of training images by creating multiple sub-images and corresponding separate concepts is interesting and reasonable.
3. The controllability of the proposed method is good.","1. Only one baseline model (i.e., StyleDrop) is adopted to compare with the proposed method. Many highly related SOTA methods are not introduced or compared in this paper, such as DreamStyler [1*], ControlStyle [2*], StyleAligned [10], and IP-Adapter [40]. They can perform the same task as the proposed method. \
[1*] DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion Models. AAAI 2024. \
[2*] ControlStyle: Text-Driven Stylized Image Generation Using Diffusion Priors. ACM MM 2023.

2. The proposed method requires very detailed and complex text description for each input style reference image, which is inconvenient and needs human intervention. Moreover, as the authors say, ‘it is often challenging to faithfully describe the visual look of a style in pure text form.’ In contrast, many other methods do not require additional text description of the input style image, such as DreamStyler [1*], ControlStyle [2*], StyleAligned [10], and IP-Adapter [40].

3. The proposed method is inferior to previous method StyleDrop in style learning, which can be observed from both qualitative results and quantitative results. 


4. Detailed information about human evaluation is not provided. How many image-text pairs and participants are involved in the conducted human evaluation? In addition, the sum of the user preference proportions reported in Table 2 is not 1.

5. I am curious about the running time of the proposed method. Is it comparable or superior to previous methods in speed at inference?",Please see **Weaknesses**.,The limitations and potential negative societal impact are discussed in the supplementary material.,['No ethics review needed.'],5,4,,Yes,3,2,2,1719890261272,,,NeurIPS.cc/2024/Conference,1SmXUGzrH8,"['NeurIPS.cc/2024/Conference/Submission13859/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879666510,[],2,,,['everyone'],1SmXUGzrH8,['NeurIPS.cc/2024/Conference/Submission13859/Reviewer_NTkh'],1719890261272,1730879666510,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission13859/Reviewer_NTkh']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. DreamStyler [1*]
2. ControlStyle [2*]
3. StyleAligned [10]
4. IP-Adapter [40]

The reviewer mentions that these highly related state-of-the-art (SOTA) methods are not introduced or compared in the paper, and suggests that they should be included for a more comprehensive comparison.",1,,DreamStyler 
YANLuWunFf,This paper proposes a few-shot fine-tuning paradigm called FineStyle for controllability-enhanced style personalization that requires only a single reference image. A concept-oriented data scaling scheme and a parameter-efficient adapter are two key components of the proposed method to achieve this goal.,"1. This paper is well-motivated and well-organized.
2. This idea of scaling the number of training images by creating multiple sub-images and corresponding separate concepts is interesting and reasonable.
3. The controllability of the proposed method is good.","1. Only one baseline model (i.e., StyleDrop) is adopted to compare with the proposed method. Many highly related SOTA methods are not introduced or compared in this paper, such as DreamStyler [1*], ControlStyle [2*], StyleAligned [10], and IP-Adapter [40]. They can perform the same task as the proposed method. \
[1*] DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion Models. AAAI 2024. \
[2*] ControlStyle: Text-Driven Stylized Image Generation Using Diffusion Priors. ACM MM 2023.

2. The proposed method requires very detailed and complex text description for each input style reference image, which is inconvenient and needs human intervention. Moreover, as the authors say, ‘it is often challenging to faithfully describe the visual look of a style in pure text form.’ In contrast, many other methods do not require additional text description of the input style image, such as DreamStyler [1*], ControlStyle [2*], StyleAligned [10], and IP-Adapter [40].

3. The proposed method is inferior to previous method StyleDrop in style learning, which can be observed from both qualitative results and quantitative results. 


4. Detailed information about human evaluation is not provided. How many image-text pairs and participants are involved in the conducted human evaluation? In addition, the sum of the user preference proportions reported in Table 2 is not 1.

5. I am curious about the running time of the proposed method. Is it comparable or superior to previous methods in speed at inference?",Please see **Weaknesses**.,The limitations and potential negative societal impact are discussed in the supplementary material.,['No ethics review needed.'],5,4,,Yes,3,2,2,1719890261272,,,NeurIPS.cc/2024/Conference,1SmXUGzrH8,"['NeurIPS.cc/2024/Conference/Submission13859/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879666510,[],2,,,['everyone'],1SmXUGzrH8,['NeurIPS.cc/2024/Conference/Submission13859/Reviewer_NTkh'],1719890261272,1730879666510,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission13859/Reviewer_NTkh']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. DreamStyler [1*]
2. ControlStyle [2*]
3. StyleAligned [10]
4. IP-Adapter [40]

The reviewer mentions that these highly related state-of-the-art (SOTA) methods are not introduced or compared in the paper, and suggests that they should be included for a more comprehensive comparison.",1,,ControlStyle 
YANLuWunFf,This paper proposes a few-shot fine-tuning paradigm called FineStyle for controllability-enhanced style personalization that requires only a single reference image. A concept-oriented data scaling scheme and a parameter-efficient adapter are two key components of the proposed method to achieve this goal.,"1. This paper is well-motivated and well-organized.
2. This idea of scaling the number of training images by creating multiple sub-images and corresponding separate concepts is interesting and reasonable.
3. The controllability of the proposed method is good.","1. Only one baseline model (i.e., StyleDrop) is adopted to compare with the proposed method. Many highly related SOTA methods are not introduced or compared in this paper, such as DreamStyler [1*], ControlStyle [2*], StyleAligned [10], and IP-Adapter [40]. They can perform the same task as the proposed method. \
[1*] DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion Models. AAAI 2024. \
[2*] ControlStyle: Text-Driven Stylized Image Generation Using Diffusion Priors. ACM MM 2023.

2. The proposed method requires very detailed and complex text description for each input style reference image, which is inconvenient and needs human intervention. Moreover, as the authors say, ‘it is often challenging to faithfully describe the visual look of a style in pure text form.’ In contrast, many other methods do not require additional text description of the input style image, such as DreamStyler [1*], ControlStyle [2*], StyleAligned [10], and IP-Adapter [40].

3. The proposed method is inferior to previous method StyleDrop in style learning, which can be observed from both qualitative results and quantitative results. 


4. Detailed information about human evaluation is not provided. How many image-text pairs and participants are involved in the conducted human evaluation? In addition, the sum of the user preference proportions reported in Table 2 is not 1.

5. I am curious about the running time of the proposed method. Is it comparable or superior to previous methods in speed at inference?",Please see **Weaknesses**.,The limitations and potential negative societal impact are discussed in the supplementary material.,['No ethics review needed.'],5,4,,Yes,3,2,2,1719890261272,,,NeurIPS.cc/2024/Conference,1SmXUGzrH8,"['NeurIPS.cc/2024/Conference/Submission13859/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879666510,[],2,,,['everyone'],1SmXUGzrH8,['NeurIPS.cc/2024/Conference/Submission13859/Reviewer_NTkh'],1719890261272,1730879666510,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission13859/Reviewer_NTkh']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. DreamStyler [1*]
2. ControlStyle [2*]
3. StyleAligned [10]
4. IP-Adapter [40]

The reviewer mentions that these highly related state-of-the-art (SOTA) methods are not introduced or compared in the paper, and suggests that they should be included for a more comprehensive comparison.",1,,StyleAligned 
YANLuWunFf,This paper proposes a few-shot fine-tuning paradigm called FineStyle for controllability-enhanced style personalization that requires only a single reference image. A concept-oriented data scaling scheme and a parameter-efficient adapter are two key components of the proposed method to achieve this goal.,"1. This paper is well-motivated and well-organized.
2. This idea of scaling the number of training images by creating multiple sub-images and corresponding separate concepts is interesting and reasonable.
3. The controllability of the proposed method is good.","1. Only one baseline model (i.e., StyleDrop) is adopted to compare with the proposed method. Many highly related SOTA methods are not introduced or compared in this paper, such as DreamStyler [1*], ControlStyle [2*], StyleAligned [10], and IP-Adapter [40]. They can perform the same task as the proposed method. \
[1*] DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion Models. AAAI 2024. \
[2*] ControlStyle: Text-Driven Stylized Image Generation Using Diffusion Priors. ACM MM 2023.

2. The proposed method requires very detailed and complex text description for each input style reference image, which is inconvenient and needs human intervention. Moreover, as the authors say, ‘it is often challenging to faithfully describe the visual look of a style in pure text form.’ In contrast, many other methods do not require additional text description of the input style image, such as DreamStyler [1*], ControlStyle [2*], StyleAligned [10], and IP-Adapter [40].

3. The proposed method is inferior to previous method StyleDrop in style learning, which can be observed from both qualitative results and quantitative results. 


4. Detailed information about human evaluation is not provided. How many image-text pairs and participants are involved in the conducted human evaluation? In addition, the sum of the user preference proportions reported in Table 2 is not 1.

5. I am curious about the running time of the proposed method. Is it comparable or superior to previous methods in speed at inference?",Please see **Weaknesses**.,The limitations and potential negative societal impact are discussed in the supplementary material.,['No ethics review needed.'],5,4,,Yes,3,2,2,1719890261272,,,NeurIPS.cc/2024/Conference,1SmXUGzrH8,"['NeurIPS.cc/2024/Conference/Submission13859/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879666510,[],2,,,['everyone'],1SmXUGzrH8,['NeurIPS.cc/2024/Conference/Submission13859/Reviewer_NTkh'],1719890261272,1730879666510,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission13859/Reviewer_NTkh']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. DreamStyler [1*]
2. ControlStyle [2*]
3. StyleAligned [10]
4. IP-Adapter [40]

The reviewer mentions that these highly related state-of-the-art (SOTA) methods are not introduced or compared in the paper, and suggests that they should be included for a more comprehensive comparison.",1,,IP-Adapter
pfsAPsNBnD,"This work investigates sequential recommendation, and proposes a new method that utilizes stochastic differential equations (SDEs) to model dynamic time intervals and estimate uncertainty.

Overall, this study addresses an engaging problem and provides a novel and reasonable solution. Extensive experiments have been conducted. Consequently, I lean towards accept.","1.	This work studies on an interesting and important problem --- how to capture dynamic time interval as well as estimate model uncertainty. 

2.	The paper is well-written, with clear motivations.

3.	The application of stochastic differential equations to model sequential recommendation is both novel and reasonable.

4.	Extensive experiments are conducted to validate the effectiveness of the proposal.","1.	It would be advantageous to include diffusion model-based sequential recommendation baselines for comparison in the experiments, such as [a1][a2], especially since SDEs have been utilized in these methods as well.

2.	The work reports performance metrics only for P@5 and NDCG@5. It would be better to include the results with different @N, particularly @20, which is commonly adopted by recent work.

3.	A discussion on the limitations and future directions of the research in Section 6 would be beneficial.

4.	There are some typos. For example, in the eq.(13), ‘BPR’->’WBPR’; In the line 316, removing ‘vs’. 


5.	Some important relate work is omitted:
[a1] TOIS’23: Diffurec: A diffusion model for sequential recommendation
[a2] NIPS’23: Generate what you prefer: Reshaping sequential recommendation via guided diffusion",Please refer to weaknesses.,No concern.,['No ethics review needed.'],7,2,,Yes,3,3,3,1720838509646,,,NeurIPS.cc/2024/Conference,1PmsSugB87,"['NeurIPS.cc/2024/Conference/Submission3047/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878822460,[],4,,,['everyone'],1PmsSugB87,['NeurIPS.cc/2024/Conference/Submission3047/Reviewer_p7WH'],1720838509646,1730878822460,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3047/Reviewer_p7WH']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. [a1] TOIS'23: Diffurec: A diffusion model for sequential recommendation
2. [a2] NIPS'23: Generate what you prefer: Reshaping sequential recommendation via guided diffusion

The reviewer mentions that these papers are related to the work and should be included as baselines for comparison in the experiments.",1,"2023, 2023",Diffurec A diffusion model for sequential recommendation 
pfsAPsNBnD,"This work investigates sequential recommendation, and proposes a new method that utilizes stochastic differential equations (SDEs) to model dynamic time intervals and estimate uncertainty.

Overall, this study addresses an engaging problem and provides a novel and reasonable solution. Extensive experiments have been conducted. Consequently, I lean towards accept.","1.	This work studies on an interesting and important problem --- how to capture dynamic time interval as well as estimate model uncertainty. 

2.	The paper is well-written, with clear motivations.

3.	The application of stochastic differential equations to model sequential recommendation is both novel and reasonable.

4.	Extensive experiments are conducted to validate the effectiveness of the proposal.","1.	It would be advantageous to include diffusion model-based sequential recommendation baselines for comparison in the experiments, such as [a1][a2], especially since SDEs have been utilized in these methods as well.

2.	The work reports performance metrics only for P@5 and NDCG@5. It would be better to include the results with different @N, particularly @20, which is commonly adopted by recent work.

3.	A discussion on the limitations and future directions of the research in Section 6 would be beneficial.

4.	There are some typos. For example, in the eq.(13), ‘BPR’->’WBPR’; In the line 316, removing ‘vs’. 


5.	Some important relate work is omitted:
[a1] TOIS’23: Diffurec: A diffusion model for sequential recommendation
[a2] NIPS’23: Generate what you prefer: Reshaping sequential recommendation via guided diffusion",Please refer to weaknesses.,No concern.,['No ethics review needed.'],7,2,,Yes,3,3,3,1720838509646,,,NeurIPS.cc/2024/Conference,1PmsSugB87,"['NeurIPS.cc/2024/Conference/Submission3047/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878822460,[],4,,,['everyone'],1PmsSugB87,['NeurIPS.cc/2024/Conference/Submission3047/Reviewer_p7WH'],1720838509646,1730878822460,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3047/Reviewer_p7WH']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. [a1] TOIS'23: Diffurec: A diffusion model for sequential recommendation
2. [a2] NIPS'23: Generate what you prefer: Reshaping sequential recommendation via guided diffusion

The reviewer mentions that these papers are related to the work and should be included as baselines for comparison in the experiments.",1,"2023, 2023",Generate what you prefer Reshaping sequential recommendation via guided diffusion
e0jelGNlZZ,This paper introduces a defence against jailbreak fine-tuning attacks that markedly improves over the baseline suggested by Qi et al. Their method works by implanting a safety backdoor that is subsequently used during inference and show that it is effective on preventing few shot fine-tuning attacks across a variety of controlled settings.,"Generally this paper is very well written, novel, and an extremely valuable contribution to the emerging threat of fine-tuning attacks. Not only do they convincingly demonstrate their defence is effective on the settings presented by Qi et al, and that their method indeed improves over a set of controls for different settings like using a natural language secret prompt, not using category-wise safety samples and in a setting of mixed safe and unsafe samples. I would be excited to see this paper accepted.","There are a few clarity issues in the paper but the main issues I’d like to see addressed are:

(1) The “pure_bad” dataset construction details are insuffecient. What is meant by redteaming?(181) What process was used for it? How was this dataset constructed? What format?  Where are the examples? Why wasn’t Qi et al. or other already existing harmful sample datasets used? Section A.2 is not enough details. Without these details we cannot trust as a reader that these were actually harmful samples.

(2) I think that the authors fail to discuss Prompt Injection attacks that leak the secret prompt. In a LLMaaS FJAttack threat model, what if the attacker gets access to the secret prompt? As mentioned in the paper and the motivation for chosing a non-semantically meaninfdul secret prompt, this means the attacker could then finetune against this prompt. I would recommend the authors at least discuss this limitation but would encourage them to add an experiment showing the effectiveness of this adaptive attack and how likely standard prompt injection methods for prompt leakage are liable to work.

(3) This is minor and is related to a weakness below but 10% of safety samples needed seems like a high cost for a defence (for example this is 10k samples for a 100k training set). Perhaps though this won’t be the case for much stronger attacks. We just don’t know what is required for stronger attacks based on the results in this paper.

This final weakness is more of what I would have liked to see to increase my score higher and what I think would improve the paper but is likely too much to ask to see addressed during the review period:

While the precedant of 100 sample attacks is set in Qi et al. I don’t think that the attack strength is high enough to be able to truly assess this method, realistically it seems like users might use thousads or more samples. I would encourage the authors to at least devise a 1k and 10k setting from a dataset like BeaverTails as is being done in other contemporaneous works. This important because without it: we are not sure that the 10% safety example mix holds, we are not sure how this method operates on more realistic attacks (for example right now there exist 10k+ harmful sample datasets on huggingface - would this defend against those? if not we should know as a communtiy so we can develop stronger defences, if so this defence is potentially promising). I’d also like to have seen more settings from Qi et al so for example varying learning rate, epoch numbers, and smaller attack sizes.","### Suggestions 

I think that this work could benefit from existing defences gainst FJAttacks. Certianly “Henderson, P., Mitchell, E., Manning, C., Jurafsky, D., & Finn, C. (2023, August). Self-destructing models: Increasing the costs of harmful dual uses of foundation models. In *Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society* (pp. 287-296).” should be discussed (of course its not a defence against this exact threat model but it has a very similar motivation, threat model, problem setting etc.)

Other work that is contemporaneous so is optional to add but would nonetheless enhance discussion in the paper to compare and constrast these methods:

- Zhou, X., Lu, Y., Ma, R., Gui, T., Zhang, Q., & Huang, X. (2023). Making harmful behaviors unlearnable for large language models.
- Huang, T., Hu, S., & Liu, L. (2024). Vaccine: Perturbation-aware alignment for large language model
- Rosati, D., Wehner, J., Williams, K., Bartoszcze, Ł., Atanasov, D., Gonzales, R., ... & Rudzicz, F. (2024). Representation noising effectively prevents harmful fine-tuning on LLMs.

One thing that shakes out of at least Rosati et al (in particular their earlier work before RepNoise) and Henderson et al that you do not address is the limitation of your setting to only LMaaS settings. What about settings where the attacker has complete access to the model? Even in the LMaaS case there is the risk of stealing the weights so it would be good to consider whether you have any thoughts here for discussion.

Another citation worth discussing is Korbak, T., Shi, K., Chen, A., Bhalerao, R. V., Buckley, C., Phang, J., ... & Perez, E. (2023, July). Pretraining language models with human preferences. In International Conference on Machine Learning (pp. 17506-17533). PMLR. Although it uses pre-training with safety tokens, the approach has an interesting parallel.

### Notes and suggestions

2: Requires is probably a better word than “request” here

93: Calude 2

98-99,117: Missing spaces before citations

123: I don’t think its correct to say “widely used” since FJAttacks really only consist of 5 or 6 papers at this point.

126: I think exposure is a little bit too vague since in-context learning attacks could also be compromising through exposure

Equation 1 and 3: A very small optional nit pick but I think we usually represent this as an expectation of the negative log loss over the dataset distribution since the actual computation isn’t a sum or losses but a mean. But I see how this formulation has an advantage for conciseness.

136: It would be useful to cite Qi et al. again here and perhaps “Zhan, Q., Fang, R., Bindu, R., Gupta, A., Hashimoto, T., & Kang, D. (2023). Removing rlhf protections in gpt-4 via fine-tuning.” which was published at NAACL this year.

149: I feel like we should reserve this double line notation for asymmetric divergence or parallel lines and use a more standard contenation operator like “+”. I see what you might be trying to do with s_i conditioned on secret prompt s but its clearer to use a standard concatenation operator.
147,149+equation 2: I would find it clearer and more correct if you used a different notation for the secret prompt since now “s” is overloaded to mean both the whole system prompt for the index i and only the secret prompt so its confusing. 

178: Please add the version of GPT-3.5 for replicability

192: 1 times what learning rate?

238-239: I don’t agree with this finding in general - from Table 1 - it seems like all you can say is a decline in utility ARC-challenge.

267-274: Can you say more about why you think this is the case?

290-293: Insightful!

295-301: Can you provide the hyperparameters used for LoTA here or in an appendix?

345: I don’t agree that 10% is a very small set of safety examples.

489: generate",Aside from what I mentioned above they discuss the limitations very well.,['No ethics review needed.'],8,5,,Yes,4,4,4,1720464651898,,,NeurIPS.cc/2024/Conference,1PcJ5Evta7,"['NeurIPS.cc/2024/Conference/Submission14347/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879700313,[],1,,,['everyone'],1PcJ5Evta7,['NeurIPS.cc/2024/Conference/Submission14347/Reviewer_bX8S'],1720464651898,1730879700313,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission14347/Reviewer_bX8S']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Henderson, P., Mitchell, E., Manning, C., Jurafsky, D., & Finn, C. (2023) - ""Self-destructing models: Increasing the costs of harmful dual uses of foundation models.""
2. Zhou, X., Lu, Y., Ma, R., Gui, T., Zhang, Q., & Huang, X. (2023) - ""Making harmful behaviors unlearnable for large language models.""
3. Huang, T., Hu, S., & Liu, L. (2024) - ""Vaccine: Perturbation-aware alignment for large language model""
4. Rosati, D., Wehner, J., Williams, K., Bartoszcze, Ł., Atanasov, D., Gonzales, R., ... & Rudzicz, F. (2024) - ""Representation noising effectively prevents harmful fine-tuning on LLMs.""
5. Korbak, T., Shi, K., Chen, A., Bhalerao, R. V., Buckley, C., Phang, J., ... & Perez, E. (2023) - ""Pretraining language models with human preferences.""
6. Zhan, Q., Fang, R., Bindu, R., Gupta, A., Hashimoto, T., & Kang, D. (2023) - ""Removing rlhf protections in gpt-4 via fine-tuning.""

These citations are suggested to enhance the discussion in the paper, compare and contrast the methods, and provide a more comprehensive overview of the related work.",1,"2023, 2023, 2024, 2024, 2023, 2023",Self-destructing models: Increasing the costs of harmful dual uses of foundation models
e0jelGNlZZ,This paper introduces a defence against jailbreak fine-tuning attacks that markedly improves over the baseline suggested by Qi et al. Their method works by implanting a safety backdoor that is subsequently used during inference and show that it is effective on preventing few shot fine-tuning attacks across a variety of controlled settings.,"Generally this paper is very well written, novel, and an extremely valuable contribution to the emerging threat of fine-tuning attacks. Not only do they convincingly demonstrate their defence is effective on the settings presented by Qi et al, and that their method indeed improves over a set of controls for different settings like using a natural language secret prompt, not using category-wise safety samples and in a setting of mixed safe and unsafe samples. I would be excited to see this paper accepted.","There are a few clarity issues in the paper but the main issues I’d like to see addressed are:

(1) The “pure_bad” dataset construction details are insuffecient. What is meant by redteaming?(181) What process was used for it? How was this dataset constructed? What format?  Where are the examples? Why wasn’t Qi et al. or other already existing harmful sample datasets used? Section A.2 is not enough details. Without these details we cannot trust as a reader that these were actually harmful samples.

(2) I think that the authors fail to discuss Prompt Injection attacks that leak the secret prompt. In a LLMaaS FJAttack threat model, what if the attacker gets access to the secret prompt? As mentioned in the paper and the motivation for chosing a non-semantically meaninfdul secret prompt, this means the attacker could then finetune against this prompt. I would recommend the authors at least discuss this limitation but would encourage them to add an experiment showing the effectiveness of this adaptive attack and how likely standard prompt injection methods for prompt leakage are liable to work.

(3) This is minor and is related to a weakness below but 10% of safety samples needed seems like a high cost for a defence (for example this is 10k samples for a 100k training set). Perhaps though this won’t be the case for much stronger attacks. We just don’t know what is required for stronger attacks based on the results in this paper.

This final weakness is more of what I would have liked to see to increase my score higher and what I think would improve the paper but is likely too much to ask to see addressed during the review period:

While the precedant of 100 sample attacks is set in Qi et al. I don’t think that the attack strength is high enough to be able to truly assess this method, realistically it seems like users might use thousads or more samples. I would encourage the authors to at least devise a 1k and 10k setting from a dataset like BeaverTails as is being done in other contemporaneous works. This important because without it: we are not sure that the 10% safety example mix holds, we are not sure how this method operates on more realistic attacks (for example right now there exist 10k+ harmful sample datasets on huggingface - would this defend against those? if not we should know as a communtiy so we can develop stronger defences, if so this defence is potentially promising). I’d also like to have seen more settings from Qi et al so for example varying learning rate, epoch numbers, and smaller attack sizes.","### Suggestions 

I think that this work could benefit from existing defences gainst FJAttacks. Certianly “Henderson, P., Mitchell, E., Manning, C., Jurafsky, D., & Finn, C. (2023, August). Self-destructing models: Increasing the costs of harmful dual uses of foundation models. In *Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society* (pp. 287-296).” should be discussed (of course its not a defence against this exact threat model but it has a very similar motivation, threat model, problem setting etc.)

Other work that is contemporaneous so is optional to add but would nonetheless enhance discussion in the paper to compare and constrast these methods:

- Zhou, X., Lu, Y., Ma, R., Gui, T., Zhang, Q., & Huang, X. (2023). Making harmful behaviors unlearnable for large language models.
- Huang, T., Hu, S., & Liu, L. (2024). Vaccine: Perturbation-aware alignment for large language model
- Rosati, D., Wehner, J., Williams, K., Bartoszcze, Ł., Atanasov, D., Gonzales, R., ... & Rudzicz, F. (2024). Representation noising effectively prevents harmful fine-tuning on LLMs.

One thing that shakes out of at least Rosati et al (in particular their earlier work before RepNoise) and Henderson et al that you do not address is the limitation of your setting to only LMaaS settings. What about settings where the attacker has complete access to the model? Even in the LMaaS case there is the risk of stealing the weights so it would be good to consider whether you have any thoughts here for discussion.

Another citation worth discussing is Korbak, T., Shi, K., Chen, A., Bhalerao, R. V., Buckley, C., Phang, J., ... & Perez, E. (2023, July). Pretraining language models with human preferences. In International Conference on Machine Learning (pp. 17506-17533). PMLR. Although it uses pre-training with safety tokens, the approach has an interesting parallel.

### Notes and suggestions

2: Requires is probably a better word than “request” here

93: Calude 2

98-99,117: Missing spaces before citations

123: I don’t think its correct to say “widely used” since FJAttacks really only consist of 5 or 6 papers at this point.

126: I think exposure is a little bit too vague since in-context learning attacks could also be compromising through exposure

Equation 1 and 3: A very small optional nit pick but I think we usually represent this as an expectation of the negative log loss over the dataset distribution since the actual computation isn’t a sum or losses but a mean. But I see how this formulation has an advantage for conciseness.

136: It would be useful to cite Qi et al. again here and perhaps “Zhan, Q., Fang, R., Bindu, R., Gupta, A., Hashimoto, T., & Kang, D. (2023). Removing rlhf protections in gpt-4 via fine-tuning.” which was published at NAACL this year.

149: I feel like we should reserve this double line notation for asymmetric divergence or parallel lines and use a more standard contenation operator like “+”. I see what you might be trying to do with s_i conditioned on secret prompt s but its clearer to use a standard concatenation operator.
147,149+equation 2: I would find it clearer and more correct if you used a different notation for the secret prompt since now “s” is overloaded to mean both the whole system prompt for the index i and only the secret prompt so its confusing. 

178: Please add the version of GPT-3.5 for replicability

192: 1 times what learning rate?

238-239: I don’t agree with this finding in general - from Table 1 - it seems like all you can say is a decline in utility ARC-challenge.

267-274: Can you say more about why you think this is the case?

290-293: Insightful!

295-301: Can you provide the hyperparameters used for LoTA here or in an appendix?

345: I don’t agree that 10% is a very small set of safety examples.

489: generate",Aside from what I mentioned above they discuss the limitations very well.,['No ethics review needed.'],8,5,,Yes,4,4,4,1720464651898,,,NeurIPS.cc/2024/Conference,1PcJ5Evta7,"['NeurIPS.cc/2024/Conference/Submission14347/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879700313,[],1,,,['everyone'],1PcJ5Evta7,['NeurIPS.cc/2024/Conference/Submission14347/Reviewer_bX8S'],1720464651898,1730879700313,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission14347/Reviewer_bX8S']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Henderson, P., Mitchell, E., Manning, C., Jurafsky, D., & Finn, C. (2023) - ""Self-destructing models: Increasing the costs of harmful dual uses of foundation models.""
2. Zhou, X., Lu, Y., Ma, R., Gui, T., Zhang, Q., & Huang, X. (2023) - ""Making harmful behaviors unlearnable for large language models.""
3. Huang, T., Hu, S., & Liu, L. (2024) - ""Vaccine: Perturbation-aware alignment for large language model""
4. Rosati, D., Wehner, J., Williams, K., Bartoszcze, Ł., Atanasov, D., Gonzales, R., ... & Rudzicz, F. (2024) - ""Representation noising effectively prevents harmful fine-tuning on LLMs.""
5. Korbak, T., Shi, K., Chen, A., Bhalerao, R. V., Buckley, C., Phang, J., ... & Perez, E. (2023) - ""Pretraining language models with human preferences.""
6. Zhan, Q., Fang, R., Bindu, R., Gupta, A., Hashimoto, T., & Kang, D. (2023) - ""Removing rlhf protections in gpt-4 via fine-tuning.""

These citations are suggested to enhance the discussion in the paper, compare and contrast the methods, and provide a more comprehensive overview of the related work.",1,"2023, 2023, 2024, 2024, 2023, 2023",Making harmful behaviors unlearnable for large language models
e0jelGNlZZ,This paper introduces a defence against jailbreak fine-tuning attacks that markedly improves over the baseline suggested by Qi et al. Their method works by implanting a safety backdoor that is subsequently used during inference and show that it is effective on preventing few shot fine-tuning attacks across a variety of controlled settings.,"Generally this paper is very well written, novel, and an extremely valuable contribution to the emerging threat of fine-tuning attacks. Not only do they convincingly demonstrate their defence is effective on the settings presented by Qi et al, and that their method indeed improves over a set of controls for different settings like using a natural language secret prompt, not using category-wise safety samples and in a setting of mixed safe and unsafe samples. I would be excited to see this paper accepted.","There are a few clarity issues in the paper but the main issues I’d like to see addressed are:

(1) The “pure_bad” dataset construction details are insuffecient. What is meant by redteaming?(181) What process was used for it? How was this dataset constructed? What format?  Where are the examples? Why wasn’t Qi et al. or other already existing harmful sample datasets used? Section A.2 is not enough details. Without these details we cannot trust as a reader that these were actually harmful samples.

(2) I think that the authors fail to discuss Prompt Injection attacks that leak the secret prompt. In a LLMaaS FJAttack threat model, what if the attacker gets access to the secret prompt? As mentioned in the paper and the motivation for chosing a non-semantically meaninfdul secret prompt, this means the attacker could then finetune against this prompt. I would recommend the authors at least discuss this limitation but would encourage them to add an experiment showing the effectiveness of this adaptive attack and how likely standard prompt injection methods for prompt leakage are liable to work.

(3) This is minor and is related to a weakness below but 10% of safety samples needed seems like a high cost for a defence (for example this is 10k samples for a 100k training set). Perhaps though this won’t be the case for much stronger attacks. We just don’t know what is required for stronger attacks based on the results in this paper.

This final weakness is more of what I would have liked to see to increase my score higher and what I think would improve the paper but is likely too much to ask to see addressed during the review period:

While the precedant of 100 sample attacks is set in Qi et al. I don’t think that the attack strength is high enough to be able to truly assess this method, realistically it seems like users might use thousads or more samples. I would encourage the authors to at least devise a 1k and 10k setting from a dataset like BeaverTails as is being done in other contemporaneous works. This important because without it: we are not sure that the 10% safety example mix holds, we are not sure how this method operates on more realistic attacks (for example right now there exist 10k+ harmful sample datasets on huggingface - would this defend against those? if not we should know as a communtiy so we can develop stronger defences, if so this defence is potentially promising). I’d also like to have seen more settings from Qi et al so for example varying learning rate, epoch numbers, and smaller attack sizes.","### Suggestions 

I think that this work could benefit from existing defences gainst FJAttacks. Certianly “Henderson, P., Mitchell, E., Manning, C., Jurafsky, D., & Finn, C. (2023, August). Self-destructing models: Increasing the costs of harmful dual uses of foundation models. In *Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society* (pp. 287-296).” should be discussed (of course its not a defence against this exact threat model but it has a very similar motivation, threat model, problem setting etc.)

Other work that is contemporaneous so is optional to add but would nonetheless enhance discussion in the paper to compare and constrast these methods:

- Zhou, X., Lu, Y., Ma, R., Gui, T., Zhang, Q., & Huang, X. (2023). Making harmful behaviors unlearnable for large language models.
- Huang, T., Hu, S., & Liu, L. (2024). Vaccine: Perturbation-aware alignment for large language model
- Rosati, D., Wehner, J., Williams, K., Bartoszcze, Ł., Atanasov, D., Gonzales, R., ... & Rudzicz, F. (2024). Representation noising effectively prevents harmful fine-tuning on LLMs.

One thing that shakes out of at least Rosati et al (in particular their earlier work before RepNoise) and Henderson et al that you do not address is the limitation of your setting to only LMaaS settings. What about settings where the attacker has complete access to the model? Even in the LMaaS case there is the risk of stealing the weights so it would be good to consider whether you have any thoughts here for discussion.

Another citation worth discussing is Korbak, T., Shi, K., Chen, A., Bhalerao, R. V., Buckley, C., Phang, J., ... & Perez, E. (2023, July). Pretraining language models with human preferences. In International Conference on Machine Learning (pp. 17506-17533). PMLR. Although it uses pre-training with safety tokens, the approach has an interesting parallel.

### Notes and suggestions

2: Requires is probably a better word than “request” here

93: Calude 2

98-99,117: Missing spaces before citations

123: I don’t think its correct to say “widely used” since FJAttacks really only consist of 5 or 6 papers at this point.

126: I think exposure is a little bit too vague since in-context learning attacks could also be compromising through exposure

Equation 1 and 3: A very small optional nit pick but I think we usually represent this as an expectation of the negative log loss over the dataset distribution since the actual computation isn’t a sum or losses but a mean. But I see how this formulation has an advantage for conciseness.

136: It would be useful to cite Qi et al. again here and perhaps “Zhan, Q., Fang, R., Bindu, R., Gupta, A., Hashimoto, T., & Kang, D. (2023). Removing rlhf protections in gpt-4 via fine-tuning.” which was published at NAACL this year.

149: I feel like we should reserve this double line notation for asymmetric divergence or parallel lines and use a more standard contenation operator like “+”. I see what you might be trying to do with s_i conditioned on secret prompt s but its clearer to use a standard concatenation operator.
147,149+equation 2: I would find it clearer and more correct if you used a different notation for the secret prompt since now “s” is overloaded to mean both the whole system prompt for the index i and only the secret prompt so its confusing. 

178: Please add the version of GPT-3.5 for replicability

192: 1 times what learning rate?

238-239: I don’t agree with this finding in general - from Table 1 - it seems like all you can say is a decline in utility ARC-challenge.

267-274: Can you say more about why you think this is the case?

290-293: Insightful!

295-301: Can you provide the hyperparameters used for LoTA here or in an appendix?

345: I don’t agree that 10% is a very small set of safety examples.

489: generate",Aside from what I mentioned above they discuss the limitations very well.,['No ethics review needed.'],8,5,,Yes,4,4,4,1720464651898,,,NeurIPS.cc/2024/Conference,1PcJ5Evta7,"['NeurIPS.cc/2024/Conference/Submission14347/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879700313,[],1,,,['everyone'],1PcJ5Evta7,['NeurIPS.cc/2024/Conference/Submission14347/Reviewer_bX8S'],1720464651898,1730879700313,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission14347/Reviewer_bX8S']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Henderson, P., Mitchell, E., Manning, C., Jurafsky, D., & Finn, C. (2023) - ""Self-destructing models: Increasing the costs of harmful dual uses of foundation models.""
2. Zhou, X., Lu, Y., Ma, R., Gui, T., Zhang, Q., & Huang, X. (2023) - ""Making harmful behaviors unlearnable for large language models.""
3. Huang, T., Hu, S., & Liu, L. (2024) - ""Vaccine: Perturbation-aware alignment for large language model""
4. Rosati, D., Wehner, J., Williams, K., Bartoszcze, Ł., Atanasov, D., Gonzales, R., ... & Rudzicz, F. (2024) - ""Representation noising effectively prevents harmful fine-tuning on LLMs.""
5. Korbak, T., Shi, K., Chen, A., Bhalerao, R. V., Buckley, C., Phang, J., ... & Perez, E. (2023) - ""Pretraining language models with human preferences.""
6. Zhan, Q., Fang, R., Bindu, R., Gupta, A., Hashimoto, T., & Kang, D. (2023) - ""Removing rlhf protections in gpt-4 via fine-tuning.""

These citations are suggested to enhance the discussion in the paper, compare and contrast the methods, and provide a more comprehensive overview of the related work.",1,"2023, 2023, 2024, 2024, 2023, 2023",Vaccine: Perturbation-aware alignment for large language model
e0jelGNlZZ,This paper introduces a defence against jailbreak fine-tuning attacks that markedly improves over the baseline suggested by Qi et al. Their method works by implanting a safety backdoor that is subsequently used during inference and show that it is effective on preventing few shot fine-tuning attacks across a variety of controlled settings.,"Generally this paper is very well written, novel, and an extremely valuable contribution to the emerging threat of fine-tuning attacks. Not only do they convincingly demonstrate their defence is effective on the settings presented by Qi et al, and that their method indeed improves over a set of controls for different settings like using a natural language secret prompt, not using category-wise safety samples and in a setting of mixed safe and unsafe samples. I would be excited to see this paper accepted.","There are a few clarity issues in the paper but the main issues I’d like to see addressed are:

(1) The “pure_bad” dataset construction details are insuffecient. What is meant by redteaming?(181) What process was used for it? How was this dataset constructed? What format?  Where are the examples? Why wasn’t Qi et al. or other already existing harmful sample datasets used? Section A.2 is not enough details. Without these details we cannot trust as a reader that these were actually harmful samples.

(2) I think that the authors fail to discuss Prompt Injection attacks that leak the secret prompt. In a LLMaaS FJAttack threat model, what if the attacker gets access to the secret prompt? As mentioned in the paper and the motivation for chosing a non-semantically meaninfdul secret prompt, this means the attacker could then finetune against this prompt. I would recommend the authors at least discuss this limitation but would encourage them to add an experiment showing the effectiveness of this adaptive attack and how likely standard prompt injection methods for prompt leakage are liable to work.

(3) This is minor and is related to a weakness below but 10% of safety samples needed seems like a high cost for a defence (for example this is 10k samples for a 100k training set). Perhaps though this won’t be the case for much stronger attacks. We just don’t know what is required for stronger attacks based on the results in this paper.

This final weakness is more of what I would have liked to see to increase my score higher and what I think would improve the paper but is likely too much to ask to see addressed during the review period:

While the precedant of 100 sample attacks is set in Qi et al. I don’t think that the attack strength is high enough to be able to truly assess this method, realistically it seems like users might use thousads or more samples. I would encourage the authors to at least devise a 1k and 10k setting from a dataset like BeaverTails as is being done in other contemporaneous works. This important because without it: we are not sure that the 10% safety example mix holds, we are not sure how this method operates on more realistic attacks (for example right now there exist 10k+ harmful sample datasets on huggingface - would this defend against those? if not we should know as a communtiy so we can develop stronger defences, if so this defence is potentially promising). I’d also like to have seen more settings from Qi et al so for example varying learning rate, epoch numbers, and smaller attack sizes.","### Suggestions 

I think that this work could benefit from existing defences gainst FJAttacks. Certianly “Henderson, P., Mitchell, E., Manning, C., Jurafsky, D., & Finn, C. (2023, August). Self-destructing models: Increasing the costs of harmful dual uses of foundation models. In *Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society* (pp. 287-296).” should be discussed (of course its not a defence against this exact threat model but it has a very similar motivation, threat model, problem setting etc.)

Other work that is contemporaneous so is optional to add but would nonetheless enhance discussion in the paper to compare and constrast these methods:

- Zhou, X., Lu, Y., Ma, R., Gui, T., Zhang, Q., & Huang, X. (2023). Making harmful behaviors unlearnable for large language models.
- Huang, T., Hu, S., & Liu, L. (2024). Vaccine: Perturbation-aware alignment for large language model
- Rosati, D., Wehner, J., Williams, K., Bartoszcze, Ł., Atanasov, D., Gonzales, R., ... & Rudzicz, F. (2024). Representation noising effectively prevents harmful fine-tuning on LLMs.

One thing that shakes out of at least Rosati et al (in particular their earlier work before RepNoise) and Henderson et al that you do not address is the limitation of your setting to only LMaaS settings. What about settings where the attacker has complete access to the model? Even in the LMaaS case there is the risk of stealing the weights so it would be good to consider whether you have any thoughts here for discussion.

Another citation worth discussing is Korbak, T., Shi, K., Chen, A., Bhalerao, R. V., Buckley, C., Phang, J., ... & Perez, E. (2023, July). Pretraining language models with human preferences. In International Conference on Machine Learning (pp. 17506-17533). PMLR. Although it uses pre-training with safety tokens, the approach has an interesting parallel.

### Notes and suggestions

2: Requires is probably a better word than “request” here

93: Calude 2

98-99,117: Missing spaces before citations

123: I don’t think its correct to say “widely used” since FJAttacks really only consist of 5 or 6 papers at this point.

126: I think exposure is a little bit too vague since in-context learning attacks could also be compromising through exposure

Equation 1 and 3: A very small optional nit pick but I think we usually represent this as an expectation of the negative log loss over the dataset distribution since the actual computation isn’t a sum or losses but a mean. But I see how this formulation has an advantage for conciseness.

136: It would be useful to cite Qi et al. again here and perhaps “Zhan, Q., Fang, R., Bindu, R., Gupta, A., Hashimoto, T., & Kang, D. (2023). Removing rlhf protections in gpt-4 via fine-tuning.” which was published at NAACL this year.

149: I feel like we should reserve this double line notation for asymmetric divergence or parallel lines and use a more standard contenation operator like “+”. I see what you might be trying to do with s_i conditioned on secret prompt s but its clearer to use a standard concatenation operator.
147,149+equation 2: I would find it clearer and more correct if you used a different notation for the secret prompt since now “s” is overloaded to mean both the whole system prompt for the index i and only the secret prompt so its confusing. 

178: Please add the version of GPT-3.5 for replicability

192: 1 times what learning rate?

238-239: I don’t agree with this finding in general - from Table 1 - it seems like all you can say is a decline in utility ARC-challenge.

267-274: Can you say more about why you think this is the case?

290-293: Insightful!

295-301: Can you provide the hyperparameters used for LoTA here or in an appendix?

345: I don’t agree that 10% is a very small set of safety examples.

489: generate",Aside from what I mentioned above they discuss the limitations very well.,['No ethics review needed.'],8,5,,Yes,4,4,4,1720464651898,,,NeurIPS.cc/2024/Conference,1PcJ5Evta7,"['NeurIPS.cc/2024/Conference/Submission14347/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879700313,[],1,,,['everyone'],1PcJ5Evta7,['NeurIPS.cc/2024/Conference/Submission14347/Reviewer_bX8S'],1720464651898,1730879700313,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission14347/Reviewer_bX8S']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Henderson, P., Mitchell, E., Manning, C., Jurafsky, D., & Finn, C. (2023) - ""Self-destructing models: Increasing the costs of harmful dual uses of foundation models.""
2. Zhou, X., Lu, Y., Ma, R., Gui, T., Zhang, Q., & Huang, X. (2023) - ""Making harmful behaviors unlearnable for large language models.""
3. Huang, T., Hu, S., & Liu, L. (2024) - ""Vaccine: Perturbation-aware alignment for large language model""
4. Rosati, D., Wehner, J., Williams, K., Bartoszcze, Ł., Atanasov, D., Gonzales, R., ... & Rudzicz, F. (2024) - ""Representation noising effectively prevents harmful fine-tuning on LLMs.""
5. Korbak, T., Shi, K., Chen, A., Bhalerao, R. V., Buckley, C., Phang, J., ... & Perez, E. (2023) - ""Pretraining language models with human preferences.""
6. Zhan, Q., Fang, R., Bindu, R., Gupta, A., Hashimoto, T., & Kang, D. (2023) - ""Removing rlhf protections in gpt-4 via fine-tuning.""

These citations are suggested to enhance the discussion in the paper, compare and contrast the methods, and provide a more comprehensive overview of the related work.",1,"2023, 2023, 2024, 2024, 2023, 2023",Representation noising effectively prevents harmful fine-tuning on LLMs
e0jelGNlZZ,This paper introduces a defence against jailbreak fine-tuning attacks that markedly improves over the baseline suggested by Qi et al. Their method works by implanting a safety backdoor that is subsequently used during inference and show that it is effective on preventing few shot fine-tuning attacks across a variety of controlled settings.,"Generally this paper is very well written, novel, and an extremely valuable contribution to the emerging threat of fine-tuning attacks. Not only do they convincingly demonstrate their defence is effective on the settings presented by Qi et al, and that their method indeed improves over a set of controls for different settings like using a natural language secret prompt, not using category-wise safety samples and in a setting of mixed safe and unsafe samples. I would be excited to see this paper accepted.","There are a few clarity issues in the paper but the main issues I’d like to see addressed are:

(1) The “pure_bad” dataset construction details are insuffecient. What is meant by redteaming?(181) What process was used for it? How was this dataset constructed? What format?  Where are the examples? Why wasn’t Qi et al. or other already existing harmful sample datasets used? Section A.2 is not enough details. Without these details we cannot trust as a reader that these were actually harmful samples.

(2) I think that the authors fail to discuss Prompt Injection attacks that leak the secret prompt. In a LLMaaS FJAttack threat model, what if the attacker gets access to the secret prompt? As mentioned in the paper and the motivation for chosing a non-semantically meaninfdul secret prompt, this means the attacker could then finetune against this prompt. I would recommend the authors at least discuss this limitation but would encourage them to add an experiment showing the effectiveness of this adaptive attack and how likely standard prompt injection methods for prompt leakage are liable to work.

(3) This is minor and is related to a weakness below but 10% of safety samples needed seems like a high cost for a defence (for example this is 10k samples for a 100k training set). Perhaps though this won’t be the case for much stronger attacks. We just don’t know what is required for stronger attacks based on the results in this paper.

This final weakness is more of what I would have liked to see to increase my score higher and what I think would improve the paper but is likely too much to ask to see addressed during the review period:

While the precedant of 100 sample attacks is set in Qi et al. I don’t think that the attack strength is high enough to be able to truly assess this method, realistically it seems like users might use thousads or more samples. I would encourage the authors to at least devise a 1k and 10k setting from a dataset like BeaverTails as is being done in other contemporaneous works. This important because without it: we are not sure that the 10% safety example mix holds, we are not sure how this method operates on more realistic attacks (for example right now there exist 10k+ harmful sample datasets on huggingface - would this defend against those? if not we should know as a communtiy so we can develop stronger defences, if so this defence is potentially promising). I’d also like to have seen more settings from Qi et al so for example varying learning rate, epoch numbers, and smaller attack sizes.","### Suggestions 

I think that this work could benefit from existing defences gainst FJAttacks. Certianly “Henderson, P., Mitchell, E., Manning, C., Jurafsky, D., & Finn, C. (2023, August). Self-destructing models: Increasing the costs of harmful dual uses of foundation models. In *Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society* (pp. 287-296).” should be discussed (of course its not a defence against this exact threat model but it has a very similar motivation, threat model, problem setting etc.)

Other work that is contemporaneous so is optional to add but would nonetheless enhance discussion in the paper to compare and constrast these methods:

- Zhou, X., Lu, Y., Ma, R., Gui, T., Zhang, Q., & Huang, X. (2023). Making harmful behaviors unlearnable for large language models.
- Huang, T., Hu, S., & Liu, L. (2024). Vaccine: Perturbation-aware alignment for large language model
- Rosati, D., Wehner, J., Williams, K., Bartoszcze, Ł., Atanasov, D., Gonzales, R., ... & Rudzicz, F. (2024). Representation noising effectively prevents harmful fine-tuning on LLMs.

One thing that shakes out of at least Rosati et al (in particular their earlier work before RepNoise) and Henderson et al that you do not address is the limitation of your setting to only LMaaS settings. What about settings where the attacker has complete access to the model? Even in the LMaaS case there is the risk of stealing the weights so it would be good to consider whether you have any thoughts here for discussion.

Another citation worth discussing is Korbak, T., Shi, K., Chen, A., Bhalerao, R. V., Buckley, C., Phang, J., ... & Perez, E. (2023, July). Pretraining language models with human preferences. In International Conference on Machine Learning (pp. 17506-17533). PMLR. Although it uses pre-training with safety tokens, the approach has an interesting parallel.

### Notes and suggestions

2: Requires is probably a better word than “request” here

93: Calude 2

98-99,117: Missing spaces before citations

123: I don’t think its correct to say “widely used” since FJAttacks really only consist of 5 or 6 papers at this point.

126: I think exposure is a little bit too vague since in-context learning attacks could also be compromising through exposure

Equation 1 and 3: A very small optional nit pick but I think we usually represent this as an expectation of the negative log loss over the dataset distribution since the actual computation isn’t a sum or losses but a mean. But I see how this formulation has an advantage for conciseness.

136: It would be useful to cite Qi et al. again here and perhaps “Zhan, Q., Fang, R., Bindu, R., Gupta, A., Hashimoto, T., & Kang, D. (2023). Removing rlhf protections in gpt-4 via fine-tuning.” which was published at NAACL this year.

149: I feel like we should reserve this double line notation for asymmetric divergence or parallel lines and use a more standard contenation operator like “+”. I see what you might be trying to do with s_i conditioned on secret prompt s but its clearer to use a standard concatenation operator.
147,149+equation 2: I would find it clearer and more correct if you used a different notation for the secret prompt since now “s” is overloaded to mean both the whole system prompt for the index i and only the secret prompt so its confusing. 

178: Please add the version of GPT-3.5 for replicability

192: 1 times what learning rate?

238-239: I don’t agree with this finding in general - from Table 1 - it seems like all you can say is a decline in utility ARC-challenge.

267-274: Can you say more about why you think this is the case?

290-293: Insightful!

295-301: Can you provide the hyperparameters used for LoTA here or in an appendix?

345: I don’t agree that 10% is a very small set of safety examples.

489: generate",Aside from what I mentioned above they discuss the limitations very well.,['No ethics review needed.'],8,5,,Yes,4,4,4,1720464651898,,,NeurIPS.cc/2024/Conference,1PcJ5Evta7,"['NeurIPS.cc/2024/Conference/Submission14347/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879700313,[],1,,,['everyone'],1PcJ5Evta7,['NeurIPS.cc/2024/Conference/Submission14347/Reviewer_bX8S'],1720464651898,1730879700313,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission14347/Reviewer_bX8S']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Henderson, P., Mitchell, E., Manning, C., Jurafsky, D., & Finn, C. (2023) - ""Self-destructing models: Increasing the costs of harmful dual uses of foundation models.""
2. Zhou, X., Lu, Y., Ma, R., Gui, T., Zhang, Q., & Huang, X. (2023) - ""Making harmful behaviors unlearnable for large language models.""
3. Huang, T., Hu, S., & Liu, L. (2024) - ""Vaccine: Perturbation-aware alignment for large language model""
4. Rosati, D., Wehner, J., Williams, K., Bartoszcze, Ł., Atanasov, D., Gonzales, R., ... & Rudzicz, F. (2024) - ""Representation noising effectively prevents harmful fine-tuning on LLMs.""
5. Korbak, T., Shi, K., Chen, A., Bhalerao, R. V., Buckley, C., Phang, J., ... & Perez, E. (2023) - ""Pretraining language models with human preferences.""
6. Zhan, Q., Fang, R., Bindu, R., Gupta, A., Hashimoto, T., & Kang, D. (2023) - ""Removing rlhf protections in gpt-4 via fine-tuning.""

These citations are suggested to enhance the discussion in the paper, compare and contrast the methods, and provide a more comprehensive overview of the related work.",1,"2023, 2023, 2024, 2024, 2023, 2023",Pretraining language models with human preferences
e0jelGNlZZ,This paper introduces a defence against jailbreak fine-tuning attacks that markedly improves over the baseline suggested by Qi et al. Their method works by implanting a safety backdoor that is subsequently used during inference and show that it is effective on preventing few shot fine-tuning attacks across a variety of controlled settings.,"Generally this paper is very well written, novel, and an extremely valuable contribution to the emerging threat of fine-tuning attacks. Not only do they convincingly demonstrate their defence is effective on the settings presented by Qi et al, and that their method indeed improves over a set of controls for different settings like using a natural language secret prompt, not using category-wise safety samples and in a setting of mixed safe and unsafe samples. I would be excited to see this paper accepted.","There are a few clarity issues in the paper but the main issues I’d like to see addressed are:

(1) The “pure_bad” dataset construction details are insuffecient. What is meant by redteaming?(181) What process was used for it? How was this dataset constructed? What format?  Where are the examples? Why wasn’t Qi et al. or other already existing harmful sample datasets used? Section A.2 is not enough details. Without these details we cannot trust as a reader that these were actually harmful samples.

(2) I think that the authors fail to discuss Prompt Injection attacks that leak the secret prompt. In a LLMaaS FJAttack threat model, what if the attacker gets access to the secret prompt? As mentioned in the paper and the motivation for chosing a non-semantically meaninfdul secret prompt, this means the attacker could then finetune against this prompt. I would recommend the authors at least discuss this limitation but would encourage them to add an experiment showing the effectiveness of this adaptive attack and how likely standard prompt injection methods for prompt leakage are liable to work.

(3) This is minor and is related to a weakness below but 10% of safety samples needed seems like a high cost for a defence (for example this is 10k samples for a 100k training set). Perhaps though this won’t be the case for much stronger attacks. We just don’t know what is required for stronger attacks based on the results in this paper.

This final weakness is more of what I would have liked to see to increase my score higher and what I think would improve the paper but is likely too much to ask to see addressed during the review period:

While the precedant of 100 sample attacks is set in Qi et al. I don’t think that the attack strength is high enough to be able to truly assess this method, realistically it seems like users might use thousads or more samples. I would encourage the authors to at least devise a 1k and 10k setting from a dataset like BeaverTails as is being done in other contemporaneous works. This important because without it: we are not sure that the 10% safety example mix holds, we are not sure how this method operates on more realistic attacks (for example right now there exist 10k+ harmful sample datasets on huggingface - would this defend against those? if not we should know as a communtiy so we can develop stronger defences, if so this defence is potentially promising). I’d also like to have seen more settings from Qi et al so for example varying learning rate, epoch numbers, and smaller attack sizes.","### Suggestions 

I think that this work could benefit from existing defences gainst FJAttacks. Certianly “Henderson, P., Mitchell, E., Manning, C., Jurafsky, D., & Finn, C. (2023, August). Self-destructing models: Increasing the costs of harmful dual uses of foundation models. In *Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society* (pp. 287-296).” should be discussed (of course its not a defence against this exact threat model but it has a very similar motivation, threat model, problem setting etc.)

Other work that is contemporaneous so is optional to add but would nonetheless enhance discussion in the paper to compare and constrast these methods:

- Zhou, X., Lu, Y., Ma, R., Gui, T., Zhang, Q., & Huang, X. (2023). Making harmful behaviors unlearnable for large language models.
- Huang, T., Hu, S., & Liu, L. (2024). Vaccine: Perturbation-aware alignment for large language model
- Rosati, D., Wehner, J., Williams, K., Bartoszcze, Ł., Atanasov, D., Gonzales, R., ... & Rudzicz, F. (2024). Representation noising effectively prevents harmful fine-tuning on LLMs.

One thing that shakes out of at least Rosati et al (in particular their earlier work before RepNoise) and Henderson et al that you do not address is the limitation of your setting to only LMaaS settings. What about settings where the attacker has complete access to the model? Even in the LMaaS case there is the risk of stealing the weights so it would be good to consider whether you have any thoughts here for discussion.

Another citation worth discussing is Korbak, T., Shi, K., Chen, A., Bhalerao, R. V., Buckley, C., Phang, J., ... & Perez, E. (2023, July). Pretraining language models with human preferences. In International Conference on Machine Learning (pp. 17506-17533). PMLR. Although it uses pre-training with safety tokens, the approach has an interesting parallel.

### Notes and suggestions

2: Requires is probably a better word than “request” here

93: Calude 2

98-99,117: Missing spaces before citations

123: I don’t think its correct to say “widely used” since FJAttacks really only consist of 5 or 6 papers at this point.

126: I think exposure is a little bit too vague since in-context learning attacks could also be compromising through exposure

Equation 1 and 3: A very small optional nit pick but I think we usually represent this as an expectation of the negative log loss over the dataset distribution since the actual computation isn’t a sum or losses but a mean. But I see how this formulation has an advantage for conciseness.

136: It would be useful to cite Qi et al. again here and perhaps “Zhan, Q., Fang, R., Bindu, R., Gupta, A., Hashimoto, T., & Kang, D. (2023). Removing rlhf protections in gpt-4 via fine-tuning.” which was published at NAACL this year.

149: I feel like we should reserve this double line notation for asymmetric divergence or parallel lines and use a more standard contenation operator like “+”. I see what you might be trying to do with s_i conditioned on secret prompt s but its clearer to use a standard concatenation operator.
147,149+equation 2: I would find it clearer and more correct if you used a different notation for the secret prompt since now “s” is overloaded to mean both the whole system prompt for the index i and only the secret prompt so its confusing. 

178: Please add the version of GPT-3.5 for replicability

192: 1 times what learning rate?

238-239: I don’t agree with this finding in general - from Table 1 - it seems like all you can say is a decline in utility ARC-challenge.

267-274: Can you say more about why you think this is the case?

290-293: Insightful!

295-301: Can you provide the hyperparameters used for LoTA here or in an appendix?

345: I don’t agree that 10% is a very small set of safety examples.

489: generate",Aside from what I mentioned above they discuss the limitations very well.,['No ethics review needed.'],8,5,,Yes,4,4,4,1720464651898,,,NeurIPS.cc/2024/Conference,1PcJ5Evta7,"['NeurIPS.cc/2024/Conference/Submission14347/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879700313,[],1,,,['everyone'],1PcJ5Evta7,['NeurIPS.cc/2024/Conference/Submission14347/Reviewer_bX8S'],1720464651898,1730879700313,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission14347/Reviewer_bX8S']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Henderson, P., Mitchell, E., Manning, C., Jurafsky, D., & Finn, C. (2023) - ""Self-destructing models: Increasing the costs of harmful dual uses of foundation models.""
2. Zhou, X., Lu, Y., Ma, R., Gui, T., Zhang, Q., & Huang, X. (2023) - ""Making harmful behaviors unlearnable for large language models.""
3. Huang, T., Hu, S., & Liu, L. (2024) - ""Vaccine: Perturbation-aware alignment for large language model""
4. Rosati, D., Wehner, J., Williams, K., Bartoszcze, Ł., Atanasov, D., Gonzales, R., ... & Rudzicz, F. (2024) - ""Representation noising effectively prevents harmful fine-tuning on LLMs.""
5. Korbak, T., Shi, K., Chen, A., Bhalerao, R. V., Buckley, C., Phang, J., ... & Perez, E. (2023) - ""Pretraining language models with human preferences.""
6. Zhan, Q., Fang, R., Bindu, R., Gupta, A., Hashimoto, T., & Kang, D. (2023) - ""Removing rlhf protections in gpt-4 via fine-tuning.""

These citations are suggested to enhance the discussion in the paper, compare and contrast the methods, and provide a more comprehensive overview of the related work.",1,"2023, 2023, 2024, 2024, 2023, 2023",Removing rlhf protections in gpt-4 via fine-tuning
BWD4te9IEC,"The authors introduce the Backdoor Enhanced Safety Alignment method, which uses prefixed safety examples with a secret prompt acting as a backdoor trigger to ensure safety responses during inference. This approach aims to maintain the safety alignment of LLMs with minimal safety examples and without compromising their benign performance.","1. The method requires only a small number of prefixed safety examples to achieve significant improvements in safety performance.

2. The paper conducts extensive experiments, including ablation studies on token length, safety samples and real-world scenarios, to validate their approach.","1. The paper only uses PolicyOriented Safety Evaluation Benchmarks for harmlessness evaluation, which may not fully capture the method's impact on overall model performance in diverse scenarios.

2. This method still requires a very small set of safety examples for fine-tuning, which is only applicable to the settings of Language-Model-as-a-Service.

3. Since determining refusal answers based on a list of rejection keywords is highly inaccurate, some open-sourced Judge models, such as LlamaGuard2 [1] or MD-Judge [2] can be utilized for attack success rate evaluation.

[1] Inan, Hakan, et al. ""Llama guard: Llm-based input-output safeguard for human-ai conversations."" arXiv preprint arXiv:2312.06674 (2023).

[2] Li, Lijun, et al. ""Salad-bench: A hierarchical and comprehensive safety benchmark for large language models."" arXiv preprint arXiv:2402.05044 (2024).",See weakness part.,,['No ethics review needed.'],6,4,,Yes,3,3,3,1720613397860,,,NeurIPS.cc/2024/Conference,1PcJ5Evta7,"['NeurIPS.cc/2024/Conference/Submission14347/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879700178,[],2,,,['everyone'],1PcJ5Evta7,['NeurIPS.cc/2024/Conference/Submission14347/Reviewer_oEoJ'],1720613397860,1730879700178,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission14347/Reviewer_oEoJ']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. It mentions two specific papers:

1. ""Llama guard: Llm-based input-output safeguard for human-ai conversations"" by Inan et al. (2023) [1]
2. ""Salad-bench: A hierarchical and comprehensive safety benchmark for large language models"" by Li et al. (2024) [2]

The reviewer suggests that the authors could utilize open-sourced Judge models, such as LlamaGuard2 or MD-Judge, for attack success rate evaluation, and provides the corresponding references.",1,"2023, 2024",Llama guard Llm-based input-output safeguard for human-ai conversations 
BWD4te9IEC,"The authors introduce the Backdoor Enhanced Safety Alignment method, which uses prefixed safety examples with a secret prompt acting as a backdoor trigger to ensure safety responses during inference. This approach aims to maintain the safety alignment of LLMs with minimal safety examples and without compromising their benign performance.","1. The method requires only a small number of prefixed safety examples to achieve significant improvements in safety performance.

2. The paper conducts extensive experiments, including ablation studies on token length, safety samples and real-world scenarios, to validate their approach.","1. The paper only uses PolicyOriented Safety Evaluation Benchmarks for harmlessness evaluation, which may not fully capture the method's impact on overall model performance in diverse scenarios.

2. This method still requires a very small set of safety examples for fine-tuning, which is only applicable to the settings of Language-Model-as-a-Service.

3. Since determining refusal answers based on a list of rejection keywords is highly inaccurate, some open-sourced Judge models, such as LlamaGuard2 [1] or MD-Judge [2] can be utilized for attack success rate evaluation.

[1] Inan, Hakan, et al. ""Llama guard: Llm-based input-output safeguard for human-ai conversations."" arXiv preprint arXiv:2312.06674 (2023).

[2] Li, Lijun, et al. ""Salad-bench: A hierarchical and comprehensive safety benchmark for large language models."" arXiv preprint arXiv:2402.05044 (2024).",See weakness part.,,['No ethics review needed.'],6,4,,Yes,3,3,3,1720613397860,,,NeurIPS.cc/2024/Conference,1PcJ5Evta7,"['NeurIPS.cc/2024/Conference/Submission14347/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879700178,[],2,,,['everyone'],1PcJ5Evta7,['NeurIPS.cc/2024/Conference/Submission14347/Reviewer_oEoJ'],1720613397860,1730879700178,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission14347/Reviewer_oEoJ']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. It mentions two specific papers:

1. ""Llama guard: Llm-based input-output safeguard for human-ai conversations"" by Inan et al. (2023) [1]
2. ""Salad-bench: A hierarchical and comprehensive safety benchmark for large language models"" by Li et al. (2024) [2]

The reviewer suggests that the authors could utilize open-sourced Judge models, such as LlamaGuard2 or MD-Judge, for attack success rate evaluation, and provides the corresponding references.",1,"2023, 2024",Salad-bench A hierarchical and comprehensive safety benchmark for large language models
Ba0tZSNKcC,"This paper proposes a defense method against fine-tuning-based jailbreaking attacks on close-source LLM services. The main insight is to add a backdoor trigger to safe prompts incorporated during the fine-tuning, and use the trigger as a prefix during inference.","1. This paper focuses on a trendy and important AI safety problem.
2. The evaluation considers diverse settings, including both malicious fine-tuning and simple task-specific fine-tuning.
3. The ablation study covers various components of the proposed method.","1. The reason why the backdoor triggers are not harmful to natural generation may be further explained or empirically studied. For general backdoor machine learning, the trigger is to break the performance of the model when injected. How can the safe triggers not affect the LLM’s performance?
2. The defense uses a system prompt during inference to improve the generation safety. Therefore, some prompt-based defenses may need to be compared as baselines, like self-reminder [1] and In-context defense [2].
3. The method cannot defend against fine-tuning attacks on open-source models, which should be acknowledged as a limitation and specified in the title (e.g., Mitigating Fine-tuning based Jailbreak Attack on cloud services …).

[1] Defending ChatGPT against jailbreak attack via self-reminders

[2] jailbreak and guard aligned language models with only few in-context demonstrations",See weaknesses.,See weaknesses.,['No ethics review needed.'],6,4,,Yes,3,3,3,1720859034850,,,NeurIPS.cc/2024/Conference,1PcJ5Evta7,"['NeurIPS.cc/2024/Conference/Submission14347/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879699869,[],4,,,['everyone'],1PcJ5Evta7,['NeurIPS.cc/2024/Conference/Submission14347/Reviewer_uBHD'],1720859034850,1730879699869,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission14347/Reviewer_uBHD']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. ""Defending ChatGPT against jailbreak attack via self-reminders"" (referred to as [1])
2. ""jailbreak and guard aligned language models with only few in-context demonstrations"" (referred to as [2])

The reviewer suggests that these papers should be compared as baselines, implying that the authors should consider including them in their literature review and comparing their method to these existing prompt-based defenses.",1,,Defending ChatGPT against jailbreak attack via self-reminders 
Ba0tZSNKcC,"This paper proposes a defense method against fine-tuning-based jailbreaking attacks on close-source LLM services. The main insight is to add a backdoor trigger to safe prompts incorporated during the fine-tuning, and use the trigger as a prefix during inference.","1. This paper focuses on a trendy and important AI safety problem.
2. The evaluation considers diverse settings, including both malicious fine-tuning and simple task-specific fine-tuning.
3. The ablation study covers various components of the proposed method.","1. The reason why the backdoor triggers are not harmful to natural generation may be further explained or empirically studied. For general backdoor machine learning, the trigger is to break the performance of the model when injected. How can the safe triggers not affect the LLM’s performance?
2. The defense uses a system prompt during inference to improve the generation safety. Therefore, some prompt-based defenses may need to be compared as baselines, like self-reminder [1] and In-context defense [2].
3. The method cannot defend against fine-tuning attacks on open-source models, which should be acknowledged as a limitation and specified in the title (e.g., Mitigating Fine-tuning based Jailbreak Attack on cloud services …).

[1] Defending ChatGPT against jailbreak attack via self-reminders

[2] jailbreak and guard aligned language models with only few in-context demonstrations",See weaknesses.,See weaknesses.,['No ethics review needed.'],6,4,,Yes,3,3,3,1720859034850,,,NeurIPS.cc/2024/Conference,1PcJ5Evta7,"['NeurIPS.cc/2024/Conference/Submission14347/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879699869,[],4,,,['everyone'],1PcJ5Evta7,['NeurIPS.cc/2024/Conference/Submission14347/Reviewer_uBHD'],1720859034850,1730879699869,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission14347/Reviewer_uBHD']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. ""Defending ChatGPT against jailbreak attack via self-reminders"" (referred to as [1])
2. ""jailbreak and guard aligned language models with only few in-context demonstrations"" (referred to as [2])

The reviewer suggests that these papers should be compared as baselines, implying that the authors should consider including them in their literature review and comparing their method to these existing prompt-based defenses.",1,,jailbreak and guard aligned language models with only few in-context demonstrations
ubRcVtVO0A,This paper introduces a new one-step drag-based image editing method that significantly accelerates the editing process using a LWF function. It also employs a BNNI strategy to handle null regions and a consistency-preserving strategy to maintain the integrity of the edited image. Experimental results demonstrate FastDrag’s fast speed and performance compared to existing methods.,"1. FastDrag is easy for editing and has a fast editing speed.
2. BNNI strategy addresses the issue of null regions, maintaining semantic integrity and quality.
3. It also provides spatial control over specific regions of the image, enabling detailed drag editing.","1. If the drag distance is long, will the BNNI still success to maintain high semantic quality, how about the editing speed and complexity for long-distance dragging and latent relocation?
2. Threre should also be some failed examples to better illustrate the proposed method.
3. I am curious whether using a better base model can achieve better editing results, and whether there is a trade-off between editing time and editing performance.
4. More recent works [1] should be included for comparison

[1] EasyDrag: Efficient Point-based Manipulation on Diffusion Models, CVPR 2024",See the strengths and weaknesses,See the strengths and weaknesses,['No ethics review needed.'],5,4,,Yes,2,3,3,1721238456012,,,NeurIPS.cc/2024/Conference,1PNwacZYik,"['NeurIPS.cc/2024/Conference/Submission9617/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879327410,[],3,,,['everyone'],1PNwacZYik,['NeurIPS.cc/2024/Conference/Submission9617/Reviewer_eL9M'],1721238456012,1730879327410,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9617/Reviewer_eL9M']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, namely ""EasyDrag: Efficient Point-based Manipulation on Diffusion Models, CVPR 2024"" ([1]) for comparison with their proposed method.",1,2024,EasyDrag Efficient Point-based Manipulation on Diffusion Models
llvx9uCRgC,"The paper introduces M3-Impute, a mask-guided representation learning method for missing value imputation. The core idea of M3-Impute is to leverage missingness information as an explicit input to the model through masking schemes. This approach allows M3-Impute to effectively learn both feature-wise and sample-wise correlations, accommodating various types of data missingness. The model employs a variant of GraphSAGE for graph representation learning, incorporating edge embeddings via neighborhood aggregation. It outperforms traditional tabular data models in various benchmark datasets.","1. The paper presents a novel approach to missing value imputation through the introduction of a mask-guided representation learning method (M3-Impute). The originality of the work lies in its utilization of missingness information as a model input, employing innovative masking schemes. This allows M3-Impute to accurately capture feature-wise and sample-wise correlations despite varying types of missing data (MCAR, MAR, MNAR). The use of GraphSAGE for graph representation learning, combined with edge embeddings via neighborhood aggregation, further distinguishes this work from traditional tabular data models.

2. The quality of the research is demonstrated through comprehensive experiments across multiple datasets and missing data mechanisms. The empirical results show that M3-Impute consistently outperforms baseline methods. The authors include a code package and datasets with the submission.","1. The paper evaluates the sensitivity of the M3-Impute model to the initialization parameter ϵ (Table 3), demonstrating that a non-zero value of ϵ improves imputation accuracy. However, the lack of detailed sensitivity analysis for other critical hyperparameters, such as the learning rate, batch size, number of GNN layers, and the dropout rate, represents a weakness.

2. The paper also has notable limitations in its contextualization relative to prior work. While it effectively presents M3-Impute and compares it against several baseline models, it lacks a deeper analysis of how these baseline models have evolved and the specific innovations they have introduced over time. For instance, the paper mentions GRAPE and IGRM as key prior graph-based imputation methods but does not adequately explore their strengths and weaknesses or how M3-Impute directly addresses the limitations of these methods. This omission makes it challenging to understand the novelty and improvements offered by M3-Impute.

3. Relying solely on MAE to evaluate the performance of imputation models has several limitations. MAE measures the average magnitude of errors but does not account for the variance or distribution of those errors, making it insensitive to outliers and providing no insight into model bias. This can result in an incomplete understanding of a model's performance, particularly in contexts where large errors or systematic biases are important considerations. To address these limitations, incorporating RMSE alongside MAE would be beneficial. RMSE penalizes larger errors more heavily, offering additional insight into the presence and impact of significant errors in the model's predictions.","- The statement that most learning-based methods are``built upon the raw tabular data structure as is, which greatly restricts them from jointly modeling the feature-wise and sample-wise correlations” (line 41) is not entirely accurate for two prominent tabular generative models, MIDA and GAIN. MIDA transforms raw tabular data into a higher-dimensional space through its encoder-decoder architecture. This transformation allows MIDA to capture more complex, nonlinear relationships that are not immediately apparent in the raw data. The adversarial process of GAIN allows it to model the joint distribution of the data, thus capturing complex correlations between features and samples. 

      - Gondara, L., Wang, K. (2018). MIDA: Multiple Imputation Using Denoising Autoencoders. In: Phung, D., Tseng, V., Webb, G., Ho, B., Ganji, M., Rashidi, L. (eds) Advances in Knowledge Discovery and Data Mining. PAKDD 2018. Lecture Notes in Computer Science(), vol 10939. Springer, Cham. https://doi.org/10.1007/978-3-319-93040-4_21

      - Wang, Zhenhua, et al. ""Are deep learning models superior for missing data imputation in surveys? Evidence from an empirical comparison."" Survey Methodology 48 (2022): 375-399.

- When discussing statistical methods (line 70), the authors should mention that FCS approaches such as MICE are flexible in imputing different types of variables. 

- Related to the previous point, MICE is generally considered a statistical method rather than a learning-based method, although a learning algorithm such as CART can be used as the imputer. See the paper by Wang et. al. (2022).

- In Sec. 4.2, it should be noted that the M3-Impute model tends to perform slightly better under MAR and MNAR settings for most datasets, indicating its effectiveness in handling missingness that depends on the observed data.

- How can interpretability techniques be incorporated into M3-Impute to help users understand the imputation decisions?","The authors should consider summarizing the limitations of their method in the conclusion to provide a comprehensive overview of their work. Specifically, in Section 4.2, the authors discuss the cases of MAE degradation for the Kin8nm and Naval datasets. They attribute this to the independence of features in Kin8nm, which prevents observed features from aiding in the imputation of missing values, and the strong linear correlations between nearly all features in the Naval dataset. Summarizing these points in the conclusion would give readers a clear understanding of the method's limitations and the contexts in which it performs best.",['No ethics review needed.'],6,3,,Yes,3,2,3,1719781711353,,,NeurIPS.cc/2024/Conference,1MQXBnEbE8,"['NeurIPS.cc/2024/Conference/Submission5431/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879000377,[],1,,,['everyone'],1MQXBnEbE8,['NeurIPS.cc/2024/Conference/Submission5431/Reviewer_WjjR'],1719781711353,1730879000377,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5431/Reviewer_WjjR']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. 

The reviewer mentions two specific papers:
1. Gondara, L., Wang, K. (2018). MIDA: Multiple Imputation Using Denoising Autoencoders.
2. Wang, Zhenhua, et al. ""Are deep learning models superior for missing data imputation in surveys? Evidence from an empirical comparison."" Survey Methodology 48 (2022): 375-399.

The reviewer also implies that the authors should be aware of the paper by Wang et. al. (2022) when discussing statistical methods and MICE. 

These citations are suggested to improve the accuracy and completeness of the paper, particularly in relation to the discussion of prior work and the comparison of M3-Impute with other methods.",1,"2018, 2022, 2022",MIDA: Multiple Imputation Using Denoising Autoencoders 
llvx9uCRgC,"The paper introduces M3-Impute, a mask-guided representation learning method for missing value imputation. The core idea of M3-Impute is to leverage missingness information as an explicit input to the model through masking schemes. This approach allows M3-Impute to effectively learn both feature-wise and sample-wise correlations, accommodating various types of data missingness. The model employs a variant of GraphSAGE for graph representation learning, incorporating edge embeddings via neighborhood aggregation. It outperforms traditional tabular data models in various benchmark datasets.","1. The paper presents a novel approach to missing value imputation through the introduction of a mask-guided representation learning method (M3-Impute). The originality of the work lies in its utilization of missingness information as a model input, employing innovative masking schemes. This allows M3-Impute to accurately capture feature-wise and sample-wise correlations despite varying types of missing data (MCAR, MAR, MNAR). The use of GraphSAGE for graph representation learning, combined with edge embeddings via neighborhood aggregation, further distinguishes this work from traditional tabular data models.

2. The quality of the research is demonstrated through comprehensive experiments across multiple datasets and missing data mechanisms. The empirical results show that M3-Impute consistently outperforms baseline methods. The authors include a code package and datasets with the submission.","1. The paper evaluates the sensitivity of the M3-Impute model to the initialization parameter ϵ (Table 3), demonstrating that a non-zero value of ϵ improves imputation accuracy. However, the lack of detailed sensitivity analysis for other critical hyperparameters, such as the learning rate, batch size, number of GNN layers, and the dropout rate, represents a weakness.

2. The paper also has notable limitations in its contextualization relative to prior work. While it effectively presents M3-Impute and compares it against several baseline models, it lacks a deeper analysis of how these baseline models have evolved and the specific innovations they have introduced over time. For instance, the paper mentions GRAPE and IGRM as key prior graph-based imputation methods but does not adequately explore their strengths and weaknesses or how M3-Impute directly addresses the limitations of these methods. This omission makes it challenging to understand the novelty and improvements offered by M3-Impute.

3. Relying solely on MAE to evaluate the performance of imputation models has several limitations. MAE measures the average magnitude of errors but does not account for the variance or distribution of those errors, making it insensitive to outliers and providing no insight into model bias. This can result in an incomplete understanding of a model's performance, particularly in contexts where large errors or systematic biases are important considerations. To address these limitations, incorporating RMSE alongside MAE would be beneficial. RMSE penalizes larger errors more heavily, offering additional insight into the presence and impact of significant errors in the model's predictions.","- The statement that most learning-based methods are``built upon the raw tabular data structure as is, which greatly restricts them from jointly modeling the feature-wise and sample-wise correlations” (line 41) is not entirely accurate for two prominent tabular generative models, MIDA and GAIN. MIDA transforms raw tabular data into a higher-dimensional space through its encoder-decoder architecture. This transformation allows MIDA to capture more complex, nonlinear relationships that are not immediately apparent in the raw data. The adversarial process of GAIN allows it to model the joint distribution of the data, thus capturing complex correlations between features and samples. 

      - Gondara, L., Wang, K. (2018). MIDA: Multiple Imputation Using Denoising Autoencoders. In: Phung, D., Tseng, V., Webb, G., Ho, B., Ganji, M., Rashidi, L. (eds) Advances in Knowledge Discovery and Data Mining. PAKDD 2018. Lecture Notes in Computer Science(), vol 10939. Springer, Cham. https://doi.org/10.1007/978-3-319-93040-4_21

      - Wang, Zhenhua, et al. ""Are deep learning models superior for missing data imputation in surveys? Evidence from an empirical comparison."" Survey Methodology 48 (2022): 375-399.

- When discussing statistical methods (line 70), the authors should mention that FCS approaches such as MICE are flexible in imputing different types of variables. 

- Related to the previous point, MICE is generally considered a statistical method rather than a learning-based method, although a learning algorithm such as CART can be used as the imputer. See the paper by Wang et. al. (2022).

- In Sec. 4.2, it should be noted that the M3-Impute model tends to perform slightly better under MAR and MNAR settings for most datasets, indicating its effectiveness in handling missingness that depends on the observed data.

- How can interpretability techniques be incorporated into M3-Impute to help users understand the imputation decisions?","The authors should consider summarizing the limitations of their method in the conclusion to provide a comprehensive overview of their work. Specifically, in Section 4.2, the authors discuss the cases of MAE degradation for the Kin8nm and Naval datasets. They attribute this to the independence of features in Kin8nm, which prevents observed features from aiding in the imputation of missing values, and the strong linear correlations between nearly all features in the Naval dataset. Summarizing these points in the conclusion would give readers a clear understanding of the method's limitations and the contexts in which it performs best.",['No ethics review needed.'],6,3,,Yes,3,2,3,1719781711353,,,NeurIPS.cc/2024/Conference,1MQXBnEbE8,"['NeurIPS.cc/2024/Conference/Submission5431/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879000377,[],1,,,['everyone'],1MQXBnEbE8,['NeurIPS.cc/2024/Conference/Submission5431/Reviewer_WjjR'],1719781711353,1730879000377,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5431/Reviewer_WjjR']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. 

The reviewer mentions two specific papers:
1. Gondara, L., Wang, K. (2018). MIDA: Multiple Imputation Using Denoising Autoencoders.
2. Wang, Zhenhua, et al. ""Are deep learning models superior for missing data imputation in surveys? Evidence from an empirical comparison."" Survey Methodology 48 (2022): 375-399.

The reviewer also implies that the authors should be aware of the paper by Wang et. al. (2022) when discussing statistical methods and MICE. 

These citations are suggested to improve the accuracy and completeness of the paper, particularly in relation to the discussion of prior work and the comparison of M3-Impute with other methods.",1,"2018, 2022, 2022",Are deep learning models superior for missing data imputation in surveys? Evidence from an empirical comparison
JiLn9BGbVm,"The paper proposed a new imputations method called M3-impute. M3-impute follows the basic structure of some recent imputation methods: a undirected bipartite graph is constructed with nodes for features and samples, where edge weights correspond to observed data at the given feature-sample pair. Previous approaches use Graph Neural Networks (GNNs) to impute missing values via edge weight prediction. M3-impute improves these approaches by adding two new components on top of an initial GNN to model feature-wise and sample-wise correlations respectively. Empirical results show that M3-impute achieves competitive performance in terms of MAE for imputation across several tabular datasets.","- The paper is generally well written.
- Empirical results are extensive. Many other imputations methods are included for comparison, providing a good representation for the state-of-the-art for tabular data imputation. Ablation studies and robustness studies also further strengthen the credibility of the methodology.","- The paper does not support categorical features. This is a big weakness compared to other imputation methods that can handle categorical features such as iterative approaches like hyperimpute. 
- The paper does not discuss the impact of missing value imputation on downstream tasks. Imputation is usually a preprocessing step, and thus assessing the impact on possible downstream tasks is paramount. For example, in supervised learning, some recent evidence suggests that mean/zero imputation is as good as more complex imputations [1, 2]. 

[1] Le Morvan, Marine, et al. ""What’s a good imputation to predict with missing values?."" Advances in Neural Information Processing Systems 34 (2021): 11530-11540.
[2] Van Ness, Mike, and Madeleine Udell. ""In defense of zero imputation for tabular deep learning."" NeurIPS 2023 Second Table Representation Learning Workshop. 2023.","- What is the current approach for handling categorical features? Do none of the datasets in the experiments have any categorical features, or are these feature simply being one-hot encoded?
- How does the runtime of M3-impute compare to the other methods? I know this is briefly discussed in appendix 5, but more details runtimes would be appreciated. 
- Why are standard deviations not included for Table 1?","See weaknesses. In particular, not handling categorical features is not mentioned in the paper anywhere as a limitation of the method.",['No ethics review needed.'],6,4,,Yes,3,3,3,1720577888060,,,NeurIPS.cc/2024/Conference,1MQXBnEbE8,"['NeurIPS.cc/2024/Conference/Submission5431/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878999866,[],4,,,['everyone'],1MQXBnEbE8,['NeurIPS.cc/2024/Conference/Submission5431/Reviewer_f6SV'],1720577888060,1730878999866,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5431/Reviewer_f6SV']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. Le Morvan, Marine, et al. ""What’s a good imputation to predict with missing values?."" Advances in Neural Information Processing Systems 34 (2021): 11530-11540.
2. Van Ness, Mike, and Madeleine Udell. ""In defense of zero imputation for tabular deep learning."" NeurIPS 2023 Second Table Representation Learning Workshop. 2023.

These citations are provided as references to support the reviewer's comment that some recent evidence suggests that mean/zero imputation is as good as more complex imputations in certain scenarios, and to highlight the importance of assessing the impact of missing value imputation on downstream tasks.",1,"2021, 2023, 2023",What’s a good imputation to predict with missing values 
JiLn9BGbVm,"The paper proposed a new imputations method called M3-impute. M3-impute follows the basic structure of some recent imputation methods: a undirected bipartite graph is constructed with nodes for features and samples, where edge weights correspond to observed data at the given feature-sample pair. Previous approaches use Graph Neural Networks (GNNs) to impute missing values via edge weight prediction. M3-impute improves these approaches by adding two new components on top of an initial GNN to model feature-wise and sample-wise correlations respectively. Empirical results show that M3-impute achieves competitive performance in terms of MAE for imputation across several tabular datasets.","- The paper is generally well written.
- Empirical results are extensive. Many other imputations methods are included for comparison, providing a good representation for the state-of-the-art for tabular data imputation. Ablation studies and robustness studies also further strengthen the credibility of the methodology.","- The paper does not support categorical features. This is a big weakness compared to other imputation methods that can handle categorical features such as iterative approaches like hyperimpute. 
- The paper does not discuss the impact of missing value imputation on downstream tasks. Imputation is usually a preprocessing step, and thus assessing the impact on possible downstream tasks is paramount. For example, in supervised learning, some recent evidence suggests that mean/zero imputation is as good as more complex imputations [1, 2]. 

[1] Le Morvan, Marine, et al. ""What’s a good imputation to predict with missing values?."" Advances in Neural Information Processing Systems 34 (2021): 11530-11540.
[2] Van Ness, Mike, and Madeleine Udell. ""In defense of zero imputation for tabular deep learning."" NeurIPS 2023 Second Table Representation Learning Workshop. 2023.","- What is the current approach for handling categorical features? Do none of the datasets in the experiments have any categorical features, or are these feature simply being one-hot encoded?
- How does the runtime of M3-impute compare to the other methods? I know this is briefly discussed in appendix 5, but more details runtimes would be appreciated. 
- Why are standard deviations not included for Table 1?","See weaknesses. In particular, not handling categorical features is not mentioned in the paper anywhere as a limitation of the method.",['No ethics review needed.'],6,4,,Yes,3,3,3,1720577888060,,,NeurIPS.cc/2024/Conference,1MQXBnEbE8,"['NeurIPS.cc/2024/Conference/Submission5431/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878999866,[],4,,,['everyone'],1MQXBnEbE8,['NeurIPS.cc/2024/Conference/Submission5431/Reviewer_f6SV'],1720577888060,1730878999866,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5431/Reviewer_f6SV']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. Le Morvan, Marine, et al. ""What’s a good imputation to predict with missing values?."" Advances in Neural Information Processing Systems 34 (2021): 11530-11540.
2. Van Ness, Mike, and Madeleine Udell. ""In defense of zero imputation for tabular deep learning."" NeurIPS 2023 Second Table Representation Learning Workshop. 2023.

These citations are provided as references to support the reviewer's comment that some recent evidence suggests that mean/zero imputation is as good as more complex imputations in certain scenarios, and to highlight the importance of assessing the impact of missing value imputation on downstream tasks.",1,"2021, 2023, 2023",In defense of zero imputation for tabular deep learning
R9zNNz0KJz,"This paper presents a novel imputation method, based on a bipartite graph constructed from the data and the missing-data patterns, and two components which allow to measure similarities between the features and samples.

The method shows very good results in terms of MAE on several datasets for MCAR, MAR and MNAR data.","- The paper is well written. 

- Experiments are well conducted, on several datasets, with different missing-data ratios and considering MCAR, MAR or MNAR data. The authors have made an effort to compare themselves with many other imputation methods. 

- There is a true discussion on the parameters to choose in the experiments. The authors are honest about the performance of their method, and give explanations when another method is better.","- Although well presented, the method is complicated to understand. 

- The methods uses 8 MLPs and one GNN. The authors discuss in Appendix the computational resources, but do not compare other methods on this point.","General remarks: 
- How does this methodology relate to the simple concatenation of the mask to the data matrix, and the execution of an imputation method on the augmented matrix? (see Josse, Julie, et al. ""On the consistency of supervised learning with missing values."")
- Is M3-Impute supposed to work well for MNAR? This should be discussed more in details, as the authors claim that the method utilizes the data-missingness information. A remark: there exists for MIWAE an extension specifically designed for MNAR data, called not-MIWAE. Ipsen, Niels Bruun, Pierre-Alexandre Mattei, and Jes Frellsen. ""not-MIWAE: Deep generative modelling with missing not at random data.""
It can be interesting to have a comparison of M3-Impute with this one in a final version. 

Algorithm: 
- Figure 1: maybe the authors should add numbers in the graphics to refer to them when describing the method in the text (especially in 3.1)
- In Algorithm 1, one of the input is the GNN model. How are hyperparameters of the GNN managed in practice? 

Numerical experiments: 
- In the final version, the authors should add a comparison with the missForest algorithm, which is one of the most widely used imputation methods. 
- for other methods, such as MIWAE, which hyperparameters did the authors choose? 
- in the MAR setting, how many features are selected to be observed? Did the authors take the best subset for the results?

Minor comments:
- l.15 mechanisms instead of patterns
- l.56 ""the the""
- l.137 notation col_s: harmonise d and m
- l.548 ""these remaining"" <- ""the remaining""
- l.291 mechanisms instead of patterns",Yes,['No ethics review needed.'],6,3,,Yes,2,3,3,1720821419823,,,NeurIPS.cc/2024/Conference,1MQXBnEbE8,"['NeurIPS.cc/2024/Conference/Submission5431/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878999431,[],7,,,['everyone'],1MQXBnEbE8,['NeurIPS.cc/2024/Conference/Submission5431/Reviewer_LUcW'],1720821419823,1730878999431,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5431/Reviewer_LUcW']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. Josse, Julie, et al. ""On the consistency of supervised learning with missing values.""
2. Ipsen, Niels Bruun, Pierre-Alexandre Mattei, and Jes Frellsen. ""not-MIWAE: Deep generative modelling with missing not at random data.""

The reviewer also mentions the missForest algorithm, which is one of the most widely used imputation methods, and suggests that the authors should add a comparison with it in the final version. However, this is not a direct suggestion to cite a specific literature, but rather to include a comparison with a specific method.",1,,On the consistency of supervised learning with missing values
R9zNNz0KJz,"This paper presents a novel imputation method, based on a bipartite graph constructed from the data and the missing-data patterns, and two components which allow to measure similarities between the features and samples.

The method shows very good results in terms of MAE on several datasets for MCAR, MAR and MNAR data.","- The paper is well written. 

- Experiments are well conducted, on several datasets, with different missing-data ratios and considering MCAR, MAR or MNAR data. The authors have made an effort to compare themselves with many other imputation methods. 

- There is a true discussion on the parameters to choose in the experiments. The authors are honest about the performance of their method, and give explanations when another method is better.","- Although well presented, the method is complicated to understand. 

- The methods uses 8 MLPs and one GNN. The authors discuss in Appendix the computational resources, but do not compare other methods on this point.","General remarks: 
- How does this methodology relate to the simple concatenation of the mask to the data matrix, and the execution of an imputation method on the augmented matrix? (see Josse, Julie, et al. ""On the consistency of supervised learning with missing values."")
- Is M3-Impute supposed to work well for MNAR? This should be discussed more in details, as the authors claim that the method utilizes the data-missingness information. A remark: there exists for MIWAE an extension specifically designed for MNAR data, called not-MIWAE. Ipsen, Niels Bruun, Pierre-Alexandre Mattei, and Jes Frellsen. ""not-MIWAE: Deep generative modelling with missing not at random data.""
It can be interesting to have a comparison of M3-Impute with this one in a final version. 

Algorithm: 
- Figure 1: maybe the authors should add numbers in the graphics to refer to them when describing the method in the text (especially in 3.1)
- In Algorithm 1, one of the input is the GNN model. How are hyperparameters of the GNN managed in practice? 

Numerical experiments: 
- In the final version, the authors should add a comparison with the missForest algorithm, which is one of the most widely used imputation methods. 
- for other methods, such as MIWAE, which hyperparameters did the authors choose? 
- in the MAR setting, how many features are selected to be observed? Did the authors take the best subset for the results?

Minor comments:
- l.15 mechanisms instead of patterns
- l.56 ""the the""
- l.137 notation col_s: harmonise d and m
- l.548 ""these remaining"" <- ""the remaining""
- l.291 mechanisms instead of patterns",Yes,['No ethics review needed.'],6,3,,Yes,2,3,3,1720821419823,,,NeurIPS.cc/2024/Conference,1MQXBnEbE8,"['NeurIPS.cc/2024/Conference/Submission5431/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878999431,[],7,,,['everyone'],1MQXBnEbE8,['NeurIPS.cc/2024/Conference/Submission5431/Reviewer_LUcW'],1720821419823,1730878999431,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5431/Reviewer_LUcW']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. Josse, Julie, et al. ""On the consistency of supervised learning with missing values.""
2. Ipsen, Niels Bruun, Pierre-Alexandre Mattei, and Jes Frellsen. ""not-MIWAE: Deep generative modelling with missing not at random data.""

The reviewer also mentions the missForest algorithm, which is one of the most widely used imputation methods, and suggests that the authors should add a comparison with it in the final version. However, this is not a direct suggestion to cite a specific literature, but rather to include a comparison with a specific method.",1,,not-MIWAE Deep generative modelling with missing not at random data
V1veVqLxtX,"The paper proposes a pre-training approach called Multi-view Masked Contrastive Representation Learning for endoscopic videos. The approach combines self-distillation and masked video modeling under multi-view setting. To consider the characteristics of inter-frame instability and small inter-class differences of endoscopic videos, the paper introduces a frame aggregated attention guided tube masking strategy to capture global spatio-temporal representation and employs random tube masking on local views to capture local representations. The approach is pre-trained on seven endoscopic datasets and fine-tuned on three additional datasets. Experiments show that it outperforms the baselines on classification, segmentation and detection tasks.","- The paper is easy to read.
- The paper shows the combination of self-distillation and masked video modeling for pre-training ViT-B model using endoscopic videos.
- Frame-aggregated attention guided tube masking (FAGTM) to learn global spatio-temporal representation learning.
- Experiments on multiple tasks to show the efficacy of the approach.","- Although the pre-training approach is proposed for endoscopic videos, the novelty is limited. It's a combination of self-distillation and masked video modeling. 
- FAGTM is also an extension of either [1] and [2] which propose attention guide masking strategy for image based pre-training. The paper merely aggregates the attention for all frames and use the mean of that to guide the masking.
- The paper mentions in section 3.3, ""This self-distillation method of self-supervision is also considered a form of contrastive learning"". Can the authors please give remark on why self-distillation is a form of contrastive learning?
- Which block of the teacher ViT-B is used for FAGTM? Ablation study would be great.
- Did the author pre-train ViT-B from the scratch? or initialized from some weights?
- Ablation on number of epochs during pre-training is missing
- Only ViT-B is used in the experiment? Different architecture should be studied too.
- Did the authors also pre-train VideoMAE and other baselines using your dataset? Can the authors show some results using kinetics pre-trained SSL weights? 
- More baselines should be compared with. For example, MME[3], AdaMAE[4], and other masked video modeling approach.
- What did the author use as an evaluation or metric to stop pre-training?
- Can FAGTM be used on local views?
- The approach looks very sensitive to $\gamma$. Table 3 shows the impact of it on all the tasks.
- Is the masking ratio used for FAGTM and random tube masking same? Ablation study on the impact of different masking ratio for each of the masking strategy would be useful.
- The paper only uses linear layer for the reconstruction objective. Study of different decoders would be helpful. In masked video modeling, most of the approaches used asymmetric encoder and decoder design. It would be great to pre-train baselines like VideoMAE with linear layer decoder for a better comparison.
- Most of the recent approaches use L2 loss for the reconstruction objective. Comparison of L1 and L2 loss is missing and can the authors please give a remark on why L1 loss is preferred?
- Given the approach is mostly empirical with limited novelty, the performance on other datasets like Cholec80, a surgical phase recognition benchmark dataset, would be great. 

- There are some typos in the paper: section 3.2.1 'spatiotempora' -> temporal, table2 'gloabl' -> global

[1] What to Hide from Your Students: Attention-Guided Masked Image Modeling, ECCV 2022

[2] Good helper is around you: Attention-driven Masked Image Modeling, AAAI 2023.

[3] Masked Motion Encoding for Self-Supervised Video Representation Learning, CVPR 2023

[4] AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders, CVPR 2023",Please see the weakness section for the questions and suggestions.,"Yes, the authors have adequately addressed the limitations.",['No ethics review needed.'],4,5,,Yes,2,3,3,1720998726605,,,NeurIPS.cc/2024/Conference,1M67AdMBbg,"['NeurIPS.cc/2024/Conference/Submission9335/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879306743,[],4,,,['everyone'],1M67AdMBbg,['NeurIPS.cc/2024/Conference/Submission9335/Reviewer_wGJR'],1720998726605,1730879306743,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9335/Reviewer_wGJR']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. [1] ""What to Hide from Your Students: Attention-Guided Masked Image Modeling, ECCV 2022""
2. [2] ""Good helper is around you: Attention-driven Masked Image Modeling, AAAI 2023""
3. [3] ""Masked Motion Encoding for Self-Supervised Video Representation Learning, CVPR 2023""
4. [4] ""AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders, CVPR 2023""

These citations are mentioned in the weaknesses section of the review, where the reviewer suggests that the authors' approach is an extension of existing work and that they should compare their approach to other baselines, including MME and AdaMAE.",1,"2022, 2023, 2023, 2023",What to Hide from Your Students: Attention-Guided Masked Image Modeling
V1veVqLxtX,"The paper proposes a pre-training approach called Multi-view Masked Contrastive Representation Learning for endoscopic videos. The approach combines self-distillation and masked video modeling under multi-view setting. To consider the characteristics of inter-frame instability and small inter-class differences of endoscopic videos, the paper introduces a frame aggregated attention guided tube masking strategy to capture global spatio-temporal representation and employs random tube masking on local views to capture local representations. The approach is pre-trained on seven endoscopic datasets and fine-tuned on three additional datasets. Experiments show that it outperforms the baselines on classification, segmentation and detection tasks.","- The paper is easy to read.
- The paper shows the combination of self-distillation and masked video modeling for pre-training ViT-B model using endoscopic videos.
- Frame-aggregated attention guided tube masking (FAGTM) to learn global spatio-temporal representation learning.
- Experiments on multiple tasks to show the efficacy of the approach.","- Although the pre-training approach is proposed for endoscopic videos, the novelty is limited. It's a combination of self-distillation and masked video modeling. 
- FAGTM is also an extension of either [1] and [2] which propose attention guide masking strategy for image based pre-training. The paper merely aggregates the attention for all frames and use the mean of that to guide the masking.
- The paper mentions in section 3.3, ""This self-distillation method of self-supervision is also considered a form of contrastive learning"". Can the authors please give remark on why self-distillation is a form of contrastive learning?
- Which block of the teacher ViT-B is used for FAGTM? Ablation study would be great.
- Did the author pre-train ViT-B from the scratch? or initialized from some weights?
- Ablation on number of epochs during pre-training is missing
- Only ViT-B is used in the experiment? Different architecture should be studied too.
- Did the authors also pre-train VideoMAE and other baselines using your dataset? Can the authors show some results using kinetics pre-trained SSL weights? 
- More baselines should be compared with. For example, MME[3], AdaMAE[4], and other masked video modeling approach.
- What did the author use as an evaluation or metric to stop pre-training?
- Can FAGTM be used on local views?
- The approach looks very sensitive to $\gamma$. Table 3 shows the impact of it on all the tasks.
- Is the masking ratio used for FAGTM and random tube masking same? Ablation study on the impact of different masking ratio for each of the masking strategy would be useful.
- The paper only uses linear layer for the reconstruction objective. Study of different decoders would be helpful. In masked video modeling, most of the approaches used asymmetric encoder and decoder design. It would be great to pre-train baselines like VideoMAE with linear layer decoder for a better comparison.
- Most of the recent approaches use L2 loss for the reconstruction objective. Comparison of L1 and L2 loss is missing and can the authors please give a remark on why L1 loss is preferred?
- Given the approach is mostly empirical with limited novelty, the performance on other datasets like Cholec80, a surgical phase recognition benchmark dataset, would be great. 

- There are some typos in the paper: section 3.2.1 'spatiotempora' -> temporal, table2 'gloabl' -> global

[1] What to Hide from Your Students: Attention-Guided Masked Image Modeling, ECCV 2022

[2] Good helper is around you: Attention-driven Masked Image Modeling, AAAI 2023.

[3] Masked Motion Encoding for Self-Supervised Video Representation Learning, CVPR 2023

[4] AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders, CVPR 2023",Please see the weakness section for the questions and suggestions.,"Yes, the authors have adequately addressed the limitations.",['No ethics review needed.'],4,5,,Yes,2,3,3,1720998726605,,,NeurIPS.cc/2024/Conference,1M67AdMBbg,"['NeurIPS.cc/2024/Conference/Submission9335/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879306743,[],4,,,['everyone'],1M67AdMBbg,['NeurIPS.cc/2024/Conference/Submission9335/Reviewer_wGJR'],1720998726605,1730879306743,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9335/Reviewer_wGJR']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. [1] ""What to Hide from Your Students: Attention-Guided Masked Image Modeling, ECCV 2022""
2. [2] ""Good helper is around you: Attention-driven Masked Image Modeling, AAAI 2023""
3. [3] ""Masked Motion Encoding for Self-Supervised Video Representation Learning, CVPR 2023""
4. [4] ""AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders, CVPR 2023""

These citations are mentioned in the weaknesses section of the review, where the reviewer suggests that the authors' approach is an extension of existing work and that they should compare their approach to other baselines, including MME and AdaMAE.",1,"2022, 2023, 2023, 2023",Good helper is around you: Attention-driven Masked Image Modeling
V1veVqLxtX,"The paper proposes a pre-training approach called Multi-view Masked Contrastive Representation Learning for endoscopic videos. The approach combines self-distillation and masked video modeling under multi-view setting. To consider the characteristics of inter-frame instability and small inter-class differences of endoscopic videos, the paper introduces a frame aggregated attention guided tube masking strategy to capture global spatio-temporal representation and employs random tube masking on local views to capture local representations. The approach is pre-trained on seven endoscopic datasets and fine-tuned on three additional datasets. Experiments show that it outperforms the baselines on classification, segmentation and detection tasks.","- The paper is easy to read.
- The paper shows the combination of self-distillation and masked video modeling for pre-training ViT-B model using endoscopic videos.
- Frame-aggregated attention guided tube masking (FAGTM) to learn global spatio-temporal representation learning.
- Experiments on multiple tasks to show the efficacy of the approach.","- Although the pre-training approach is proposed for endoscopic videos, the novelty is limited. It's a combination of self-distillation and masked video modeling. 
- FAGTM is also an extension of either [1] and [2] which propose attention guide masking strategy for image based pre-training. The paper merely aggregates the attention for all frames and use the mean of that to guide the masking.
- The paper mentions in section 3.3, ""This self-distillation method of self-supervision is also considered a form of contrastive learning"". Can the authors please give remark on why self-distillation is a form of contrastive learning?
- Which block of the teacher ViT-B is used for FAGTM? Ablation study would be great.
- Did the author pre-train ViT-B from the scratch? or initialized from some weights?
- Ablation on number of epochs during pre-training is missing
- Only ViT-B is used in the experiment? Different architecture should be studied too.
- Did the authors also pre-train VideoMAE and other baselines using your dataset? Can the authors show some results using kinetics pre-trained SSL weights? 
- More baselines should be compared with. For example, MME[3], AdaMAE[4], and other masked video modeling approach.
- What did the author use as an evaluation or metric to stop pre-training?
- Can FAGTM be used on local views?
- The approach looks very sensitive to $\gamma$. Table 3 shows the impact of it on all the tasks.
- Is the masking ratio used for FAGTM and random tube masking same? Ablation study on the impact of different masking ratio for each of the masking strategy would be useful.
- The paper only uses linear layer for the reconstruction objective. Study of different decoders would be helpful. In masked video modeling, most of the approaches used asymmetric encoder and decoder design. It would be great to pre-train baselines like VideoMAE with linear layer decoder for a better comparison.
- Most of the recent approaches use L2 loss for the reconstruction objective. Comparison of L1 and L2 loss is missing and can the authors please give a remark on why L1 loss is preferred?
- Given the approach is mostly empirical with limited novelty, the performance on other datasets like Cholec80, a surgical phase recognition benchmark dataset, would be great. 

- There are some typos in the paper: section 3.2.1 'spatiotempora' -> temporal, table2 'gloabl' -> global

[1] What to Hide from Your Students: Attention-Guided Masked Image Modeling, ECCV 2022

[2] Good helper is around you: Attention-driven Masked Image Modeling, AAAI 2023.

[3] Masked Motion Encoding for Self-Supervised Video Representation Learning, CVPR 2023

[4] AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders, CVPR 2023",Please see the weakness section for the questions and suggestions.,"Yes, the authors have adequately addressed the limitations.",['No ethics review needed.'],4,5,,Yes,2,3,3,1720998726605,,,NeurIPS.cc/2024/Conference,1M67AdMBbg,"['NeurIPS.cc/2024/Conference/Submission9335/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879306743,[],4,,,['everyone'],1M67AdMBbg,['NeurIPS.cc/2024/Conference/Submission9335/Reviewer_wGJR'],1720998726605,1730879306743,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9335/Reviewer_wGJR']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. [1] ""What to Hide from Your Students: Attention-Guided Masked Image Modeling, ECCV 2022""
2. [2] ""Good helper is around you: Attention-driven Masked Image Modeling, AAAI 2023""
3. [3] ""Masked Motion Encoding for Self-Supervised Video Representation Learning, CVPR 2023""
4. [4] ""AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders, CVPR 2023""

These citations are mentioned in the weaknesses section of the review, where the reviewer suggests that the authors' approach is an extension of existing work and that they should compare their approach to other baselines, including MME and AdaMAE.",1,"2022, 2023, 2023, 2023",Masked Motion Encoding for Self-Supervised Video Representation Learning
V1veVqLxtX,"The paper proposes a pre-training approach called Multi-view Masked Contrastive Representation Learning for endoscopic videos. The approach combines self-distillation and masked video modeling under multi-view setting. To consider the characteristics of inter-frame instability and small inter-class differences of endoscopic videos, the paper introduces a frame aggregated attention guided tube masking strategy to capture global spatio-temporal representation and employs random tube masking on local views to capture local representations. The approach is pre-trained on seven endoscopic datasets and fine-tuned on three additional datasets. Experiments show that it outperforms the baselines on classification, segmentation and detection tasks.","- The paper is easy to read.
- The paper shows the combination of self-distillation and masked video modeling for pre-training ViT-B model using endoscopic videos.
- Frame-aggregated attention guided tube masking (FAGTM) to learn global spatio-temporal representation learning.
- Experiments on multiple tasks to show the efficacy of the approach.","- Although the pre-training approach is proposed for endoscopic videos, the novelty is limited. It's a combination of self-distillation and masked video modeling. 
- FAGTM is also an extension of either [1] and [2] which propose attention guide masking strategy for image based pre-training. The paper merely aggregates the attention for all frames and use the mean of that to guide the masking.
- The paper mentions in section 3.3, ""This self-distillation method of self-supervision is also considered a form of contrastive learning"". Can the authors please give remark on why self-distillation is a form of contrastive learning?
- Which block of the teacher ViT-B is used for FAGTM? Ablation study would be great.
- Did the author pre-train ViT-B from the scratch? or initialized from some weights?
- Ablation on number of epochs during pre-training is missing
- Only ViT-B is used in the experiment? Different architecture should be studied too.
- Did the authors also pre-train VideoMAE and other baselines using your dataset? Can the authors show some results using kinetics pre-trained SSL weights? 
- More baselines should be compared with. For example, MME[3], AdaMAE[4], and other masked video modeling approach.
- What did the author use as an evaluation or metric to stop pre-training?
- Can FAGTM be used on local views?
- The approach looks very sensitive to $\gamma$. Table 3 shows the impact of it on all the tasks.
- Is the masking ratio used for FAGTM and random tube masking same? Ablation study on the impact of different masking ratio for each of the masking strategy would be useful.
- The paper only uses linear layer for the reconstruction objective. Study of different decoders would be helpful. In masked video modeling, most of the approaches used asymmetric encoder and decoder design. It would be great to pre-train baselines like VideoMAE with linear layer decoder for a better comparison.
- Most of the recent approaches use L2 loss for the reconstruction objective. Comparison of L1 and L2 loss is missing and can the authors please give a remark on why L1 loss is preferred?
- Given the approach is mostly empirical with limited novelty, the performance on other datasets like Cholec80, a surgical phase recognition benchmark dataset, would be great. 

- There are some typos in the paper: section 3.2.1 'spatiotempora' -> temporal, table2 'gloabl' -> global

[1] What to Hide from Your Students: Attention-Guided Masked Image Modeling, ECCV 2022

[2] Good helper is around you: Attention-driven Masked Image Modeling, AAAI 2023.

[3] Masked Motion Encoding for Self-Supervised Video Representation Learning, CVPR 2023

[4] AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders, CVPR 2023",Please see the weakness section for the questions and suggestions.,"Yes, the authors have adequately addressed the limitations.",['No ethics review needed.'],4,5,,Yes,2,3,3,1720998726605,,,NeurIPS.cc/2024/Conference,1M67AdMBbg,"['NeurIPS.cc/2024/Conference/Submission9335/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879306743,[],4,,,['everyone'],1M67AdMBbg,['NeurIPS.cc/2024/Conference/Submission9335/Reviewer_wGJR'],1720998726605,1730879306743,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9335/Reviewer_wGJR']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. [1] ""What to Hide from Your Students: Attention-Guided Masked Image Modeling, ECCV 2022""
2. [2] ""Good helper is around you: Attention-driven Masked Image Modeling, AAAI 2023""
3. [3] ""Masked Motion Encoding for Self-Supervised Video Representation Learning, CVPR 2023""
4. [4] ""AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders, CVPR 2023""

These citations are mentioned in the weaknesses section of the review, where the reviewer suggests that the authors' approach is an extension of existing work and that they should compare their approach to other baselines, including MME and AdaMAE.",1,"2022, 2023, 2023, 2023",AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders
INlbXPBnWQ,"The paper proposes an adversarial example construction method targeting Diffusion-based Policies, aiming to create malicious observation inputs to diffusion policies that cause them to fail in generating correct actions, leading to robot errors. The authors present attack methods including both untargeted and targeted attacks. The main idea is to construct adversarial examples by optimizing a malicious denoising loss and updating the image according to the gradient. Experiments demonstrate that the generated adversarial examples can lower the success rate of the target diffusion policy.","- This is the first adversarial attack against a diffusion-based visuomotor policies.
- The proposed attack framework is comprehensive, including targeted, untargeted, online, and offline attacks.
- The paper is well-written and easy to understand.","- The proposed method seems to be a straightforward extension of a previous approach applied to images.
- The threat model is not well-defined.
- The attack method makes strong assumptions on attackers, and its effectiveness in real-world scenarios, especially for patched attacks, is unclear.","Overall, this paper is interesting and presents the first adversarial attack against diffusion-based visuomotor policies. However, I have the following concerns:

- The proposed method seems to be a straightforward extension of prior work [1], with the main modification being the adjustment of the adversarial loss to accommodate the differences between diffusion policy and standard T2I models.

- Unlike related work that uses adversarial examples to prevent painting imitation, this paper attacks the system directly. Can the authors provide a clear threat model, including a well-defined attacker's goal and capabilities? It would be helpful to provide corresponding scenarios.

- The authors claim that DP-Attacker can generate highly transferable perturbations. How is this demonstrated in the experiments? For example, the authors claim that it is actually the encoder being attacked. The diffusion policy uses ResNet-18 as the encoder [2], can the adversarial examples generated by DP-Attacker transfer to other encoders?

[1] Adversarial example does good: Preventing painting imitation from diffusion models via adversarial examples, 2023

[2] Diffusion Policy: Visuomotor Policy Learning via Action Diffusion, 2023","One major limitation is the lack of real-world demonstrations for patched attacks. The authors have acknowledged this in the paper. Additionally, I have some questions regarding the authors' claim about the transferability of the generated adversarial example.",['No ethics review needed.'],6,4,,Yes,2,3,3,1720727169282,,,NeurIPS.cc/2024/Conference,1L5vaNIoK5,"['NeurIPS.cc/2024/Conference/Submission5384/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878997822,[],2,,,['everyone'],1L5vaNIoK5,['NeurIPS.cc/2024/Conference/Submission5384/Reviewer_FStp'],1720727169282,1730878997822,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5384/Reviewer_FStp']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. ""Adversarial example does good: Preventing painting imitation from diffusion models via adversarial examples, 2023"" (referenced as [1])
2. ""Diffusion Policy: Visuomotor Policy Learning via Action Diffusion, 2023"" (referenced as [2])

These citations are mentioned in the review to provide context and comparisons to the proposed method, and to question the novelty and contributions of the paper.",1,"2023, 2023",Adversarial example does good Preventing painting imitation from diffusion models via adversarial examples 
INlbXPBnWQ,"The paper proposes an adversarial example construction method targeting Diffusion-based Policies, aiming to create malicious observation inputs to diffusion policies that cause them to fail in generating correct actions, leading to robot errors. The authors present attack methods including both untargeted and targeted attacks. The main idea is to construct adversarial examples by optimizing a malicious denoising loss and updating the image according to the gradient. Experiments demonstrate that the generated adversarial examples can lower the success rate of the target diffusion policy.","- This is the first adversarial attack against a diffusion-based visuomotor policies.
- The proposed attack framework is comprehensive, including targeted, untargeted, online, and offline attacks.
- The paper is well-written and easy to understand.","- The proposed method seems to be a straightforward extension of a previous approach applied to images.
- The threat model is not well-defined.
- The attack method makes strong assumptions on attackers, and its effectiveness in real-world scenarios, especially for patched attacks, is unclear.","Overall, this paper is interesting and presents the first adversarial attack against diffusion-based visuomotor policies. However, I have the following concerns:

- The proposed method seems to be a straightforward extension of prior work [1], with the main modification being the adjustment of the adversarial loss to accommodate the differences between diffusion policy and standard T2I models.

- Unlike related work that uses adversarial examples to prevent painting imitation, this paper attacks the system directly. Can the authors provide a clear threat model, including a well-defined attacker's goal and capabilities? It would be helpful to provide corresponding scenarios.

- The authors claim that DP-Attacker can generate highly transferable perturbations. How is this demonstrated in the experiments? For example, the authors claim that it is actually the encoder being attacked. The diffusion policy uses ResNet-18 as the encoder [2], can the adversarial examples generated by DP-Attacker transfer to other encoders?

[1] Adversarial example does good: Preventing painting imitation from diffusion models via adversarial examples, 2023

[2] Diffusion Policy: Visuomotor Policy Learning via Action Diffusion, 2023","One major limitation is the lack of real-world demonstrations for patched attacks. The authors have acknowledged this in the paper. Additionally, I have some questions regarding the authors' claim about the transferability of the generated adversarial example.",['No ethics review needed.'],6,4,,Yes,2,3,3,1720727169282,,,NeurIPS.cc/2024/Conference,1L5vaNIoK5,"['NeurIPS.cc/2024/Conference/Submission5384/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878997822,[],2,,,['everyone'],1L5vaNIoK5,['NeurIPS.cc/2024/Conference/Submission5384/Reviewer_FStp'],1720727169282,1730878997822,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5384/Reviewer_FStp']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. ""Adversarial example does good: Preventing painting imitation from diffusion models via adversarial examples, 2023"" (referenced as [1])
2. ""Diffusion Policy: Visuomotor Policy Learning via Action Diffusion, 2023"" (referenced as [2])

These citations are mentioned in the review to provide context and comparisons to the proposed method, and to question the novelty and contributions of the paper.",1,"2023, 2023",Diffusion Policy Visuomotor Policy Learning via Action Diffusion
F9aYPE5Y9O,"The paper investigates the application of flow matching-based generative models for high-resolution image synthesis, particularly as priors for solving inverse problems. A notable challenge addressed is the slow computation of log-likelihoods in high-dimensional contexts, necessitating backpropagation through an ODE solver. To overcome this, the authors propose an efficient iterative algorithm for approximating the maximum-a-posteriori (MAP) estimator. This method involves approximating the MAP objective through a series of ""local MAP"" objectives and employs Tweedie's formula for sequential gradient optimization. The proposed method's performance is validated across multiple inverse problems and various datasets.","- The paper introduces a unique method for solving inverse problems and reconstructing a single image.
- The proposed method is supported by a solid theoretical foundation.
- The approach is effective across diverse linear inverse problems.","- Insufficient Empirical Evidence: The paper lacks enough qualitative results and empirical evidence to conclusively demonstrate the superiority of the proposed method.
- Need for Additional Metrics: Metrics like FID and LPIPS scores should be included alongside PSNR and SSIM.
- Figure 2 Presentation: The data in Figure 2 should be presented in a table format for easier interpretation of quantitative performance improvements.
- Limited Dataset Testing: For natural image experiments, the algorithm was only tested on the CelebA-HQ dataset. Pretrained models for other datasets (LSUN-bedroom, LSUN-church, and AFHQ-cat) are publicly available from the authors of the rectified flow paper and should be included.
- Blurry reconstruction results:  A closer look at Figure 3 (a,c) reveals that the reconstructed images are too smooth and lack high-frequency details. Compared to OT-ODE, the results are smoother and blurrier.
- Comparison with Recent Work: Apart from OT-ODE, recent work like ""D-Flow: Differentiating through Flows for Controlled Generation"" also addresses inverse problems and should be considered for comparison.","- Does the proposed method work for very noisy corruptions with high measurement noise (e.g., sigma_y = 0.2 or more)?
- Does the proposed method work for severely ill-posed inverse problems like 8x super-resolution or inpainting with 90% of pixels missing?
- Why was the algorithm evaluated on only 100 images from the CelebA-HQ dataset? Why wasn't the entire validation dataset used?
-There are numerous qualitative results for medical images in the appendix, but for natural image datasets like CelebA-HQ, there is only one small figure (Figure 3). It is hard to draw any conclusions based on just Figure 3. Was the authors' focus primarily on medical images?","- The paper's empirical validation is limited, requiring more comprehensive testing across various datasets and additional qualitative results to strengthen the claims of superiority.
- The presentation of quantitative results could be improved by using tables for easier comparison and interpretation.
- The evaluation metrics need to be expanded to include FID and LPIPS scores to provide a more comprehensive assessment of performance.
- Blurry results",['No ethics review needed.'],5,4,,Yes,2,2,3,1720723036429,,,NeurIPS.cc/2024/Conference,1H2e7USI09,"['NeurIPS.cc/2024/Conference/Submission1142/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878680855,[],1,,,['everyone'],1H2e7USI09,['NeurIPS.cc/2024/Conference/Submission1142/Reviewer_qjx2'],1720723036429,1730878680855,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission1142/Reviewer_qjx2']","Yes, the peer review explicitly suggests the authors of the paper to cite the literature ""D-Flow: Differentiating through Flows for Controlled Generation"" for comparison with recent work.",1,,D-Flow: Differentiating through Flows for Controlled Generation
PfOWxZuKDR,"The paper proposes a flow prior under the MAP structure for solving inverse problems, a theoretical analysis is also given.","1. The paper is easy to follow, the presentation from concepts to methods is concise, the motivation of the proposed method on overcoming shortage of flow model is also clear and straightforward.
2. Incorporating the flow prior into MAP to solve inverse problems is interesting and worth exploring.
3. The discussion on feasibility of assumptions made in the paper, as well as hyperparameter effects are very informative to the readers, and are valuable to the research in the community.","1. Theorem 1 is trivial in terms of $N \rightarrow 0$, and the existence of constant $c(N)$. The approximation gap converges to 0 as N goes to infinity does not provide insightful guidance on the practical implementation since $N \rightarrow 0$ is infeasible (decreases efficiency) in practice. Also, the implicit representation of approximation error constant $c(N)$ does not make sense because it gives no information about how the error could be scaled with $N$, the authors are expected to provide explicit expression of $c( \cdot )$ as a function of $N$.

2. Obtaining measurements $u_t$ in the ‘corrupted trajectory’ and generating auxiliary path $s_t$ do not make too much sense to me, especially when $x_t$ is very noisy and the forward operator $A(\cdot)$ is challenging. Suppose $A$ is very ill-posed (e.g. compressed sensing with low sampling rate), then the $y_t$ in the auxiliary path is not good itself, nevertheless the measurement $u_t = A(x_t)$ obtained in the corrupted trajectory especially when $x_t$ has high noise level. The assumption on exact compliance of trajectory (between corrupted trajectory and auxiliary path) is not theoretically guaranteed as stated by the authors (line 170-171), and the strong empirical results can not support the existence of the assumption made. The good empirical results could only be valid in less challenging inverse problems, or those inverse problems that are suitable for generative models to solve, e.g. inpainting, super-resolution.

3. In the compressed sensing experiment, the sampling rate $\nu$ is relatively large (0.25, 0.5). The authors are expected to use smaller sampling rates (e.g. 0.05, 0.1), and at the same time compare it with classical recovery algorithms, developed from the seminal work by Donoho, et al [1,2] (no neural networks involved), as well as compressed sensing with other generative models (VAE, GAN, Diffusion). The current results and comparison are not convincing. 

[1] Donoho, David L. ""Compressed sensing."" IEEE Transactions on information theory 52.4 (2006): 1289-1306.

[2] Lustig, Michael, et al. ""Compressed sensing MRI."" IEEE signal processing magazine 25.2 (2008): 72-82.

4. The $\lambda_t$ used in Proposition 1 as SNR can also be found in previous work [1], the authors are expected to provide some comparison or discussion with [1] although it is based on Diffusion, it uses MAP structure and solve optimization problem during the sampling process.

[1] Mardani, Morteza, et al. ""A variational perspective on solving inverse problems with diffusion models."" arXiv preprint arXiv:2305.04391 (2023).

5. The number of iterations $K$ affects the performance a lot on different tasks, the authors are expected to provide more explanation on the choice of $K$. Also, how are the $K$ and $\lambda$ picked in the experiments? Given that the testing performances are sensitive to these hyperparameters.

6. The baseline methods compared are limited, only 3 flow based models are picked, generative models have been widely used for image restoration tasks, the authors are expected to provide at least several other representative generative models for comparison.",,,['No ethics review needed.'],5,4,,Yes,3,3,3,1720755770940,,,NeurIPS.cc/2024/Conference,1H2e7USI09,"['NeurIPS.cc/2024/Conference/Submission1142/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878680702,[],2,,,['everyone'],1H2e7USI09,['NeurIPS.cc/2024/Conference/Submission1142/Reviewer_sT2G'],1720755770940,1730878680702,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission1142/Reviewer_sT2G']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. 

The reviewer mentions the following papers that the authors are expected to compare or discuss with:
1. Donoho, David L. ""Compressed sensing."" IEEE Transactions on information theory 52.4 (2006): 1289-1306.
2. Lustig, Michael, et al. ""Compressed sensing MRI."" IEEE signal processing magazine 25.2 (2008): 72-82.
3. Mardani, Morteza, et al. ""A variational perspective on solving inverse problems with diffusion models."" arXiv preprint arXiv:2305.04391 (2023).

The reviewer expects the authors to provide comparisons or discussions with these papers, especially in the context of compressed sensing and solving inverse problems with generative models.",1,"2006, 2008, 2023, 2023",Compressed sensing
PfOWxZuKDR,"The paper proposes a flow prior under the MAP structure for solving inverse problems, a theoretical analysis is also given.","1. The paper is easy to follow, the presentation from concepts to methods is concise, the motivation of the proposed method on overcoming shortage of flow model is also clear and straightforward.
2. Incorporating the flow prior into MAP to solve inverse problems is interesting and worth exploring.
3. The discussion on feasibility of assumptions made in the paper, as well as hyperparameter effects are very informative to the readers, and are valuable to the research in the community.","1. Theorem 1 is trivial in terms of $N \rightarrow 0$, and the existence of constant $c(N)$. The approximation gap converges to 0 as N goes to infinity does not provide insightful guidance on the practical implementation since $N \rightarrow 0$ is infeasible (decreases efficiency) in practice. Also, the implicit representation of approximation error constant $c(N)$ does not make sense because it gives no information about how the error could be scaled with $N$, the authors are expected to provide explicit expression of $c( \cdot )$ as a function of $N$.

2. Obtaining measurements $u_t$ in the ‘corrupted trajectory’ and generating auxiliary path $s_t$ do not make too much sense to me, especially when $x_t$ is very noisy and the forward operator $A(\cdot)$ is challenging. Suppose $A$ is very ill-posed (e.g. compressed sensing with low sampling rate), then the $y_t$ in the auxiliary path is not good itself, nevertheless the measurement $u_t = A(x_t)$ obtained in the corrupted trajectory especially when $x_t$ has high noise level. The assumption on exact compliance of trajectory (between corrupted trajectory and auxiliary path) is not theoretically guaranteed as stated by the authors (line 170-171), and the strong empirical results can not support the existence of the assumption made. The good empirical results could only be valid in less challenging inverse problems, or those inverse problems that are suitable for generative models to solve, e.g. inpainting, super-resolution.

3. In the compressed sensing experiment, the sampling rate $\nu$ is relatively large (0.25, 0.5). The authors are expected to use smaller sampling rates (e.g. 0.05, 0.1), and at the same time compare it with classical recovery algorithms, developed from the seminal work by Donoho, et al [1,2] (no neural networks involved), as well as compressed sensing with other generative models (VAE, GAN, Diffusion). The current results and comparison are not convincing. 

[1] Donoho, David L. ""Compressed sensing."" IEEE Transactions on information theory 52.4 (2006): 1289-1306.

[2] Lustig, Michael, et al. ""Compressed sensing MRI."" IEEE signal processing magazine 25.2 (2008): 72-82.

4. The $\lambda_t$ used in Proposition 1 as SNR can also be found in previous work [1], the authors are expected to provide some comparison or discussion with [1] although it is based on Diffusion, it uses MAP structure and solve optimization problem during the sampling process.

[1] Mardani, Morteza, et al. ""A variational perspective on solving inverse problems with diffusion models."" arXiv preprint arXiv:2305.04391 (2023).

5. The number of iterations $K$ affects the performance a lot on different tasks, the authors are expected to provide more explanation on the choice of $K$. Also, how are the $K$ and $\lambda$ picked in the experiments? Given that the testing performances are sensitive to these hyperparameters.

6. The baseline methods compared are limited, only 3 flow based models are picked, generative models have been widely used for image restoration tasks, the authors are expected to provide at least several other representative generative models for comparison.",,,['No ethics review needed.'],5,4,,Yes,3,3,3,1720755770940,,,NeurIPS.cc/2024/Conference,1H2e7USI09,"['NeurIPS.cc/2024/Conference/Submission1142/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878680702,[],2,,,['everyone'],1H2e7USI09,['NeurIPS.cc/2024/Conference/Submission1142/Reviewer_sT2G'],1720755770940,1730878680702,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission1142/Reviewer_sT2G']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. 

The reviewer mentions the following papers that the authors are expected to compare or discuss with:
1. Donoho, David L. ""Compressed sensing."" IEEE Transactions on information theory 52.4 (2006): 1289-1306.
2. Lustig, Michael, et al. ""Compressed sensing MRI."" IEEE signal processing magazine 25.2 (2008): 72-82.
3. Mardani, Morteza, et al. ""A variational perspective on solving inverse problems with diffusion models."" arXiv preprint arXiv:2305.04391 (2023).

The reviewer expects the authors to provide comparisons or discussions with these papers, especially in the context of compressed sensing and solving inverse problems with generative models.",1,"2006, 2008, 2023, 2023",Compressed sensing MRI
PfOWxZuKDR,"The paper proposes a flow prior under the MAP structure for solving inverse problems, a theoretical analysis is also given.","1. The paper is easy to follow, the presentation from concepts to methods is concise, the motivation of the proposed method on overcoming shortage of flow model is also clear and straightforward.
2. Incorporating the flow prior into MAP to solve inverse problems is interesting and worth exploring.
3. The discussion on feasibility of assumptions made in the paper, as well as hyperparameter effects are very informative to the readers, and are valuable to the research in the community.","1. Theorem 1 is trivial in terms of $N \rightarrow 0$, and the existence of constant $c(N)$. The approximation gap converges to 0 as N goes to infinity does not provide insightful guidance on the practical implementation since $N \rightarrow 0$ is infeasible (decreases efficiency) in practice. Also, the implicit representation of approximation error constant $c(N)$ does not make sense because it gives no information about how the error could be scaled with $N$, the authors are expected to provide explicit expression of $c( \cdot )$ as a function of $N$.

2. Obtaining measurements $u_t$ in the ‘corrupted trajectory’ and generating auxiliary path $s_t$ do not make too much sense to me, especially when $x_t$ is very noisy and the forward operator $A(\cdot)$ is challenging. Suppose $A$ is very ill-posed (e.g. compressed sensing with low sampling rate), then the $y_t$ in the auxiliary path is not good itself, nevertheless the measurement $u_t = A(x_t)$ obtained in the corrupted trajectory especially when $x_t$ has high noise level. The assumption on exact compliance of trajectory (between corrupted trajectory and auxiliary path) is not theoretically guaranteed as stated by the authors (line 170-171), and the strong empirical results can not support the existence of the assumption made. The good empirical results could only be valid in less challenging inverse problems, or those inverse problems that are suitable for generative models to solve, e.g. inpainting, super-resolution.

3. In the compressed sensing experiment, the sampling rate $\nu$ is relatively large (0.25, 0.5). The authors are expected to use smaller sampling rates (e.g. 0.05, 0.1), and at the same time compare it with classical recovery algorithms, developed from the seminal work by Donoho, et al [1,2] (no neural networks involved), as well as compressed sensing with other generative models (VAE, GAN, Diffusion). The current results and comparison are not convincing. 

[1] Donoho, David L. ""Compressed sensing."" IEEE Transactions on information theory 52.4 (2006): 1289-1306.

[2] Lustig, Michael, et al. ""Compressed sensing MRI."" IEEE signal processing magazine 25.2 (2008): 72-82.

4. The $\lambda_t$ used in Proposition 1 as SNR can also be found in previous work [1], the authors are expected to provide some comparison or discussion with [1] although it is based on Diffusion, it uses MAP structure and solve optimization problem during the sampling process.

[1] Mardani, Morteza, et al. ""A variational perspective on solving inverse problems with diffusion models."" arXiv preprint arXiv:2305.04391 (2023).

5. The number of iterations $K$ affects the performance a lot on different tasks, the authors are expected to provide more explanation on the choice of $K$. Also, how are the $K$ and $\lambda$ picked in the experiments? Given that the testing performances are sensitive to these hyperparameters.

6. The baseline methods compared are limited, only 3 flow based models are picked, generative models have been widely used for image restoration tasks, the authors are expected to provide at least several other representative generative models for comparison.",,,['No ethics review needed.'],5,4,,Yes,3,3,3,1720755770940,,,NeurIPS.cc/2024/Conference,1H2e7USI09,"['NeurIPS.cc/2024/Conference/Submission1142/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878680702,[],2,,,['everyone'],1H2e7USI09,['NeurIPS.cc/2024/Conference/Submission1142/Reviewer_sT2G'],1720755770940,1730878680702,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission1142/Reviewer_sT2G']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. 

The reviewer mentions the following papers that the authors are expected to compare or discuss with:
1. Donoho, David L. ""Compressed sensing."" IEEE Transactions on information theory 52.4 (2006): 1289-1306.
2. Lustig, Michael, et al. ""Compressed sensing MRI."" IEEE signal processing magazine 25.2 (2008): 72-82.
3. Mardani, Morteza, et al. ""A variational perspective on solving inverse problems with diffusion models."" arXiv preprint arXiv:2305.04391 (2023).

The reviewer expects the authors to provide comparisons or discussions with these papers, especially in the context of compressed sensing and solving inverse problems with generative models.",1,"2006, 2008, 2023, 2023",A variational perspective on solving inverse problems with diffusion models
HdIoLZgwaI,"This paper proposes a depth-range-free Multi-View Stereo (MVS) method, which iteratively updates the depth using a GRU-based approach. To eliminate the dependency on depth priors, the paper improves the depth initialization method of DispMVS. To fully utilize multi-frame information, the paper encodes the observation information between multiple source frames and the reference frame into features and proposes a Multi-view Disparity Attention module for multi-frame information fusion. To enhance the preservation and utilization of geometric information, the paper introduces 3D pose embedding, uncertainty estimation, and disparity hidden states. The paper has been tested on the DTU and T&T datasets, and the experimental results show that the method exhibits robust depth estimation results in the absence of depth range priors.","-The motivation for the model design is clear, and the experimental results to some extent reflect the effectiveness of the model.

-The experimental results demonstrate that the method can achieve good predictive results without relying on depth priors.","-Poor writing quality: The consistency of the symbols in the paper is poor, such as the left side of Eq. 5 should be V_i(p0); The Fd_i in Fig. 2, Eq. 8, and F^d_i in Sec 3.4, the H_i in Fig. 2 and  Hd_i in Eq. 8; the use of symbols is not standardized, such as the representation of matrices and vectors, the authors are advised to carefully check the entire text; In Eq. 8, there is an extra dot multiplication symbol before phi_4.

-Missing method description: For the final GRU update part, the paper lacks a complete description. My current guess is that the authors use Fd_i and context features as input information to update the hidden state not mentioned in the paper, and decode the residual from this hidden state.

-Incorrect key citation: There is an error in the citation of one of the main comparative methods, DispMVS[5], and the authors are advised to carefully check the reference list. ""Rethinking the multi-view stereo from the perspective of rendering-based augmentation."" -> ""Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity""

-The application of cross-attention is strange: The cross-attention in this paper is only calculated at the same pixel positions in different frames, and the paper emphasizes that there are few continuous smooth trajectories between different frames in MVS, making this design very illogical. The authors are expected to provide a detailed explanation.

-Missing comparisons: CER-MVS [Ⅰ], as an early GRU-based MVS work, should be included in the comparison. Other works such as MVSFormer series[Ⅱ, Ⅲ], GeoMVSNet [Ⅳ] should not be ignored either.  

-Incomplete ablation experiments: There is a lack of separate ablation experiments on uncertainty and disparity feature hidden states, and the existing ablation experiments couple the two together. There is a lack of ablation experiments on the MDA module.

[Ⅰ] Ma, Zeyu, Zachary Teed, and Jia Deng. ""Multiview stereo with cascaded epipolar raft."" ECCV 2022.

[Ⅱ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer: Multi-view stereo by learning robust image features and temperature-based depth."" arXiv preprint arXiv:2208.02541 (2022).

[Ⅲ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo."" ICLR 2024.

[Ⅳ] Zhang, et al. ""Geomvsnet: Learning multi-view stereo with geometry perception."" CVPR 2023.","-The number of Fd_i encoded by the authors is related to the number of source frames. From Fig. 3, it seems that during the GRU update process, they are directly concatenated, which will cause the channel number to be related to the number of source frames. So, if the model uses 5 frames in training and then the number of frames cannot be changed during testing, is that correct?

-From the numerical results and method description, the paper has completely abandoned the use of depth priors now. But if the depth prior is known and the prior is more compact than the depth range calculated in Sec 3.2, can using the depth prior improve the performance of this method?

-As a GRU-type method, how does the accuracy of the estimated results change with the number of iterations?","-Limited performance: From the experimental results, the method in this paper is not outstanding on the benchmark, and the gap with the state-of-the-art methods is quite obvious, even only compared with GRU-based methods (such as CER-MVS).

-Limited novelty: The method in this paper is more like a combination of existing modules.",['No ethics review needed.'],5,5,,Yes,3,1,2,1720799279239,,,NeurIPS.cc/2024/Conference,1FikBPewU9,"['NeurIPS.cc/2024/Conference/Submission7274/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879147671,[],2,,,['everyone'],1FikBPewU9,['NeurIPS.cc/2024/Conference/Submission7274/Reviewer_Q3xc'],1720799279239,1730879147671,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7274/Reviewer_Q3xc']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. 

The reviewer mentions that the authors should include comparisons with other works such as CER-MVS [Ⅰ], MVSFormer series [Ⅱ, Ⅲ], and GeoMVSNet [Ⅳ], and provides the corresponding references. 

[Ⅰ] Ma, Zeyu, Zachary Teed, and Jia Deng. ""Multiview stereo with cascaded epipolar raft."" ECCV 2022.

[Ⅱ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer: Multi-view stereo by learning robust image features and temperature-based depth."" arXiv preprint arXiv:2208.02541 (2022).

[Ⅲ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo."" ICLR 2024.

[Ⅳ] Zhang, et al. ""Geomvsnet: Learning multi-view stereo with geometry perception."" CVPR 2023.

Additionally, the reviewer corrects an incorrect citation of DispMVS and suggests the authors to use the correct title ""Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity"" instead of ""Rethinking the multi-view stereo from the perspective of rendering-based augmentation"".",1,"2022, 2022, 2022, 2024, 2023",Multiview stereo with cascaded epipolar raft
HdIoLZgwaI,"This paper proposes a depth-range-free Multi-View Stereo (MVS) method, which iteratively updates the depth using a GRU-based approach. To eliminate the dependency on depth priors, the paper improves the depth initialization method of DispMVS. To fully utilize multi-frame information, the paper encodes the observation information between multiple source frames and the reference frame into features and proposes a Multi-view Disparity Attention module for multi-frame information fusion. To enhance the preservation and utilization of geometric information, the paper introduces 3D pose embedding, uncertainty estimation, and disparity hidden states. The paper has been tested on the DTU and T&T datasets, and the experimental results show that the method exhibits robust depth estimation results in the absence of depth range priors.","-The motivation for the model design is clear, and the experimental results to some extent reflect the effectiveness of the model.

-The experimental results demonstrate that the method can achieve good predictive results without relying on depth priors.","-Poor writing quality: The consistency of the symbols in the paper is poor, such as the left side of Eq. 5 should be V_i(p0); The Fd_i in Fig. 2, Eq. 8, and F^d_i in Sec 3.4, the H_i in Fig. 2 and  Hd_i in Eq. 8; the use of symbols is not standardized, such as the representation of matrices and vectors, the authors are advised to carefully check the entire text; In Eq. 8, there is an extra dot multiplication symbol before phi_4.

-Missing method description: For the final GRU update part, the paper lacks a complete description. My current guess is that the authors use Fd_i and context features as input information to update the hidden state not mentioned in the paper, and decode the residual from this hidden state.

-Incorrect key citation: There is an error in the citation of one of the main comparative methods, DispMVS[5], and the authors are advised to carefully check the reference list. ""Rethinking the multi-view stereo from the perspective of rendering-based augmentation."" -> ""Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity""

-The application of cross-attention is strange: The cross-attention in this paper is only calculated at the same pixel positions in different frames, and the paper emphasizes that there are few continuous smooth trajectories between different frames in MVS, making this design very illogical. The authors are expected to provide a detailed explanation.

-Missing comparisons: CER-MVS [Ⅰ], as an early GRU-based MVS work, should be included in the comparison. Other works such as MVSFormer series[Ⅱ, Ⅲ], GeoMVSNet [Ⅳ] should not be ignored either.  

-Incomplete ablation experiments: There is a lack of separate ablation experiments on uncertainty and disparity feature hidden states, and the existing ablation experiments couple the two together. There is a lack of ablation experiments on the MDA module.

[Ⅰ] Ma, Zeyu, Zachary Teed, and Jia Deng. ""Multiview stereo with cascaded epipolar raft."" ECCV 2022.

[Ⅱ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer: Multi-view stereo by learning robust image features and temperature-based depth."" arXiv preprint arXiv:2208.02541 (2022).

[Ⅲ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo."" ICLR 2024.

[Ⅳ] Zhang, et al. ""Geomvsnet: Learning multi-view stereo with geometry perception."" CVPR 2023.","-The number of Fd_i encoded by the authors is related to the number of source frames. From Fig. 3, it seems that during the GRU update process, they are directly concatenated, which will cause the channel number to be related to the number of source frames. So, if the model uses 5 frames in training and then the number of frames cannot be changed during testing, is that correct?

-From the numerical results and method description, the paper has completely abandoned the use of depth priors now. But if the depth prior is known and the prior is more compact than the depth range calculated in Sec 3.2, can using the depth prior improve the performance of this method?

-As a GRU-type method, how does the accuracy of the estimated results change with the number of iterations?","-Limited performance: From the experimental results, the method in this paper is not outstanding on the benchmark, and the gap with the state-of-the-art methods is quite obvious, even only compared with GRU-based methods (such as CER-MVS).

-Limited novelty: The method in this paper is more like a combination of existing modules.",['No ethics review needed.'],5,5,,Yes,3,1,2,1720799279239,,,NeurIPS.cc/2024/Conference,1FikBPewU9,"['NeurIPS.cc/2024/Conference/Submission7274/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879147671,[],2,,,['everyone'],1FikBPewU9,['NeurIPS.cc/2024/Conference/Submission7274/Reviewer_Q3xc'],1720799279239,1730879147671,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7274/Reviewer_Q3xc']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. 

The reviewer mentions that the authors should include comparisons with other works such as CER-MVS [Ⅰ], MVSFormer series [Ⅱ, Ⅲ], and GeoMVSNet [Ⅳ], and provides the corresponding references. 

[Ⅰ] Ma, Zeyu, Zachary Teed, and Jia Deng. ""Multiview stereo with cascaded epipolar raft."" ECCV 2022.

[Ⅱ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer: Multi-view stereo by learning robust image features and temperature-based depth."" arXiv preprint arXiv:2208.02541 (2022).

[Ⅲ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo."" ICLR 2024.

[Ⅳ] Zhang, et al. ""Geomvsnet: Learning multi-view stereo with geometry perception."" CVPR 2023.

Additionally, the reviewer corrects an incorrect citation of DispMVS and suggests the authors to use the correct title ""Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity"" instead of ""Rethinking the multi-view stereo from the perspective of rendering-based augmentation"".",1,"2022, 2022, 2022, 2024, 2023",MVSFormer Multi-view stereo by learning robust image features and temperature-based depth
HdIoLZgwaI,"This paper proposes a depth-range-free Multi-View Stereo (MVS) method, which iteratively updates the depth using a GRU-based approach. To eliminate the dependency on depth priors, the paper improves the depth initialization method of DispMVS. To fully utilize multi-frame information, the paper encodes the observation information between multiple source frames and the reference frame into features and proposes a Multi-view Disparity Attention module for multi-frame information fusion. To enhance the preservation and utilization of geometric information, the paper introduces 3D pose embedding, uncertainty estimation, and disparity hidden states. The paper has been tested on the DTU and T&T datasets, and the experimental results show that the method exhibits robust depth estimation results in the absence of depth range priors.","-The motivation for the model design is clear, and the experimental results to some extent reflect the effectiveness of the model.

-The experimental results demonstrate that the method can achieve good predictive results without relying on depth priors.","-Poor writing quality: The consistency of the symbols in the paper is poor, such as the left side of Eq. 5 should be V_i(p0); The Fd_i in Fig. 2, Eq. 8, and F^d_i in Sec 3.4, the H_i in Fig. 2 and  Hd_i in Eq. 8; the use of symbols is not standardized, such as the representation of matrices and vectors, the authors are advised to carefully check the entire text; In Eq. 8, there is an extra dot multiplication symbol before phi_4.

-Missing method description: For the final GRU update part, the paper lacks a complete description. My current guess is that the authors use Fd_i and context features as input information to update the hidden state not mentioned in the paper, and decode the residual from this hidden state.

-Incorrect key citation: There is an error in the citation of one of the main comparative methods, DispMVS[5], and the authors are advised to carefully check the reference list. ""Rethinking the multi-view stereo from the perspective of rendering-based augmentation."" -> ""Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity""

-The application of cross-attention is strange: The cross-attention in this paper is only calculated at the same pixel positions in different frames, and the paper emphasizes that there are few continuous smooth trajectories between different frames in MVS, making this design very illogical. The authors are expected to provide a detailed explanation.

-Missing comparisons: CER-MVS [Ⅰ], as an early GRU-based MVS work, should be included in the comparison. Other works such as MVSFormer series[Ⅱ, Ⅲ], GeoMVSNet [Ⅳ] should not be ignored either.  

-Incomplete ablation experiments: There is a lack of separate ablation experiments on uncertainty and disparity feature hidden states, and the existing ablation experiments couple the two together. There is a lack of ablation experiments on the MDA module.

[Ⅰ] Ma, Zeyu, Zachary Teed, and Jia Deng. ""Multiview stereo with cascaded epipolar raft."" ECCV 2022.

[Ⅱ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer: Multi-view stereo by learning robust image features and temperature-based depth."" arXiv preprint arXiv:2208.02541 (2022).

[Ⅲ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo."" ICLR 2024.

[Ⅳ] Zhang, et al. ""Geomvsnet: Learning multi-view stereo with geometry perception."" CVPR 2023.","-The number of Fd_i encoded by the authors is related to the number of source frames. From Fig. 3, it seems that during the GRU update process, they are directly concatenated, which will cause the channel number to be related to the number of source frames. So, if the model uses 5 frames in training and then the number of frames cannot be changed during testing, is that correct?

-From the numerical results and method description, the paper has completely abandoned the use of depth priors now. But if the depth prior is known and the prior is more compact than the depth range calculated in Sec 3.2, can using the depth prior improve the performance of this method?

-As a GRU-type method, how does the accuracy of the estimated results change with the number of iterations?","-Limited performance: From the experimental results, the method in this paper is not outstanding on the benchmark, and the gap with the state-of-the-art methods is quite obvious, even only compared with GRU-based methods (such as CER-MVS).

-Limited novelty: The method in this paper is more like a combination of existing modules.",['No ethics review needed.'],5,5,,Yes,3,1,2,1720799279239,,,NeurIPS.cc/2024/Conference,1FikBPewU9,"['NeurIPS.cc/2024/Conference/Submission7274/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879147671,[],2,,,['everyone'],1FikBPewU9,['NeurIPS.cc/2024/Conference/Submission7274/Reviewer_Q3xc'],1720799279239,1730879147671,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7274/Reviewer_Q3xc']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. 

The reviewer mentions that the authors should include comparisons with other works such as CER-MVS [Ⅰ], MVSFormer series [Ⅱ, Ⅲ], and GeoMVSNet [Ⅳ], and provides the corresponding references. 

[Ⅰ] Ma, Zeyu, Zachary Teed, and Jia Deng. ""Multiview stereo with cascaded epipolar raft."" ECCV 2022.

[Ⅱ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer: Multi-view stereo by learning robust image features and temperature-based depth."" arXiv preprint arXiv:2208.02541 (2022).

[Ⅲ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo."" ICLR 2024.

[Ⅳ] Zhang, et al. ""Geomvsnet: Learning multi-view stereo with geometry perception."" CVPR 2023.

Additionally, the reviewer corrects an incorrect citation of DispMVS and suggests the authors to use the correct title ""Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity"" instead of ""Rethinking the multi-view stereo from the perspective of rendering-based augmentation"".",1,"2022, 2022, 2022, 2024, 2023",MVSFormer Revealing the Devil in Transformer's Details for Multi-View Stereo
HdIoLZgwaI,"This paper proposes a depth-range-free Multi-View Stereo (MVS) method, which iteratively updates the depth using a GRU-based approach. To eliminate the dependency on depth priors, the paper improves the depth initialization method of DispMVS. To fully utilize multi-frame information, the paper encodes the observation information between multiple source frames and the reference frame into features and proposes a Multi-view Disparity Attention module for multi-frame information fusion. To enhance the preservation and utilization of geometric information, the paper introduces 3D pose embedding, uncertainty estimation, and disparity hidden states. The paper has been tested on the DTU and T&T datasets, and the experimental results show that the method exhibits robust depth estimation results in the absence of depth range priors.","-The motivation for the model design is clear, and the experimental results to some extent reflect the effectiveness of the model.

-The experimental results demonstrate that the method can achieve good predictive results without relying on depth priors.","-Poor writing quality: The consistency of the symbols in the paper is poor, such as the left side of Eq. 5 should be V_i(p0); The Fd_i in Fig. 2, Eq. 8, and F^d_i in Sec 3.4, the H_i in Fig. 2 and  Hd_i in Eq. 8; the use of symbols is not standardized, such as the representation of matrices and vectors, the authors are advised to carefully check the entire text; In Eq. 8, there is an extra dot multiplication symbol before phi_4.

-Missing method description: For the final GRU update part, the paper lacks a complete description. My current guess is that the authors use Fd_i and context features as input information to update the hidden state not mentioned in the paper, and decode the residual from this hidden state.

-Incorrect key citation: There is an error in the citation of one of the main comparative methods, DispMVS[5], and the authors are advised to carefully check the reference list. ""Rethinking the multi-view stereo from the perspective of rendering-based augmentation."" -> ""Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity""

-The application of cross-attention is strange: The cross-attention in this paper is only calculated at the same pixel positions in different frames, and the paper emphasizes that there are few continuous smooth trajectories between different frames in MVS, making this design very illogical. The authors are expected to provide a detailed explanation.

-Missing comparisons: CER-MVS [Ⅰ], as an early GRU-based MVS work, should be included in the comparison. Other works such as MVSFormer series[Ⅱ, Ⅲ], GeoMVSNet [Ⅳ] should not be ignored either.  

-Incomplete ablation experiments: There is a lack of separate ablation experiments on uncertainty and disparity feature hidden states, and the existing ablation experiments couple the two together. There is a lack of ablation experiments on the MDA module.

[Ⅰ] Ma, Zeyu, Zachary Teed, and Jia Deng. ""Multiview stereo with cascaded epipolar raft."" ECCV 2022.

[Ⅱ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer: Multi-view stereo by learning robust image features and temperature-based depth."" arXiv preprint arXiv:2208.02541 (2022).

[Ⅲ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo."" ICLR 2024.

[Ⅳ] Zhang, et al. ""Geomvsnet: Learning multi-view stereo with geometry perception."" CVPR 2023.","-The number of Fd_i encoded by the authors is related to the number of source frames. From Fig. 3, it seems that during the GRU update process, they are directly concatenated, which will cause the channel number to be related to the number of source frames. So, if the model uses 5 frames in training and then the number of frames cannot be changed during testing, is that correct?

-From the numerical results and method description, the paper has completely abandoned the use of depth priors now. But if the depth prior is known and the prior is more compact than the depth range calculated in Sec 3.2, can using the depth prior improve the performance of this method?

-As a GRU-type method, how does the accuracy of the estimated results change with the number of iterations?","-Limited performance: From the experimental results, the method in this paper is not outstanding on the benchmark, and the gap with the state-of-the-art methods is quite obvious, even only compared with GRU-based methods (such as CER-MVS).

-Limited novelty: The method in this paper is more like a combination of existing modules.",['No ethics review needed.'],5,5,,Yes,3,1,2,1720799279239,,,NeurIPS.cc/2024/Conference,1FikBPewU9,"['NeurIPS.cc/2024/Conference/Submission7274/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879147671,[],2,,,['everyone'],1FikBPewU9,['NeurIPS.cc/2024/Conference/Submission7274/Reviewer_Q3xc'],1720799279239,1730879147671,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7274/Reviewer_Q3xc']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. 

The reviewer mentions that the authors should include comparisons with other works such as CER-MVS [Ⅰ], MVSFormer series [Ⅱ, Ⅲ], and GeoMVSNet [Ⅳ], and provides the corresponding references. 

[Ⅰ] Ma, Zeyu, Zachary Teed, and Jia Deng. ""Multiview stereo with cascaded epipolar raft."" ECCV 2022.

[Ⅱ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer: Multi-view stereo by learning robust image features and temperature-based depth."" arXiv preprint arXiv:2208.02541 (2022).

[Ⅲ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo."" ICLR 2024.

[Ⅳ] Zhang, et al. ""Geomvsnet: Learning multi-view stereo with geometry perception."" CVPR 2023.

Additionally, the reviewer corrects an incorrect citation of DispMVS and suggests the authors to use the correct title ""Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity"" instead of ""Rethinking the multi-view stereo from the perspective of rendering-based augmentation"".",1,"2022, 2022, 2022, 2024, 2023",Geomvsnet Learning multi-view stereo with geometry perception
HdIoLZgwaI,"This paper proposes a depth-range-free Multi-View Stereo (MVS) method, which iteratively updates the depth using a GRU-based approach. To eliminate the dependency on depth priors, the paper improves the depth initialization method of DispMVS. To fully utilize multi-frame information, the paper encodes the observation information between multiple source frames and the reference frame into features and proposes a Multi-view Disparity Attention module for multi-frame information fusion. To enhance the preservation and utilization of geometric information, the paper introduces 3D pose embedding, uncertainty estimation, and disparity hidden states. The paper has been tested on the DTU and T&T datasets, and the experimental results show that the method exhibits robust depth estimation results in the absence of depth range priors.","-The motivation for the model design is clear, and the experimental results to some extent reflect the effectiveness of the model.

-The experimental results demonstrate that the method can achieve good predictive results without relying on depth priors.","-Poor writing quality: The consistency of the symbols in the paper is poor, such as the left side of Eq. 5 should be V_i(p0); The Fd_i in Fig. 2, Eq. 8, and F^d_i in Sec 3.4, the H_i in Fig. 2 and  Hd_i in Eq. 8; the use of symbols is not standardized, such as the representation of matrices and vectors, the authors are advised to carefully check the entire text; In Eq. 8, there is an extra dot multiplication symbol before phi_4.

-Missing method description: For the final GRU update part, the paper lacks a complete description. My current guess is that the authors use Fd_i and context features as input information to update the hidden state not mentioned in the paper, and decode the residual from this hidden state.

-Incorrect key citation: There is an error in the citation of one of the main comparative methods, DispMVS[5], and the authors are advised to carefully check the reference list. ""Rethinking the multi-view stereo from the perspective of rendering-based augmentation."" -> ""Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity""

-The application of cross-attention is strange: The cross-attention in this paper is only calculated at the same pixel positions in different frames, and the paper emphasizes that there are few continuous smooth trajectories between different frames in MVS, making this design very illogical. The authors are expected to provide a detailed explanation.

-Missing comparisons: CER-MVS [Ⅰ], as an early GRU-based MVS work, should be included in the comparison. Other works such as MVSFormer series[Ⅱ, Ⅲ], GeoMVSNet [Ⅳ] should not be ignored either.  

-Incomplete ablation experiments: There is a lack of separate ablation experiments on uncertainty and disparity feature hidden states, and the existing ablation experiments couple the two together. There is a lack of ablation experiments on the MDA module.

[Ⅰ] Ma, Zeyu, Zachary Teed, and Jia Deng. ""Multiview stereo with cascaded epipolar raft."" ECCV 2022.

[Ⅱ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer: Multi-view stereo by learning robust image features and temperature-based depth."" arXiv preprint arXiv:2208.02541 (2022).

[Ⅲ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo."" ICLR 2024.

[Ⅳ] Zhang, et al. ""Geomvsnet: Learning multi-view stereo with geometry perception."" CVPR 2023.","-The number of Fd_i encoded by the authors is related to the number of source frames. From Fig. 3, it seems that during the GRU update process, they are directly concatenated, which will cause the channel number to be related to the number of source frames. So, if the model uses 5 frames in training and then the number of frames cannot be changed during testing, is that correct?

-From the numerical results and method description, the paper has completely abandoned the use of depth priors now. But if the depth prior is known and the prior is more compact than the depth range calculated in Sec 3.2, can using the depth prior improve the performance of this method?

-As a GRU-type method, how does the accuracy of the estimated results change with the number of iterations?","-Limited performance: From the experimental results, the method in this paper is not outstanding on the benchmark, and the gap with the state-of-the-art methods is quite obvious, even only compared with GRU-based methods (such as CER-MVS).

-Limited novelty: The method in this paper is more like a combination of existing modules.",['No ethics review needed.'],5,5,,Yes,3,1,2,1720799279239,,,NeurIPS.cc/2024/Conference,1FikBPewU9,"['NeurIPS.cc/2024/Conference/Submission7274/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879147671,[],2,,,['everyone'],1FikBPewU9,['NeurIPS.cc/2024/Conference/Submission7274/Reviewer_Q3xc'],1720799279239,1730879147671,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission7274/Reviewer_Q3xc']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. 

The reviewer mentions that the authors should include comparisons with other works such as CER-MVS [Ⅰ], MVSFormer series [Ⅱ, Ⅲ], and GeoMVSNet [Ⅳ], and provides the corresponding references. 

[Ⅰ] Ma, Zeyu, Zachary Teed, and Jia Deng. ""Multiview stereo with cascaded epipolar raft."" ECCV 2022.

[Ⅱ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer: Multi-view stereo by learning robust image features and temperature-based depth."" arXiv preprint arXiv:2208.02541 (2022).

[Ⅲ] Cao, Chenjie, Xinlin Ren, and Yanwei Fu. ""MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo."" ICLR 2024.

[Ⅳ] Zhang, et al. ""Geomvsnet: Learning multi-view stereo with geometry perception."" CVPR 2023.

Additionally, the reviewer corrects an incorrect citation of DispMVS and suggests the authors to use the correct title ""Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity"" instead of ""Rethinking the multi-view stereo from the perspective of rendering-based augmentation"".",1,"2022, 2022, 2022, 2024, 2023",Rethinking Disparity A Depth Range Free Multi-View Stereo Based on Disparity
TFzdHXeFb3,"This work introduces $\alpha$-DSBM, a new way of training DSBM-like models, which does not require a Markovian projection at each step and eliminates the need to train multiple models. The main advantage over previous DSBM-based approaches is that $\alpha$-DSBM only needs to train a single model with a single model, thus exhibiting a more stable training procedure.

The authors thoroughly contextualize their work within related work and provide detailed theoretical derivations to motivate their approach. Empirically $\alpha$-DSBM is validated by comparing to existing DSBM-based approaches across different unpaired image translation tasks as well as some toy data examples.","- The new $\alpha$-DSBM is introduced based on thorough theoretical motivation and derivations.
- The authors manage to present and contextualize their method very clearly within the scope of related work across the different bridge matching approaches (Appendix E) and highlight connections accordingly (e.g. connection to the reflow procedure).
- In general, the paper is well-written and, given the complexity of the topic, quite clear to follow.
- Empirical validation includes important ablations giving further insights into the hyperparameter choice of e.g. $\varepsilon$.","- While the experimental section of the paper thoroughly analyzes and compares DSBM and its different flavors, including the proposed method, a comparison with other competing methods could further support $\alpha$-DSBM through empirical evidence. Specifically, a comparison to bridge/flow matching with mini-batch OT similar to [1, 2], a highly optimized CycleGAN as in [3], and adversarial-based OT methods like [4] could be good candidates for further comparisons. The authors also mention these as competing methods.


[1] Alexander Tong and Kilian Fatras and Nikolay Malkin and Guillaume Huguet and Yanlei Zhang and Jarrid Rector-Brooks and Guy Wolf and Yoshua Bengio. ""# Improving and generalizing flow-based generative models with minibatch optimal transport"". IN TMLR 2024.

[2] Luca Eyring and Dominik Klein and Théo Uscidda and Giovanni Palla and Niki Kilbertus and Zeynep Akata and Fabian Theis. ""Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation"". In ICLR 2024.

[3] Dmitrii Torbunov and Yi Huang and Huan-Hsin Tseng and Haiwang Yu and Jin Huang and Shinjae Yoo and Meifeng Lin and Brett Viren and Yihui Ren. ""UVCGAN v2: An Improved Cycle-Consistent GAN for Unpaired Image-to-Image Translation"". In Arxiv 2023.

[4] Beomsu Kim and Gihyun Kwon and Kwanyoung Kim and Jong Chul Ye. ""Unpaired Image-to-Image Translation via Neural Schrödinger Bridge"". In ICLR 2024.","- How does $\alpha$-DSBM perform compared to bridge matching with mini-batch OT sampling empirically? While it is clear that these methods introduce significant errors because of the mini-batch approximation, it is unclear how this affects results empirically compared to $\alpha$-DSBM. I think this is the most important additional competing work (apart from DSBM), as these methods share their overall goal.
- Does it make sense to combine $\alpha$-DSBM with mini-batch OT sampling for the initial pretraining? How would this impact $\alpha$-DSBM?","- The main limitation of $\alpha$-DSBM is that new data needs to be generated with the current model during its fine-tuning, making the procedure not simulation-free and, thus, more expensive. This is sufficiently addressed in the paper.",['No ethics review needed.'],7,4,,Yes,3,4,3,1720809059231,,,NeurIPS.cc/2024/Conference,1F32iCJFfa,"['NeurIPS.cc/2024/Conference/Submission11179/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879446749,[],3,,,['everyone'],1F32iCJFfa,['NeurIPS.cc/2024/Conference/Submission11179/Reviewer_xpT6'],1720809059231,1730879446749,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11179/Reviewer_xpT6']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Alexander Tong et al. (2024) - ""Improving and generalizing flow-based generative models with minibatch optimal transport""
2. Luca Eyring et al. (2024) - ""Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation""
3. Dmitrii Torbunov et al. (2023) - ""UVCGAN v2: An Improved Cycle-Consistent GAN for Unpaired Image-to-Image Translation""
4. Beomsu Kim et al. (2024) - ""Unpaired Image-to-Image Translation via Neural Schrödinger Bridge""

The reviewer suggests that comparing $\alpha$-DSBM to these competing methods could further support the proposed method through empirical evidence.",1,"2024, 2024, 2023, 2024",Improving and generalizing flow-based generative models with minibatch optimal transport
TFzdHXeFb3,"This work introduces $\alpha$-DSBM, a new way of training DSBM-like models, which does not require a Markovian projection at each step and eliminates the need to train multiple models. The main advantage over previous DSBM-based approaches is that $\alpha$-DSBM only needs to train a single model with a single model, thus exhibiting a more stable training procedure.

The authors thoroughly contextualize their work within related work and provide detailed theoretical derivations to motivate their approach. Empirically $\alpha$-DSBM is validated by comparing to existing DSBM-based approaches across different unpaired image translation tasks as well as some toy data examples.","- The new $\alpha$-DSBM is introduced based on thorough theoretical motivation and derivations.
- The authors manage to present and contextualize their method very clearly within the scope of related work across the different bridge matching approaches (Appendix E) and highlight connections accordingly (e.g. connection to the reflow procedure).
- In general, the paper is well-written and, given the complexity of the topic, quite clear to follow.
- Empirical validation includes important ablations giving further insights into the hyperparameter choice of e.g. $\varepsilon$.","- While the experimental section of the paper thoroughly analyzes and compares DSBM and its different flavors, including the proposed method, a comparison with other competing methods could further support $\alpha$-DSBM through empirical evidence. Specifically, a comparison to bridge/flow matching with mini-batch OT similar to [1, 2], a highly optimized CycleGAN as in [3], and adversarial-based OT methods like [4] could be good candidates for further comparisons. The authors also mention these as competing methods.


[1] Alexander Tong and Kilian Fatras and Nikolay Malkin and Guillaume Huguet and Yanlei Zhang and Jarrid Rector-Brooks and Guy Wolf and Yoshua Bengio. ""# Improving and generalizing flow-based generative models with minibatch optimal transport"". IN TMLR 2024.

[2] Luca Eyring and Dominik Klein and Théo Uscidda and Giovanni Palla and Niki Kilbertus and Zeynep Akata and Fabian Theis. ""Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation"". In ICLR 2024.

[3] Dmitrii Torbunov and Yi Huang and Huan-Hsin Tseng and Haiwang Yu and Jin Huang and Shinjae Yoo and Meifeng Lin and Brett Viren and Yihui Ren. ""UVCGAN v2: An Improved Cycle-Consistent GAN for Unpaired Image-to-Image Translation"". In Arxiv 2023.

[4] Beomsu Kim and Gihyun Kwon and Kwanyoung Kim and Jong Chul Ye. ""Unpaired Image-to-Image Translation via Neural Schrödinger Bridge"". In ICLR 2024.","- How does $\alpha$-DSBM perform compared to bridge matching with mini-batch OT sampling empirically? While it is clear that these methods introduce significant errors because of the mini-batch approximation, it is unclear how this affects results empirically compared to $\alpha$-DSBM. I think this is the most important additional competing work (apart from DSBM), as these methods share their overall goal.
- Does it make sense to combine $\alpha$-DSBM with mini-batch OT sampling for the initial pretraining? How would this impact $\alpha$-DSBM?","- The main limitation of $\alpha$-DSBM is that new data needs to be generated with the current model during its fine-tuning, making the procedure not simulation-free and, thus, more expensive. This is sufficiently addressed in the paper.",['No ethics review needed.'],7,4,,Yes,3,4,3,1720809059231,,,NeurIPS.cc/2024/Conference,1F32iCJFfa,"['NeurIPS.cc/2024/Conference/Submission11179/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879446749,[],3,,,['everyone'],1F32iCJFfa,['NeurIPS.cc/2024/Conference/Submission11179/Reviewer_xpT6'],1720809059231,1730879446749,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11179/Reviewer_xpT6']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Alexander Tong et al. (2024) - ""Improving and generalizing flow-based generative models with minibatch optimal transport""
2. Luca Eyring et al. (2024) - ""Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation""
3. Dmitrii Torbunov et al. (2023) - ""UVCGAN v2: An Improved Cycle-Consistent GAN for Unpaired Image-to-Image Translation""
4. Beomsu Kim et al. (2024) - ""Unpaired Image-to-Image Translation via Neural Schrödinger Bridge""

The reviewer suggests that comparing $\alpha$-DSBM to these competing methods could further support the proposed method through empirical evidence.",1,"2024, 2024, 2023, 2024",Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation
TFzdHXeFb3,"This work introduces $\alpha$-DSBM, a new way of training DSBM-like models, which does not require a Markovian projection at each step and eliminates the need to train multiple models. The main advantage over previous DSBM-based approaches is that $\alpha$-DSBM only needs to train a single model with a single model, thus exhibiting a more stable training procedure.

The authors thoroughly contextualize their work within related work and provide detailed theoretical derivations to motivate their approach. Empirically $\alpha$-DSBM is validated by comparing to existing DSBM-based approaches across different unpaired image translation tasks as well as some toy data examples.","- The new $\alpha$-DSBM is introduced based on thorough theoretical motivation and derivations.
- The authors manage to present and contextualize their method very clearly within the scope of related work across the different bridge matching approaches (Appendix E) and highlight connections accordingly (e.g. connection to the reflow procedure).
- In general, the paper is well-written and, given the complexity of the topic, quite clear to follow.
- Empirical validation includes important ablations giving further insights into the hyperparameter choice of e.g. $\varepsilon$.","- While the experimental section of the paper thoroughly analyzes and compares DSBM and its different flavors, including the proposed method, a comparison with other competing methods could further support $\alpha$-DSBM through empirical evidence. Specifically, a comparison to bridge/flow matching with mini-batch OT similar to [1, 2], a highly optimized CycleGAN as in [3], and adversarial-based OT methods like [4] could be good candidates for further comparisons. The authors also mention these as competing methods.


[1] Alexander Tong and Kilian Fatras and Nikolay Malkin and Guillaume Huguet and Yanlei Zhang and Jarrid Rector-Brooks and Guy Wolf and Yoshua Bengio. ""# Improving and generalizing flow-based generative models with minibatch optimal transport"". IN TMLR 2024.

[2] Luca Eyring and Dominik Klein and Théo Uscidda and Giovanni Palla and Niki Kilbertus and Zeynep Akata and Fabian Theis. ""Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation"". In ICLR 2024.

[3] Dmitrii Torbunov and Yi Huang and Huan-Hsin Tseng and Haiwang Yu and Jin Huang and Shinjae Yoo and Meifeng Lin and Brett Viren and Yihui Ren. ""UVCGAN v2: An Improved Cycle-Consistent GAN for Unpaired Image-to-Image Translation"". In Arxiv 2023.

[4] Beomsu Kim and Gihyun Kwon and Kwanyoung Kim and Jong Chul Ye. ""Unpaired Image-to-Image Translation via Neural Schrödinger Bridge"". In ICLR 2024.","- How does $\alpha$-DSBM perform compared to bridge matching with mini-batch OT sampling empirically? While it is clear that these methods introduce significant errors because of the mini-batch approximation, it is unclear how this affects results empirically compared to $\alpha$-DSBM. I think this is the most important additional competing work (apart from DSBM), as these methods share their overall goal.
- Does it make sense to combine $\alpha$-DSBM with mini-batch OT sampling for the initial pretraining? How would this impact $\alpha$-DSBM?","- The main limitation of $\alpha$-DSBM is that new data needs to be generated with the current model during its fine-tuning, making the procedure not simulation-free and, thus, more expensive. This is sufficiently addressed in the paper.",['No ethics review needed.'],7,4,,Yes,3,4,3,1720809059231,,,NeurIPS.cc/2024/Conference,1F32iCJFfa,"['NeurIPS.cc/2024/Conference/Submission11179/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879446749,[],3,,,['everyone'],1F32iCJFfa,['NeurIPS.cc/2024/Conference/Submission11179/Reviewer_xpT6'],1720809059231,1730879446749,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11179/Reviewer_xpT6']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Alexander Tong et al. (2024) - ""Improving and generalizing flow-based generative models with minibatch optimal transport""
2. Luca Eyring et al. (2024) - ""Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation""
3. Dmitrii Torbunov et al. (2023) - ""UVCGAN v2: An Improved Cycle-Consistent GAN for Unpaired Image-to-Image Translation""
4. Beomsu Kim et al. (2024) - ""Unpaired Image-to-Image Translation via Neural Schrödinger Bridge""

The reviewer suggests that comparing $\alpha$-DSBM to these competing methods could further support the proposed method through empirical evidence.",1,"2024, 2024, 2023, 2024",UVCGAN v2 An Improved Cycle-Consistent GAN for Unpaired Image-to-Image Translation
TFzdHXeFb3,"This work introduces $\alpha$-DSBM, a new way of training DSBM-like models, which does not require a Markovian projection at each step and eliminates the need to train multiple models. The main advantage over previous DSBM-based approaches is that $\alpha$-DSBM only needs to train a single model with a single model, thus exhibiting a more stable training procedure.

The authors thoroughly contextualize their work within related work and provide detailed theoretical derivations to motivate their approach. Empirically $\alpha$-DSBM is validated by comparing to existing DSBM-based approaches across different unpaired image translation tasks as well as some toy data examples.","- The new $\alpha$-DSBM is introduced based on thorough theoretical motivation and derivations.
- The authors manage to present and contextualize their method very clearly within the scope of related work across the different bridge matching approaches (Appendix E) and highlight connections accordingly (e.g. connection to the reflow procedure).
- In general, the paper is well-written and, given the complexity of the topic, quite clear to follow.
- Empirical validation includes important ablations giving further insights into the hyperparameter choice of e.g. $\varepsilon$.","- While the experimental section of the paper thoroughly analyzes and compares DSBM and its different flavors, including the proposed method, a comparison with other competing methods could further support $\alpha$-DSBM through empirical evidence. Specifically, a comparison to bridge/flow matching with mini-batch OT similar to [1, 2], a highly optimized CycleGAN as in [3], and adversarial-based OT methods like [4] could be good candidates for further comparisons. The authors also mention these as competing methods.


[1] Alexander Tong and Kilian Fatras and Nikolay Malkin and Guillaume Huguet and Yanlei Zhang and Jarrid Rector-Brooks and Guy Wolf and Yoshua Bengio. ""# Improving and generalizing flow-based generative models with minibatch optimal transport"". IN TMLR 2024.

[2] Luca Eyring and Dominik Klein and Théo Uscidda and Giovanni Palla and Niki Kilbertus and Zeynep Akata and Fabian Theis. ""Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation"". In ICLR 2024.

[3] Dmitrii Torbunov and Yi Huang and Huan-Hsin Tseng and Haiwang Yu and Jin Huang and Shinjae Yoo and Meifeng Lin and Brett Viren and Yihui Ren. ""UVCGAN v2: An Improved Cycle-Consistent GAN for Unpaired Image-to-Image Translation"". In Arxiv 2023.

[4] Beomsu Kim and Gihyun Kwon and Kwanyoung Kim and Jong Chul Ye. ""Unpaired Image-to-Image Translation via Neural Schrödinger Bridge"". In ICLR 2024.","- How does $\alpha$-DSBM perform compared to bridge matching with mini-batch OT sampling empirically? While it is clear that these methods introduce significant errors because of the mini-batch approximation, it is unclear how this affects results empirically compared to $\alpha$-DSBM. I think this is the most important additional competing work (apart from DSBM), as these methods share their overall goal.
- Does it make sense to combine $\alpha$-DSBM with mini-batch OT sampling for the initial pretraining? How would this impact $\alpha$-DSBM?","- The main limitation of $\alpha$-DSBM is that new data needs to be generated with the current model during its fine-tuning, making the procedure not simulation-free and, thus, more expensive. This is sufficiently addressed in the paper.",['No ethics review needed.'],7,4,,Yes,3,4,3,1720809059231,,,NeurIPS.cc/2024/Conference,1F32iCJFfa,"['NeurIPS.cc/2024/Conference/Submission11179/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879446749,[],3,,,['everyone'],1F32iCJFfa,['NeurIPS.cc/2024/Conference/Submission11179/Reviewer_xpT6'],1720809059231,1730879446749,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11179/Reviewer_xpT6']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Alexander Tong et al. (2024) - ""Improving and generalizing flow-based generative models with minibatch optimal transport""
2. Luca Eyring et al. (2024) - ""Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation""
3. Dmitrii Torbunov et al. (2023) - ""UVCGAN v2: An Improved Cycle-Consistent GAN for Unpaired Image-to-Image Translation""
4. Beomsu Kim et al. (2024) - ""Unpaired Image-to-Image Translation via Neural Schrödinger Bridge""

The reviewer suggests that comparing $\alpha$-DSBM to these competing methods could further support the proposed method through empirical evidence.",1,"2024, 2024, 2023, 2024",Unpaired Image-to-Image Translation via Neural Schrödinger Bridge
WPPuGH5ltA,"This paper describes a new formulation of GAN-based speech enhancement. It includes an analysis of the convexity in different feature spaces of the distribution of TTS utterances generated from the same inputs, concluding that WavLM's convolutional encoders provide the most convex such space. This representation is then incorporated into the input of HiFi++ and also a separate, unrelated upsampling stage is added at the end.

On the VoxCeleb real data validation set and the validation data of UNIVERSE, the proposed approach outperforms other strong baselines in both quality (MOS from a subjective listening test and other objective metrics) as well as in realtime factor. For example, on VoxCeleb, the proposed system is rated at 4.63 MOS compared to the second best system HiFi-Gan-2 at 4.47 while the proposed system is ~15x faster. For systems with comparable RTFs, the difference in MOS is 4.63 vs 3.79 for DEMUCS.","Significance:
* The argument for the relevance of GANs to speech enhancement is thoughtful, interesting, and convincing. It brings clarity on a point that I did not previously appreciate.
* Analysis of the different feature spaces in terms of their convexity is another valuable and interesting contribution. It provides clearly actionable findings that are shown in the experiments to make a meaningful difference to system performance. This analysis can be applied more broadly to compare different SSL representations for various tasks.

System performance:
* Improving both the performance and the efficiency of a speech enhancement system is quite valuable and these differences appear to be large compared with strong baselines.
* Listening to the provided audio examples in the supplementary material shows impressive performance, especially in comparison to the halucinations of UNIVERSE in low-SNR instances, although it is not clear how these particular examples were selected.

Clarity:
* The paper is well written and easy to follow. The figures are helpful in understanding it. The description of the loss and different training stages is particularly clear and helpful.
* The ablations are thorough and informative and show clear benefits to each of the stages of the model/training.","One point that could be added to the discussion of previous work is that of Maiti and Mandel (2019) and related work, which introduced the idea of speech enhancement by synthesis of a clean utterance that contains the same content as the original utterance.

The evaluation was conducted on a crowdsourcing platform without IRB review. This should be reviewed by ethics reviewers.

S Maiti and M Mandel (2019). Parametric resynthesis with neural vocoders. Proc. IEEE WASPAA.

Minor comments:
* Line 187 states, ""we report MOS score"" but it does not state where this MOS score comes from. Please describe the experiment/measurement that generated the MOS scores. Presumably it was the human listening test described in the appendix, but this is not clear at this point in the manuscript.
* Equation (2): please define phi
* Line 299 calls losses based on UTMOS and PESQ ""human feedback"" losses, but since these are algorithms predicting human feedback, I don't think their outputs can be called human feedback itself.",,"Limitations of the approach are discussed in the appendix, section D.4. The limitation of this approach being non-streaming is mentioned there and is important to highlight.",['Ethics review needed: Research involving human subjects'],8,4,,Yes,3,3,3,1720874004642,,,NeurIPS.cc/2024/Conference,18RdkSv9h9,"['NeurIPS.cc/2024/Conference/Submission11256/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879451502,[],4,,,['everyone'],18RdkSv9h9,['NeurIPS.cc/2024/Conference/Submission11256/Reviewer_dAZE'],1720874004642,1730879451502,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11256/Reviewer_dAZE']","Yes, the peer review explicitly suggests the authors of the paper to cite the work of Maiti and Mandel (2019), specifically their paper ""Parametric resynthesis with neural vocoders"" (Proc. IEEE WASPAA).",1,2019,Parametric resynthesis with neural vocoders
xVet5ngD59,"The authors propose a method for debiasing the representations of Vision-Language Models (VLMs) that can be applied at various layers of the image and text encoders/decoders, and can be used for a variety of downstream tasks such as image generation, 0-shot classification, text to image retrieval, and image captioning.","- This work's goal of debiasing VLMs is an important and timely problem that should be of interest to many in the NeurIPS community 
- The proposed approach is seemingly effective, lightweight and seems easy to apply
- The method is finetuning-free, which mitigates issues such as catastrophic forgetting","**Minor issues:**

- The writing could be improved in parts. There are minor grammatical errors in parts, such as ""For instance, Hirota et al. [18], Zhao et al. [42] investigated bias in image captioning, where specific genders or races are disproportionately represented **leading to generate** biased caption."" I suggest another editing pass or two.
- I find the structure of section 3 ""Bias Analysis in VLMs"" is a little odd. It mostly reads like background/preliminary material, but it also contains some experimental setup details (such as in line 165). This seems off, as this is before the proposed method section. I suggest moving these experimental details to section 5, with the rest of the experimental setup. 
- Figure 4 shows that DeAR fails to produce bias-free representations. Including a figure likes this naturally makes the reader want to see a figure showing that the proposed approach **does** succeed here. It feels incomplete as-is. 

**More significant issues:**

- The experimental results don't include confidence intervals. The authors justify this by pointing out that the proposed approach is deterministic. However, CIs still can and should be calculated by an approach such as bootstrapping the test set. 
- Relatedly, the text to image generation experiment is **not** deterministic if the text2img generator's random seed is changed, so CIs should definitely be reported here. 
- The compared methods are limited to only 2 other debiasing approaches and the baseline model. 
- The proposed approach of 1) finding features most associated with the biased attributes and 2) replacing these features with an imputed value from low-confidence samples is, I think, very similar in practice to Chuang et al.'s approach [1] in ""Debiasing Vision-Language Models via Biased Prompts"". Chuang modifies embeddings by projecting them onto the subspace defined by the linear direction most associated with the biased attribute(s). Intuitively, the direction most associated with the biased attribute should be similar to the direction defined by the features identified in step 1) of the proposed approach. Not that I am **not** saying that this similarity alone is a limitation; I think the proposed approach is different enough to still have sufficient novelty. However, I think that Chuang's approach really needs to be compared against (for all experiments except maybe image captioning), in order to verify that these features are either finding a different direction in the embedding space or that the low confidence imputation performs better than just projecting onto the bias subspace. 

[1] Chuang, Ching-Yao, et al. ""Debiasing vision-language models via biased prompts."" arXiv preprint arXiv:2302.00070 (2023).","- Is the improvement of the proposed approach over the compared methods significant when CI are considered, where these CI's are obtained from bootstrapping or some other way?
- How does the proposed approach perform when compared against the method proposed in ""Debiasing vision-language models via biased prompts.""?","I think the discussion on limitations could be improved. The authors point to Section ***5.2 Result Analysis** as their discussion of limitations. 5.2 covers the results of their experiments, and does include some discussion on how the experimental results on image generation point to room for improvement. However, I feel like a discussion of the limitations would be greatly improved by dedicating a separate section/subsection to it. I would expect the authors to discuss more fundamental limitations, rather than just experimental performance. For instance, I would include details on how the method assumes access to a validation set with labels for bias/protected attributes (e.g. a dataset with race/gender/etc labels).",['No ethics review needed.'],6,4,,Yes,2,3,3,1720753681558,,,NeurIPS.cc/2024/Conference,181llen2gw,"['NeurIPS.cc/2024/Conference/Submission14102/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879684953,[],1,,,['everyone'],181llen2gw,['NeurIPS.cc/2024/Conference/Submission14102/Reviewer_Wrj8'],1720753681558,1730879684953,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission14102/Reviewer_Wrj8']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, namely:

Chuang, Ching-Yao, et al. ""Debiasing vision-language models via biased prompts."" arXiv preprint arXiv:2302.00070 (2023).

The reviewer mentions that Chuang's approach is similar to the proposed approach and suggests that the authors should compare their method against Chuang's approach in order to verify the novelty and effectiveness of their proposed approach.",1,"2023, 2023",Debiasing vision-language models via biased prompts
JefUAe9HkR,"This paper introduce an iterative random feature Dense Associative Memory Model (DenseAM).
It is a kernel approximation of the standard DenseAMs using random feature decomposition and approximation. 
The authors term this approach to DenseAMs as distributed representation/formulation of memory (DrDAM).

Theoretically, they analyze the time complexity of the proposed method (Thm1) and the approximation error (Thm2), both benchmarked against the standard DenseAM (MrDAM). 
Experimentally, they evaluate the approximation accuracy of DrDAM's energies and gradients, defined as the MAE difference between DrDAM and MrDAM, and the retrieval accuracy of DrDAM. 
Importantly, their analysis of DrDAM considers its iterative nature, distinguishing their contribution from prior works.

In sum, they address important research questions and their approach is natural and intuitive based on recent advances in the random feature kernel trick.","* **Originality**: This paper expands our understanding of Dense Associative Memory Models (DenseAMs) by presenting a random feature DenseAM, termed DrDAM. The idea of DrDAM is novel and beneficial to the ML and associative memory community.

* **Significance**: While the idea of random feature DenseAM is not entirely new, this work delves deeper than most prior studies. For example, to the best of my knowledge, there is nothing as concrete as the iterative Algorithm 1 presented in prior works. This represents a significant and solid step forward for the community, and I appreciate the effort.

* **Theoretical Contribution**: This paper provides an efficiency and approximation analysis of DrDAM.

* **Experimental Contribution**: They explore some aspects of DrDAM, including the approximation of energies and gradients and the approximation ability of DrDAM. Reproducible code is also provided.","## Summary of Weaknesses

Overall, this paper presents a good idea, but it seems rushed, which affects the contribution of an otherwise very interesting work. Regardless of the final decision, I hope the authors find my comments helpful in further refining their draft.

There are a few areas that could benefit from further improvement and clarity:

* **Experiments:** The current experimental results would be strengthened by including comparisons with established baselines and more ablation studies.
* **Clarity:** Some of the theoretical results are difficult to interpret due to minor typos and a need for increased mathematical clarity.
* **Motivation:** The motivation and problem statement could be articulated more convincingly. Even after multiple readings of the intro, it remains unclear if distributed representation is truly parameter-efficient beyond the nonparametric sense.
* **Related Works:** Additionally, while not critical, the idea of Random Feature DenseAM (and Kernel DenseAM) has been discussed in prior works. The related discussion in this paper could be expanded to better position the contribution within the existing literature. For examples:
  * ```Random Feature DenseAM``` Random Feature Hopfield Networks generalize retrieval to previously unseen examples https://openreview.net/forum?id=bv2szxARh2)
  * ```Random Feature DenseAM``` Nonparametric Modern Hopfield Models https://arxiv.org/abs/2404.03900
  * ```Kernel DenseAM``` Kernel Memory Networks: A Unifying Framework for Memory Modeling  https://arxiv.org/abs/2208.09416
  * ```Kernel DenseAM``` Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models  https://arxiv.org/abs/2404.03827
  * ```Kernel DenseAM``` Bridging Associative Memory and Probabilistic Modeling https://arxiv.org/abs/2402.10202



**Note:** I have tried my best to evaluate this paper. I spent much more time on this review than on my previous ones because I like this paper. Still, I might have missed something. Please correct me if I am wrong with fair justifications. I am open to changing my opinion and raising the score.

---

## Major: My main concern with this paper is its soundness and inadequate experimental evidence

### General


* ```line23:``` ""Memory representation"" is a strange term for me. If you are referring to the way of encoding memory patterns onto the energy landscape, isn't it ""memory encoding""? Representation generally involves learning, and to my understanding, there is no learning here.

  >Thus, in situations when the set of the memories needs to be expanded by introducing new patterns one must introduce additional weights.

  A side comment: this statement implies nonparametric, as suggested in [17].

* ```distributed representation```: I find the description of distributed representation vague. With more memories, $K$ increases, resulting in more degrees of freedom in $\mathbf{T}$. You can say the total number of entries in $\mathbf{T}$ is fixed, but not the number of parameters, unless you clearly define ""parameters"" differently. The current draft makes it difficult to parse the soundness.  I believe the idea of distributed representation deserves more elaboration. The current draft seems nonparametric to me.

  In my current review, I assume what is stated in lines 29-30 is correct.

* ```Sec3```: Section 3 is hard to follow due to typos and the lack of clarity.

* ```Missing Broader Impacts```: The authors didn't discuss both potential positive and negative societal impacts except in the checklist. My understanding is that this discussion needs to be included in the main text or the appendix, as the checklist is not considered part of the paper.

---

### Theory


* ```line92```: Eqn. (6) is hard to follow without clearly defined $S,s$. 

  I suppose $S:\mathbb{R}^d\times \mathbb{R}^d\to \mathbb{R}$ which makes $s\in\mathbb{R}$ a scalar realization of $S$?


* ```No fixed point convergence results```: Per my understanding, DenseAMs are energy models with memories stored in their local minima. Memory retrieval is conducted through energy minimization. This setting requires convergence between local minima and fixed points of retrieval updates, such as the convergence results of [Ramsauer2020,Hu2023]. Otherwise, there may be unbounded retrieval error due to the mismatch between local minima and fixed points of retrieval updates. Specifically, I believe lines 106-110 are at best ambiguous.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.

* ```Theorem 1```: I feel Thm1 may be incorrect. Could you elaborate more on this?

  * **My understanding:** Let $L$ be the number of updates, $K$ be the number of stored memories, $D$ be the memory dimension, and $Y$ be the feature space dimension. DrDAM improves time complexity from $O(LKD)$ to $O(D(Y K + L(Y + D))$, and improves peak memory from $O(KD)$ to $O(Y+D)$.
  * **Comment1:** $O(D(Y K + L(Y + D))$ is clearly a typo and makes the result hard to parse.
  * **Comment2:** Without specifying the relationships between $L$, $K$, $D$, and $Y$, it's hard to tell if this is truly an improvement. I can easily think of counterexamples.

  Given these, can you kindly elaborate more on the significance of thm1?


* ```Theorem 2```: Eqn. (12) is strange. Is there any guarantee ensuring $\alpha L(1+2K\beta e^{\beta/2}) < 1$? If not, it doesn't make sense that more updates would result in larger error. Perhaps this is related to the missing fixed point convergence?

---

### Experiments

* ```No Comparison to existing works:``` there is no baseline compared. 

* ```No efficiency evaluation1:``` Please include ablation studies on changing $L,K,D,Y$ to verify Thm1. 

* ```No efficiency evaluation2:``` Please also compare the efficiency with other methods, including linear, top-K, random feature, and random masked from [17], as well as dense [Ramsauer2020], sparse [Hu2023], and generalized sparse [Wu2023] MHNs. For example, the current draft needs some figures similar to Fig. 4 of [17] to justify the efficiency. Please do whatever makes sense to you. For instance, you can pick just two out of [Ramsauer2020, Hu2023, Wu2023] since they share similar structures.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Millidge2022] Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models. Millidge, B., Salvatori, T., Song, Y., Lukasiewicz, T., and Bogacz, R., 2022, June. In International Conference on Machine Learning (pp. 15561-15583). PMLR.
  
  * [Wu2023] Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.



* ```Compare with existing kernel DenseAMs.``` Also, a direct comparison with existing kernel methods is also necessary. For example,
  * Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models. Wu, D., Hu, J.Y.C., Hsiao, T.Y., and Liu, H., 2024. arXiv preprint arXiv:2404.03827.
  
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.

---

## Minor

* ```Inadequate Related Work Discussion```: A paragraph discussing related works is given at the end of the introduction. However, I feel it could be made more comprehensive to provide more background on the evolution of ideas and existing works in this field. At least, I feel the current draft is hard for a non-expert in DenseAMs to follow. Please see the following points.

* ```line38:``` I believe here can be benefited by including more comprehensive references. There are other recent works showing exponentially large memory storage capacity in various settings and dense associative memory (or modern Hopfield) networks/models. For examples: (I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.)

   * Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  * On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.
  * Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.
  * Sparse and Structured Hopfield Networks. Santos, S., Niculae, V., McNamee, D., and Martins, A.F., 2024. arXiv preprint arXiv:2402.13725.
  * On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. Hu, J.Y.C., Lin, T., Song, Z., and Liu, H., 2024. arXiv preprint arXiv:2402.04520.
  * Outlier-Efficient Hopfield Layers for Large Transformer-Based Models. Hu, J.Y.C., Chang, P.H., Luo, R., Chen, H.Y., Li, W., Wang, W.P., and Liu, H., 2024. arXiv preprint arXiv:2404.03828.


* ```line46:``` Similarly, here can be benefited by including more recent references
  > DenseAM family [...] 

* ```line51```: A similar motivating question is asked and explored in [17] from a kernel regression perspective. I agree this paper contributes something different and even beyond [17]. However, given the similarity of aims between the two, the current draft should:
  1. State the overlaps between the two works (both use a kernel approach to DenseAMs, and...).
  2. State the clear distinctions between the two works (both use a kernel approach to DenseAMs, but...).

  Such discussion will help readers parse the contributions of this work, which is currently lacking.

  [17] Jerry Yao-Chieh Hu, Bo-Yu Chen, Dennis Wu, Feng Ruan, and Han Liu. Nonparametric modern hopfield models. arXiv preprint arXiv:2404.03900, 2024. URL https://arxiv.org/pdf/2404.03900.pdf.
 

* ```line92```: 
  > those results have been recently applied to associative memory [15].

  I might have missed something, but it would be better to make the discussion of prior work more complete if it's presented in its current form (e.g., a paragraph highlighting the novelty and contributions benchmarked against existing works). The application of the kernel trick to associative memory is not new. While [16,17] are discussed right after [15], I feel it's better to cite them together as [15,16,17]. Additionally, there are two papers related to the kernel trick in associative memory, which I have attached below. Again, I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.

  - Iatropoulos, G., Brea, J., & Gerstner, W. (2022). Kernel memory networks: A unifying framework for memory modeling. Advances in neural information processing systems, 35, 35326-35338.
  
  -  Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R. and Gromov, A., 2024. Bridging Associative Memory and Probabilistic Modeling. arXiv preprint arXiv:2402.10202.

* ```line97```: 
  > Another paper [17] uses kernels for studying the sparse modern Hopfield network. 

  This is incorrect. 

  As stated in their abstract, [17] presents a general framework (referred to as nonparametric) to analyze and design modern Hopfield networks. The sparse network is just a special case of their framework. Additionally, [17] has already introduced the construction of random feature HMNs. While this construction lacks detailed analysis, which is a limitation they acknowledged, it would be more accurate to say that the submitted draft serves as a strong companion to [17] with rigorous theoretical and empirical results. I understand that the authors are not obliged to treat arXiv preprints (unpublished papers) too seriously, but it is better to give accurate credit to existing works when possible. To clarify, I am very happy to see this draft improves the results/proposal of [17] with detailed analysis, including multiple retrieval updates.

* I did not check the proofs line by line. However, I had a quick skim through them and found some typos and areas for improvement. Please do another round of proofreading if possible.


---

### Update 2024/08/07: raise score from 4 -> 5 -> 6 -> 7","* ```line109```: why you call the number of updates as *layers*? Are you recurrently passing the output as input to the same network or the network really has many layers? For example, recurrent layer is RNN sense is the later. 


* ```Proposition 1,2,3```: what is peak memory? why we should care about it?

* ```Time Complexity```: I appreciate the analysis of the computational complexity of the proposed method. From my view, this proposal is a special case of [Hu2024] with $L=1$ (where $L$ is the sequence length in their analysis). [Hu2024] provides a characterization of all sub-quadratic (efficient) variants of the modern Hopfield model. Essentially, your proposal is an efficient approximation to the softmax DenseAMs. Hence, the relevance holds. Can you discuss how your proposal fits into the results of [Hu2024]?
  
  * [Hu2024] Hu, J.Y.C., Lin, T., Song, Z. and Liu, H., 2024. On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. arXiv preprint arXiv:2402.04520.


* ```line255, Exp Observation 2```: This observation is a bit counterintuitive. Normally, large $\beta$ means low-temperature region and leads to more stable/accurate retrieval, e.g., infinity $\beta$ leads to argmax-retrieval. Why random DrDAM shows otherwise?  



* ```Fig3```: Intuitively, why larger $\beta$ needs larger $Y$?

* ```line303```: What's the point of approximating energies and update dynamics? Shouldn't the significance lie in the approximation error of retrieval?

* I am wondering if you have explored the learning aspect of the proposed method. It is known that many DenseAMs are connected to transformer attention and can be used as a learning model or layer. Can you explore this part a bit as in [17]? If not, please explain why.

* Can you kindly remind me which part of this work supports the claim ""making it possible to introduce new memories without increasing the number of weights""?","There is a limitation section but no broader impact or impact statement expect in the checklist.


Appendix A of the draft acknowledges that the experimental explorations are limited. However, it would benefit from discussing comparisons with baselines and including some vital ablations. This would help clarify the contribution and soundness of the proposed method. See above for other limitations.",['No ethics review needed.'],7,4,,Yes,3,3,2,1718224581283,,,NeurIPS.cc/2024/Conference,164QnJsYjF,"['NeurIPS.cc/2024/Conference/Submission18824/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880001942,[],1,,,['everyone'],164QnJsYjF,['NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh'],1718224581283,1730880001942,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Ramsauer et al. (2020) - ""Hopfield Networks is All You Need""
2. Hu et al. (2023) - ""On Sparse Modern Hopfield Model""
3. Millidge et al. (2022) - ""Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models""
4. Wu et al. (2023) - ""Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction""
5. Iatropoulos et al. (2022) - ""Kernel Memory Networks: A Unifying Framework for Memory Modeling""
6. Schaeffer et al. (2024) - ""Bridging Associative Memory and Probabilistic Modeling""
7. Hu et al. (2024) - ""On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis""
8. Hu et al. (2024) - ""Nonparametric Modern Hopfield Models""

The reviewer also mentions that the authors should discuss the overlaps and distinctions between their work and the work presented in [17], which refers to Hu et al. (2024) - ""Nonparametric Modern Hopfield Models"".",1,"2020, 2023, 2022, 2023, 2022, 2024, 2024, 2024, 2024",Hopfield Networks is All You Need 
JefUAe9HkR,"This paper introduce an iterative random feature Dense Associative Memory Model (DenseAM).
It is a kernel approximation of the standard DenseAMs using random feature decomposition and approximation. 
The authors term this approach to DenseAMs as distributed representation/formulation of memory (DrDAM).

Theoretically, they analyze the time complexity of the proposed method (Thm1) and the approximation error (Thm2), both benchmarked against the standard DenseAM (MrDAM). 
Experimentally, they evaluate the approximation accuracy of DrDAM's energies and gradients, defined as the MAE difference between DrDAM and MrDAM, and the retrieval accuracy of DrDAM. 
Importantly, their analysis of DrDAM considers its iterative nature, distinguishing their contribution from prior works.

In sum, they address important research questions and their approach is natural and intuitive based on recent advances in the random feature kernel trick.","* **Originality**: This paper expands our understanding of Dense Associative Memory Models (DenseAMs) by presenting a random feature DenseAM, termed DrDAM. The idea of DrDAM is novel and beneficial to the ML and associative memory community.

* **Significance**: While the idea of random feature DenseAM is not entirely new, this work delves deeper than most prior studies. For example, to the best of my knowledge, there is nothing as concrete as the iterative Algorithm 1 presented in prior works. This represents a significant and solid step forward for the community, and I appreciate the effort.

* **Theoretical Contribution**: This paper provides an efficiency and approximation analysis of DrDAM.

* **Experimental Contribution**: They explore some aspects of DrDAM, including the approximation of energies and gradients and the approximation ability of DrDAM. Reproducible code is also provided.","## Summary of Weaknesses

Overall, this paper presents a good idea, but it seems rushed, which affects the contribution of an otherwise very interesting work. Regardless of the final decision, I hope the authors find my comments helpful in further refining their draft.

There are a few areas that could benefit from further improvement and clarity:

* **Experiments:** The current experimental results would be strengthened by including comparisons with established baselines and more ablation studies.
* **Clarity:** Some of the theoretical results are difficult to interpret due to minor typos and a need for increased mathematical clarity.
* **Motivation:** The motivation and problem statement could be articulated more convincingly. Even after multiple readings of the intro, it remains unclear if distributed representation is truly parameter-efficient beyond the nonparametric sense.
* **Related Works:** Additionally, while not critical, the idea of Random Feature DenseAM (and Kernel DenseAM) has been discussed in prior works. The related discussion in this paper could be expanded to better position the contribution within the existing literature. For examples:
  * ```Random Feature DenseAM``` Random Feature Hopfield Networks generalize retrieval to previously unseen examples https://openreview.net/forum?id=bv2szxARh2)
  * ```Random Feature DenseAM``` Nonparametric Modern Hopfield Models https://arxiv.org/abs/2404.03900
  * ```Kernel DenseAM``` Kernel Memory Networks: A Unifying Framework for Memory Modeling  https://arxiv.org/abs/2208.09416
  * ```Kernel DenseAM``` Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models  https://arxiv.org/abs/2404.03827
  * ```Kernel DenseAM``` Bridging Associative Memory and Probabilistic Modeling https://arxiv.org/abs/2402.10202



**Note:** I have tried my best to evaluate this paper. I spent much more time on this review than on my previous ones because I like this paper. Still, I might have missed something. Please correct me if I am wrong with fair justifications. I am open to changing my opinion and raising the score.

---

## Major: My main concern with this paper is its soundness and inadequate experimental evidence

### General


* ```line23:``` ""Memory representation"" is a strange term for me. If you are referring to the way of encoding memory patterns onto the energy landscape, isn't it ""memory encoding""? Representation generally involves learning, and to my understanding, there is no learning here.

  >Thus, in situations when the set of the memories needs to be expanded by introducing new patterns one must introduce additional weights.

  A side comment: this statement implies nonparametric, as suggested in [17].

* ```distributed representation```: I find the description of distributed representation vague. With more memories, $K$ increases, resulting in more degrees of freedom in $\mathbf{T}$. You can say the total number of entries in $\mathbf{T}$ is fixed, but not the number of parameters, unless you clearly define ""parameters"" differently. The current draft makes it difficult to parse the soundness.  I believe the idea of distributed representation deserves more elaboration. The current draft seems nonparametric to me.

  In my current review, I assume what is stated in lines 29-30 is correct.

* ```Sec3```: Section 3 is hard to follow due to typos and the lack of clarity.

* ```Missing Broader Impacts```: The authors didn't discuss both potential positive and negative societal impacts except in the checklist. My understanding is that this discussion needs to be included in the main text or the appendix, as the checklist is not considered part of the paper.

---

### Theory


* ```line92```: Eqn. (6) is hard to follow without clearly defined $S,s$. 

  I suppose $S:\mathbb{R}^d\times \mathbb{R}^d\to \mathbb{R}$ which makes $s\in\mathbb{R}$ a scalar realization of $S$?


* ```No fixed point convergence results```: Per my understanding, DenseAMs are energy models with memories stored in their local minima. Memory retrieval is conducted through energy minimization. This setting requires convergence between local minima and fixed points of retrieval updates, such as the convergence results of [Ramsauer2020,Hu2023]. Otherwise, there may be unbounded retrieval error due to the mismatch between local minima and fixed points of retrieval updates. Specifically, I believe lines 106-110 are at best ambiguous.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.

* ```Theorem 1```: I feel Thm1 may be incorrect. Could you elaborate more on this?

  * **My understanding:** Let $L$ be the number of updates, $K$ be the number of stored memories, $D$ be the memory dimension, and $Y$ be the feature space dimension. DrDAM improves time complexity from $O(LKD)$ to $O(D(Y K + L(Y + D))$, and improves peak memory from $O(KD)$ to $O(Y+D)$.
  * **Comment1:** $O(D(Y K + L(Y + D))$ is clearly a typo and makes the result hard to parse.
  * **Comment2:** Without specifying the relationships between $L$, $K$, $D$, and $Y$, it's hard to tell if this is truly an improvement. I can easily think of counterexamples.

  Given these, can you kindly elaborate more on the significance of thm1?


* ```Theorem 2```: Eqn. (12) is strange. Is there any guarantee ensuring $\alpha L(1+2K\beta e^{\beta/2}) < 1$? If not, it doesn't make sense that more updates would result in larger error. Perhaps this is related to the missing fixed point convergence?

---

### Experiments

* ```No Comparison to existing works:``` there is no baseline compared. 

* ```No efficiency evaluation1:``` Please include ablation studies on changing $L,K,D,Y$ to verify Thm1. 

* ```No efficiency evaluation2:``` Please also compare the efficiency with other methods, including linear, top-K, random feature, and random masked from [17], as well as dense [Ramsauer2020], sparse [Hu2023], and generalized sparse [Wu2023] MHNs. For example, the current draft needs some figures similar to Fig. 4 of [17] to justify the efficiency. Please do whatever makes sense to you. For instance, you can pick just two out of [Ramsauer2020, Hu2023, Wu2023] since they share similar structures.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Millidge2022] Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models. Millidge, B., Salvatori, T., Song, Y., Lukasiewicz, T., and Bogacz, R., 2022, June. In International Conference on Machine Learning (pp. 15561-15583). PMLR.
  
  * [Wu2023] Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.



* ```Compare with existing kernel DenseAMs.``` Also, a direct comparison with existing kernel methods is also necessary. For example,
  * Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models. Wu, D., Hu, J.Y.C., Hsiao, T.Y., and Liu, H., 2024. arXiv preprint arXiv:2404.03827.
  
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.

---

## Minor

* ```Inadequate Related Work Discussion```: A paragraph discussing related works is given at the end of the introduction. However, I feel it could be made more comprehensive to provide more background on the evolution of ideas and existing works in this field. At least, I feel the current draft is hard for a non-expert in DenseAMs to follow. Please see the following points.

* ```line38:``` I believe here can be benefited by including more comprehensive references. There are other recent works showing exponentially large memory storage capacity in various settings and dense associative memory (or modern Hopfield) networks/models. For examples: (I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.)

   * Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  * On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.
  * Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.
  * Sparse and Structured Hopfield Networks. Santos, S., Niculae, V., McNamee, D., and Martins, A.F., 2024. arXiv preprint arXiv:2402.13725.
  * On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. Hu, J.Y.C., Lin, T., Song, Z., and Liu, H., 2024. arXiv preprint arXiv:2402.04520.
  * Outlier-Efficient Hopfield Layers for Large Transformer-Based Models. Hu, J.Y.C., Chang, P.H., Luo, R., Chen, H.Y., Li, W., Wang, W.P., and Liu, H., 2024. arXiv preprint arXiv:2404.03828.


* ```line46:``` Similarly, here can be benefited by including more recent references
  > DenseAM family [...] 

* ```line51```: A similar motivating question is asked and explored in [17] from a kernel regression perspective. I agree this paper contributes something different and even beyond [17]. However, given the similarity of aims between the two, the current draft should:
  1. State the overlaps between the two works (both use a kernel approach to DenseAMs, and...).
  2. State the clear distinctions between the two works (both use a kernel approach to DenseAMs, but...).

  Such discussion will help readers parse the contributions of this work, which is currently lacking.

  [17] Jerry Yao-Chieh Hu, Bo-Yu Chen, Dennis Wu, Feng Ruan, and Han Liu. Nonparametric modern hopfield models. arXiv preprint arXiv:2404.03900, 2024. URL https://arxiv.org/pdf/2404.03900.pdf.
 

* ```line92```: 
  > those results have been recently applied to associative memory [15].

  I might have missed something, but it would be better to make the discussion of prior work more complete if it's presented in its current form (e.g., a paragraph highlighting the novelty and contributions benchmarked against existing works). The application of the kernel trick to associative memory is not new. While [16,17] are discussed right after [15], I feel it's better to cite them together as [15,16,17]. Additionally, there are two papers related to the kernel trick in associative memory, which I have attached below. Again, I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.

  - Iatropoulos, G., Brea, J., & Gerstner, W. (2022). Kernel memory networks: A unifying framework for memory modeling. Advances in neural information processing systems, 35, 35326-35338.
  
  -  Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R. and Gromov, A., 2024. Bridging Associative Memory and Probabilistic Modeling. arXiv preprint arXiv:2402.10202.

* ```line97```: 
  > Another paper [17] uses kernels for studying the sparse modern Hopfield network. 

  This is incorrect. 

  As stated in their abstract, [17] presents a general framework (referred to as nonparametric) to analyze and design modern Hopfield networks. The sparse network is just a special case of their framework. Additionally, [17] has already introduced the construction of random feature HMNs. While this construction lacks detailed analysis, which is a limitation they acknowledged, it would be more accurate to say that the submitted draft serves as a strong companion to [17] with rigorous theoretical and empirical results. I understand that the authors are not obliged to treat arXiv preprints (unpublished papers) too seriously, but it is better to give accurate credit to existing works when possible. To clarify, I am very happy to see this draft improves the results/proposal of [17] with detailed analysis, including multiple retrieval updates.

* I did not check the proofs line by line. However, I had a quick skim through them and found some typos and areas for improvement. Please do another round of proofreading if possible.


---

### Update 2024/08/07: raise score from 4 -> 5 -> 6 -> 7","* ```line109```: why you call the number of updates as *layers*? Are you recurrently passing the output as input to the same network or the network really has many layers? For example, recurrent layer is RNN sense is the later. 


* ```Proposition 1,2,3```: what is peak memory? why we should care about it?

* ```Time Complexity```: I appreciate the analysis of the computational complexity of the proposed method. From my view, this proposal is a special case of [Hu2024] with $L=1$ (where $L$ is the sequence length in their analysis). [Hu2024] provides a characterization of all sub-quadratic (efficient) variants of the modern Hopfield model. Essentially, your proposal is an efficient approximation to the softmax DenseAMs. Hence, the relevance holds. Can you discuss how your proposal fits into the results of [Hu2024]?
  
  * [Hu2024] Hu, J.Y.C., Lin, T., Song, Z. and Liu, H., 2024. On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. arXiv preprint arXiv:2402.04520.


* ```line255, Exp Observation 2```: This observation is a bit counterintuitive. Normally, large $\beta$ means low-temperature region and leads to more stable/accurate retrieval, e.g., infinity $\beta$ leads to argmax-retrieval. Why random DrDAM shows otherwise?  



* ```Fig3```: Intuitively, why larger $\beta$ needs larger $Y$?

* ```line303```: What's the point of approximating energies and update dynamics? Shouldn't the significance lie in the approximation error of retrieval?

* I am wondering if you have explored the learning aspect of the proposed method. It is known that many DenseAMs are connected to transformer attention and can be used as a learning model or layer. Can you explore this part a bit as in [17]? If not, please explain why.

* Can you kindly remind me which part of this work supports the claim ""making it possible to introduce new memories without increasing the number of weights""?","There is a limitation section but no broader impact or impact statement expect in the checklist.


Appendix A of the draft acknowledges that the experimental explorations are limited. However, it would benefit from discussing comparisons with baselines and including some vital ablations. This would help clarify the contribution and soundness of the proposed method. See above for other limitations.",['No ethics review needed.'],7,4,,Yes,3,3,2,1718224581283,,,NeurIPS.cc/2024/Conference,164QnJsYjF,"['NeurIPS.cc/2024/Conference/Submission18824/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880001942,[],1,,,['everyone'],164QnJsYjF,['NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh'],1718224581283,1730880001942,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Ramsauer et al. (2020) - ""Hopfield Networks is All You Need""
2. Hu et al. (2023) - ""On Sparse Modern Hopfield Model""
3. Millidge et al. (2022) - ""Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models""
4. Wu et al. (2023) - ""Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction""
5. Iatropoulos et al. (2022) - ""Kernel Memory Networks: A Unifying Framework for Memory Modeling""
6. Schaeffer et al. (2024) - ""Bridging Associative Memory and Probabilistic Modeling""
7. Hu et al. (2024) - ""On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis""
8. Hu et al. (2024) - ""Nonparametric Modern Hopfield Models""

The reviewer also mentions that the authors should discuss the overlaps and distinctions between their work and the work presented in [17], which refers to Hu et al. (2024) - ""Nonparametric Modern Hopfield Models"".",1,"2020, 2023, 2022, 2023, 2022, 2024, 2024, 2024, 2024",On Sparse Modern Hopfield Model 
JefUAe9HkR,"This paper introduce an iterative random feature Dense Associative Memory Model (DenseAM).
It is a kernel approximation of the standard DenseAMs using random feature decomposition and approximation. 
The authors term this approach to DenseAMs as distributed representation/formulation of memory (DrDAM).

Theoretically, they analyze the time complexity of the proposed method (Thm1) and the approximation error (Thm2), both benchmarked against the standard DenseAM (MrDAM). 
Experimentally, they evaluate the approximation accuracy of DrDAM's energies and gradients, defined as the MAE difference between DrDAM and MrDAM, and the retrieval accuracy of DrDAM. 
Importantly, their analysis of DrDAM considers its iterative nature, distinguishing their contribution from prior works.

In sum, they address important research questions and their approach is natural and intuitive based on recent advances in the random feature kernel trick.","* **Originality**: This paper expands our understanding of Dense Associative Memory Models (DenseAMs) by presenting a random feature DenseAM, termed DrDAM. The idea of DrDAM is novel and beneficial to the ML and associative memory community.

* **Significance**: While the idea of random feature DenseAM is not entirely new, this work delves deeper than most prior studies. For example, to the best of my knowledge, there is nothing as concrete as the iterative Algorithm 1 presented in prior works. This represents a significant and solid step forward for the community, and I appreciate the effort.

* **Theoretical Contribution**: This paper provides an efficiency and approximation analysis of DrDAM.

* **Experimental Contribution**: They explore some aspects of DrDAM, including the approximation of energies and gradients and the approximation ability of DrDAM. Reproducible code is also provided.","## Summary of Weaknesses

Overall, this paper presents a good idea, but it seems rushed, which affects the contribution of an otherwise very interesting work. Regardless of the final decision, I hope the authors find my comments helpful in further refining their draft.

There are a few areas that could benefit from further improvement and clarity:

* **Experiments:** The current experimental results would be strengthened by including comparisons with established baselines and more ablation studies.
* **Clarity:** Some of the theoretical results are difficult to interpret due to minor typos and a need for increased mathematical clarity.
* **Motivation:** The motivation and problem statement could be articulated more convincingly. Even after multiple readings of the intro, it remains unclear if distributed representation is truly parameter-efficient beyond the nonparametric sense.
* **Related Works:** Additionally, while not critical, the idea of Random Feature DenseAM (and Kernel DenseAM) has been discussed in prior works. The related discussion in this paper could be expanded to better position the contribution within the existing literature. For examples:
  * ```Random Feature DenseAM``` Random Feature Hopfield Networks generalize retrieval to previously unseen examples https://openreview.net/forum?id=bv2szxARh2)
  * ```Random Feature DenseAM``` Nonparametric Modern Hopfield Models https://arxiv.org/abs/2404.03900
  * ```Kernel DenseAM``` Kernel Memory Networks: A Unifying Framework for Memory Modeling  https://arxiv.org/abs/2208.09416
  * ```Kernel DenseAM``` Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models  https://arxiv.org/abs/2404.03827
  * ```Kernel DenseAM``` Bridging Associative Memory and Probabilistic Modeling https://arxiv.org/abs/2402.10202



**Note:** I have tried my best to evaluate this paper. I spent much more time on this review than on my previous ones because I like this paper. Still, I might have missed something. Please correct me if I am wrong with fair justifications. I am open to changing my opinion and raising the score.

---

## Major: My main concern with this paper is its soundness and inadequate experimental evidence

### General


* ```line23:``` ""Memory representation"" is a strange term for me. If you are referring to the way of encoding memory patterns onto the energy landscape, isn't it ""memory encoding""? Representation generally involves learning, and to my understanding, there is no learning here.

  >Thus, in situations when the set of the memories needs to be expanded by introducing new patterns one must introduce additional weights.

  A side comment: this statement implies nonparametric, as suggested in [17].

* ```distributed representation```: I find the description of distributed representation vague. With more memories, $K$ increases, resulting in more degrees of freedom in $\mathbf{T}$. You can say the total number of entries in $\mathbf{T}$ is fixed, but not the number of parameters, unless you clearly define ""parameters"" differently. The current draft makes it difficult to parse the soundness.  I believe the idea of distributed representation deserves more elaboration. The current draft seems nonparametric to me.

  In my current review, I assume what is stated in lines 29-30 is correct.

* ```Sec3```: Section 3 is hard to follow due to typos and the lack of clarity.

* ```Missing Broader Impacts```: The authors didn't discuss both potential positive and negative societal impacts except in the checklist. My understanding is that this discussion needs to be included in the main text or the appendix, as the checklist is not considered part of the paper.

---

### Theory


* ```line92```: Eqn. (6) is hard to follow without clearly defined $S,s$. 

  I suppose $S:\mathbb{R}^d\times \mathbb{R}^d\to \mathbb{R}$ which makes $s\in\mathbb{R}$ a scalar realization of $S$?


* ```No fixed point convergence results```: Per my understanding, DenseAMs are energy models with memories stored in their local minima. Memory retrieval is conducted through energy minimization. This setting requires convergence between local minima and fixed points of retrieval updates, such as the convergence results of [Ramsauer2020,Hu2023]. Otherwise, there may be unbounded retrieval error due to the mismatch between local minima and fixed points of retrieval updates. Specifically, I believe lines 106-110 are at best ambiguous.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.

* ```Theorem 1```: I feel Thm1 may be incorrect. Could you elaborate more on this?

  * **My understanding:** Let $L$ be the number of updates, $K$ be the number of stored memories, $D$ be the memory dimension, and $Y$ be the feature space dimension. DrDAM improves time complexity from $O(LKD)$ to $O(D(Y K + L(Y + D))$, and improves peak memory from $O(KD)$ to $O(Y+D)$.
  * **Comment1:** $O(D(Y K + L(Y + D))$ is clearly a typo and makes the result hard to parse.
  * **Comment2:** Without specifying the relationships between $L$, $K$, $D$, and $Y$, it's hard to tell if this is truly an improvement. I can easily think of counterexamples.

  Given these, can you kindly elaborate more on the significance of thm1?


* ```Theorem 2```: Eqn. (12) is strange. Is there any guarantee ensuring $\alpha L(1+2K\beta e^{\beta/2}) < 1$? If not, it doesn't make sense that more updates would result in larger error. Perhaps this is related to the missing fixed point convergence?

---

### Experiments

* ```No Comparison to existing works:``` there is no baseline compared. 

* ```No efficiency evaluation1:``` Please include ablation studies on changing $L,K,D,Y$ to verify Thm1. 

* ```No efficiency evaluation2:``` Please also compare the efficiency with other methods, including linear, top-K, random feature, and random masked from [17], as well as dense [Ramsauer2020], sparse [Hu2023], and generalized sparse [Wu2023] MHNs. For example, the current draft needs some figures similar to Fig. 4 of [17] to justify the efficiency. Please do whatever makes sense to you. For instance, you can pick just two out of [Ramsauer2020, Hu2023, Wu2023] since they share similar structures.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Millidge2022] Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models. Millidge, B., Salvatori, T., Song, Y., Lukasiewicz, T., and Bogacz, R., 2022, June. In International Conference on Machine Learning (pp. 15561-15583). PMLR.
  
  * [Wu2023] Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.



* ```Compare with existing kernel DenseAMs.``` Also, a direct comparison with existing kernel methods is also necessary. For example,
  * Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models. Wu, D., Hu, J.Y.C., Hsiao, T.Y., and Liu, H., 2024. arXiv preprint arXiv:2404.03827.
  
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.

---

## Minor

* ```Inadequate Related Work Discussion```: A paragraph discussing related works is given at the end of the introduction. However, I feel it could be made more comprehensive to provide more background on the evolution of ideas and existing works in this field. At least, I feel the current draft is hard for a non-expert in DenseAMs to follow. Please see the following points.

* ```line38:``` I believe here can be benefited by including more comprehensive references. There are other recent works showing exponentially large memory storage capacity in various settings and dense associative memory (or modern Hopfield) networks/models. For examples: (I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.)

   * Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  * On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.
  * Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.
  * Sparse and Structured Hopfield Networks. Santos, S., Niculae, V., McNamee, D., and Martins, A.F., 2024. arXiv preprint arXiv:2402.13725.
  * On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. Hu, J.Y.C., Lin, T., Song, Z., and Liu, H., 2024. arXiv preprint arXiv:2402.04520.
  * Outlier-Efficient Hopfield Layers for Large Transformer-Based Models. Hu, J.Y.C., Chang, P.H., Luo, R., Chen, H.Y., Li, W., Wang, W.P., and Liu, H., 2024. arXiv preprint arXiv:2404.03828.


* ```line46:``` Similarly, here can be benefited by including more recent references
  > DenseAM family [...] 

* ```line51```: A similar motivating question is asked and explored in [17] from a kernel regression perspective. I agree this paper contributes something different and even beyond [17]. However, given the similarity of aims between the two, the current draft should:
  1. State the overlaps between the two works (both use a kernel approach to DenseAMs, and...).
  2. State the clear distinctions between the two works (both use a kernel approach to DenseAMs, but...).

  Such discussion will help readers parse the contributions of this work, which is currently lacking.

  [17] Jerry Yao-Chieh Hu, Bo-Yu Chen, Dennis Wu, Feng Ruan, and Han Liu. Nonparametric modern hopfield models. arXiv preprint arXiv:2404.03900, 2024. URL https://arxiv.org/pdf/2404.03900.pdf.
 

* ```line92```: 
  > those results have been recently applied to associative memory [15].

  I might have missed something, but it would be better to make the discussion of prior work more complete if it's presented in its current form (e.g., a paragraph highlighting the novelty and contributions benchmarked against existing works). The application of the kernel trick to associative memory is not new. While [16,17] are discussed right after [15], I feel it's better to cite them together as [15,16,17]. Additionally, there are two papers related to the kernel trick in associative memory, which I have attached below. Again, I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.

  - Iatropoulos, G., Brea, J., & Gerstner, W. (2022). Kernel memory networks: A unifying framework for memory modeling. Advances in neural information processing systems, 35, 35326-35338.
  
  -  Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R. and Gromov, A., 2024. Bridging Associative Memory and Probabilistic Modeling. arXiv preprint arXiv:2402.10202.

* ```line97```: 
  > Another paper [17] uses kernels for studying the sparse modern Hopfield network. 

  This is incorrect. 

  As stated in their abstract, [17] presents a general framework (referred to as nonparametric) to analyze and design modern Hopfield networks. The sparse network is just a special case of their framework. Additionally, [17] has already introduced the construction of random feature HMNs. While this construction lacks detailed analysis, which is a limitation they acknowledged, it would be more accurate to say that the submitted draft serves as a strong companion to [17] with rigorous theoretical and empirical results. I understand that the authors are not obliged to treat arXiv preprints (unpublished papers) too seriously, but it is better to give accurate credit to existing works when possible. To clarify, I am very happy to see this draft improves the results/proposal of [17] with detailed analysis, including multiple retrieval updates.

* I did not check the proofs line by line. However, I had a quick skim through them and found some typos and areas for improvement. Please do another round of proofreading if possible.


---

### Update 2024/08/07: raise score from 4 -> 5 -> 6 -> 7","* ```line109```: why you call the number of updates as *layers*? Are you recurrently passing the output as input to the same network or the network really has many layers? For example, recurrent layer is RNN sense is the later. 


* ```Proposition 1,2,3```: what is peak memory? why we should care about it?

* ```Time Complexity```: I appreciate the analysis of the computational complexity of the proposed method. From my view, this proposal is a special case of [Hu2024] with $L=1$ (where $L$ is the sequence length in their analysis). [Hu2024] provides a characterization of all sub-quadratic (efficient) variants of the modern Hopfield model. Essentially, your proposal is an efficient approximation to the softmax DenseAMs. Hence, the relevance holds. Can you discuss how your proposal fits into the results of [Hu2024]?
  
  * [Hu2024] Hu, J.Y.C., Lin, T., Song, Z. and Liu, H., 2024. On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. arXiv preprint arXiv:2402.04520.


* ```line255, Exp Observation 2```: This observation is a bit counterintuitive. Normally, large $\beta$ means low-temperature region and leads to more stable/accurate retrieval, e.g., infinity $\beta$ leads to argmax-retrieval. Why random DrDAM shows otherwise?  



* ```Fig3```: Intuitively, why larger $\beta$ needs larger $Y$?

* ```line303```: What's the point of approximating energies and update dynamics? Shouldn't the significance lie in the approximation error of retrieval?

* I am wondering if you have explored the learning aspect of the proposed method. It is known that many DenseAMs are connected to transformer attention and can be used as a learning model or layer. Can you explore this part a bit as in [17]? If not, please explain why.

* Can you kindly remind me which part of this work supports the claim ""making it possible to introduce new memories without increasing the number of weights""?","There is a limitation section but no broader impact or impact statement expect in the checklist.


Appendix A of the draft acknowledges that the experimental explorations are limited. However, it would benefit from discussing comparisons with baselines and including some vital ablations. This would help clarify the contribution and soundness of the proposed method. See above for other limitations.",['No ethics review needed.'],7,4,,Yes,3,3,2,1718224581283,,,NeurIPS.cc/2024/Conference,164QnJsYjF,"['NeurIPS.cc/2024/Conference/Submission18824/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880001942,[],1,,,['everyone'],164QnJsYjF,['NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh'],1718224581283,1730880001942,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Ramsauer et al. (2020) - ""Hopfield Networks is All You Need""
2. Hu et al. (2023) - ""On Sparse Modern Hopfield Model""
3. Millidge et al. (2022) - ""Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models""
4. Wu et al. (2023) - ""Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction""
5. Iatropoulos et al. (2022) - ""Kernel Memory Networks: A Unifying Framework for Memory Modeling""
6. Schaeffer et al. (2024) - ""Bridging Associative Memory and Probabilistic Modeling""
7. Hu et al. (2024) - ""On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis""
8. Hu et al. (2024) - ""Nonparametric Modern Hopfield Models""

The reviewer also mentions that the authors should discuss the overlaps and distinctions between their work and the work presented in [17], which refers to Hu et al. (2024) - ""Nonparametric Modern Hopfield Models"".",1,"2020, 2023, 2022, 2023, 2022, 2024, 2024, 2024, 2024",Universal Hopfield Networks A General Framework for Single-Shot Associative Memory Models 
JefUAe9HkR,"This paper introduce an iterative random feature Dense Associative Memory Model (DenseAM).
It is a kernel approximation of the standard DenseAMs using random feature decomposition and approximation. 
The authors term this approach to DenseAMs as distributed representation/formulation of memory (DrDAM).

Theoretically, they analyze the time complexity of the proposed method (Thm1) and the approximation error (Thm2), both benchmarked against the standard DenseAM (MrDAM). 
Experimentally, they evaluate the approximation accuracy of DrDAM's energies and gradients, defined as the MAE difference between DrDAM and MrDAM, and the retrieval accuracy of DrDAM. 
Importantly, their analysis of DrDAM considers its iterative nature, distinguishing their contribution from prior works.

In sum, they address important research questions and their approach is natural and intuitive based on recent advances in the random feature kernel trick.","* **Originality**: This paper expands our understanding of Dense Associative Memory Models (DenseAMs) by presenting a random feature DenseAM, termed DrDAM. The idea of DrDAM is novel and beneficial to the ML and associative memory community.

* **Significance**: While the idea of random feature DenseAM is not entirely new, this work delves deeper than most prior studies. For example, to the best of my knowledge, there is nothing as concrete as the iterative Algorithm 1 presented in prior works. This represents a significant and solid step forward for the community, and I appreciate the effort.

* **Theoretical Contribution**: This paper provides an efficiency and approximation analysis of DrDAM.

* **Experimental Contribution**: They explore some aspects of DrDAM, including the approximation of energies and gradients and the approximation ability of DrDAM. Reproducible code is also provided.","## Summary of Weaknesses

Overall, this paper presents a good idea, but it seems rushed, which affects the contribution of an otherwise very interesting work. Regardless of the final decision, I hope the authors find my comments helpful in further refining their draft.

There are a few areas that could benefit from further improvement and clarity:

* **Experiments:** The current experimental results would be strengthened by including comparisons with established baselines and more ablation studies.
* **Clarity:** Some of the theoretical results are difficult to interpret due to minor typos and a need for increased mathematical clarity.
* **Motivation:** The motivation and problem statement could be articulated more convincingly. Even after multiple readings of the intro, it remains unclear if distributed representation is truly parameter-efficient beyond the nonparametric sense.
* **Related Works:** Additionally, while not critical, the idea of Random Feature DenseAM (and Kernel DenseAM) has been discussed in prior works. The related discussion in this paper could be expanded to better position the contribution within the existing literature. For examples:
  * ```Random Feature DenseAM``` Random Feature Hopfield Networks generalize retrieval to previously unseen examples https://openreview.net/forum?id=bv2szxARh2)
  * ```Random Feature DenseAM``` Nonparametric Modern Hopfield Models https://arxiv.org/abs/2404.03900
  * ```Kernel DenseAM``` Kernel Memory Networks: A Unifying Framework for Memory Modeling  https://arxiv.org/abs/2208.09416
  * ```Kernel DenseAM``` Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models  https://arxiv.org/abs/2404.03827
  * ```Kernel DenseAM``` Bridging Associative Memory and Probabilistic Modeling https://arxiv.org/abs/2402.10202



**Note:** I have tried my best to evaluate this paper. I spent much more time on this review than on my previous ones because I like this paper. Still, I might have missed something. Please correct me if I am wrong with fair justifications. I am open to changing my opinion and raising the score.

---

## Major: My main concern with this paper is its soundness and inadequate experimental evidence

### General


* ```line23:``` ""Memory representation"" is a strange term for me. If you are referring to the way of encoding memory patterns onto the energy landscape, isn't it ""memory encoding""? Representation generally involves learning, and to my understanding, there is no learning here.

  >Thus, in situations when the set of the memories needs to be expanded by introducing new patterns one must introduce additional weights.

  A side comment: this statement implies nonparametric, as suggested in [17].

* ```distributed representation```: I find the description of distributed representation vague. With more memories, $K$ increases, resulting in more degrees of freedom in $\mathbf{T}$. You can say the total number of entries in $\mathbf{T}$ is fixed, but not the number of parameters, unless you clearly define ""parameters"" differently. The current draft makes it difficult to parse the soundness.  I believe the idea of distributed representation deserves more elaboration. The current draft seems nonparametric to me.

  In my current review, I assume what is stated in lines 29-30 is correct.

* ```Sec3```: Section 3 is hard to follow due to typos and the lack of clarity.

* ```Missing Broader Impacts```: The authors didn't discuss both potential positive and negative societal impacts except in the checklist. My understanding is that this discussion needs to be included in the main text or the appendix, as the checklist is not considered part of the paper.

---

### Theory


* ```line92```: Eqn. (6) is hard to follow without clearly defined $S,s$. 

  I suppose $S:\mathbb{R}^d\times \mathbb{R}^d\to \mathbb{R}$ which makes $s\in\mathbb{R}$ a scalar realization of $S$?


* ```No fixed point convergence results```: Per my understanding, DenseAMs are energy models with memories stored in their local minima. Memory retrieval is conducted through energy minimization. This setting requires convergence between local minima and fixed points of retrieval updates, such as the convergence results of [Ramsauer2020,Hu2023]. Otherwise, there may be unbounded retrieval error due to the mismatch between local minima and fixed points of retrieval updates. Specifically, I believe lines 106-110 are at best ambiguous.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.

* ```Theorem 1```: I feel Thm1 may be incorrect. Could you elaborate more on this?

  * **My understanding:** Let $L$ be the number of updates, $K$ be the number of stored memories, $D$ be the memory dimension, and $Y$ be the feature space dimension. DrDAM improves time complexity from $O(LKD)$ to $O(D(Y K + L(Y + D))$, and improves peak memory from $O(KD)$ to $O(Y+D)$.
  * **Comment1:** $O(D(Y K + L(Y + D))$ is clearly a typo and makes the result hard to parse.
  * **Comment2:** Without specifying the relationships between $L$, $K$, $D$, and $Y$, it's hard to tell if this is truly an improvement. I can easily think of counterexamples.

  Given these, can you kindly elaborate more on the significance of thm1?


* ```Theorem 2```: Eqn. (12) is strange. Is there any guarantee ensuring $\alpha L(1+2K\beta e^{\beta/2}) < 1$? If not, it doesn't make sense that more updates would result in larger error. Perhaps this is related to the missing fixed point convergence?

---

### Experiments

* ```No Comparison to existing works:``` there is no baseline compared. 

* ```No efficiency evaluation1:``` Please include ablation studies on changing $L,K,D,Y$ to verify Thm1. 

* ```No efficiency evaluation2:``` Please also compare the efficiency with other methods, including linear, top-K, random feature, and random masked from [17], as well as dense [Ramsauer2020], sparse [Hu2023], and generalized sparse [Wu2023] MHNs. For example, the current draft needs some figures similar to Fig. 4 of [17] to justify the efficiency. Please do whatever makes sense to you. For instance, you can pick just two out of [Ramsauer2020, Hu2023, Wu2023] since they share similar structures.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Millidge2022] Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models. Millidge, B., Salvatori, T., Song, Y., Lukasiewicz, T., and Bogacz, R., 2022, June. In International Conference on Machine Learning (pp. 15561-15583). PMLR.
  
  * [Wu2023] Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.



* ```Compare with existing kernel DenseAMs.``` Also, a direct comparison with existing kernel methods is also necessary. For example,
  * Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models. Wu, D., Hu, J.Y.C., Hsiao, T.Y., and Liu, H., 2024. arXiv preprint arXiv:2404.03827.
  
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.

---

## Minor

* ```Inadequate Related Work Discussion```: A paragraph discussing related works is given at the end of the introduction. However, I feel it could be made more comprehensive to provide more background on the evolution of ideas and existing works in this field. At least, I feel the current draft is hard for a non-expert in DenseAMs to follow. Please see the following points.

* ```line38:``` I believe here can be benefited by including more comprehensive references. There are other recent works showing exponentially large memory storage capacity in various settings and dense associative memory (or modern Hopfield) networks/models. For examples: (I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.)

   * Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  * On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.
  * Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.
  * Sparse and Structured Hopfield Networks. Santos, S., Niculae, V., McNamee, D., and Martins, A.F., 2024. arXiv preprint arXiv:2402.13725.
  * On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. Hu, J.Y.C., Lin, T., Song, Z., and Liu, H., 2024. arXiv preprint arXiv:2402.04520.
  * Outlier-Efficient Hopfield Layers for Large Transformer-Based Models. Hu, J.Y.C., Chang, P.H., Luo, R., Chen, H.Y., Li, W., Wang, W.P., and Liu, H., 2024. arXiv preprint arXiv:2404.03828.


* ```line46:``` Similarly, here can be benefited by including more recent references
  > DenseAM family [...] 

* ```line51```: A similar motivating question is asked and explored in [17] from a kernel regression perspective. I agree this paper contributes something different and even beyond [17]. However, given the similarity of aims between the two, the current draft should:
  1. State the overlaps between the two works (both use a kernel approach to DenseAMs, and...).
  2. State the clear distinctions between the two works (both use a kernel approach to DenseAMs, but...).

  Such discussion will help readers parse the contributions of this work, which is currently lacking.

  [17] Jerry Yao-Chieh Hu, Bo-Yu Chen, Dennis Wu, Feng Ruan, and Han Liu. Nonparametric modern hopfield models. arXiv preprint arXiv:2404.03900, 2024. URL https://arxiv.org/pdf/2404.03900.pdf.
 

* ```line92```: 
  > those results have been recently applied to associative memory [15].

  I might have missed something, but it would be better to make the discussion of prior work more complete if it's presented in its current form (e.g., a paragraph highlighting the novelty and contributions benchmarked against existing works). The application of the kernel trick to associative memory is not new. While [16,17] are discussed right after [15], I feel it's better to cite them together as [15,16,17]. Additionally, there are two papers related to the kernel trick in associative memory, which I have attached below. Again, I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.

  - Iatropoulos, G., Brea, J., & Gerstner, W. (2022). Kernel memory networks: A unifying framework for memory modeling. Advances in neural information processing systems, 35, 35326-35338.
  
  -  Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R. and Gromov, A., 2024. Bridging Associative Memory and Probabilistic Modeling. arXiv preprint arXiv:2402.10202.

* ```line97```: 
  > Another paper [17] uses kernels for studying the sparse modern Hopfield network. 

  This is incorrect. 

  As stated in their abstract, [17] presents a general framework (referred to as nonparametric) to analyze and design modern Hopfield networks. The sparse network is just a special case of their framework. Additionally, [17] has already introduced the construction of random feature HMNs. While this construction lacks detailed analysis, which is a limitation they acknowledged, it would be more accurate to say that the submitted draft serves as a strong companion to [17] with rigorous theoretical and empirical results. I understand that the authors are not obliged to treat arXiv preprints (unpublished papers) too seriously, but it is better to give accurate credit to existing works when possible. To clarify, I am very happy to see this draft improves the results/proposal of [17] with detailed analysis, including multiple retrieval updates.

* I did not check the proofs line by line. However, I had a quick skim through them and found some typos and areas for improvement. Please do another round of proofreading if possible.


---

### Update 2024/08/07: raise score from 4 -> 5 -> 6 -> 7","* ```line109```: why you call the number of updates as *layers*? Are you recurrently passing the output as input to the same network or the network really has many layers? For example, recurrent layer is RNN sense is the later. 


* ```Proposition 1,2,3```: what is peak memory? why we should care about it?

* ```Time Complexity```: I appreciate the analysis of the computational complexity of the proposed method. From my view, this proposal is a special case of [Hu2024] with $L=1$ (where $L$ is the sequence length in their analysis). [Hu2024] provides a characterization of all sub-quadratic (efficient) variants of the modern Hopfield model. Essentially, your proposal is an efficient approximation to the softmax DenseAMs. Hence, the relevance holds. Can you discuss how your proposal fits into the results of [Hu2024]?
  
  * [Hu2024] Hu, J.Y.C., Lin, T., Song, Z. and Liu, H., 2024. On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. arXiv preprint arXiv:2402.04520.


* ```line255, Exp Observation 2```: This observation is a bit counterintuitive. Normally, large $\beta$ means low-temperature region and leads to more stable/accurate retrieval, e.g., infinity $\beta$ leads to argmax-retrieval. Why random DrDAM shows otherwise?  



* ```Fig3```: Intuitively, why larger $\beta$ needs larger $Y$?

* ```line303```: What's the point of approximating energies and update dynamics? Shouldn't the significance lie in the approximation error of retrieval?

* I am wondering if you have explored the learning aspect of the proposed method. It is known that many DenseAMs are connected to transformer attention and can be used as a learning model or layer. Can you explore this part a bit as in [17]? If not, please explain why.

* Can you kindly remind me which part of this work supports the claim ""making it possible to introduce new memories without increasing the number of weights""?","There is a limitation section but no broader impact or impact statement expect in the checklist.


Appendix A of the draft acknowledges that the experimental explorations are limited. However, it would benefit from discussing comparisons with baselines and including some vital ablations. This would help clarify the contribution and soundness of the proposed method. See above for other limitations.",['No ethics review needed.'],7,4,,Yes,3,3,2,1718224581283,,,NeurIPS.cc/2024/Conference,164QnJsYjF,"['NeurIPS.cc/2024/Conference/Submission18824/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880001942,[],1,,,['everyone'],164QnJsYjF,['NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh'],1718224581283,1730880001942,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Ramsauer et al. (2020) - ""Hopfield Networks is All You Need""
2. Hu et al. (2023) - ""On Sparse Modern Hopfield Model""
3. Millidge et al. (2022) - ""Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models""
4. Wu et al. (2023) - ""Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction""
5. Iatropoulos et al. (2022) - ""Kernel Memory Networks: A Unifying Framework for Memory Modeling""
6. Schaeffer et al. (2024) - ""Bridging Associative Memory and Probabilistic Modeling""
7. Hu et al. (2024) - ""On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis""
8. Hu et al. (2024) - ""Nonparametric Modern Hopfield Models""

The reviewer also mentions that the authors should discuss the overlaps and distinctions between their work and the work presented in [17], which refers to Hu et al. (2024) - ""Nonparametric Modern Hopfield Models"".",1,"2020, 2023, 2022, 2023, 2022, 2024, 2024, 2024, 2024",Stanhop Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction 
JefUAe9HkR,"This paper introduce an iterative random feature Dense Associative Memory Model (DenseAM).
It is a kernel approximation of the standard DenseAMs using random feature decomposition and approximation. 
The authors term this approach to DenseAMs as distributed representation/formulation of memory (DrDAM).

Theoretically, they analyze the time complexity of the proposed method (Thm1) and the approximation error (Thm2), both benchmarked against the standard DenseAM (MrDAM). 
Experimentally, they evaluate the approximation accuracy of DrDAM's energies and gradients, defined as the MAE difference between DrDAM and MrDAM, and the retrieval accuracy of DrDAM. 
Importantly, their analysis of DrDAM considers its iterative nature, distinguishing their contribution from prior works.

In sum, they address important research questions and their approach is natural and intuitive based on recent advances in the random feature kernel trick.","* **Originality**: This paper expands our understanding of Dense Associative Memory Models (DenseAMs) by presenting a random feature DenseAM, termed DrDAM. The idea of DrDAM is novel and beneficial to the ML and associative memory community.

* **Significance**: While the idea of random feature DenseAM is not entirely new, this work delves deeper than most prior studies. For example, to the best of my knowledge, there is nothing as concrete as the iterative Algorithm 1 presented in prior works. This represents a significant and solid step forward for the community, and I appreciate the effort.

* **Theoretical Contribution**: This paper provides an efficiency and approximation analysis of DrDAM.

* **Experimental Contribution**: They explore some aspects of DrDAM, including the approximation of energies and gradients and the approximation ability of DrDAM. Reproducible code is also provided.","## Summary of Weaknesses

Overall, this paper presents a good idea, but it seems rushed, which affects the contribution of an otherwise very interesting work. Regardless of the final decision, I hope the authors find my comments helpful in further refining their draft.

There are a few areas that could benefit from further improvement and clarity:

* **Experiments:** The current experimental results would be strengthened by including comparisons with established baselines and more ablation studies.
* **Clarity:** Some of the theoretical results are difficult to interpret due to minor typos and a need for increased mathematical clarity.
* **Motivation:** The motivation and problem statement could be articulated more convincingly. Even after multiple readings of the intro, it remains unclear if distributed representation is truly parameter-efficient beyond the nonparametric sense.
* **Related Works:** Additionally, while not critical, the idea of Random Feature DenseAM (and Kernel DenseAM) has been discussed in prior works. The related discussion in this paper could be expanded to better position the contribution within the existing literature. For examples:
  * ```Random Feature DenseAM``` Random Feature Hopfield Networks generalize retrieval to previously unseen examples https://openreview.net/forum?id=bv2szxARh2)
  * ```Random Feature DenseAM``` Nonparametric Modern Hopfield Models https://arxiv.org/abs/2404.03900
  * ```Kernel DenseAM``` Kernel Memory Networks: A Unifying Framework for Memory Modeling  https://arxiv.org/abs/2208.09416
  * ```Kernel DenseAM``` Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models  https://arxiv.org/abs/2404.03827
  * ```Kernel DenseAM``` Bridging Associative Memory and Probabilistic Modeling https://arxiv.org/abs/2402.10202



**Note:** I have tried my best to evaluate this paper. I spent much more time on this review than on my previous ones because I like this paper. Still, I might have missed something. Please correct me if I am wrong with fair justifications. I am open to changing my opinion and raising the score.

---

## Major: My main concern with this paper is its soundness and inadequate experimental evidence

### General


* ```line23:``` ""Memory representation"" is a strange term for me. If you are referring to the way of encoding memory patterns onto the energy landscape, isn't it ""memory encoding""? Representation generally involves learning, and to my understanding, there is no learning here.

  >Thus, in situations when the set of the memories needs to be expanded by introducing new patterns one must introduce additional weights.

  A side comment: this statement implies nonparametric, as suggested in [17].

* ```distributed representation```: I find the description of distributed representation vague. With more memories, $K$ increases, resulting in more degrees of freedom in $\mathbf{T}$. You can say the total number of entries in $\mathbf{T}$ is fixed, but not the number of parameters, unless you clearly define ""parameters"" differently. The current draft makes it difficult to parse the soundness.  I believe the idea of distributed representation deserves more elaboration. The current draft seems nonparametric to me.

  In my current review, I assume what is stated in lines 29-30 is correct.

* ```Sec3```: Section 3 is hard to follow due to typos and the lack of clarity.

* ```Missing Broader Impacts```: The authors didn't discuss both potential positive and negative societal impacts except in the checklist. My understanding is that this discussion needs to be included in the main text or the appendix, as the checklist is not considered part of the paper.

---

### Theory


* ```line92```: Eqn. (6) is hard to follow without clearly defined $S,s$. 

  I suppose $S:\mathbb{R}^d\times \mathbb{R}^d\to \mathbb{R}$ which makes $s\in\mathbb{R}$ a scalar realization of $S$?


* ```No fixed point convergence results```: Per my understanding, DenseAMs are energy models with memories stored in their local minima. Memory retrieval is conducted through energy minimization. This setting requires convergence between local minima and fixed points of retrieval updates, such as the convergence results of [Ramsauer2020,Hu2023]. Otherwise, there may be unbounded retrieval error due to the mismatch between local minima and fixed points of retrieval updates. Specifically, I believe lines 106-110 are at best ambiguous.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.

* ```Theorem 1```: I feel Thm1 may be incorrect. Could you elaborate more on this?

  * **My understanding:** Let $L$ be the number of updates, $K$ be the number of stored memories, $D$ be the memory dimension, and $Y$ be the feature space dimension. DrDAM improves time complexity from $O(LKD)$ to $O(D(Y K + L(Y + D))$, and improves peak memory from $O(KD)$ to $O(Y+D)$.
  * **Comment1:** $O(D(Y K + L(Y + D))$ is clearly a typo and makes the result hard to parse.
  * **Comment2:** Without specifying the relationships between $L$, $K$, $D$, and $Y$, it's hard to tell if this is truly an improvement. I can easily think of counterexamples.

  Given these, can you kindly elaborate more on the significance of thm1?


* ```Theorem 2```: Eqn. (12) is strange. Is there any guarantee ensuring $\alpha L(1+2K\beta e^{\beta/2}) < 1$? If not, it doesn't make sense that more updates would result in larger error. Perhaps this is related to the missing fixed point convergence?

---

### Experiments

* ```No Comparison to existing works:``` there is no baseline compared. 

* ```No efficiency evaluation1:``` Please include ablation studies on changing $L,K,D,Y$ to verify Thm1. 

* ```No efficiency evaluation2:``` Please also compare the efficiency with other methods, including linear, top-K, random feature, and random masked from [17], as well as dense [Ramsauer2020], sparse [Hu2023], and generalized sparse [Wu2023] MHNs. For example, the current draft needs some figures similar to Fig. 4 of [17] to justify the efficiency. Please do whatever makes sense to you. For instance, you can pick just two out of [Ramsauer2020, Hu2023, Wu2023] since they share similar structures.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Millidge2022] Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models. Millidge, B., Salvatori, T., Song, Y., Lukasiewicz, T., and Bogacz, R., 2022, June. In International Conference on Machine Learning (pp. 15561-15583). PMLR.
  
  * [Wu2023] Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.



* ```Compare with existing kernel DenseAMs.``` Also, a direct comparison with existing kernel methods is also necessary. For example,
  * Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models. Wu, D., Hu, J.Y.C., Hsiao, T.Y., and Liu, H., 2024. arXiv preprint arXiv:2404.03827.
  
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.

---

## Minor

* ```Inadequate Related Work Discussion```: A paragraph discussing related works is given at the end of the introduction. However, I feel it could be made more comprehensive to provide more background on the evolution of ideas and existing works in this field. At least, I feel the current draft is hard for a non-expert in DenseAMs to follow. Please see the following points.

* ```line38:``` I believe here can be benefited by including more comprehensive references. There are other recent works showing exponentially large memory storage capacity in various settings and dense associative memory (or modern Hopfield) networks/models. For examples: (I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.)

   * Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  * On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.
  * Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.
  * Sparse and Structured Hopfield Networks. Santos, S., Niculae, V., McNamee, D., and Martins, A.F., 2024. arXiv preprint arXiv:2402.13725.
  * On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. Hu, J.Y.C., Lin, T., Song, Z., and Liu, H., 2024. arXiv preprint arXiv:2402.04520.
  * Outlier-Efficient Hopfield Layers for Large Transformer-Based Models. Hu, J.Y.C., Chang, P.H., Luo, R., Chen, H.Y., Li, W., Wang, W.P., and Liu, H., 2024. arXiv preprint arXiv:2404.03828.


* ```line46:``` Similarly, here can be benefited by including more recent references
  > DenseAM family [...] 

* ```line51```: A similar motivating question is asked and explored in [17] from a kernel regression perspective. I agree this paper contributes something different and even beyond [17]. However, given the similarity of aims between the two, the current draft should:
  1. State the overlaps between the two works (both use a kernel approach to DenseAMs, and...).
  2. State the clear distinctions between the two works (both use a kernel approach to DenseAMs, but...).

  Such discussion will help readers parse the contributions of this work, which is currently lacking.

  [17] Jerry Yao-Chieh Hu, Bo-Yu Chen, Dennis Wu, Feng Ruan, and Han Liu. Nonparametric modern hopfield models. arXiv preprint arXiv:2404.03900, 2024. URL https://arxiv.org/pdf/2404.03900.pdf.
 

* ```line92```: 
  > those results have been recently applied to associative memory [15].

  I might have missed something, but it would be better to make the discussion of prior work more complete if it's presented in its current form (e.g., a paragraph highlighting the novelty and contributions benchmarked against existing works). The application of the kernel trick to associative memory is not new. While [16,17] are discussed right after [15], I feel it's better to cite them together as [15,16,17]. Additionally, there are two papers related to the kernel trick in associative memory, which I have attached below. Again, I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.

  - Iatropoulos, G., Brea, J., & Gerstner, W. (2022). Kernel memory networks: A unifying framework for memory modeling. Advances in neural information processing systems, 35, 35326-35338.
  
  -  Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R. and Gromov, A., 2024. Bridging Associative Memory and Probabilistic Modeling. arXiv preprint arXiv:2402.10202.

* ```line97```: 
  > Another paper [17] uses kernels for studying the sparse modern Hopfield network. 

  This is incorrect. 

  As stated in their abstract, [17] presents a general framework (referred to as nonparametric) to analyze and design modern Hopfield networks. The sparse network is just a special case of their framework. Additionally, [17] has already introduced the construction of random feature HMNs. While this construction lacks detailed analysis, which is a limitation they acknowledged, it would be more accurate to say that the submitted draft serves as a strong companion to [17] with rigorous theoretical and empirical results. I understand that the authors are not obliged to treat arXiv preprints (unpublished papers) too seriously, but it is better to give accurate credit to existing works when possible. To clarify, I am very happy to see this draft improves the results/proposal of [17] with detailed analysis, including multiple retrieval updates.

* I did not check the proofs line by line. However, I had a quick skim through them and found some typos and areas for improvement. Please do another round of proofreading if possible.


---

### Update 2024/08/07: raise score from 4 -> 5 -> 6 -> 7","* ```line109```: why you call the number of updates as *layers*? Are you recurrently passing the output as input to the same network or the network really has many layers? For example, recurrent layer is RNN sense is the later. 


* ```Proposition 1,2,3```: what is peak memory? why we should care about it?

* ```Time Complexity```: I appreciate the analysis of the computational complexity of the proposed method. From my view, this proposal is a special case of [Hu2024] with $L=1$ (where $L$ is the sequence length in their analysis). [Hu2024] provides a characterization of all sub-quadratic (efficient) variants of the modern Hopfield model. Essentially, your proposal is an efficient approximation to the softmax DenseAMs. Hence, the relevance holds. Can you discuss how your proposal fits into the results of [Hu2024]?
  
  * [Hu2024] Hu, J.Y.C., Lin, T., Song, Z. and Liu, H., 2024. On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. arXiv preprint arXiv:2402.04520.


* ```line255, Exp Observation 2```: This observation is a bit counterintuitive. Normally, large $\beta$ means low-temperature region and leads to more stable/accurate retrieval, e.g., infinity $\beta$ leads to argmax-retrieval. Why random DrDAM shows otherwise?  



* ```Fig3```: Intuitively, why larger $\beta$ needs larger $Y$?

* ```line303```: What's the point of approximating energies and update dynamics? Shouldn't the significance lie in the approximation error of retrieval?

* I am wondering if you have explored the learning aspect of the proposed method. It is known that many DenseAMs are connected to transformer attention and can be used as a learning model or layer. Can you explore this part a bit as in [17]? If not, please explain why.

* Can you kindly remind me which part of this work supports the claim ""making it possible to introduce new memories without increasing the number of weights""?","There is a limitation section but no broader impact or impact statement expect in the checklist.


Appendix A of the draft acknowledges that the experimental explorations are limited. However, it would benefit from discussing comparisons with baselines and including some vital ablations. This would help clarify the contribution and soundness of the proposed method. See above for other limitations.",['No ethics review needed.'],7,4,,Yes,3,3,2,1718224581283,,,NeurIPS.cc/2024/Conference,164QnJsYjF,"['NeurIPS.cc/2024/Conference/Submission18824/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880001942,[],1,,,['everyone'],164QnJsYjF,['NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh'],1718224581283,1730880001942,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Ramsauer et al. (2020) - ""Hopfield Networks is All You Need""
2. Hu et al. (2023) - ""On Sparse Modern Hopfield Model""
3. Millidge et al. (2022) - ""Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models""
4. Wu et al. (2023) - ""Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction""
5. Iatropoulos et al. (2022) - ""Kernel Memory Networks: A Unifying Framework for Memory Modeling""
6. Schaeffer et al. (2024) - ""Bridging Associative Memory and Probabilistic Modeling""
7. Hu et al. (2024) - ""On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis""
8. Hu et al. (2024) - ""Nonparametric Modern Hopfield Models""

The reviewer also mentions that the authors should discuss the overlaps and distinctions between their work and the work presented in [17], which refers to Hu et al. (2024) - ""Nonparametric Modern Hopfield Models"".",1,"2020, 2023, 2022, 2023, 2022, 2024, 2024, 2024, 2024",Kernel Memory Networks A Unifying Framework for Memory Modeling 
JefUAe9HkR,"This paper introduce an iterative random feature Dense Associative Memory Model (DenseAM).
It is a kernel approximation of the standard DenseAMs using random feature decomposition and approximation. 
The authors term this approach to DenseAMs as distributed representation/formulation of memory (DrDAM).

Theoretically, they analyze the time complexity of the proposed method (Thm1) and the approximation error (Thm2), both benchmarked against the standard DenseAM (MrDAM). 
Experimentally, they evaluate the approximation accuracy of DrDAM's energies and gradients, defined as the MAE difference between DrDAM and MrDAM, and the retrieval accuracy of DrDAM. 
Importantly, their analysis of DrDAM considers its iterative nature, distinguishing their contribution from prior works.

In sum, they address important research questions and their approach is natural and intuitive based on recent advances in the random feature kernel trick.","* **Originality**: This paper expands our understanding of Dense Associative Memory Models (DenseAMs) by presenting a random feature DenseAM, termed DrDAM. The idea of DrDAM is novel and beneficial to the ML and associative memory community.

* **Significance**: While the idea of random feature DenseAM is not entirely new, this work delves deeper than most prior studies. For example, to the best of my knowledge, there is nothing as concrete as the iterative Algorithm 1 presented in prior works. This represents a significant and solid step forward for the community, and I appreciate the effort.

* **Theoretical Contribution**: This paper provides an efficiency and approximation analysis of DrDAM.

* **Experimental Contribution**: They explore some aspects of DrDAM, including the approximation of energies and gradients and the approximation ability of DrDAM. Reproducible code is also provided.","## Summary of Weaknesses

Overall, this paper presents a good idea, but it seems rushed, which affects the contribution of an otherwise very interesting work. Regardless of the final decision, I hope the authors find my comments helpful in further refining their draft.

There are a few areas that could benefit from further improvement and clarity:

* **Experiments:** The current experimental results would be strengthened by including comparisons with established baselines and more ablation studies.
* **Clarity:** Some of the theoretical results are difficult to interpret due to minor typos and a need for increased mathematical clarity.
* **Motivation:** The motivation and problem statement could be articulated more convincingly. Even after multiple readings of the intro, it remains unclear if distributed representation is truly parameter-efficient beyond the nonparametric sense.
* **Related Works:** Additionally, while not critical, the idea of Random Feature DenseAM (and Kernel DenseAM) has been discussed in prior works. The related discussion in this paper could be expanded to better position the contribution within the existing literature. For examples:
  * ```Random Feature DenseAM``` Random Feature Hopfield Networks generalize retrieval to previously unseen examples https://openreview.net/forum?id=bv2szxARh2)
  * ```Random Feature DenseAM``` Nonparametric Modern Hopfield Models https://arxiv.org/abs/2404.03900
  * ```Kernel DenseAM``` Kernel Memory Networks: A Unifying Framework for Memory Modeling  https://arxiv.org/abs/2208.09416
  * ```Kernel DenseAM``` Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models  https://arxiv.org/abs/2404.03827
  * ```Kernel DenseAM``` Bridging Associative Memory and Probabilistic Modeling https://arxiv.org/abs/2402.10202



**Note:** I have tried my best to evaluate this paper. I spent much more time on this review than on my previous ones because I like this paper. Still, I might have missed something. Please correct me if I am wrong with fair justifications. I am open to changing my opinion and raising the score.

---

## Major: My main concern with this paper is its soundness and inadequate experimental evidence

### General


* ```line23:``` ""Memory representation"" is a strange term for me. If you are referring to the way of encoding memory patterns onto the energy landscape, isn't it ""memory encoding""? Representation generally involves learning, and to my understanding, there is no learning here.

  >Thus, in situations when the set of the memories needs to be expanded by introducing new patterns one must introduce additional weights.

  A side comment: this statement implies nonparametric, as suggested in [17].

* ```distributed representation```: I find the description of distributed representation vague. With more memories, $K$ increases, resulting in more degrees of freedom in $\mathbf{T}$. You can say the total number of entries in $\mathbf{T}$ is fixed, but not the number of parameters, unless you clearly define ""parameters"" differently. The current draft makes it difficult to parse the soundness.  I believe the idea of distributed representation deserves more elaboration. The current draft seems nonparametric to me.

  In my current review, I assume what is stated in lines 29-30 is correct.

* ```Sec3```: Section 3 is hard to follow due to typos and the lack of clarity.

* ```Missing Broader Impacts```: The authors didn't discuss both potential positive and negative societal impacts except in the checklist. My understanding is that this discussion needs to be included in the main text or the appendix, as the checklist is not considered part of the paper.

---

### Theory


* ```line92```: Eqn. (6) is hard to follow without clearly defined $S,s$. 

  I suppose $S:\mathbb{R}^d\times \mathbb{R}^d\to \mathbb{R}$ which makes $s\in\mathbb{R}$ a scalar realization of $S$?


* ```No fixed point convergence results```: Per my understanding, DenseAMs are energy models with memories stored in their local minima. Memory retrieval is conducted through energy minimization. This setting requires convergence between local minima and fixed points of retrieval updates, such as the convergence results of [Ramsauer2020,Hu2023]. Otherwise, there may be unbounded retrieval error due to the mismatch between local minima and fixed points of retrieval updates. Specifically, I believe lines 106-110 are at best ambiguous.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.

* ```Theorem 1```: I feel Thm1 may be incorrect. Could you elaborate more on this?

  * **My understanding:** Let $L$ be the number of updates, $K$ be the number of stored memories, $D$ be the memory dimension, and $Y$ be the feature space dimension. DrDAM improves time complexity from $O(LKD)$ to $O(D(Y K + L(Y + D))$, and improves peak memory from $O(KD)$ to $O(Y+D)$.
  * **Comment1:** $O(D(Y K + L(Y + D))$ is clearly a typo and makes the result hard to parse.
  * **Comment2:** Without specifying the relationships between $L$, $K$, $D$, and $Y$, it's hard to tell if this is truly an improvement. I can easily think of counterexamples.

  Given these, can you kindly elaborate more on the significance of thm1?


* ```Theorem 2```: Eqn. (12) is strange. Is there any guarantee ensuring $\alpha L(1+2K\beta e^{\beta/2}) < 1$? If not, it doesn't make sense that more updates would result in larger error. Perhaps this is related to the missing fixed point convergence?

---

### Experiments

* ```No Comparison to existing works:``` there is no baseline compared. 

* ```No efficiency evaluation1:``` Please include ablation studies on changing $L,K,D,Y$ to verify Thm1. 

* ```No efficiency evaluation2:``` Please also compare the efficiency with other methods, including linear, top-K, random feature, and random masked from [17], as well as dense [Ramsauer2020], sparse [Hu2023], and generalized sparse [Wu2023] MHNs. For example, the current draft needs some figures similar to Fig. 4 of [17] to justify the efficiency. Please do whatever makes sense to you. For instance, you can pick just two out of [Ramsauer2020, Hu2023, Wu2023] since they share similar structures.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Millidge2022] Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models. Millidge, B., Salvatori, T., Song, Y., Lukasiewicz, T., and Bogacz, R., 2022, June. In International Conference on Machine Learning (pp. 15561-15583). PMLR.
  
  * [Wu2023] Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.



* ```Compare with existing kernel DenseAMs.``` Also, a direct comparison with existing kernel methods is also necessary. For example,
  * Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models. Wu, D., Hu, J.Y.C., Hsiao, T.Y., and Liu, H., 2024. arXiv preprint arXiv:2404.03827.
  
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.

---

## Minor

* ```Inadequate Related Work Discussion```: A paragraph discussing related works is given at the end of the introduction. However, I feel it could be made more comprehensive to provide more background on the evolution of ideas and existing works in this field. At least, I feel the current draft is hard for a non-expert in DenseAMs to follow. Please see the following points.

* ```line38:``` I believe here can be benefited by including more comprehensive references. There are other recent works showing exponentially large memory storage capacity in various settings and dense associative memory (or modern Hopfield) networks/models. For examples: (I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.)

   * Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  * On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.
  * Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.
  * Sparse and Structured Hopfield Networks. Santos, S., Niculae, V., McNamee, D., and Martins, A.F., 2024. arXiv preprint arXiv:2402.13725.
  * On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. Hu, J.Y.C., Lin, T., Song, Z., and Liu, H., 2024. arXiv preprint arXiv:2402.04520.
  * Outlier-Efficient Hopfield Layers for Large Transformer-Based Models. Hu, J.Y.C., Chang, P.H., Luo, R., Chen, H.Y., Li, W., Wang, W.P., and Liu, H., 2024. arXiv preprint arXiv:2404.03828.


* ```line46:``` Similarly, here can be benefited by including more recent references
  > DenseAM family [...] 

* ```line51```: A similar motivating question is asked and explored in [17] from a kernel regression perspective. I agree this paper contributes something different and even beyond [17]. However, given the similarity of aims between the two, the current draft should:
  1. State the overlaps between the two works (both use a kernel approach to DenseAMs, and...).
  2. State the clear distinctions between the two works (both use a kernel approach to DenseAMs, but...).

  Such discussion will help readers parse the contributions of this work, which is currently lacking.

  [17] Jerry Yao-Chieh Hu, Bo-Yu Chen, Dennis Wu, Feng Ruan, and Han Liu. Nonparametric modern hopfield models. arXiv preprint arXiv:2404.03900, 2024. URL https://arxiv.org/pdf/2404.03900.pdf.
 

* ```line92```: 
  > those results have been recently applied to associative memory [15].

  I might have missed something, but it would be better to make the discussion of prior work more complete if it's presented in its current form (e.g., a paragraph highlighting the novelty and contributions benchmarked against existing works). The application of the kernel trick to associative memory is not new. While [16,17] are discussed right after [15], I feel it's better to cite them together as [15,16,17]. Additionally, there are two papers related to the kernel trick in associative memory, which I have attached below. Again, I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.

  - Iatropoulos, G., Brea, J., & Gerstner, W. (2022). Kernel memory networks: A unifying framework for memory modeling. Advances in neural information processing systems, 35, 35326-35338.
  
  -  Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R. and Gromov, A., 2024. Bridging Associative Memory and Probabilistic Modeling. arXiv preprint arXiv:2402.10202.

* ```line97```: 
  > Another paper [17] uses kernels for studying the sparse modern Hopfield network. 

  This is incorrect. 

  As stated in their abstract, [17] presents a general framework (referred to as nonparametric) to analyze and design modern Hopfield networks. The sparse network is just a special case of their framework. Additionally, [17] has already introduced the construction of random feature HMNs. While this construction lacks detailed analysis, which is a limitation they acknowledged, it would be more accurate to say that the submitted draft serves as a strong companion to [17] with rigorous theoretical and empirical results. I understand that the authors are not obliged to treat arXiv preprints (unpublished papers) too seriously, but it is better to give accurate credit to existing works when possible. To clarify, I am very happy to see this draft improves the results/proposal of [17] with detailed analysis, including multiple retrieval updates.

* I did not check the proofs line by line. However, I had a quick skim through them and found some typos and areas for improvement. Please do another round of proofreading if possible.


---

### Update 2024/08/07: raise score from 4 -> 5 -> 6 -> 7","* ```line109```: why you call the number of updates as *layers*? Are you recurrently passing the output as input to the same network or the network really has many layers? For example, recurrent layer is RNN sense is the later. 


* ```Proposition 1,2,3```: what is peak memory? why we should care about it?

* ```Time Complexity```: I appreciate the analysis of the computational complexity of the proposed method. From my view, this proposal is a special case of [Hu2024] with $L=1$ (where $L$ is the sequence length in their analysis). [Hu2024] provides a characterization of all sub-quadratic (efficient) variants of the modern Hopfield model. Essentially, your proposal is an efficient approximation to the softmax DenseAMs. Hence, the relevance holds. Can you discuss how your proposal fits into the results of [Hu2024]?
  
  * [Hu2024] Hu, J.Y.C., Lin, T., Song, Z. and Liu, H., 2024. On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. arXiv preprint arXiv:2402.04520.


* ```line255, Exp Observation 2```: This observation is a bit counterintuitive. Normally, large $\beta$ means low-temperature region and leads to more stable/accurate retrieval, e.g., infinity $\beta$ leads to argmax-retrieval. Why random DrDAM shows otherwise?  



* ```Fig3```: Intuitively, why larger $\beta$ needs larger $Y$?

* ```line303```: What's the point of approximating energies and update dynamics? Shouldn't the significance lie in the approximation error of retrieval?

* I am wondering if you have explored the learning aspect of the proposed method. It is known that many DenseAMs are connected to transformer attention and can be used as a learning model or layer. Can you explore this part a bit as in [17]? If not, please explain why.

* Can you kindly remind me which part of this work supports the claim ""making it possible to introduce new memories without increasing the number of weights""?","There is a limitation section but no broader impact or impact statement expect in the checklist.


Appendix A of the draft acknowledges that the experimental explorations are limited. However, it would benefit from discussing comparisons with baselines and including some vital ablations. This would help clarify the contribution and soundness of the proposed method. See above for other limitations.",['No ethics review needed.'],7,4,,Yes,3,3,2,1718224581283,,,NeurIPS.cc/2024/Conference,164QnJsYjF,"['NeurIPS.cc/2024/Conference/Submission18824/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880001942,[],1,,,['everyone'],164QnJsYjF,['NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh'],1718224581283,1730880001942,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Ramsauer et al. (2020) - ""Hopfield Networks is All You Need""
2. Hu et al. (2023) - ""On Sparse Modern Hopfield Model""
3. Millidge et al. (2022) - ""Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models""
4. Wu et al. (2023) - ""Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction""
5. Iatropoulos et al. (2022) - ""Kernel Memory Networks: A Unifying Framework for Memory Modeling""
6. Schaeffer et al. (2024) - ""Bridging Associative Memory and Probabilistic Modeling""
7. Hu et al. (2024) - ""On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis""
8. Hu et al. (2024) - ""Nonparametric Modern Hopfield Models""

The reviewer also mentions that the authors should discuss the overlaps and distinctions between their work and the work presented in [17], which refers to Hu et al. (2024) - ""Nonparametric Modern Hopfield Models"".",1,"2020, 2023, 2022, 2023, 2022, 2024, 2024, 2024, 2024",Bridging Associative Memory and Probabilistic Modeling 
JefUAe9HkR,"This paper introduce an iterative random feature Dense Associative Memory Model (DenseAM).
It is a kernel approximation of the standard DenseAMs using random feature decomposition and approximation. 
The authors term this approach to DenseAMs as distributed representation/formulation of memory (DrDAM).

Theoretically, they analyze the time complexity of the proposed method (Thm1) and the approximation error (Thm2), both benchmarked against the standard DenseAM (MrDAM). 
Experimentally, they evaluate the approximation accuracy of DrDAM's energies and gradients, defined as the MAE difference between DrDAM and MrDAM, and the retrieval accuracy of DrDAM. 
Importantly, their analysis of DrDAM considers its iterative nature, distinguishing their contribution from prior works.

In sum, they address important research questions and their approach is natural and intuitive based on recent advances in the random feature kernel trick.","* **Originality**: This paper expands our understanding of Dense Associative Memory Models (DenseAMs) by presenting a random feature DenseAM, termed DrDAM. The idea of DrDAM is novel and beneficial to the ML and associative memory community.

* **Significance**: While the idea of random feature DenseAM is not entirely new, this work delves deeper than most prior studies. For example, to the best of my knowledge, there is nothing as concrete as the iterative Algorithm 1 presented in prior works. This represents a significant and solid step forward for the community, and I appreciate the effort.

* **Theoretical Contribution**: This paper provides an efficiency and approximation analysis of DrDAM.

* **Experimental Contribution**: They explore some aspects of DrDAM, including the approximation of energies and gradients and the approximation ability of DrDAM. Reproducible code is also provided.","## Summary of Weaknesses

Overall, this paper presents a good idea, but it seems rushed, which affects the contribution of an otherwise very interesting work. Regardless of the final decision, I hope the authors find my comments helpful in further refining their draft.

There are a few areas that could benefit from further improvement and clarity:

* **Experiments:** The current experimental results would be strengthened by including comparisons with established baselines and more ablation studies.
* **Clarity:** Some of the theoretical results are difficult to interpret due to minor typos and a need for increased mathematical clarity.
* **Motivation:** The motivation and problem statement could be articulated more convincingly. Even after multiple readings of the intro, it remains unclear if distributed representation is truly parameter-efficient beyond the nonparametric sense.
* **Related Works:** Additionally, while not critical, the idea of Random Feature DenseAM (and Kernel DenseAM) has been discussed in prior works. The related discussion in this paper could be expanded to better position the contribution within the existing literature. For examples:
  * ```Random Feature DenseAM``` Random Feature Hopfield Networks generalize retrieval to previously unseen examples https://openreview.net/forum?id=bv2szxARh2)
  * ```Random Feature DenseAM``` Nonparametric Modern Hopfield Models https://arxiv.org/abs/2404.03900
  * ```Kernel DenseAM``` Kernel Memory Networks: A Unifying Framework for Memory Modeling  https://arxiv.org/abs/2208.09416
  * ```Kernel DenseAM``` Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models  https://arxiv.org/abs/2404.03827
  * ```Kernel DenseAM``` Bridging Associative Memory and Probabilistic Modeling https://arxiv.org/abs/2402.10202



**Note:** I have tried my best to evaluate this paper. I spent much more time on this review than on my previous ones because I like this paper. Still, I might have missed something. Please correct me if I am wrong with fair justifications. I am open to changing my opinion and raising the score.

---

## Major: My main concern with this paper is its soundness and inadequate experimental evidence

### General


* ```line23:``` ""Memory representation"" is a strange term for me. If you are referring to the way of encoding memory patterns onto the energy landscape, isn't it ""memory encoding""? Representation generally involves learning, and to my understanding, there is no learning here.

  >Thus, in situations when the set of the memories needs to be expanded by introducing new patterns one must introduce additional weights.

  A side comment: this statement implies nonparametric, as suggested in [17].

* ```distributed representation```: I find the description of distributed representation vague. With more memories, $K$ increases, resulting in more degrees of freedom in $\mathbf{T}$. You can say the total number of entries in $\mathbf{T}$ is fixed, but not the number of parameters, unless you clearly define ""parameters"" differently. The current draft makes it difficult to parse the soundness.  I believe the idea of distributed representation deserves more elaboration. The current draft seems nonparametric to me.

  In my current review, I assume what is stated in lines 29-30 is correct.

* ```Sec3```: Section 3 is hard to follow due to typos and the lack of clarity.

* ```Missing Broader Impacts```: The authors didn't discuss both potential positive and negative societal impacts except in the checklist. My understanding is that this discussion needs to be included in the main text or the appendix, as the checklist is not considered part of the paper.

---

### Theory


* ```line92```: Eqn. (6) is hard to follow without clearly defined $S,s$. 

  I suppose $S:\mathbb{R}^d\times \mathbb{R}^d\to \mathbb{R}$ which makes $s\in\mathbb{R}$ a scalar realization of $S$?


* ```No fixed point convergence results```: Per my understanding, DenseAMs are energy models with memories stored in their local minima. Memory retrieval is conducted through energy minimization. This setting requires convergence between local minima and fixed points of retrieval updates, such as the convergence results of [Ramsauer2020,Hu2023]. Otherwise, there may be unbounded retrieval error due to the mismatch between local minima and fixed points of retrieval updates. Specifically, I believe lines 106-110 are at best ambiguous.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.

* ```Theorem 1```: I feel Thm1 may be incorrect. Could you elaborate more on this?

  * **My understanding:** Let $L$ be the number of updates, $K$ be the number of stored memories, $D$ be the memory dimension, and $Y$ be the feature space dimension. DrDAM improves time complexity from $O(LKD)$ to $O(D(Y K + L(Y + D))$, and improves peak memory from $O(KD)$ to $O(Y+D)$.
  * **Comment1:** $O(D(Y K + L(Y + D))$ is clearly a typo and makes the result hard to parse.
  * **Comment2:** Without specifying the relationships between $L$, $K$, $D$, and $Y$, it's hard to tell if this is truly an improvement. I can easily think of counterexamples.

  Given these, can you kindly elaborate more on the significance of thm1?


* ```Theorem 2```: Eqn. (12) is strange. Is there any guarantee ensuring $\alpha L(1+2K\beta e^{\beta/2}) < 1$? If not, it doesn't make sense that more updates would result in larger error. Perhaps this is related to the missing fixed point convergence?

---

### Experiments

* ```No Comparison to existing works:``` there is no baseline compared. 

* ```No efficiency evaluation1:``` Please include ablation studies on changing $L,K,D,Y$ to verify Thm1. 

* ```No efficiency evaluation2:``` Please also compare the efficiency with other methods, including linear, top-K, random feature, and random masked from [17], as well as dense [Ramsauer2020], sparse [Hu2023], and generalized sparse [Wu2023] MHNs. For example, the current draft needs some figures similar to Fig. 4 of [17] to justify the efficiency. Please do whatever makes sense to you. For instance, you can pick just two out of [Ramsauer2020, Hu2023, Wu2023] since they share similar structures.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Millidge2022] Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models. Millidge, B., Salvatori, T., Song, Y., Lukasiewicz, T., and Bogacz, R., 2022, June. In International Conference on Machine Learning (pp. 15561-15583). PMLR.
  
  * [Wu2023] Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.



* ```Compare with existing kernel DenseAMs.``` Also, a direct comparison with existing kernel methods is also necessary. For example,
  * Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models. Wu, D., Hu, J.Y.C., Hsiao, T.Y., and Liu, H., 2024. arXiv preprint arXiv:2404.03827.
  
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.

---

## Minor

* ```Inadequate Related Work Discussion```: A paragraph discussing related works is given at the end of the introduction. However, I feel it could be made more comprehensive to provide more background on the evolution of ideas and existing works in this field. At least, I feel the current draft is hard for a non-expert in DenseAMs to follow. Please see the following points.

* ```line38:``` I believe here can be benefited by including more comprehensive references. There are other recent works showing exponentially large memory storage capacity in various settings and dense associative memory (or modern Hopfield) networks/models. For examples: (I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.)

   * Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  * On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.
  * Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.
  * Sparse and Structured Hopfield Networks. Santos, S., Niculae, V., McNamee, D., and Martins, A.F., 2024. arXiv preprint arXiv:2402.13725.
  * On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. Hu, J.Y.C., Lin, T., Song, Z., and Liu, H., 2024. arXiv preprint arXiv:2402.04520.
  * Outlier-Efficient Hopfield Layers for Large Transformer-Based Models. Hu, J.Y.C., Chang, P.H., Luo, R., Chen, H.Y., Li, W., Wang, W.P., and Liu, H., 2024. arXiv preprint arXiv:2404.03828.


* ```line46:``` Similarly, here can be benefited by including more recent references
  > DenseAM family [...] 

* ```line51```: A similar motivating question is asked and explored in [17] from a kernel regression perspective. I agree this paper contributes something different and even beyond [17]. However, given the similarity of aims between the two, the current draft should:
  1. State the overlaps between the two works (both use a kernel approach to DenseAMs, and...).
  2. State the clear distinctions between the two works (both use a kernel approach to DenseAMs, but...).

  Such discussion will help readers parse the contributions of this work, which is currently lacking.

  [17] Jerry Yao-Chieh Hu, Bo-Yu Chen, Dennis Wu, Feng Ruan, and Han Liu. Nonparametric modern hopfield models. arXiv preprint arXiv:2404.03900, 2024. URL https://arxiv.org/pdf/2404.03900.pdf.
 

* ```line92```: 
  > those results have been recently applied to associative memory [15].

  I might have missed something, but it would be better to make the discussion of prior work more complete if it's presented in its current form (e.g., a paragraph highlighting the novelty and contributions benchmarked against existing works). The application of the kernel trick to associative memory is not new. While [16,17] are discussed right after [15], I feel it's better to cite them together as [15,16,17]. Additionally, there are two papers related to the kernel trick in associative memory, which I have attached below. Again, I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.

  - Iatropoulos, G., Brea, J., & Gerstner, W. (2022). Kernel memory networks: A unifying framework for memory modeling. Advances in neural information processing systems, 35, 35326-35338.
  
  -  Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R. and Gromov, A., 2024. Bridging Associative Memory and Probabilistic Modeling. arXiv preprint arXiv:2402.10202.

* ```line97```: 
  > Another paper [17] uses kernels for studying the sparse modern Hopfield network. 

  This is incorrect. 

  As stated in their abstract, [17] presents a general framework (referred to as nonparametric) to analyze and design modern Hopfield networks. The sparse network is just a special case of their framework. Additionally, [17] has already introduced the construction of random feature HMNs. While this construction lacks detailed analysis, which is a limitation they acknowledged, it would be more accurate to say that the submitted draft serves as a strong companion to [17] with rigorous theoretical and empirical results. I understand that the authors are not obliged to treat arXiv preprints (unpublished papers) too seriously, but it is better to give accurate credit to existing works when possible. To clarify, I am very happy to see this draft improves the results/proposal of [17] with detailed analysis, including multiple retrieval updates.

* I did not check the proofs line by line. However, I had a quick skim through them and found some typos and areas for improvement. Please do another round of proofreading if possible.


---

### Update 2024/08/07: raise score from 4 -> 5 -> 6 -> 7","* ```line109```: why you call the number of updates as *layers*? Are you recurrently passing the output as input to the same network or the network really has many layers? For example, recurrent layer is RNN sense is the later. 


* ```Proposition 1,2,3```: what is peak memory? why we should care about it?

* ```Time Complexity```: I appreciate the analysis of the computational complexity of the proposed method. From my view, this proposal is a special case of [Hu2024] with $L=1$ (where $L$ is the sequence length in their analysis). [Hu2024] provides a characterization of all sub-quadratic (efficient) variants of the modern Hopfield model. Essentially, your proposal is an efficient approximation to the softmax DenseAMs. Hence, the relevance holds. Can you discuss how your proposal fits into the results of [Hu2024]?
  
  * [Hu2024] Hu, J.Y.C., Lin, T., Song, Z. and Liu, H., 2024. On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. arXiv preprint arXiv:2402.04520.


* ```line255, Exp Observation 2```: This observation is a bit counterintuitive. Normally, large $\beta$ means low-temperature region and leads to more stable/accurate retrieval, e.g., infinity $\beta$ leads to argmax-retrieval. Why random DrDAM shows otherwise?  



* ```Fig3```: Intuitively, why larger $\beta$ needs larger $Y$?

* ```line303```: What's the point of approximating energies and update dynamics? Shouldn't the significance lie in the approximation error of retrieval?

* I am wondering if you have explored the learning aspect of the proposed method. It is known that many DenseAMs are connected to transformer attention and can be used as a learning model or layer. Can you explore this part a bit as in [17]? If not, please explain why.

* Can you kindly remind me which part of this work supports the claim ""making it possible to introduce new memories without increasing the number of weights""?","There is a limitation section but no broader impact or impact statement expect in the checklist.


Appendix A of the draft acknowledges that the experimental explorations are limited. However, it would benefit from discussing comparisons with baselines and including some vital ablations. This would help clarify the contribution and soundness of the proposed method. See above for other limitations.",['No ethics review needed.'],7,4,,Yes,3,3,2,1718224581283,,,NeurIPS.cc/2024/Conference,164QnJsYjF,"['NeurIPS.cc/2024/Conference/Submission18824/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880001942,[],1,,,['everyone'],164QnJsYjF,['NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh'],1718224581283,1730880001942,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Ramsauer et al. (2020) - ""Hopfield Networks is All You Need""
2. Hu et al. (2023) - ""On Sparse Modern Hopfield Model""
3. Millidge et al. (2022) - ""Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models""
4. Wu et al. (2023) - ""Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction""
5. Iatropoulos et al. (2022) - ""Kernel Memory Networks: A Unifying Framework for Memory Modeling""
6. Schaeffer et al. (2024) - ""Bridging Associative Memory and Probabilistic Modeling""
7. Hu et al. (2024) - ""On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis""
8. Hu et al. (2024) - ""Nonparametric Modern Hopfield Models""

The reviewer also mentions that the authors should discuss the overlaps and distinctions between their work and the work presented in [17], which refers to Hu et al. (2024) - ""Nonparametric Modern Hopfield Models"".",1,"2020, 2023, 2022, 2023, 2022, 2024, 2024, 2024, 2024",On Computational Limits of Modern Hopfield Models A Fine-Grained Complexity Analysis 
JefUAe9HkR,"This paper introduce an iterative random feature Dense Associative Memory Model (DenseAM).
It is a kernel approximation of the standard DenseAMs using random feature decomposition and approximation. 
The authors term this approach to DenseAMs as distributed representation/formulation of memory (DrDAM).

Theoretically, they analyze the time complexity of the proposed method (Thm1) and the approximation error (Thm2), both benchmarked against the standard DenseAM (MrDAM). 
Experimentally, they evaluate the approximation accuracy of DrDAM's energies and gradients, defined as the MAE difference between DrDAM and MrDAM, and the retrieval accuracy of DrDAM. 
Importantly, their analysis of DrDAM considers its iterative nature, distinguishing their contribution from prior works.

In sum, they address important research questions and their approach is natural and intuitive based on recent advances in the random feature kernel trick.","* **Originality**: This paper expands our understanding of Dense Associative Memory Models (DenseAMs) by presenting a random feature DenseAM, termed DrDAM. The idea of DrDAM is novel and beneficial to the ML and associative memory community.

* **Significance**: While the idea of random feature DenseAM is not entirely new, this work delves deeper than most prior studies. For example, to the best of my knowledge, there is nothing as concrete as the iterative Algorithm 1 presented in prior works. This represents a significant and solid step forward for the community, and I appreciate the effort.

* **Theoretical Contribution**: This paper provides an efficiency and approximation analysis of DrDAM.

* **Experimental Contribution**: They explore some aspects of DrDAM, including the approximation of energies and gradients and the approximation ability of DrDAM. Reproducible code is also provided.","## Summary of Weaknesses

Overall, this paper presents a good idea, but it seems rushed, which affects the contribution of an otherwise very interesting work. Regardless of the final decision, I hope the authors find my comments helpful in further refining their draft.

There are a few areas that could benefit from further improvement and clarity:

* **Experiments:** The current experimental results would be strengthened by including comparisons with established baselines and more ablation studies.
* **Clarity:** Some of the theoretical results are difficult to interpret due to minor typos and a need for increased mathematical clarity.
* **Motivation:** The motivation and problem statement could be articulated more convincingly. Even after multiple readings of the intro, it remains unclear if distributed representation is truly parameter-efficient beyond the nonparametric sense.
* **Related Works:** Additionally, while not critical, the idea of Random Feature DenseAM (and Kernel DenseAM) has been discussed in prior works. The related discussion in this paper could be expanded to better position the contribution within the existing literature. For examples:
  * ```Random Feature DenseAM``` Random Feature Hopfield Networks generalize retrieval to previously unseen examples https://openreview.net/forum?id=bv2szxARh2)
  * ```Random Feature DenseAM``` Nonparametric Modern Hopfield Models https://arxiv.org/abs/2404.03900
  * ```Kernel DenseAM``` Kernel Memory Networks: A Unifying Framework for Memory Modeling  https://arxiv.org/abs/2208.09416
  * ```Kernel DenseAM``` Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models  https://arxiv.org/abs/2404.03827
  * ```Kernel DenseAM``` Bridging Associative Memory and Probabilistic Modeling https://arxiv.org/abs/2402.10202



**Note:** I have tried my best to evaluate this paper. I spent much more time on this review than on my previous ones because I like this paper. Still, I might have missed something. Please correct me if I am wrong with fair justifications. I am open to changing my opinion and raising the score.

---

## Major: My main concern with this paper is its soundness and inadequate experimental evidence

### General


* ```line23:``` ""Memory representation"" is a strange term for me. If you are referring to the way of encoding memory patterns onto the energy landscape, isn't it ""memory encoding""? Representation generally involves learning, and to my understanding, there is no learning here.

  >Thus, in situations when the set of the memories needs to be expanded by introducing new patterns one must introduce additional weights.

  A side comment: this statement implies nonparametric, as suggested in [17].

* ```distributed representation```: I find the description of distributed representation vague. With more memories, $K$ increases, resulting in more degrees of freedom in $\mathbf{T}$. You can say the total number of entries in $\mathbf{T}$ is fixed, but not the number of parameters, unless you clearly define ""parameters"" differently. The current draft makes it difficult to parse the soundness.  I believe the idea of distributed representation deserves more elaboration. The current draft seems nonparametric to me.

  In my current review, I assume what is stated in lines 29-30 is correct.

* ```Sec3```: Section 3 is hard to follow due to typos and the lack of clarity.

* ```Missing Broader Impacts```: The authors didn't discuss both potential positive and negative societal impacts except in the checklist. My understanding is that this discussion needs to be included in the main text or the appendix, as the checklist is not considered part of the paper.

---

### Theory


* ```line92```: Eqn. (6) is hard to follow without clearly defined $S,s$. 

  I suppose $S:\mathbb{R}^d\times \mathbb{R}^d\to \mathbb{R}$ which makes $s\in\mathbb{R}$ a scalar realization of $S$?


* ```No fixed point convergence results```: Per my understanding, DenseAMs are energy models with memories stored in their local minima. Memory retrieval is conducted through energy minimization. This setting requires convergence between local minima and fixed points of retrieval updates, such as the convergence results of [Ramsauer2020,Hu2023]. Otherwise, there may be unbounded retrieval error due to the mismatch between local minima and fixed points of retrieval updates. Specifically, I believe lines 106-110 are at best ambiguous.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.

* ```Theorem 1```: I feel Thm1 may be incorrect. Could you elaborate more on this?

  * **My understanding:** Let $L$ be the number of updates, $K$ be the number of stored memories, $D$ be the memory dimension, and $Y$ be the feature space dimension. DrDAM improves time complexity from $O(LKD)$ to $O(D(Y K + L(Y + D))$, and improves peak memory from $O(KD)$ to $O(Y+D)$.
  * **Comment1:** $O(D(Y K + L(Y + D))$ is clearly a typo and makes the result hard to parse.
  * **Comment2:** Without specifying the relationships between $L$, $K$, $D$, and $Y$, it's hard to tell if this is truly an improvement. I can easily think of counterexamples.

  Given these, can you kindly elaborate more on the significance of thm1?


* ```Theorem 2```: Eqn. (12) is strange. Is there any guarantee ensuring $\alpha L(1+2K\beta e^{\beta/2}) < 1$? If not, it doesn't make sense that more updates would result in larger error. Perhaps this is related to the missing fixed point convergence?

---

### Experiments

* ```No Comparison to existing works:``` there is no baseline compared. 

* ```No efficiency evaluation1:``` Please include ablation studies on changing $L,K,D,Y$ to verify Thm1. 

* ```No efficiency evaluation2:``` Please also compare the efficiency with other methods, including linear, top-K, random feature, and random masked from [17], as well as dense [Ramsauer2020], sparse [Hu2023], and generalized sparse [Wu2023] MHNs. For example, the current draft needs some figures similar to Fig. 4 of [17] to justify the efficiency. Please do whatever makes sense to you. For instance, you can pick just two out of [Ramsauer2020, Hu2023, Wu2023] since they share similar structures.

  * [Ramsauer2020] Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  
  * [Millidge2022] Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models. Millidge, B., Salvatori, T., Song, Y., Lukasiewicz, T., and Bogacz, R., 2022, June. In International Conference on Machine Learning (pp. 15561-15583). PMLR.
  
  * [Wu2023] Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  
  * [Hu2023] On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.



* ```Compare with existing kernel DenseAMs.``` Also, a direct comparison with existing kernel methods is also necessary. For example,
  * Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models. Wu, D., Hu, J.Y.C., Hsiao, T.Y., and Liu, H., 2024. arXiv preprint arXiv:2404.03827.
  
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.

---

## Minor

* ```Inadequate Related Work Discussion```: A paragraph discussing related works is given at the end of the introduction. However, I feel it could be made more comprehensive to provide more background on the evolution of ideas and existing works in this field. At least, I feel the current draft is hard for a non-expert in DenseAMs to follow. Please see the following points.

* ```line38:``` I believe here can be benefited by including more comprehensive references. There are other recent works showing exponentially large memory storage capacity in various settings and dense associative memory (or modern Hopfield) networks/models. For examples: (I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.)

   * Hopfield Networks is All You Need. Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G.K., and Greiff, V., 2020. arXiv preprint arXiv:2008.02217.
  * Kernel Memory Networks: A Unifying Framework for Memory Modeling. Iatropoulos, G., Brea, J., & Gerstner, W., 2022. Advances in Neural Information Processing Systems, 35, 35326-35338.
  * On Sparse Modern Hopfield Model. Hu, J.Y.C., Yang, D., Wu, D., Xu, C., Chen, B.Y., and Liu, H., 2023. Advances in Neural Information Processing Systems, 36.
  * Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. Wu, D., Hu, J.Y.C., Li, W., Chen, B.Y., and Liu, H., 2023. arXiv preprint arXiv:2312.17346.
  * Bridging Associative Memory and Probabilistic Modeling. Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R., and Gromov, A., 2024. arXiv preprint arXiv:2402.10202.
  * Sparse and Structured Hopfield Networks. Santos, S., Niculae, V., McNamee, D., and Martins, A.F., 2024. arXiv preprint arXiv:2402.13725.
  * On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. Hu, J.Y.C., Lin, T., Song, Z., and Liu, H., 2024. arXiv preprint arXiv:2402.04520.
  * Outlier-Efficient Hopfield Layers for Large Transformer-Based Models. Hu, J.Y.C., Chang, P.H., Luo, R., Chen, H.Y., Li, W., Wang, W.P., and Liu, H., 2024. arXiv preprint arXiv:2404.03828.


* ```line46:``` Similarly, here can be benefited by including more recent references
  > DenseAM family [...] 

* ```line51```: A similar motivating question is asked and explored in [17] from a kernel regression perspective. I agree this paper contributes something different and even beyond [17]. However, given the similarity of aims between the two, the current draft should:
  1. State the overlaps between the two works (both use a kernel approach to DenseAMs, and...).
  2. State the clear distinctions between the two works (both use a kernel approach to DenseAMs, but...).

  Such discussion will help readers parse the contributions of this work, which is currently lacking.

  [17] Jerry Yao-Chieh Hu, Bo-Yu Chen, Dennis Wu, Feng Ruan, and Han Liu. Nonparametric modern hopfield models. arXiv preprint arXiv:2404.03900, 2024. URL https://arxiv.org/pdf/2404.03900.pdf.
 

* ```line92```: 
  > those results have been recently applied to associative memory [15].

  I might have missed something, but it would be better to make the discussion of prior work more complete if it's presented in its current form (e.g., a paragraph highlighting the novelty and contributions benchmarked against existing works). The application of the kernel trick to associative memory is not new. While [16,17] are discussed right after [15], I feel it's better to cite them together as [15,16,17]. Additionally, there are two papers related to the kernel trick in associative memory, which I have attached below. Again, I am not sure of their exact relevance, so I will leave it to the authors to decide whether they should be included and discussed.

  - Iatropoulos, G., Brea, J., & Gerstner, W. (2022). Kernel memory networks: A unifying framework for memory modeling. Advances in neural information processing systems, 35, 35326-35338.
  
  -  Schaeffer, R., Zahedi, N., Khona, M., Pai, D., Truong, S., Du, Y., Ostrow, M., Chandra, S., Carranza, A., Fiete, I.R. and Gromov, A., 2024. Bridging Associative Memory and Probabilistic Modeling. arXiv preprint arXiv:2402.10202.

* ```line97```: 
  > Another paper [17] uses kernels for studying the sparse modern Hopfield network. 

  This is incorrect. 

  As stated in their abstract, [17] presents a general framework (referred to as nonparametric) to analyze and design modern Hopfield networks. The sparse network is just a special case of their framework. Additionally, [17] has already introduced the construction of random feature HMNs. While this construction lacks detailed analysis, which is a limitation they acknowledged, it would be more accurate to say that the submitted draft serves as a strong companion to [17] with rigorous theoretical and empirical results. I understand that the authors are not obliged to treat arXiv preprints (unpublished papers) too seriously, but it is better to give accurate credit to existing works when possible. To clarify, I am very happy to see this draft improves the results/proposal of [17] with detailed analysis, including multiple retrieval updates.

* I did not check the proofs line by line. However, I had a quick skim through them and found some typos and areas for improvement. Please do another round of proofreading if possible.


---

### Update 2024/08/07: raise score from 4 -> 5 -> 6 -> 7","* ```line109```: why you call the number of updates as *layers*? Are you recurrently passing the output as input to the same network or the network really has many layers? For example, recurrent layer is RNN sense is the later. 


* ```Proposition 1,2,3```: what is peak memory? why we should care about it?

* ```Time Complexity```: I appreciate the analysis of the computational complexity of the proposed method. From my view, this proposal is a special case of [Hu2024] with $L=1$ (where $L$ is the sequence length in their analysis). [Hu2024] provides a characterization of all sub-quadratic (efficient) variants of the modern Hopfield model. Essentially, your proposal is an efficient approximation to the softmax DenseAMs. Hence, the relevance holds. Can you discuss how your proposal fits into the results of [Hu2024]?
  
  * [Hu2024] Hu, J.Y.C., Lin, T., Song, Z. and Liu, H., 2024. On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis. arXiv preprint arXiv:2402.04520.


* ```line255, Exp Observation 2```: This observation is a bit counterintuitive. Normally, large $\beta$ means low-temperature region and leads to more stable/accurate retrieval, e.g., infinity $\beta$ leads to argmax-retrieval. Why random DrDAM shows otherwise?  



* ```Fig3```: Intuitively, why larger $\beta$ needs larger $Y$?

* ```line303```: What's the point of approximating energies and update dynamics? Shouldn't the significance lie in the approximation error of retrieval?

* I am wondering if you have explored the learning aspect of the proposed method. It is known that many DenseAMs are connected to transformer attention and can be used as a learning model or layer. Can you explore this part a bit as in [17]? If not, please explain why.

* Can you kindly remind me which part of this work supports the claim ""making it possible to introduce new memories without increasing the number of weights""?","There is a limitation section but no broader impact or impact statement expect in the checklist.


Appendix A of the draft acknowledges that the experimental explorations are limited. However, it would benefit from discussing comparisons with baselines and including some vital ablations. This would help clarify the contribution and soundness of the proposed method. See above for other limitations.",['No ethics review needed.'],7,4,,Yes,3,3,2,1718224581283,,,NeurIPS.cc/2024/Conference,164QnJsYjF,"['NeurIPS.cc/2024/Conference/Submission18824/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880001942,[],1,,,['everyone'],164QnJsYjF,['NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh'],1718224581283,1730880001942,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18824/Reviewer_9NBh']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Ramsauer et al. (2020) - ""Hopfield Networks is All You Need""
2. Hu et al. (2023) - ""On Sparse Modern Hopfield Model""
3. Millidge et al. (2022) - ""Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models""
4. Wu et al. (2023) - ""Stanhop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction""
5. Iatropoulos et al. (2022) - ""Kernel Memory Networks: A Unifying Framework for Memory Modeling""
6. Schaeffer et al. (2024) - ""Bridging Associative Memory and Probabilistic Modeling""
7. Hu et al. (2024) - ""On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis""
8. Hu et al. (2024) - ""Nonparametric Modern Hopfield Models""

The reviewer also mentions that the authors should discuss the overlaps and distinctions between their work and the work presented in [17], which refers to Hu et al. (2024) - ""Nonparametric Modern Hopfield Models"".",1,"2020, 2023, 2022, 2023, 2022, 2024, 2024, 2024, 2024",On Nonparametric Modern Hopfield Models
8Un6PMgLXC,"This paper aims to leverage prompt tuning of vision-language models for Unsupervised Domain Adaptation (UDA) tasks. The authors formulate UDA as a multi-objective problem where each objective is modeled by a domain loss. To resolve conflicts between domains, they manipulate gradients by maximizing their cosine similarity. Additionally, to stabilize the training procedure, they propose using the norm of the gradients as a regularization term. They also provide a generalization error bound for their method. Empirical results demonstrate the effectiveness of the proposed method.","The paper is well-organized and the presentation is clear. To my knowledge, the idea of aligning gradients of different objectives by maximizing cosine similarity and regularizing the gradient norm is intuitive and novel. The authors also provide a generalization bound for the proposed method, which is a valuable contribution.","Major:

(1) Recent empirical and theoretical studies [1] show that simply reweighting the loss of different objectives can match the performance of gradient surgery. When the model is under-parameterized (which may be the case for prompt learning, as the prompt parameters are relatively small compared to the CLIP parameters), simple reweighting is sufficient to fully explore the Pareto front. My question is why the proposed gradient manipulation is better. Can the authors provide theoretical analysis or empirical validation?

[1] Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective

(2) The backbone CLIP-ResNet-50 is a weak backbone. Please consider conducting some experiments on a CLIP-ViT based model.

Minor:

(1) Missing references. There have been some studies that use gradient alignment for prompt learning, e.g., [3,4]. Please consider adding them to the related works section.

[3] Prompt-aligned Gradient for Prompt Tuning
[4] Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models

(2) Table 1 in the Introduction is not well explained. It does not specify which dataset and CLIP backbone are used, and the symbols $\rightarrow C, I, P$ are not explained. In addition, Table 2 should be referenced as Figure 1.","Please refer to the weaknesses, and I am willing to raise the score if the major weaknesses are addressed.",Limitations have been discussed and no negative societal impact has been identified.,['No ethics review needed.'],6,3,,Yes,3,3,3,1719996902034,,,NeurIPS.cc/2024/Conference,14hLJr6kZ3,"['NeurIPS.cc/2024/Conference/Submission10649/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879404182,[],1,,,['everyone'],14hLJr6kZ3,['NeurIPS.cc/2024/Conference/Submission10649/Reviewer_aPJr'],1719996902034,1730879404182,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10649/Reviewer_aPJr']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references that the authors should consider adding to the related works section, including:

* [1] Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective
* [3] Prompt-aligned Gradient for Prompt Tuning
* [4] Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models

The reviewer also asks the authors to provide theoretical analysis or empirical validation to address the major weaknesses, implying that the authors should engage with the existing literature on the topic.",1,,Revisiting Scalarization in Multi-Task Learning A Theoretical Perspective
8Un6PMgLXC,"This paper aims to leverage prompt tuning of vision-language models for Unsupervised Domain Adaptation (UDA) tasks. The authors formulate UDA as a multi-objective problem where each objective is modeled by a domain loss. To resolve conflicts between domains, they manipulate gradients by maximizing their cosine similarity. Additionally, to stabilize the training procedure, they propose using the norm of the gradients as a regularization term. They also provide a generalization error bound for their method. Empirical results demonstrate the effectiveness of the proposed method.","The paper is well-organized and the presentation is clear. To my knowledge, the idea of aligning gradients of different objectives by maximizing cosine similarity and regularizing the gradient norm is intuitive and novel. The authors also provide a generalization bound for the proposed method, which is a valuable contribution.","Major:

(1) Recent empirical and theoretical studies [1] show that simply reweighting the loss of different objectives can match the performance of gradient surgery. When the model is under-parameterized (which may be the case for prompt learning, as the prompt parameters are relatively small compared to the CLIP parameters), simple reweighting is sufficient to fully explore the Pareto front. My question is why the proposed gradient manipulation is better. Can the authors provide theoretical analysis or empirical validation?

[1] Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective

(2) The backbone CLIP-ResNet-50 is a weak backbone. Please consider conducting some experiments on a CLIP-ViT based model.

Minor:

(1) Missing references. There have been some studies that use gradient alignment for prompt learning, e.g., [3,4]. Please consider adding them to the related works section.

[3] Prompt-aligned Gradient for Prompt Tuning
[4] Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models

(2) Table 1 in the Introduction is not well explained. It does not specify which dataset and CLIP backbone are used, and the symbols $\rightarrow C, I, P$ are not explained. In addition, Table 2 should be referenced as Figure 1.","Please refer to the weaknesses, and I am willing to raise the score if the major weaknesses are addressed.",Limitations have been discussed and no negative societal impact has been identified.,['No ethics review needed.'],6,3,,Yes,3,3,3,1719996902034,,,NeurIPS.cc/2024/Conference,14hLJr6kZ3,"['NeurIPS.cc/2024/Conference/Submission10649/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879404182,[],1,,,['everyone'],14hLJr6kZ3,['NeurIPS.cc/2024/Conference/Submission10649/Reviewer_aPJr'],1719996902034,1730879404182,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10649/Reviewer_aPJr']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references that the authors should consider adding to the related works section, including:

* [1] Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective
* [3] Prompt-aligned Gradient for Prompt Tuning
* [4] Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models

The reviewer also asks the authors to provide theoretical analysis or empirical validation to address the major weaknesses, implying that the authors should engage with the existing literature on the topic.",1,,Prompt-aligned Gradient for Prompt Tuning
8Un6PMgLXC,"This paper aims to leverage prompt tuning of vision-language models for Unsupervised Domain Adaptation (UDA) tasks. The authors formulate UDA as a multi-objective problem where each objective is modeled by a domain loss. To resolve conflicts between domains, they manipulate gradients by maximizing their cosine similarity. Additionally, to stabilize the training procedure, they propose using the norm of the gradients as a regularization term. They also provide a generalization error bound for their method. Empirical results demonstrate the effectiveness of the proposed method.","The paper is well-organized and the presentation is clear. To my knowledge, the idea of aligning gradients of different objectives by maximizing cosine similarity and regularizing the gradient norm is intuitive and novel. The authors also provide a generalization bound for the proposed method, which is a valuable contribution.","Major:

(1) Recent empirical and theoretical studies [1] show that simply reweighting the loss of different objectives can match the performance of gradient surgery. When the model is under-parameterized (which may be the case for prompt learning, as the prompt parameters are relatively small compared to the CLIP parameters), simple reweighting is sufficient to fully explore the Pareto front. My question is why the proposed gradient manipulation is better. Can the authors provide theoretical analysis or empirical validation?

[1] Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective

(2) The backbone CLIP-ResNet-50 is a weak backbone. Please consider conducting some experiments on a CLIP-ViT based model.

Minor:

(1) Missing references. There have been some studies that use gradient alignment for prompt learning, e.g., [3,4]. Please consider adding them to the related works section.

[3] Prompt-aligned Gradient for Prompt Tuning
[4] Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models

(2) Table 1 in the Introduction is not well explained. It does not specify which dataset and CLIP backbone are used, and the symbols $\rightarrow C, I, P$ are not explained. In addition, Table 2 should be referenced as Figure 1.","Please refer to the weaknesses, and I am willing to raise the score if the major weaknesses are addressed.",Limitations have been discussed and no negative societal impact has been identified.,['No ethics review needed.'],6,3,,Yes,3,3,3,1719996902034,,,NeurIPS.cc/2024/Conference,14hLJr6kZ3,"['NeurIPS.cc/2024/Conference/Submission10649/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879404182,[],1,,,['everyone'],14hLJr6kZ3,['NeurIPS.cc/2024/Conference/Submission10649/Reviewer_aPJr'],1719996902034,1730879404182,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10649/Reviewer_aPJr']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references that the authors should consider adding to the related works section, including:

* [1] Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective
* [3] Prompt-aligned Gradient for Prompt Tuning
* [4] Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models

The reviewer also asks the authors to provide theoretical analysis or empirical validation to address the major weaknesses, implying that the authors should engage with the existing literature on the topic.",1,,Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models
5KpBI0B771,"This paper proposed a novel domain adaptation method that tunes the text prompts based on self-training with pseudo labels. The proposed method treats the source training and target training as multi-objective optimization problems, and it introduces to alignment of the gradients from both training (Prompt Gradient Alignment) so as not to cause conflict between the source and target training. The authors validated the proposed method empirically and theoretically.","+ This paper is rich in technical novelty.
  + There are many methods in domain generalization research that aim to align gradients from multiple domains. However, requires heavy hessian calculations. The proposed method successfully avoids this issue by approximation with Taylor expansion.
+ The proposed method is empirically and theoretically justified.","+ It is questionable whether the comparison with existing methods is fair.
  + The old domain adaptation methods fail to show their effectiveness when they are applied to the CLIP model. I suspect that those domain adaptation methods were not properly applied to CLIP. Is there any reason why they fail?
  + Conversely, would it not be possible to evaluate the proposed method in accordance with existing domain adaptation benchmarks? For example, would it be possible to evaluate the proposed method by updating the model parameters instead of the prompts?
+ There are some additional related works that should be discussed in the paper.
  + Bose, Shirsha, et al. ""Stylip: Multi-scale style-conditioned prompt learning for clip-based domain generalization."" Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2024. This work proposes a prompt training method for the domain generalization tasks.
  + Zhu, Beier, et al. ""Prompt-aligned gradient for prompt tuning."" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023. This introduces a gradient matching idea into prompt tuning, which has a similar mind to this paper.
+ Some of the formulas are a little difficult to follow.
  + It is very difficult to understand which of eq 9 or eq 11 is the actual loss function. This goes for eq 16 and eq 18 as well. I recommend separating the formulations for easier understanding.","+ As mentioned in the third bullet of weaknesses, I could not fully understand the formulations. Could you explain which is the actual loss function?",+ I did not found any additional limitation for this work.,['No ethics review needed.'],7,3,,Yes,3,2,3,1720486804406,,,NeurIPS.cc/2024/Conference,14hLJr6kZ3,"['NeurIPS.cc/2024/Conference/Submission10649/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879404043,[],2,,,['everyone'],14hLJr6kZ3,['NeurIPS.cc/2024/Conference/Submission10649/Reviewer_dhjM'],1720486804406,1730879404043,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10649/Reviewer_dhjM']","Yes, the peer review explicitly suggests the authors of the paper to cite two specific literature:

1. Bose, Shirsha, et al. ""Stylip: Multi-scale style-conditioned prompt learning for clip-based domain generalization."" Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2024.
2. Zhu, Beier, et al. ""Prompt-aligned gradient for prompt tuning."" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.

The reviewer mentions that these works are related to the proposed method and should be discussed in the paper.",1,"2024, 2023",Stylip: Multi-scale style-conditioned prompt learning for clip-based domain generalization 
5KpBI0B771,"This paper proposed a novel domain adaptation method that tunes the text prompts based on self-training with pseudo labels. The proposed method treats the source training and target training as multi-objective optimization problems, and it introduces to alignment of the gradients from both training (Prompt Gradient Alignment) so as not to cause conflict between the source and target training. The authors validated the proposed method empirically and theoretically.","+ This paper is rich in technical novelty.
  + There are many methods in domain generalization research that aim to align gradients from multiple domains. However, requires heavy hessian calculations. The proposed method successfully avoids this issue by approximation with Taylor expansion.
+ The proposed method is empirically and theoretically justified.","+ It is questionable whether the comparison with existing methods is fair.
  + The old domain adaptation methods fail to show their effectiveness when they are applied to the CLIP model. I suspect that those domain adaptation methods were not properly applied to CLIP. Is there any reason why they fail?
  + Conversely, would it not be possible to evaluate the proposed method in accordance with existing domain adaptation benchmarks? For example, would it be possible to evaluate the proposed method by updating the model parameters instead of the prompts?
+ There are some additional related works that should be discussed in the paper.
  + Bose, Shirsha, et al. ""Stylip: Multi-scale style-conditioned prompt learning for clip-based domain generalization."" Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2024. This work proposes a prompt training method for the domain generalization tasks.
  + Zhu, Beier, et al. ""Prompt-aligned gradient for prompt tuning."" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023. This introduces a gradient matching idea into prompt tuning, which has a similar mind to this paper.
+ Some of the formulas are a little difficult to follow.
  + It is very difficult to understand which of eq 9 or eq 11 is the actual loss function. This goes for eq 16 and eq 18 as well. I recommend separating the formulations for easier understanding.","+ As mentioned in the third bullet of weaknesses, I could not fully understand the formulations. Could you explain which is the actual loss function?",+ I did not found any additional limitation for this work.,['No ethics review needed.'],7,3,,Yes,3,2,3,1720486804406,,,NeurIPS.cc/2024/Conference,14hLJr6kZ3,"['NeurIPS.cc/2024/Conference/Submission10649/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879404043,[],2,,,['everyone'],14hLJr6kZ3,['NeurIPS.cc/2024/Conference/Submission10649/Reviewer_dhjM'],1720486804406,1730879404043,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10649/Reviewer_dhjM']","Yes, the peer review explicitly suggests the authors of the paper to cite two specific literature:

1. Bose, Shirsha, et al. ""Stylip: Multi-scale style-conditioned prompt learning for clip-based domain generalization."" Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2024.
2. Zhu, Beier, et al. ""Prompt-aligned gradient for prompt tuning."" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.

The reviewer mentions that these works are related to the proposed method and should be discussed in the paper.",1,"2024, 2023",Prompt-aligned gradient for prompt tuning
8dSlUiVBiG,"This paper proposes a new MoE architecture called Mixture of Tokens (MoT). The motivation for this architecture is twofold: first it is the training instabilities incurred (among other things) by low precision training in standard sparse MoEs; secondly, it is the discontinuous nature of sparse MoEs that makes them hard to train. This work seem to be highly inspired by [1].

In contrast to MoEs, which select top-k subset of experts for each token, MoT aggregates tokens within groups created by subsetting examples across the batch dimension. The cross-example token aggregation weights are produced by a router conditioned on the tokens in the corresponding group. The aggregated group representations are then passed through all the experts. The output token representation is produced by a weighted average of all experts' outputs for a group, where the weights are the original aggregation weights. 

The paper measures validation perplexity of MoT comparing it to compute matched dense transformer and sparse MoEs demonstrating its superiority over the prior and on par performance with the later. MoT shows better training stability in low precision training regime as compared to sparse MoEs.

[1] Puigcerver, Joan, et al. ""From sparse to soft mixtures of experts."" arXiv preprint arXiv:2308.00951 (2023).","Overall, the paper proposes in interesting and novel extension of soft MoE to autoregressive problems. The idea of mixing tokens across examples in the batch is very interesting, given that it does not break the autoregressive property.

Originality: good. The idea of soft MoEs is not new, but its adoption to autoregressive problems is novel to the best of my knowledge.

Quality: The claims seem to be supported by evidences, yet experimental evaluation might be insufficient (see questions/weaknesses section).

Clarity: the paper is well organized. In terms of writing, several formulations might need to revisited (see weaknesses/questions).

Significance: the paper makes a moderate contribution to the field and can potentially impacting future research.","One weakness of this paper is a lack of intuitive explanation of why mixing across examples makes sense? I understand that it results in more stable training due to lack of discreet operations, but why does it make sense from the modelling perspective? 

If sentences in the batches are consecutive interrelated text passages, then MoT effectively increases the context length by letting the model to also rely on cross-example information. Can this have an effect on generalization ability? e.g. in instruction fine-tuning, examples in the batches are usually not related to each other, hence MoT type of pre-training may be detrimental for downstream task adaptation of these models, where downstream tasks examples are completely unrelated. 

Therefore, another potential weakness for me is a lack of  generalization/downstream adaptation analysis. Does the training stability advantage of MoT improves generalization and adaptability of the model to downstream tasks? Or does cross-example information sharing actually weakens downstream task generalization?","- ll. 52 - 61: I am uncertain if points 2 and 4 qualify as contributions of this work. These appear to be properties of the proposed MoT method rather than contributions in themselves.
- ll. 55-57: If I understand correctly, the key comparison should be with other sparse MoE methods rather than dense transformers. Therefore, why emphasize a speedup over dense transformers as a contribution when the more relevant comparison is the speedup over other sparse MoE architectures?
- l. 104: ""Mixture of Experts, introduced into deep learning by [24],..."" does not seem to be correct. MoEs have a much longer history, please consider works [2,3];
- l. 190: why half of feed-forward layers are replaced with MoT layers?
- ll. 167 - 169: an important difference to [15] that might be mentioned explicitly here, is that MoT aggregates tokens across examples in a batch, while [15] aggregates patches within each example.
- caption Figure 6: if I am not mistaken, MoT here not only matches but outperforms best sMoE
- since one of the main advantages of the proposed MoT is that it does not require additional load balancing tricks etc., it would be interesting to include a empirical comparison (or at least a discussion) to existing sparse MoEs that also do not require such tricks, see e.g. [4]
- how are examples in the batches created? Are these consecutive interrelated text passages from the same underlying text?
- MoT's weighted token grouping is reminiscent of an attention operation, but across examples in a batch. Is there any intuition for why aggregating information across examples can be useful? One potential way it can be useful, is that if sentences in the batches are related (e.g. maybe these are consecutive sentences from the underlying training text) then of course  incorporating information from previous/future examples can help reducing loss (training and validation), since the examples (samples in a batch) are interrelated. 

Overall, I believe this paper has significant potential. However, I have concerns regarding downstream task generalization and the relationship between the examples in the training batches. I am willing to reconsider my rating upon rebuttal.

[2] Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. Adaptive mixtures of local experts. Neural computation, 3(1):79–87, 1991b.

[3] Robert A Jacobs, Michael I Jordan, and Andrew G Barto. Task decomposition through competition in a modular connectionist architecture: The what and where vision tasks. Cognitive science, 15(2):219–250, 1991a

[4] Csordás, Róbert, Kazuki Irie, and Jürgen Schmidhuber. ""Approximating two-layer feedforward networks for efficient transformers."" arXiv preprint arXiv:2310.10837 (2023).","Limitations are addressed in Sec. 5. 
I think one missing limitation of this work is the fact that no downstream task generalization is evaluated.",['No ethics review needed.'],6,4,,Yes,3,3,3,1719997403019,,,NeurIPS.cc/2024/Conference,0zFVhMBZHJ,"['NeurIPS.cc/2024/Conference/Submission16606/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879857605,[],1,,,['everyone'],0zFVhMBZHJ,['NeurIPS.cc/2024/Conference/Submission16606/Reviewer_ef5W'],1719997403019,1730879857605,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16606/Reviewer_ef5W']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions the following papers that should be considered for citation:

1. Puigcerver, Joan, et al. ""From sparse to soft mixtures of experts."" (already cited as [1])
2. Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. ""Adaptive mixtures of local experts."" (uggested as [2])
3. Robert A Jacobs, Michael I Jordan, and Andrew G Barto. ""Task decomposition through competition in a modular connectionist architecture: The what and where vision tasks."" (suggested as [3])
4. Csordás, Róbert, Kazuki Irie, and Jürgen Schmidhuber. ""Approximating two-layer feedforward networks for efficient transformers."" (suggested as [4])

The reviewer suggests citing these papers to provide a more accurate history of Mixture of Experts (MoEs) and to compare the proposed method with other relevant works.",1,,From sparse to soft mixtures of experts
8dSlUiVBiG,"This paper proposes a new MoE architecture called Mixture of Tokens (MoT). The motivation for this architecture is twofold: first it is the training instabilities incurred (among other things) by low precision training in standard sparse MoEs; secondly, it is the discontinuous nature of sparse MoEs that makes them hard to train. This work seem to be highly inspired by [1].

In contrast to MoEs, which select top-k subset of experts for each token, MoT aggregates tokens within groups created by subsetting examples across the batch dimension. The cross-example token aggregation weights are produced by a router conditioned on the tokens in the corresponding group. The aggregated group representations are then passed through all the experts. The output token representation is produced by a weighted average of all experts' outputs for a group, where the weights are the original aggregation weights. 

The paper measures validation perplexity of MoT comparing it to compute matched dense transformer and sparse MoEs demonstrating its superiority over the prior and on par performance with the later. MoT shows better training stability in low precision training regime as compared to sparse MoEs.

[1] Puigcerver, Joan, et al. ""From sparse to soft mixtures of experts."" arXiv preprint arXiv:2308.00951 (2023).","Overall, the paper proposes in interesting and novel extension of soft MoE to autoregressive problems. The idea of mixing tokens across examples in the batch is very interesting, given that it does not break the autoregressive property.

Originality: good. The idea of soft MoEs is not new, but its adoption to autoregressive problems is novel to the best of my knowledge.

Quality: The claims seem to be supported by evidences, yet experimental evaluation might be insufficient (see questions/weaknesses section).

Clarity: the paper is well organized. In terms of writing, several formulations might need to revisited (see weaknesses/questions).

Significance: the paper makes a moderate contribution to the field and can potentially impacting future research.","One weakness of this paper is a lack of intuitive explanation of why mixing across examples makes sense? I understand that it results in more stable training due to lack of discreet operations, but why does it make sense from the modelling perspective? 

If sentences in the batches are consecutive interrelated text passages, then MoT effectively increases the context length by letting the model to also rely on cross-example information. Can this have an effect on generalization ability? e.g. in instruction fine-tuning, examples in the batches are usually not related to each other, hence MoT type of pre-training may be detrimental for downstream task adaptation of these models, where downstream tasks examples are completely unrelated. 

Therefore, another potential weakness for me is a lack of  generalization/downstream adaptation analysis. Does the training stability advantage of MoT improves generalization and adaptability of the model to downstream tasks? Or does cross-example information sharing actually weakens downstream task generalization?","- ll. 52 - 61: I am uncertain if points 2 and 4 qualify as contributions of this work. These appear to be properties of the proposed MoT method rather than contributions in themselves.
- ll. 55-57: If I understand correctly, the key comparison should be with other sparse MoE methods rather than dense transformers. Therefore, why emphasize a speedup over dense transformers as a contribution when the more relevant comparison is the speedup over other sparse MoE architectures?
- l. 104: ""Mixture of Experts, introduced into deep learning by [24],..."" does not seem to be correct. MoEs have a much longer history, please consider works [2,3];
- l. 190: why half of feed-forward layers are replaced with MoT layers?
- ll. 167 - 169: an important difference to [15] that might be mentioned explicitly here, is that MoT aggregates tokens across examples in a batch, while [15] aggregates patches within each example.
- caption Figure 6: if I am not mistaken, MoT here not only matches but outperforms best sMoE
- since one of the main advantages of the proposed MoT is that it does not require additional load balancing tricks etc., it would be interesting to include a empirical comparison (or at least a discussion) to existing sparse MoEs that also do not require such tricks, see e.g. [4]
- how are examples in the batches created? Are these consecutive interrelated text passages from the same underlying text?
- MoT's weighted token grouping is reminiscent of an attention operation, but across examples in a batch. Is there any intuition for why aggregating information across examples can be useful? One potential way it can be useful, is that if sentences in the batches are related (e.g. maybe these are consecutive sentences from the underlying training text) then of course  incorporating information from previous/future examples can help reducing loss (training and validation), since the examples (samples in a batch) are interrelated. 

Overall, I believe this paper has significant potential. However, I have concerns regarding downstream task generalization and the relationship between the examples in the training batches. I am willing to reconsider my rating upon rebuttal.

[2] Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. Adaptive mixtures of local experts. Neural computation, 3(1):79–87, 1991b.

[3] Robert A Jacobs, Michael I Jordan, and Andrew G Barto. Task decomposition through competition in a modular connectionist architecture: The what and where vision tasks. Cognitive science, 15(2):219–250, 1991a

[4] Csordás, Róbert, Kazuki Irie, and Jürgen Schmidhuber. ""Approximating two-layer feedforward networks for efficient transformers."" arXiv preprint arXiv:2310.10837 (2023).","Limitations are addressed in Sec. 5. 
I think one missing limitation of this work is the fact that no downstream task generalization is evaluated.",['No ethics review needed.'],6,4,,Yes,3,3,3,1719997403019,,,NeurIPS.cc/2024/Conference,0zFVhMBZHJ,"['NeurIPS.cc/2024/Conference/Submission16606/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879857605,[],1,,,['everyone'],0zFVhMBZHJ,['NeurIPS.cc/2024/Conference/Submission16606/Reviewer_ef5W'],1719997403019,1730879857605,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16606/Reviewer_ef5W']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions the following papers that should be considered for citation:

1. Puigcerver, Joan, et al. ""From sparse to soft mixtures of experts."" (already cited as [1])
2. Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. ""Adaptive mixtures of local experts."" (uggested as [2])
3. Robert A Jacobs, Michael I Jordan, and Andrew G Barto. ""Task decomposition through competition in a modular connectionist architecture: The what and where vision tasks."" (suggested as [3])
4. Csordás, Róbert, Kazuki Irie, and Jürgen Schmidhuber. ""Approximating two-layer feedforward networks for efficient transformers."" (suggested as [4])

The reviewer suggests citing these papers to provide a more accurate history of Mixture of Experts (MoEs) and to compare the proposed method with other relevant works.",1,,Adaptive mixtures of local experts
8dSlUiVBiG,"This paper proposes a new MoE architecture called Mixture of Tokens (MoT). The motivation for this architecture is twofold: first it is the training instabilities incurred (among other things) by low precision training in standard sparse MoEs; secondly, it is the discontinuous nature of sparse MoEs that makes them hard to train. This work seem to be highly inspired by [1].

In contrast to MoEs, which select top-k subset of experts for each token, MoT aggregates tokens within groups created by subsetting examples across the batch dimension. The cross-example token aggregation weights are produced by a router conditioned on the tokens in the corresponding group. The aggregated group representations are then passed through all the experts. The output token representation is produced by a weighted average of all experts' outputs for a group, where the weights are the original aggregation weights. 

The paper measures validation perplexity of MoT comparing it to compute matched dense transformer and sparse MoEs demonstrating its superiority over the prior and on par performance with the later. MoT shows better training stability in low precision training regime as compared to sparse MoEs.

[1] Puigcerver, Joan, et al. ""From sparse to soft mixtures of experts."" arXiv preprint arXiv:2308.00951 (2023).","Overall, the paper proposes in interesting and novel extension of soft MoE to autoregressive problems. The idea of mixing tokens across examples in the batch is very interesting, given that it does not break the autoregressive property.

Originality: good. The idea of soft MoEs is not new, but its adoption to autoregressive problems is novel to the best of my knowledge.

Quality: The claims seem to be supported by evidences, yet experimental evaluation might be insufficient (see questions/weaknesses section).

Clarity: the paper is well organized. In terms of writing, several formulations might need to revisited (see weaknesses/questions).

Significance: the paper makes a moderate contribution to the field and can potentially impacting future research.","One weakness of this paper is a lack of intuitive explanation of why mixing across examples makes sense? I understand that it results in more stable training due to lack of discreet operations, but why does it make sense from the modelling perspective? 

If sentences in the batches are consecutive interrelated text passages, then MoT effectively increases the context length by letting the model to also rely on cross-example information. Can this have an effect on generalization ability? e.g. in instruction fine-tuning, examples in the batches are usually not related to each other, hence MoT type of pre-training may be detrimental for downstream task adaptation of these models, where downstream tasks examples are completely unrelated. 

Therefore, another potential weakness for me is a lack of  generalization/downstream adaptation analysis. Does the training stability advantage of MoT improves generalization and adaptability of the model to downstream tasks? Or does cross-example information sharing actually weakens downstream task generalization?","- ll. 52 - 61: I am uncertain if points 2 and 4 qualify as contributions of this work. These appear to be properties of the proposed MoT method rather than contributions in themselves.
- ll. 55-57: If I understand correctly, the key comparison should be with other sparse MoE methods rather than dense transformers. Therefore, why emphasize a speedup over dense transformers as a contribution when the more relevant comparison is the speedup over other sparse MoE architectures?
- l. 104: ""Mixture of Experts, introduced into deep learning by [24],..."" does not seem to be correct. MoEs have a much longer history, please consider works [2,3];
- l. 190: why half of feed-forward layers are replaced with MoT layers?
- ll. 167 - 169: an important difference to [15] that might be mentioned explicitly here, is that MoT aggregates tokens across examples in a batch, while [15] aggregates patches within each example.
- caption Figure 6: if I am not mistaken, MoT here not only matches but outperforms best sMoE
- since one of the main advantages of the proposed MoT is that it does not require additional load balancing tricks etc., it would be interesting to include a empirical comparison (or at least a discussion) to existing sparse MoEs that also do not require such tricks, see e.g. [4]
- how are examples in the batches created? Are these consecutive interrelated text passages from the same underlying text?
- MoT's weighted token grouping is reminiscent of an attention operation, but across examples in a batch. Is there any intuition for why aggregating information across examples can be useful? One potential way it can be useful, is that if sentences in the batches are related (e.g. maybe these are consecutive sentences from the underlying training text) then of course  incorporating information from previous/future examples can help reducing loss (training and validation), since the examples (samples in a batch) are interrelated. 

Overall, I believe this paper has significant potential. However, I have concerns regarding downstream task generalization and the relationship between the examples in the training batches. I am willing to reconsider my rating upon rebuttal.

[2] Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. Adaptive mixtures of local experts. Neural computation, 3(1):79–87, 1991b.

[3] Robert A Jacobs, Michael I Jordan, and Andrew G Barto. Task decomposition through competition in a modular connectionist architecture: The what and where vision tasks. Cognitive science, 15(2):219–250, 1991a

[4] Csordás, Róbert, Kazuki Irie, and Jürgen Schmidhuber. ""Approximating two-layer feedforward networks for efficient transformers."" arXiv preprint arXiv:2310.10837 (2023).","Limitations are addressed in Sec. 5. 
I think one missing limitation of this work is the fact that no downstream task generalization is evaluated.",['No ethics review needed.'],6,4,,Yes,3,3,3,1719997403019,,,NeurIPS.cc/2024/Conference,0zFVhMBZHJ,"['NeurIPS.cc/2024/Conference/Submission16606/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879857605,[],1,,,['everyone'],0zFVhMBZHJ,['NeurIPS.cc/2024/Conference/Submission16606/Reviewer_ef5W'],1719997403019,1730879857605,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16606/Reviewer_ef5W']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions the following papers that should be considered for citation:

1. Puigcerver, Joan, et al. ""From sparse to soft mixtures of experts."" (already cited as [1])
2. Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. ""Adaptive mixtures of local experts."" (uggested as [2])
3. Robert A Jacobs, Michael I Jordan, and Andrew G Barto. ""Task decomposition through competition in a modular connectionist architecture: The what and where vision tasks."" (suggested as [3])
4. Csordás, Róbert, Kazuki Irie, and Jürgen Schmidhuber. ""Approximating two-layer feedforward networks for efficient transformers."" (suggested as [4])

The reviewer suggests citing these papers to provide a more accurate history of Mixture of Experts (MoEs) and to compare the proposed method with other relevant works.",1,,Task decomposition through competition in a modular connectionist architecture The what and where vision tasks
8dSlUiVBiG,"This paper proposes a new MoE architecture called Mixture of Tokens (MoT). The motivation for this architecture is twofold: first it is the training instabilities incurred (among other things) by low precision training in standard sparse MoEs; secondly, it is the discontinuous nature of sparse MoEs that makes them hard to train. This work seem to be highly inspired by [1].

In contrast to MoEs, which select top-k subset of experts for each token, MoT aggregates tokens within groups created by subsetting examples across the batch dimension. The cross-example token aggregation weights are produced by a router conditioned on the tokens in the corresponding group. The aggregated group representations are then passed through all the experts. The output token representation is produced by a weighted average of all experts' outputs for a group, where the weights are the original aggregation weights. 

The paper measures validation perplexity of MoT comparing it to compute matched dense transformer and sparse MoEs demonstrating its superiority over the prior and on par performance with the later. MoT shows better training stability in low precision training regime as compared to sparse MoEs.

[1] Puigcerver, Joan, et al. ""From sparse to soft mixtures of experts."" arXiv preprint arXiv:2308.00951 (2023).","Overall, the paper proposes in interesting and novel extension of soft MoE to autoregressive problems. The idea of mixing tokens across examples in the batch is very interesting, given that it does not break the autoregressive property.

Originality: good. The idea of soft MoEs is not new, but its adoption to autoregressive problems is novel to the best of my knowledge.

Quality: The claims seem to be supported by evidences, yet experimental evaluation might be insufficient (see questions/weaknesses section).

Clarity: the paper is well organized. In terms of writing, several formulations might need to revisited (see weaknesses/questions).

Significance: the paper makes a moderate contribution to the field and can potentially impacting future research.","One weakness of this paper is a lack of intuitive explanation of why mixing across examples makes sense? I understand that it results in more stable training due to lack of discreet operations, but why does it make sense from the modelling perspective? 

If sentences in the batches are consecutive interrelated text passages, then MoT effectively increases the context length by letting the model to also rely on cross-example information. Can this have an effect on generalization ability? e.g. in instruction fine-tuning, examples in the batches are usually not related to each other, hence MoT type of pre-training may be detrimental for downstream task adaptation of these models, where downstream tasks examples are completely unrelated. 

Therefore, another potential weakness for me is a lack of  generalization/downstream adaptation analysis. Does the training stability advantage of MoT improves generalization and adaptability of the model to downstream tasks? Or does cross-example information sharing actually weakens downstream task generalization?","- ll. 52 - 61: I am uncertain if points 2 and 4 qualify as contributions of this work. These appear to be properties of the proposed MoT method rather than contributions in themselves.
- ll. 55-57: If I understand correctly, the key comparison should be with other sparse MoE methods rather than dense transformers. Therefore, why emphasize a speedup over dense transformers as a contribution when the more relevant comparison is the speedup over other sparse MoE architectures?
- l. 104: ""Mixture of Experts, introduced into deep learning by [24],..."" does not seem to be correct. MoEs have a much longer history, please consider works [2,3];
- l. 190: why half of feed-forward layers are replaced with MoT layers?
- ll. 167 - 169: an important difference to [15] that might be mentioned explicitly here, is that MoT aggregates tokens across examples in a batch, while [15] aggregates patches within each example.
- caption Figure 6: if I am not mistaken, MoT here not only matches but outperforms best sMoE
- since one of the main advantages of the proposed MoT is that it does not require additional load balancing tricks etc., it would be interesting to include a empirical comparison (or at least a discussion) to existing sparse MoEs that also do not require such tricks, see e.g. [4]
- how are examples in the batches created? Are these consecutive interrelated text passages from the same underlying text?
- MoT's weighted token grouping is reminiscent of an attention operation, but across examples in a batch. Is there any intuition for why aggregating information across examples can be useful? One potential way it can be useful, is that if sentences in the batches are related (e.g. maybe these are consecutive sentences from the underlying training text) then of course  incorporating information from previous/future examples can help reducing loss (training and validation), since the examples (samples in a batch) are interrelated. 

Overall, I believe this paper has significant potential. However, I have concerns regarding downstream task generalization and the relationship between the examples in the training batches. I am willing to reconsider my rating upon rebuttal.

[2] Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. Adaptive mixtures of local experts. Neural computation, 3(1):79–87, 1991b.

[3] Robert A Jacobs, Michael I Jordan, and Andrew G Barto. Task decomposition through competition in a modular connectionist architecture: The what and where vision tasks. Cognitive science, 15(2):219–250, 1991a

[4] Csordás, Róbert, Kazuki Irie, and Jürgen Schmidhuber. ""Approximating two-layer feedforward networks for efficient transformers."" arXiv preprint arXiv:2310.10837 (2023).","Limitations are addressed in Sec. 5. 
I think one missing limitation of this work is the fact that no downstream task generalization is evaluated.",['No ethics review needed.'],6,4,,Yes,3,3,3,1719997403019,,,NeurIPS.cc/2024/Conference,0zFVhMBZHJ,"['NeurIPS.cc/2024/Conference/Submission16606/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879857605,[],1,,,['everyone'],0zFVhMBZHJ,['NeurIPS.cc/2024/Conference/Submission16606/Reviewer_ef5W'],1719997403019,1730879857605,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16606/Reviewer_ef5W']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions the following papers that should be considered for citation:

1. Puigcerver, Joan, et al. ""From sparse to soft mixtures of experts."" (already cited as [1])
2. Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. ""Adaptive mixtures of local experts."" (uggested as [2])
3. Robert A Jacobs, Michael I Jordan, and Andrew G Barto. ""Task decomposition through competition in a modular connectionist architecture: The what and where vision tasks."" (suggested as [3])
4. Csordás, Róbert, Kazuki Irie, and Jürgen Schmidhuber. ""Approximating two-layer feedforward networks for efficient transformers."" (suggested as [4])

The reviewer suggests citing these papers to provide a more accurate history of Mixture of Experts (MoEs) and to compare the proposed method with other relevant works.",1,,Approximating two-layer feedforward networks for efficient transformers
Fa2k7nXSvy,"In this paper, the authors propose a novel method called Mixture of Tokens (MOT), an expert-based architecture that addresses the drawbacks of existing Mixture of Experts (MoE) approaches, such as reduced training efficiency, instability, and the necessity of using load balancing losses and elaborate training schedules. These issues are often caused by the top-k operation used to select the active experts. The authors' approach combines tokens into groups (subsets of several tokens) and uses a weighted sum of tokens within these groups as input to each expert, with each expert using its own weights for the sum. This allows each token within the group to be processed by each expert, resolving the issues associated with top-k routing. The authors validate their method through extensive experiments on an autoregressive language modeling task, demonstrating significant improvements in training stability, reduced training costs (compute budget), and improved scaling with regard to model size.","* The paper is clearly written and easy to follow. The idea is intuitive and easy to grasp. The related work section provides an adequate discussion of existing approaches (MoE and variations), highlights their problems, and explains the way to resolve them

* Based on the weaknesses of existing MoE approaches, the authors develop an efficient MoT approach that is relatively simple to integrate into existing architectures, does not increase computational cost, and provides important advantages such as more stable training and better convergence

* The authors provided an extensive evaluation of their approach, showing a 3x training speedup compared to common MoE architectures and improved performance in several important setups (such as low-precision training). Therefore, I find the contribution and value of the proposed approach to be clear and evident.","* One of the weaknesses the authors pointed out in the limitations section is the necessity to use batched inference for the approach, which could limit the applicability scope of the method. While there are still important applications for batched inference, I believe that resolving this issue could significantly increase the influence of the method

* From the perspective of the experimental evaluation, I would be curious to see evidence that the behavior demonstrated in the paper would hold in other domains, such as images. Additionally, it seems that the proposed approach could resemble the method in [1] a lot.

* In terms of experiments, it would also be interesting to see comparisons with other MoE approaches mentioned in the related work, beyond the reported Token Choice and Expert Choice, or more novel approaches such as [2] and similar methods.

[1] Puigcerver, Joan, et al. ""From sparse to soft mixtures of experts."" ICLR 2024
[2] Anthony, Quentin, et al. ""Blackmamba: Mixture of experts for state-space models."" ICLR 2024","* As stated in the weaknesses section, is it possible to demonstrate the effectiveness of the approach beyond the autoregressive language modeling task? I believe it could significantly strengthen the paper.

* In addition to the previous question, could you elaborate on what the major differences are between the proposed approach and the [1] method? Is it the fact that in MoT mixing happens within different batch inputs and in [1] we mix tokens within the same image? If so, then the novelty of MoT (compared to [1]) comes from the grouping and the application to the autoregressive task, which could undermine the contribution of the paper.  

[1] Puigcerver, Joan, et al. ""From sparse to soft mixtures of experts."" ICLR 2024","No significant limitations of the paper, though the authors' discussion on limitations is much appreciated.",['No ethics review needed.'],6,3,,Yes,2,2,3,1720786348626,,,NeurIPS.cc/2024/Conference,0zFVhMBZHJ,"['NeurIPS.cc/2024/Conference/Submission16606/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879857417,[],2,,,['everyone'],0zFVhMBZHJ,['NeurIPS.cc/2024/Conference/Submission16606/Reviewer_wt4H'],1720786348626,1730879857417,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16606/Reviewer_wt4H']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. Puigcerver, Joan, et al. ""From sparse to soft mixtures of experts."" ICLR 2024 (referenced as [1] in the review)
2. Anthony, Quentin, et al. ""Blackmamba: Mixture of experts for state-space models."" ICLR 2024 (referenced as [2] in the review)

The reviewer mentions these papers in the context of comparing the proposed approach (MOT) with other existing methods, and suggests that the authors should elaborate on the differences between their approach and the method in [1], and also consider comparing their approach with other MoE approaches mentioned in the related work, including [2].",1,"2024, 2024",From sparse to soft mixtures of experts 
Fa2k7nXSvy,"In this paper, the authors propose a novel method called Mixture of Tokens (MOT), an expert-based architecture that addresses the drawbacks of existing Mixture of Experts (MoE) approaches, such as reduced training efficiency, instability, and the necessity of using load balancing losses and elaborate training schedules. These issues are often caused by the top-k operation used to select the active experts. The authors' approach combines tokens into groups (subsets of several tokens) and uses a weighted sum of tokens within these groups as input to each expert, with each expert using its own weights for the sum. This allows each token within the group to be processed by each expert, resolving the issues associated with top-k routing. The authors validate their method through extensive experiments on an autoregressive language modeling task, demonstrating significant improvements in training stability, reduced training costs (compute budget), and improved scaling with regard to model size.","* The paper is clearly written and easy to follow. The idea is intuitive and easy to grasp. The related work section provides an adequate discussion of existing approaches (MoE and variations), highlights their problems, and explains the way to resolve them

* Based on the weaknesses of existing MoE approaches, the authors develop an efficient MoT approach that is relatively simple to integrate into existing architectures, does not increase computational cost, and provides important advantages such as more stable training and better convergence

* The authors provided an extensive evaluation of their approach, showing a 3x training speedup compared to common MoE architectures and improved performance in several important setups (such as low-precision training). Therefore, I find the contribution and value of the proposed approach to be clear and evident.","* One of the weaknesses the authors pointed out in the limitations section is the necessity to use batched inference for the approach, which could limit the applicability scope of the method. While there are still important applications for batched inference, I believe that resolving this issue could significantly increase the influence of the method

* From the perspective of the experimental evaluation, I would be curious to see evidence that the behavior demonstrated in the paper would hold in other domains, such as images. Additionally, it seems that the proposed approach could resemble the method in [1] a lot.

* In terms of experiments, it would also be interesting to see comparisons with other MoE approaches mentioned in the related work, beyond the reported Token Choice and Expert Choice, or more novel approaches such as [2] and similar methods.

[1] Puigcerver, Joan, et al. ""From sparse to soft mixtures of experts."" ICLR 2024
[2] Anthony, Quentin, et al. ""Blackmamba: Mixture of experts for state-space models."" ICLR 2024","* As stated in the weaknesses section, is it possible to demonstrate the effectiveness of the approach beyond the autoregressive language modeling task? I believe it could significantly strengthen the paper.

* In addition to the previous question, could you elaborate on what the major differences are between the proposed approach and the [1] method? Is it the fact that in MoT mixing happens within different batch inputs and in [1] we mix tokens within the same image? If so, then the novelty of MoT (compared to [1]) comes from the grouping and the application to the autoregressive task, which could undermine the contribution of the paper.  

[1] Puigcerver, Joan, et al. ""From sparse to soft mixtures of experts."" ICLR 2024","No significant limitations of the paper, though the authors' discussion on limitations is much appreciated.",['No ethics review needed.'],6,3,,Yes,2,2,3,1720786348626,,,NeurIPS.cc/2024/Conference,0zFVhMBZHJ,"['NeurIPS.cc/2024/Conference/Submission16606/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879857417,[],2,,,['everyone'],0zFVhMBZHJ,['NeurIPS.cc/2024/Conference/Submission16606/Reviewer_wt4H'],1720786348626,1730879857417,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16606/Reviewer_wt4H']","Yes, this peer review explicitly suggests the authors of the paper to cite two specific literature:

1. Puigcerver, Joan, et al. ""From sparse to soft mixtures of experts."" ICLR 2024 (referenced as [1] in the review)
2. Anthony, Quentin, et al. ""Blackmamba: Mixture of experts for state-space models."" ICLR 2024 (referenced as [2] in the review)

The reviewer mentions these papers in the context of comparing the proposed approach (MOT) with other existing methods, and suggests that the authors should elaborate on the differences between their approach and the method in [1], and also consider comparing their approach with other MoE approaches mentioned in the related work, including [2].",1,"2024, 2024",Blackmamba Mixture of experts for state-space models
5Hami8UyaZ,"The paper introduces BAdam, a memory-efficient optimization method for fine-tuning large language models (LLMs) by leveraging block coordinate descent (BCD) with Adam as the inner solver. BAdam aims to reduce memory consumption while maintaining or improving performance. The paper presents theoretical convergence analysis and experimental results showing BAdam's effectiveness compared to existing methods like LoRA and LOMO, particularly in terms of memory efficiency and downstream performance.","- **Extensive Theoretical Proof of Convergence**: The paper provides substantial theoretical evidence to support the convergence of the proposed method.
- **Detailed Method Analysis**: The analysis of the method is thorough, covering aspects like memory consumption and computation time.","- **Need for More Quantitative Results**: The evaluation of 7B and 8B models requires more quantitative results, such as mathematical and world knowledge benchmarks (e.g., GSM8K and MMLU). Relying solely on MT-bench, which is scored by GPT-4, is not sufficiently objective.
- **Block-wise vs. Layer-wise Updates**: The paper's core discussion revolves around block-wise updates, but the actual implementation uses layer-wise updates. Other formats of block-wise updates should be explored.
- **Similarity to Existing Work**: The motivation of this paper is similar to ""LIFT: Efficient Layer-wise Fine-tuning for Large Model Models""[1] which also discusses ""learning one layer/block at a time"" in Section 3.2. This similarity needs to be addressed and differentiated.
- **Verbose Section 3.1.2**: The discussion in Section 3.1.2 is overly verbose. Experiments with learning rates and other hyperparameters could be moved to the ablation studies or the appendix, while the main text should focus on the core experimental results.

[1] https://openreview.net/forum?id=u0INlprg3U",,,['No ethics review needed.'],5,4,,Yes,2,2,3,1720084645852,,,NeurIPS.cc/2024/Conference,0uXtFk5KNJ,"['NeurIPS.cc/2024/Conference/Submission5025/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878971437,[],2,,,['everyone'],0uXtFk5KNJ,['NeurIPS.cc/2024/Conference/Submission5025/Reviewer_XVND'],1720084645852,1730878971437,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5025/Reviewer_XVND']","Yes, the peer review suggests the authors of the paper to cite a specific literature, ""LIFT: Efficient Layer-wise Fine-tuning for Large Model Models"" [1], in order to address and differentiate the similarity in motivation between the two works. The URL for this literature is provided as https://openreview.net/forum?id=u0INlprg3U.",1,,LIFT Efficient Layer-wise Fine-tuning for Large Model Models
0tfZpInjW7,"This paper proposes an uncertainty-aware regularization technique that uses diffusion priors to improve the reconstruction quality of underfitted areas. and a dynamic region densification technique to address the missing initialization problem on dynamic regions.
Experiments verify the proposed techniques.","1. The proposed regularization method, which applies uncertainty-aware diffusion priors on unseen views, can reduce inconsistencies with training images.
2. The proposed dynamic region densification can deal with the issue of missing initialization in dynamic regions.
3. The paper is well-written and easy to follow.","1. The experimental setup is not reasonable. The goal of this paper is to reconstruct dynamic scenes from monocular videos. However, as shown in Sec. 7.2, only one part is relevant to evaluating the proposed method, while the other two involve the generalization of uncertainty-aware regularization. I think the authors should conduct more experiments on the dynamic scene datasets and move the two parts about generalization into the `Appendix`.
2. As shown in L206, the authors claim the proposed method will compare with SC-GS. However, I cannot find such a comparison in Tables and Figures. Moreover, the proposed method should also be compared with Deformable 3D-GS[1].
3. The `Appendix` should be placed after the `References`.

[1] Yang, Z., Gao, X., Zhou, W., Jiao, S., Zhang, Y., Jin, X.: Deformable 3D Gaussians for high-fidelity monocular dynamic scene reconstruction. In CVPR. (2024)","See weaknesses.
More, 
- According to Table 2, for three components of the proposed method, *Dynamic Densification* plays the most important role (+1.3  mPSNR), $L_{\mathrm{data}}$ is the second important (+0.49 mPSNR), and $L_{\mathrm{UA-diff}}$ is the least important. (+0.26 mPSNR). I would like to know the performance of each component when used individually.
- The proposed method seems to be able to change 4D-GS to any other GS-based method. I would like to know the performance of the proposed method when applying it on Deformable 3D-GS or SC-GS.",This paper does **not** discuss the limitations and broader impacts.,"['Ethics review needed: Data privacy, copyright, and consent']",7,5,,Yes,3,4,3,1720233434684,,,NeurIPS.cc/2024/Conference,0sycTGl4In,"['NeurIPS.cc/2024/Conference/Submission15212/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879763081,[],2,,,['everyone'],0sycTGl4In,['NeurIPS.cc/2024/Conference/Submission15212/Reviewer_LdSG'],1720233434684,1730879763081,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission15212/Reviewer_LdSG']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

Yang, Z., Gao, X., Zhou, W., Jiao, S., Zhang, Y., Jin, X.: Deformable 3D Gaussians for high-fidelity monocular dynamic scene reconstruction. In CVPR. (2024)

The reviewer mentions that the proposed method should also be compared with Deformable 3D-GS [1], referring to this paper.",1,2024,Deformable 3D Gaussians for high-fidelity monocular dynamic scene reconstruction
5yBqXiWwlA,This paper proposes a novel algorithm for adaptively selecting an optimal discretisation schedule in the training of diffusion model. The proposed method does not require hyper-parameter tuning and adapts to the dynamics and geometry of the diffusion path. This method also achieves competitive FID scores on image datasets.,"+ The findings of the paper are interesting. Current schedule designs are heuristic, and this paper provides a theoretical analysis, which is of interest to the community.
+ The proposed online data-dependent adaptive discretization schedule tuning algorithm is simple and effective.
+ The mathematical analysis presented in this paper is exceptionally detailed. Meanwhile, adequate related work was discussed in detail. The authors also provide corresponding code that makes the work in this paper very solid.
+ The authors provide clear visual comparisons that show the distribution of optimized times in detail.","+ The experiments in this paper are somewhat weak and lack validation for the LDM model. In fact, the LDM model is widely used, so it is important to validate the proposed method for LDM.
+ Some other diffusion frameworks also use schedule discretization in the same way, e.g., VP-SDE [1] and Flow Matching [2], is the method proposed in this paper robust for them as well?

[1] Score-Based Generative Modeling through Stochastic Differential Equations ICLR 2021

[2] Flow Matching for Generative Modeling ICLR 2023

+ The authors should provide additional quantitative and visual comparisons, as the FID metric alone is insufficient for assessing generation quality [1]. Low FID scores do not necessarily correlate with superior generative performance. Therefore, incorporating other metrics such as sFID, Recall, and Precision would offer a more comprehensive evaluation. This enhanced analysis will help further substantiate the validity of the proposed method.

[1] The Role of ImageNet Classes in Fréchet Inception Distance ICLR 2023

[2] Diffusion Models Beat GANs on Image Synthesis  NeurIPS 2021

+ The mathematical parts of this paper are somewhat difficult to understand, especially the differential geometry part of it, and I would suggest that the authors add some background and notation notes.",Please see Weakness.,Please see Weakness.,['No ethics review needed.'],7,4,,Yes,4,4,4,1718894561527,,,NeurIPS.cc/2024/Conference,0rl5vWOzRU,"['NeurIPS.cc/2024/Conference/Submission19272/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880031581,[],1,,,['everyone'],0rl5vWOzRU,['NeurIPS.cc/2024/Conference/Submission19272/Reviewer_g4tL'],1718894561527,1730880031581,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission19272/Reviewer_g4tL']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references, including:

1. ""Score-Based Generative Modeling through Stochastic Differential Equations"" (ICLR 2021)
2. ""Flow Matching for Generative Modeling"" (ICLR 2023)
3. ""The Role of ImageNet Classes in Fréchet Inception Distance"" (ICLR 2023)
4. ""Diffusion Models Beat GANs on Image Synthesis"" (NeurIPS 2021)

The reviewer uses these references to support their comments and suggestions, implying that the authors should be aware of and potentially cite these works in their paper.",1,"2021, 2023, 2023, 2021",Score-Based Generative Modeling through Stochastic Differential Equations 
5yBqXiWwlA,This paper proposes a novel algorithm for adaptively selecting an optimal discretisation schedule in the training of diffusion model. The proposed method does not require hyper-parameter tuning and adapts to the dynamics and geometry of the diffusion path. This method also achieves competitive FID scores on image datasets.,"+ The findings of the paper are interesting. Current schedule designs are heuristic, and this paper provides a theoretical analysis, which is of interest to the community.
+ The proposed online data-dependent adaptive discretization schedule tuning algorithm is simple and effective.
+ The mathematical analysis presented in this paper is exceptionally detailed. Meanwhile, adequate related work was discussed in detail. The authors also provide corresponding code that makes the work in this paper very solid.
+ The authors provide clear visual comparisons that show the distribution of optimized times in detail.","+ The experiments in this paper are somewhat weak and lack validation for the LDM model. In fact, the LDM model is widely used, so it is important to validate the proposed method for LDM.
+ Some other diffusion frameworks also use schedule discretization in the same way, e.g., VP-SDE [1] and Flow Matching [2], is the method proposed in this paper robust for them as well?

[1] Score-Based Generative Modeling through Stochastic Differential Equations ICLR 2021

[2] Flow Matching for Generative Modeling ICLR 2023

+ The authors should provide additional quantitative and visual comparisons, as the FID metric alone is insufficient for assessing generation quality [1]. Low FID scores do not necessarily correlate with superior generative performance. Therefore, incorporating other metrics such as sFID, Recall, and Precision would offer a more comprehensive evaluation. This enhanced analysis will help further substantiate the validity of the proposed method.

[1] The Role of ImageNet Classes in Fréchet Inception Distance ICLR 2023

[2] Diffusion Models Beat GANs on Image Synthesis  NeurIPS 2021

+ The mathematical parts of this paper are somewhat difficult to understand, especially the differential geometry part of it, and I would suggest that the authors add some background and notation notes.",Please see Weakness.,Please see Weakness.,['No ethics review needed.'],7,4,,Yes,4,4,4,1718894561527,,,NeurIPS.cc/2024/Conference,0rl5vWOzRU,"['NeurIPS.cc/2024/Conference/Submission19272/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880031581,[],1,,,['everyone'],0rl5vWOzRU,['NeurIPS.cc/2024/Conference/Submission19272/Reviewer_g4tL'],1718894561527,1730880031581,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission19272/Reviewer_g4tL']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references, including:

1. ""Score-Based Generative Modeling through Stochastic Differential Equations"" (ICLR 2021)
2. ""Flow Matching for Generative Modeling"" (ICLR 2023)
3. ""The Role of ImageNet Classes in Fréchet Inception Distance"" (ICLR 2023)
4. ""Diffusion Models Beat GANs on Image Synthesis"" (NeurIPS 2021)

The reviewer uses these references to support their comments and suggestions, implying that the authors should be aware of and potentially cite these works in their paper.",1,"2021, 2023, 2023, 2021",Flow Matching for Generative Modeling 
5yBqXiWwlA,This paper proposes a novel algorithm for adaptively selecting an optimal discretisation schedule in the training of diffusion model. The proposed method does not require hyper-parameter tuning and adapts to the dynamics and geometry of the diffusion path. This method also achieves competitive FID scores on image datasets.,"+ The findings of the paper are interesting. Current schedule designs are heuristic, and this paper provides a theoretical analysis, which is of interest to the community.
+ The proposed online data-dependent adaptive discretization schedule tuning algorithm is simple and effective.
+ The mathematical analysis presented in this paper is exceptionally detailed. Meanwhile, adequate related work was discussed in detail. The authors also provide corresponding code that makes the work in this paper very solid.
+ The authors provide clear visual comparisons that show the distribution of optimized times in detail.","+ The experiments in this paper are somewhat weak and lack validation for the LDM model. In fact, the LDM model is widely used, so it is important to validate the proposed method for LDM.
+ Some other diffusion frameworks also use schedule discretization in the same way, e.g., VP-SDE [1] and Flow Matching [2], is the method proposed in this paper robust for them as well?

[1] Score-Based Generative Modeling through Stochastic Differential Equations ICLR 2021

[2] Flow Matching for Generative Modeling ICLR 2023

+ The authors should provide additional quantitative and visual comparisons, as the FID metric alone is insufficient for assessing generation quality [1]. Low FID scores do not necessarily correlate with superior generative performance. Therefore, incorporating other metrics such as sFID, Recall, and Precision would offer a more comprehensive evaluation. This enhanced analysis will help further substantiate the validity of the proposed method.

[1] The Role of ImageNet Classes in Fréchet Inception Distance ICLR 2023

[2] Diffusion Models Beat GANs on Image Synthesis  NeurIPS 2021

+ The mathematical parts of this paper are somewhat difficult to understand, especially the differential geometry part of it, and I would suggest that the authors add some background and notation notes.",Please see Weakness.,Please see Weakness.,['No ethics review needed.'],7,4,,Yes,4,4,4,1718894561527,,,NeurIPS.cc/2024/Conference,0rl5vWOzRU,"['NeurIPS.cc/2024/Conference/Submission19272/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880031581,[],1,,,['everyone'],0rl5vWOzRU,['NeurIPS.cc/2024/Conference/Submission19272/Reviewer_g4tL'],1718894561527,1730880031581,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission19272/Reviewer_g4tL']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references, including:

1. ""Score-Based Generative Modeling through Stochastic Differential Equations"" (ICLR 2021)
2. ""Flow Matching for Generative Modeling"" (ICLR 2023)
3. ""The Role of ImageNet Classes in Fréchet Inception Distance"" (ICLR 2023)
4. ""Diffusion Models Beat GANs on Image Synthesis"" (NeurIPS 2021)

The reviewer uses these references to support their comments and suggestions, implying that the authors should be aware of and potentially cite these works in their paper.",1,"2021, 2023, 2023, 2021",The Role of ImageNet Classes in Fréchet Inception Distance 
5yBqXiWwlA,This paper proposes a novel algorithm for adaptively selecting an optimal discretisation schedule in the training of diffusion model. The proposed method does not require hyper-parameter tuning and adapts to the dynamics and geometry of the diffusion path. This method also achieves competitive FID scores on image datasets.,"+ The findings of the paper are interesting. Current schedule designs are heuristic, and this paper provides a theoretical analysis, which is of interest to the community.
+ The proposed online data-dependent adaptive discretization schedule tuning algorithm is simple and effective.
+ The mathematical analysis presented in this paper is exceptionally detailed. Meanwhile, adequate related work was discussed in detail. The authors also provide corresponding code that makes the work in this paper very solid.
+ The authors provide clear visual comparisons that show the distribution of optimized times in detail.","+ The experiments in this paper are somewhat weak and lack validation for the LDM model. In fact, the LDM model is widely used, so it is important to validate the proposed method for LDM.
+ Some other diffusion frameworks also use schedule discretization in the same way, e.g., VP-SDE [1] and Flow Matching [2], is the method proposed in this paper robust for them as well?

[1] Score-Based Generative Modeling through Stochastic Differential Equations ICLR 2021

[2] Flow Matching for Generative Modeling ICLR 2023

+ The authors should provide additional quantitative and visual comparisons, as the FID metric alone is insufficient for assessing generation quality [1]. Low FID scores do not necessarily correlate with superior generative performance. Therefore, incorporating other metrics such as sFID, Recall, and Precision would offer a more comprehensive evaluation. This enhanced analysis will help further substantiate the validity of the proposed method.

[1] The Role of ImageNet Classes in Fréchet Inception Distance ICLR 2023

[2] Diffusion Models Beat GANs on Image Synthesis  NeurIPS 2021

+ The mathematical parts of this paper are somewhat difficult to understand, especially the differential geometry part of it, and I would suggest that the authors add some background and notation notes.",Please see Weakness.,Please see Weakness.,['No ethics review needed.'],7,4,,Yes,4,4,4,1718894561527,,,NeurIPS.cc/2024/Conference,0rl5vWOzRU,"['NeurIPS.cc/2024/Conference/Submission19272/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880031581,[],1,,,['everyone'],0rl5vWOzRU,['NeurIPS.cc/2024/Conference/Submission19272/Reviewer_g4tL'],1718894561527,1730880031581,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission19272/Reviewer_g4tL']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several references, including:

1. ""Score-Based Generative Modeling through Stochastic Differential Equations"" (ICLR 2021)
2. ""Flow Matching for Generative Modeling"" (ICLR 2023)
3. ""The Role of ImageNet Classes in Fréchet Inception Distance"" (ICLR 2023)
4. ""Diffusion Models Beat GANs on Image Synthesis"" (NeurIPS 2021)

The reviewer uses these references to support their comments and suggestions, implying that the authors should be aware of and potentially cite these works in their paper.",1,"2021, 2023, 2023, 2021",Diffusion Models Beat GANs on Image Synthesis
niFIVSUmpC,"The paper investigates specific neurons in LLMs  (termed ""confidence regulation neurons"")  that modulate the uncertainty of the next token prediction by modulating the output distribution. First, entropy neurons modulate the overall entropy of the output distribution by writing to an effective null space of the unembedding matrix, thereby influencing the residual stream norm with a minimal direct effect on the logits themselves. Second, token frequency neurons modulate the predictive distribution proportionally to the token frequency in the training data.","- The paper clearly written and well-organized, making complex concepts accessible.
- It provides deeper insight into the role of entropy neurons in regulating the confidence of LLMs through the unembedding null space.
- It introduces token frequency neurons, a type of neurons that have not been discussed in prior work.
- It demonstrates the presence of these entropy and token frequency neurons across various models.","- **Novelty**: The authors claim that they provide a ""novel example of how language models can use LayerNorm to indirectly manipulate the logit values"" and that prior studies ""fail to account for the normalization effects imposed by LayerNorm"" (lines 160 to 163).
However, the mechanisms of entropy neurons have already been discovered in previous work [1]. For instance, Gurnee et al. (2023) show that entropy neurons ""modulate the model’s uncertainty over the next token by using the layer norm to squeeze the logit distribution, in a manner quite similar to manually increasing the temperature when performing inference."". Although prior studies do not differentiate between the total and direct effect of an entropy neuron on the output distribution, the novelty of the analysis is not clear-cut. 

- **Clarity**: Individual neurons are referred to as *layer.position* and simply *position* interchangebly (e.g. 11.2378 and 2378). Since only neurons in the final layer were investigated, referring to the layer is redundant. Also, the authors should consider further simplifying the name of the neurons, as the exact *position* does not add immediate value to the reader.

- **Interpretability**: The interpretation of the results is sometimes unclear. For instance, the authors observe that token frequency neurons suppress common tokens and promote rare ones. They suggest this indicates the model is biased to predict common tokens more frequently than their actual occurrence. However, an alternative interpretation could be considered. The model might also assign high probability to a single rare token while assigning almost no probability to other rare tokens. Promoting all other rare tokens to match their token frequency would bring the output distribution closer to the token frequency distribution, while increasing entropy and lowering confidence. In other words, the model's bias might not be just towards common tokens but also towards certain rare tokens. Such alternative interpretations would also resolve the counterintuitive explanation. The authors should provide more insights to support their interpretations.

---
[1] Wes Gurnee, Theo Horsley, Zifan Carl Guo, Tara Rezaei Kheirkhah, Qinyi Sun, Will Hathaway, Neel Nanda, and Dimitris Bertsimas. Universal neurons in gpt2 language models.","- Why did the authors analyze 6 entropy neurons but only 5 token frequency neurons?
- In Figure 5(a), are entropy, loss, and neuron activations really all on the same scale (single y-axis)?
- Why does the induction case study not consider the novel token frequency neurons but only the known entropy neurons?",The authors adequately addressed limitations.,['No ethics review needed.'],5,4,,Yes,2,3,3,1720624580205,,,NeurIPS.cc/2024/Conference,0og7nmvDbe,"['NeurIPS.cc/2024/Conference/Submission9211/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879297050,[],2,,,['everyone'],0og7nmvDbe,['NeurIPS.cc/2024/Conference/Submission9211/Reviewer_Thsu'],1720624580205,1730879297050,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9211/Reviewer_Thsu']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature, namely the work by Wes Gurnee et al. (2023) titled ""Universal neurons in gpt2 language models"", which is referred to as [1] in the review. The reviewer mentions that the mechanisms of entropy neurons have already been discovered in this previous work, which may impact the novelty of the analysis presented in the paper.",1,2023,Universal neurons in gpt2 language models
zRfZy0mMCM,"In the paper entitled ""ProtGO: Function-Guided Protein Modeling for Unified Representation Learning"", the authors proposed a KD-based framework to incorporate GO knowledge to learn an unified, multi-modal embedding for a given protein. The cross-domain knowledge make the embeddings performs good in various downstream tasks.","1. The paper is well-written and easy-to-follow.
2. The proposed unified framework is novel and interest, it may lay as foundations for futural research on protein embedding.
3. The introduction of KD for transferring GO knowledges could potentially overcome the data insufficient problem.","Lack of sufficient baseline method, as I believe in all modalities (sequence/structure/GO), there exists other powerful methods that the authors may ignore. 

Minor:
In line 4, the authors wrote ""including sequence, structure, domains, motifs, and..."", generally domains and motifs are structural annotations, they should not be listed together with sequence and structure.","1. In table 1 and table 2, the authors may consider add ESM-1b/ESM-2/ESM-3 as sequence modality baselines. 
2. Also table 1 and 2, the authors may consider add ESM-IF1 as structural modality baselines.
3. Also table 1 and 2, the authors may consider add GO/sequence+GO modality as input, add DeepGO-SE as baselines. (https://www.nature.com/articles/s42256-024-00795-w)
4. I am interested in the downstream task performance differences for proteins with GOs (where the teacher can teach the student well) and proteins without GOs (where the teacher model may fail). Moreover, GO terms consist of 3 parts, molecular functions, cellular components, and biological processes, I wonder whether the authors could explore the effectiveness of each part through comprehensive downstream experiments.",The authors have addressed the limitations.,['No ethics review needed.'],6,4,,Yes,3,3,3,1720704449180,,,NeurIPS.cc/2024/Conference,0oUutV92YF,"['NeurIPS.cc/2024/Conference/Submission4201/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878908387,[],3,,,['everyone'],0oUutV92YF,['NeurIPS.cc/2024/Conference/Submission4201/Reviewer_kUCf'],1720704449180,1730878908387,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4201/Reviewer_kUCf']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

https://www.nature.com/articles/s42256-024-00795-w

This is related to DeepGO-SE, a baseline method that the reviewer thinks the authors should consider adding to their experiments.",1,,DeepGO-SE
VFmLx5UgF6,"This paper introduces DarkSAM, a prompt-free universal attack framework against the Segment Anything Model (SAM) in a quasi-black-box setting. The framework consists of a semantic decoupling-based spatial attack and a texture distortion-based frequency attack. While SAM uses geometric prompt inputs to guide segmentation of critical objects within images, DarkSAM disrupts these processes by decoupling the object features of images in both spatial and frequency domains using a universal adversarial perturbation (UAP). In the spatial domain, it scrambles SAM’s decisions by destroying the features of the foreground and background of the image separately. In the frequency domain, it decomposes images into high-frequency components (HFC) and low-frequency components (LFC), increasing the dissimilarity in the HFC of adversarial and benign examples while maintaining consistency in their LFC. Experiments are conducted on four public segmentation datasets (ADE20K, MS-COCO, CITYSCAPES, and SA-1B), with 100 images used for UAP generation and 2,000 images for testing for each dataset. Victim models include the pre-trained SAM, HQ-SAM, and PerSAM with the ViT-B backbone.","1. The paper is well-written and easy to follow.
2. The specific design of the shadow target strategy is tailored to SAM for prompt-based segmentation, which is unique compared to adversary attacks against traditional segmentation pipelines.
3. The attacking results are impressive. All three models show very low segmentation performance across multiple datasets.","SAM is a milestone work, and a series of follow-up studies have been proposed recently. However, this paper does not provide an up-to-date review in Section 2.1 and lacks comparison in Section 4, weakening its significance. For example:
- SAM-based adversary attack:
[1] Practical Region-level Attack against Segment Anything Models, CVPR 2024.
- Other SAM-based models:  
[2] From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation, CVPR 2024.  
[3] RobustSAM: Segment Anything Robustly on Degraded Images, CVPR 2024.  
[4] Matching Anything by Segmenting Anything, CVPR 2024.  
[5] FocSAM: Delving Deeply into Focused Objects in Segmenting Anything, CVPR 2024.  
[6] ASAM: Boosting Segment Anything Model with Adversarial Tuning, CVPR 2024.  
[7] BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model, CVPR 2024.  
[8] Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively, ECCV 2024.  
[9] CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model, ECCV 2024.  
[10] Semantic-SAM: Segment and Recognize Anything at Any Granularity, ECCV 2024.","1. How does DarkSAM perform with variants of the SAM models?
2. Please include a comparison with [1] ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024).",The paper presents a limitation that DarkSAM is tailored to SAM and cannot operate on traditional segmentation models.,['Ethics review needed: Safety and security'],5,3,,Yes,3,3,3,1720426333142,,,NeurIPS.cc/2024/Conference,0o9E8AsFgW,"['NeurIPS.cc/2024/Conference/Submission18495/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879980408,[],1,,,['everyone'],0o9E8AsFgW,['NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H'],1720426333142,1730879980408,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024)
2. ""From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation"" (CVPR 2024)
3. ""RobustSAM: Segment Anything Robustly on Degraded Images"" (CVPR 2024)
4. ""Matching Anything by Segmenting Anything"" (CVPR 2024)
5. ""FocSAM: Delving Deeply into Focused Objects in Segmenting Anything"" (CVPR 2024)
6. ""ASAM: Boosting Segment Anything Model with Adversarial Tuning"" (CVPR 2024)
7. ""BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model"" (CVPR 2024)
8. ""Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively"" (ECCV 2024)
9. ""CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model"" (ECCV 2024)
10. ""Semantic-SAM: Segment and Recognize Anything at Any Granularity"" (ECCV 2024)

These citations are suggested to provide an up-to-date review of the field and to compare the results of DarkSAM with other related works.",1,"2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024",Practical Region-level Attack against Segment Anything Models
VFmLx5UgF6,"This paper introduces DarkSAM, a prompt-free universal attack framework against the Segment Anything Model (SAM) in a quasi-black-box setting. The framework consists of a semantic decoupling-based spatial attack and a texture distortion-based frequency attack. While SAM uses geometric prompt inputs to guide segmentation of critical objects within images, DarkSAM disrupts these processes by decoupling the object features of images in both spatial and frequency domains using a universal adversarial perturbation (UAP). In the spatial domain, it scrambles SAM’s decisions by destroying the features of the foreground and background of the image separately. In the frequency domain, it decomposes images into high-frequency components (HFC) and low-frequency components (LFC), increasing the dissimilarity in the HFC of adversarial and benign examples while maintaining consistency in their LFC. Experiments are conducted on four public segmentation datasets (ADE20K, MS-COCO, CITYSCAPES, and SA-1B), with 100 images used for UAP generation and 2,000 images for testing for each dataset. Victim models include the pre-trained SAM, HQ-SAM, and PerSAM with the ViT-B backbone.","1. The paper is well-written and easy to follow.
2. The specific design of the shadow target strategy is tailored to SAM for prompt-based segmentation, which is unique compared to adversary attacks against traditional segmentation pipelines.
3. The attacking results are impressive. All three models show very low segmentation performance across multiple datasets.","SAM is a milestone work, and a series of follow-up studies have been proposed recently. However, this paper does not provide an up-to-date review in Section 2.1 and lacks comparison in Section 4, weakening its significance. For example:
- SAM-based adversary attack:
[1] Practical Region-level Attack against Segment Anything Models, CVPR 2024.
- Other SAM-based models:  
[2] From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation, CVPR 2024.  
[3] RobustSAM: Segment Anything Robustly on Degraded Images, CVPR 2024.  
[4] Matching Anything by Segmenting Anything, CVPR 2024.  
[5] FocSAM: Delving Deeply into Focused Objects in Segmenting Anything, CVPR 2024.  
[6] ASAM: Boosting Segment Anything Model with Adversarial Tuning, CVPR 2024.  
[7] BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model, CVPR 2024.  
[8] Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively, ECCV 2024.  
[9] CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model, ECCV 2024.  
[10] Semantic-SAM: Segment and Recognize Anything at Any Granularity, ECCV 2024.","1. How does DarkSAM perform with variants of the SAM models?
2. Please include a comparison with [1] ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024).",The paper presents a limitation that DarkSAM is tailored to SAM and cannot operate on traditional segmentation models.,['Ethics review needed: Safety and security'],5,3,,Yes,3,3,3,1720426333142,,,NeurIPS.cc/2024/Conference,0o9E8AsFgW,"['NeurIPS.cc/2024/Conference/Submission18495/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879980408,[],1,,,['everyone'],0o9E8AsFgW,['NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H'],1720426333142,1730879980408,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024)
2. ""From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation"" (CVPR 2024)
3. ""RobustSAM: Segment Anything Robustly on Degraded Images"" (CVPR 2024)
4. ""Matching Anything by Segmenting Anything"" (CVPR 2024)
5. ""FocSAM: Delving Deeply into Focused Objects in Segmenting Anything"" (CVPR 2024)
6. ""ASAM: Boosting Segment Anything Model with Adversarial Tuning"" (CVPR 2024)
7. ""BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model"" (CVPR 2024)
8. ""Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively"" (ECCV 2024)
9. ""CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model"" (ECCV 2024)
10. ""Semantic-SAM: Segment and Recognize Anything at Any Granularity"" (ECCV 2024)

These citations are suggested to provide an up-to-date review of the field and to compare the results of DarkSAM with other related works.",1,"2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024",From SAM to CAMs Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation
VFmLx5UgF6,"This paper introduces DarkSAM, a prompt-free universal attack framework against the Segment Anything Model (SAM) in a quasi-black-box setting. The framework consists of a semantic decoupling-based spatial attack and a texture distortion-based frequency attack. While SAM uses geometric prompt inputs to guide segmentation of critical objects within images, DarkSAM disrupts these processes by decoupling the object features of images in both spatial and frequency domains using a universal adversarial perturbation (UAP). In the spatial domain, it scrambles SAM’s decisions by destroying the features of the foreground and background of the image separately. In the frequency domain, it decomposes images into high-frequency components (HFC) and low-frequency components (LFC), increasing the dissimilarity in the HFC of adversarial and benign examples while maintaining consistency in their LFC. Experiments are conducted on four public segmentation datasets (ADE20K, MS-COCO, CITYSCAPES, and SA-1B), with 100 images used for UAP generation and 2,000 images for testing for each dataset. Victim models include the pre-trained SAM, HQ-SAM, and PerSAM with the ViT-B backbone.","1. The paper is well-written and easy to follow.
2. The specific design of the shadow target strategy is tailored to SAM for prompt-based segmentation, which is unique compared to adversary attacks against traditional segmentation pipelines.
3. The attacking results are impressive. All three models show very low segmentation performance across multiple datasets.","SAM is a milestone work, and a series of follow-up studies have been proposed recently. However, this paper does not provide an up-to-date review in Section 2.1 and lacks comparison in Section 4, weakening its significance. For example:
- SAM-based adversary attack:
[1] Practical Region-level Attack against Segment Anything Models, CVPR 2024.
- Other SAM-based models:  
[2] From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation, CVPR 2024.  
[3] RobustSAM: Segment Anything Robustly on Degraded Images, CVPR 2024.  
[4] Matching Anything by Segmenting Anything, CVPR 2024.  
[5] FocSAM: Delving Deeply into Focused Objects in Segmenting Anything, CVPR 2024.  
[6] ASAM: Boosting Segment Anything Model with Adversarial Tuning, CVPR 2024.  
[7] BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model, CVPR 2024.  
[8] Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively, ECCV 2024.  
[9] CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model, ECCV 2024.  
[10] Semantic-SAM: Segment and Recognize Anything at Any Granularity, ECCV 2024.","1. How does DarkSAM perform with variants of the SAM models?
2. Please include a comparison with [1] ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024).",The paper presents a limitation that DarkSAM is tailored to SAM and cannot operate on traditional segmentation models.,['Ethics review needed: Safety and security'],5,3,,Yes,3,3,3,1720426333142,,,NeurIPS.cc/2024/Conference,0o9E8AsFgW,"['NeurIPS.cc/2024/Conference/Submission18495/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879980408,[],1,,,['everyone'],0o9E8AsFgW,['NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H'],1720426333142,1730879980408,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024)
2. ""From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation"" (CVPR 2024)
3. ""RobustSAM: Segment Anything Robustly on Degraded Images"" (CVPR 2024)
4. ""Matching Anything by Segmenting Anything"" (CVPR 2024)
5. ""FocSAM: Delving Deeply into Focused Objects in Segmenting Anything"" (CVPR 2024)
6. ""ASAM: Boosting Segment Anything Model with Adversarial Tuning"" (CVPR 2024)
7. ""BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model"" (CVPR 2024)
8. ""Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively"" (ECCV 2024)
9. ""CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model"" (ECCV 2024)
10. ""Semantic-SAM: Segment and Recognize Anything at Any Granularity"" (ECCV 2024)

These citations are suggested to provide an up-to-date review of the field and to compare the results of DarkSAM with other related works.",1,"2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024",RobustSAM Segment Anything Robustly on Degraded Images
VFmLx5UgF6,"This paper introduces DarkSAM, a prompt-free universal attack framework against the Segment Anything Model (SAM) in a quasi-black-box setting. The framework consists of a semantic decoupling-based spatial attack and a texture distortion-based frequency attack. While SAM uses geometric prompt inputs to guide segmentation of critical objects within images, DarkSAM disrupts these processes by decoupling the object features of images in both spatial and frequency domains using a universal adversarial perturbation (UAP). In the spatial domain, it scrambles SAM’s decisions by destroying the features of the foreground and background of the image separately. In the frequency domain, it decomposes images into high-frequency components (HFC) and low-frequency components (LFC), increasing the dissimilarity in the HFC of adversarial and benign examples while maintaining consistency in their LFC. Experiments are conducted on four public segmentation datasets (ADE20K, MS-COCO, CITYSCAPES, and SA-1B), with 100 images used for UAP generation and 2,000 images for testing for each dataset. Victim models include the pre-trained SAM, HQ-SAM, and PerSAM with the ViT-B backbone.","1. The paper is well-written and easy to follow.
2. The specific design of the shadow target strategy is tailored to SAM for prompt-based segmentation, which is unique compared to adversary attacks against traditional segmentation pipelines.
3. The attacking results are impressive. All three models show very low segmentation performance across multiple datasets.","SAM is a milestone work, and a series of follow-up studies have been proposed recently. However, this paper does not provide an up-to-date review in Section 2.1 and lacks comparison in Section 4, weakening its significance. For example:
- SAM-based adversary attack:
[1] Practical Region-level Attack against Segment Anything Models, CVPR 2024.
- Other SAM-based models:  
[2] From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation, CVPR 2024.  
[3] RobustSAM: Segment Anything Robustly on Degraded Images, CVPR 2024.  
[4] Matching Anything by Segmenting Anything, CVPR 2024.  
[5] FocSAM: Delving Deeply into Focused Objects in Segmenting Anything, CVPR 2024.  
[6] ASAM: Boosting Segment Anything Model with Adversarial Tuning, CVPR 2024.  
[7] BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model, CVPR 2024.  
[8] Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively, ECCV 2024.  
[9] CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model, ECCV 2024.  
[10] Semantic-SAM: Segment and Recognize Anything at Any Granularity, ECCV 2024.","1. How does DarkSAM perform with variants of the SAM models?
2. Please include a comparison with [1] ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024).",The paper presents a limitation that DarkSAM is tailored to SAM and cannot operate on traditional segmentation models.,['Ethics review needed: Safety and security'],5,3,,Yes,3,3,3,1720426333142,,,NeurIPS.cc/2024/Conference,0o9E8AsFgW,"['NeurIPS.cc/2024/Conference/Submission18495/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879980408,[],1,,,['everyone'],0o9E8AsFgW,['NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H'],1720426333142,1730879980408,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024)
2. ""From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation"" (CVPR 2024)
3. ""RobustSAM: Segment Anything Robustly on Degraded Images"" (CVPR 2024)
4. ""Matching Anything by Segmenting Anything"" (CVPR 2024)
5. ""FocSAM: Delving Deeply into Focused Objects in Segmenting Anything"" (CVPR 2024)
6. ""ASAM: Boosting Segment Anything Model with Adversarial Tuning"" (CVPR 2024)
7. ""BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model"" (CVPR 2024)
8. ""Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively"" (ECCV 2024)
9. ""CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model"" (ECCV 2024)
10. ""Semantic-SAM: Segment and Recognize Anything at Any Granularity"" (ECCV 2024)

These citations are suggested to provide an up-to-date review of the field and to compare the results of DarkSAM with other related works.",1,"2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024",Matching Anything by Segmenting Anything
VFmLx5UgF6,"This paper introduces DarkSAM, a prompt-free universal attack framework against the Segment Anything Model (SAM) in a quasi-black-box setting. The framework consists of a semantic decoupling-based spatial attack and a texture distortion-based frequency attack. While SAM uses geometric prompt inputs to guide segmentation of critical objects within images, DarkSAM disrupts these processes by decoupling the object features of images in both spatial and frequency domains using a universal adversarial perturbation (UAP). In the spatial domain, it scrambles SAM’s decisions by destroying the features of the foreground and background of the image separately. In the frequency domain, it decomposes images into high-frequency components (HFC) and low-frequency components (LFC), increasing the dissimilarity in the HFC of adversarial and benign examples while maintaining consistency in their LFC. Experiments are conducted on four public segmentation datasets (ADE20K, MS-COCO, CITYSCAPES, and SA-1B), with 100 images used for UAP generation and 2,000 images for testing for each dataset. Victim models include the pre-trained SAM, HQ-SAM, and PerSAM with the ViT-B backbone.","1. The paper is well-written and easy to follow.
2. The specific design of the shadow target strategy is tailored to SAM for prompt-based segmentation, which is unique compared to adversary attacks against traditional segmentation pipelines.
3. The attacking results are impressive. All three models show very low segmentation performance across multiple datasets.","SAM is a milestone work, and a series of follow-up studies have been proposed recently. However, this paper does not provide an up-to-date review in Section 2.1 and lacks comparison in Section 4, weakening its significance. For example:
- SAM-based adversary attack:
[1] Practical Region-level Attack against Segment Anything Models, CVPR 2024.
- Other SAM-based models:  
[2] From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation, CVPR 2024.  
[3] RobustSAM: Segment Anything Robustly on Degraded Images, CVPR 2024.  
[4] Matching Anything by Segmenting Anything, CVPR 2024.  
[5] FocSAM: Delving Deeply into Focused Objects in Segmenting Anything, CVPR 2024.  
[6] ASAM: Boosting Segment Anything Model with Adversarial Tuning, CVPR 2024.  
[7] BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model, CVPR 2024.  
[8] Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively, ECCV 2024.  
[9] CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model, ECCV 2024.  
[10] Semantic-SAM: Segment and Recognize Anything at Any Granularity, ECCV 2024.","1. How does DarkSAM perform with variants of the SAM models?
2. Please include a comparison with [1] ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024).",The paper presents a limitation that DarkSAM is tailored to SAM and cannot operate on traditional segmentation models.,['Ethics review needed: Safety and security'],5,3,,Yes,3,3,3,1720426333142,,,NeurIPS.cc/2024/Conference,0o9E8AsFgW,"['NeurIPS.cc/2024/Conference/Submission18495/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879980408,[],1,,,['everyone'],0o9E8AsFgW,['NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H'],1720426333142,1730879980408,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024)
2. ""From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation"" (CVPR 2024)
3. ""RobustSAM: Segment Anything Robustly on Degraded Images"" (CVPR 2024)
4. ""Matching Anything by Segmenting Anything"" (CVPR 2024)
5. ""FocSAM: Delving Deeply into Focused Objects in Segmenting Anything"" (CVPR 2024)
6. ""ASAM: Boosting Segment Anything Model with Adversarial Tuning"" (CVPR 2024)
7. ""BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model"" (CVPR 2024)
8. ""Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively"" (ECCV 2024)
9. ""CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model"" (ECCV 2024)
10. ""Semantic-SAM: Segment and Recognize Anything at Any Granularity"" (ECCV 2024)

These citations are suggested to provide an up-to-date review of the field and to compare the results of DarkSAM with other related works.",1,"2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024",FocSAM Delving Deeply into Focused Objects in Segmenting Anything
VFmLx5UgF6,"This paper introduces DarkSAM, a prompt-free universal attack framework against the Segment Anything Model (SAM) in a quasi-black-box setting. The framework consists of a semantic decoupling-based spatial attack and a texture distortion-based frequency attack. While SAM uses geometric prompt inputs to guide segmentation of critical objects within images, DarkSAM disrupts these processes by decoupling the object features of images in both spatial and frequency domains using a universal adversarial perturbation (UAP). In the spatial domain, it scrambles SAM’s decisions by destroying the features of the foreground and background of the image separately. In the frequency domain, it decomposes images into high-frequency components (HFC) and low-frequency components (LFC), increasing the dissimilarity in the HFC of adversarial and benign examples while maintaining consistency in their LFC. Experiments are conducted on four public segmentation datasets (ADE20K, MS-COCO, CITYSCAPES, and SA-1B), with 100 images used for UAP generation and 2,000 images for testing for each dataset. Victim models include the pre-trained SAM, HQ-SAM, and PerSAM with the ViT-B backbone.","1. The paper is well-written and easy to follow.
2. The specific design of the shadow target strategy is tailored to SAM for prompt-based segmentation, which is unique compared to adversary attacks against traditional segmentation pipelines.
3. The attacking results are impressive. All three models show very low segmentation performance across multiple datasets.","SAM is a milestone work, and a series of follow-up studies have been proposed recently. However, this paper does not provide an up-to-date review in Section 2.1 and lacks comparison in Section 4, weakening its significance. For example:
- SAM-based adversary attack:
[1] Practical Region-level Attack against Segment Anything Models, CVPR 2024.
- Other SAM-based models:  
[2] From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation, CVPR 2024.  
[3] RobustSAM: Segment Anything Robustly on Degraded Images, CVPR 2024.  
[4] Matching Anything by Segmenting Anything, CVPR 2024.  
[5] FocSAM: Delving Deeply into Focused Objects in Segmenting Anything, CVPR 2024.  
[6] ASAM: Boosting Segment Anything Model with Adversarial Tuning, CVPR 2024.  
[7] BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model, CVPR 2024.  
[8] Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively, ECCV 2024.  
[9] CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model, ECCV 2024.  
[10] Semantic-SAM: Segment and Recognize Anything at Any Granularity, ECCV 2024.","1. How does DarkSAM perform with variants of the SAM models?
2. Please include a comparison with [1] ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024).",The paper presents a limitation that DarkSAM is tailored to SAM and cannot operate on traditional segmentation models.,['Ethics review needed: Safety and security'],5,3,,Yes,3,3,3,1720426333142,,,NeurIPS.cc/2024/Conference,0o9E8AsFgW,"['NeurIPS.cc/2024/Conference/Submission18495/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879980408,[],1,,,['everyone'],0o9E8AsFgW,['NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H'],1720426333142,1730879980408,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024)
2. ""From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation"" (CVPR 2024)
3. ""RobustSAM: Segment Anything Robustly on Degraded Images"" (CVPR 2024)
4. ""Matching Anything by Segmenting Anything"" (CVPR 2024)
5. ""FocSAM: Delving Deeply into Focused Objects in Segmenting Anything"" (CVPR 2024)
6. ""ASAM: Boosting Segment Anything Model with Adversarial Tuning"" (CVPR 2024)
7. ""BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model"" (CVPR 2024)
8. ""Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively"" (ECCV 2024)
9. ""CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model"" (ECCV 2024)
10. ""Semantic-SAM: Segment and Recognize Anything at Any Granularity"" (ECCV 2024)

These citations are suggested to provide an up-to-date review of the field and to compare the results of DarkSAM with other related works.",1,"2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024",ASAM Boosting Segment Anything Model with Adversarial Tuning
VFmLx5UgF6,"This paper introduces DarkSAM, a prompt-free universal attack framework against the Segment Anything Model (SAM) in a quasi-black-box setting. The framework consists of a semantic decoupling-based spatial attack and a texture distortion-based frequency attack. While SAM uses geometric prompt inputs to guide segmentation of critical objects within images, DarkSAM disrupts these processes by decoupling the object features of images in both spatial and frequency domains using a universal adversarial perturbation (UAP). In the spatial domain, it scrambles SAM’s decisions by destroying the features of the foreground and background of the image separately. In the frequency domain, it decomposes images into high-frequency components (HFC) and low-frequency components (LFC), increasing the dissimilarity in the HFC of adversarial and benign examples while maintaining consistency in their LFC. Experiments are conducted on four public segmentation datasets (ADE20K, MS-COCO, CITYSCAPES, and SA-1B), with 100 images used for UAP generation and 2,000 images for testing for each dataset. Victim models include the pre-trained SAM, HQ-SAM, and PerSAM with the ViT-B backbone.","1. The paper is well-written and easy to follow.
2. The specific design of the shadow target strategy is tailored to SAM for prompt-based segmentation, which is unique compared to adversary attacks against traditional segmentation pipelines.
3. The attacking results are impressive. All three models show very low segmentation performance across multiple datasets.","SAM is a milestone work, and a series of follow-up studies have been proposed recently. However, this paper does not provide an up-to-date review in Section 2.1 and lacks comparison in Section 4, weakening its significance. For example:
- SAM-based adversary attack:
[1] Practical Region-level Attack against Segment Anything Models, CVPR 2024.
- Other SAM-based models:  
[2] From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation, CVPR 2024.  
[3] RobustSAM: Segment Anything Robustly on Degraded Images, CVPR 2024.  
[4] Matching Anything by Segmenting Anything, CVPR 2024.  
[5] FocSAM: Delving Deeply into Focused Objects in Segmenting Anything, CVPR 2024.  
[6] ASAM: Boosting Segment Anything Model with Adversarial Tuning, CVPR 2024.  
[7] BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model, CVPR 2024.  
[8] Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively, ECCV 2024.  
[9] CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model, ECCV 2024.  
[10] Semantic-SAM: Segment and Recognize Anything at Any Granularity, ECCV 2024.","1. How does DarkSAM perform with variants of the SAM models?
2. Please include a comparison with [1] ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024).",The paper presents a limitation that DarkSAM is tailored to SAM and cannot operate on traditional segmentation models.,['Ethics review needed: Safety and security'],5,3,,Yes,3,3,3,1720426333142,,,NeurIPS.cc/2024/Conference,0o9E8AsFgW,"['NeurIPS.cc/2024/Conference/Submission18495/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879980408,[],1,,,['everyone'],0o9E8AsFgW,['NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H'],1720426333142,1730879980408,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024)
2. ""From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation"" (CVPR 2024)
3. ""RobustSAM: Segment Anything Robustly on Degraded Images"" (CVPR 2024)
4. ""Matching Anything by Segmenting Anything"" (CVPR 2024)
5. ""FocSAM: Delving Deeply into Focused Objects in Segmenting Anything"" (CVPR 2024)
6. ""ASAM: Boosting Segment Anything Model with Adversarial Tuning"" (CVPR 2024)
7. ""BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model"" (CVPR 2024)
8. ""Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively"" (ECCV 2024)
9. ""CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model"" (ECCV 2024)
10. ""Semantic-SAM: Segment and Recognize Anything at Any Granularity"" (ECCV 2024)

These citations are suggested to provide an up-to-date review of the field and to compare the results of DarkSAM with other related works.",1,"2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024",BA-SAM Scalable Bias-Mode Attention Mask for Segment Anything Model
VFmLx5UgF6,"This paper introduces DarkSAM, a prompt-free universal attack framework against the Segment Anything Model (SAM) in a quasi-black-box setting. The framework consists of a semantic decoupling-based spatial attack and a texture distortion-based frequency attack. While SAM uses geometric prompt inputs to guide segmentation of critical objects within images, DarkSAM disrupts these processes by decoupling the object features of images in both spatial and frequency domains using a universal adversarial perturbation (UAP). In the spatial domain, it scrambles SAM’s decisions by destroying the features of the foreground and background of the image separately. In the frequency domain, it decomposes images into high-frequency components (HFC) and low-frequency components (LFC), increasing the dissimilarity in the HFC of adversarial and benign examples while maintaining consistency in their LFC. Experiments are conducted on four public segmentation datasets (ADE20K, MS-COCO, CITYSCAPES, and SA-1B), with 100 images used for UAP generation and 2,000 images for testing for each dataset. Victim models include the pre-trained SAM, HQ-SAM, and PerSAM with the ViT-B backbone.","1. The paper is well-written and easy to follow.
2. The specific design of the shadow target strategy is tailored to SAM for prompt-based segmentation, which is unique compared to adversary attacks against traditional segmentation pipelines.
3. The attacking results are impressive. All three models show very low segmentation performance across multiple datasets.","SAM is a milestone work, and a series of follow-up studies have been proposed recently. However, this paper does not provide an up-to-date review in Section 2.1 and lacks comparison in Section 4, weakening its significance. For example:
- SAM-based adversary attack:
[1] Practical Region-level Attack against Segment Anything Models, CVPR 2024.
- Other SAM-based models:  
[2] From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation, CVPR 2024.  
[3] RobustSAM: Segment Anything Robustly on Degraded Images, CVPR 2024.  
[4] Matching Anything by Segmenting Anything, CVPR 2024.  
[5] FocSAM: Delving Deeply into Focused Objects in Segmenting Anything, CVPR 2024.  
[6] ASAM: Boosting Segment Anything Model with Adversarial Tuning, CVPR 2024.  
[7] BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model, CVPR 2024.  
[8] Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively, ECCV 2024.  
[9] CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model, ECCV 2024.  
[10] Semantic-SAM: Segment and Recognize Anything at Any Granularity, ECCV 2024.","1. How does DarkSAM perform with variants of the SAM models?
2. Please include a comparison with [1] ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024).",The paper presents a limitation that DarkSAM is tailored to SAM and cannot operate on traditional segmentation models.,['Ethics review needed: Safety and security'],5,3,,Yes,3,3,3,1720426333142,,,NeurIPS.cc/2024/Conference,0o9E8AsFgW,"['NeurIPS.cc/2024/Conference/Submission18495/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879980408,[],1,,,['everyone'],0o9E8AsFgW,['NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H'],1720426333142,1730879980408,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024)
2. ""From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation"" (CVPR 2024)
3. ""RobustSAM: Segment Anything Robustly on Degraded Images"" (CVPR 2024)
4. ""Matching Anything by Segmenting Anything"" (CVPR 2024)
5. ""FocSAM: Delving Deeply into Focused Objects in Segmenting Anything"" (CVPR 2024)
6. ""ASAM: Boosting Segment Anything Model with Adversarial Tuning"" (CVPR 2024)
7. ""BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model"" (CVPR 2024)
8. ""Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively"" (ECCV 2024)
9. ""CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model"" (ECCV 2024)
10. ""Semantic-SAM: Segment and Recognize Anything at Any Granularity"" (ECCV 2024)

These citations are suggested to provide an up-to-date review of the field and to compare the results of DarkSAM with other related works.",1,"2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024",Open-Vocabulary SAM Segment and Recognize Twenty-thousand Classes Interactively
VFmLx5UgF6,"This paper introduces DarkSAM, a prompt-free universal attack framework against the Segment Anything Model (SAM) in a quasi-black-box setting. The framework consists of a semantic decoupling-based spatial attack and a texture distortion-based frequency attack. While SAM uses geometric prompt inputs to guide segmentation of critical objects within images, DarkSAM disrupts these processes by decoupling the object features of images in both spatial and frequency domains using a universal adversarial perturbation (UAP). In the spatial domain, it scrambles SAM’s decisions by destroying the features of the foreground and background of the image separately. In the frequency domain, it decomposes images into high-frequency components (HFC) and low-frequency components (LFC), increasing the dissimilarity in the HFC of adversarial and benign examples while maintaining consistency in their LFC. Experiments are conducted on four public segmentation datasets (ADE20K, MS-COCO, CITYSCAPES, and SA-1B), with 100 images used for UAP generation and 2,000 images for testing for each dataset. Victim models include the pre-trained SAM, HQ-SAM, and PerSAM with the ViT-B backbone.","1. The paper is well-written and easy to follow.
2. The specific design of the shadow target strategy is tailored to SAM for prompt-based segmentation, which is unique compared to adversary attacks against traditional segmentation pipelines.
3. The attacking results are impressive. All three models show very low segmentation performance across multiple datasets.","SAM is a milestone work, and a series of follow-up studies have been proposed recently. However, this paper does not provide an up-to-date review in Section 2.1 and lacks comparison in Section 4, weakening its significance. For example:
- SAM-based adversary attack:
[1] Practical Region-level Attack against Segment Anything Models, CVPR 2024.
- Other SAM-based models:  
[2] From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation, CVPR 2024.  
[3] RobustSAM: Segment Anything Robustly on Degraded Images, CVPR 2024.  
[4] Matching Anything by Segmenting Anything, CVPR 2024.  
[5] FocSAM: Delving Deeply into Focused Objects in Segmenting Anything, CVPR 2024.  
[6] ASAM: Boosting Segment Anything Model with Adversarial Tuning, CVPR 2024.  
[7] BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model, CVPR 2024.  
[8] Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively, ECCV 2024.  
[9] CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model, ECCV 2024.  
[10] Semantic-SAM: Segment and Recognize Anything at Any Granularity, ECCV 2024.","1. How does DarkSAM perform with variants of the SAM models?
2. Please include a comparison with [1] ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024).",The paper presents a limitation that DarkSAM is tailored to SAM and cannot operate on traditional segmentation models.,['Ethics review needed: Safety and security'],5,3,,Yes,3,3,3,1720426333142,,,NeurIPS.cc/2024/Conference,0o9E8AsFgW,"['NeurIPS.cc/2024/Conference/Submission18495/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879980408,[],1,,,['everyone'],0o9E8AsFgW,['NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H'],1720426333142,1730879980408,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024)
2. ""From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation"" (CVPR 2024)
3. ""RobustSAM: Segment Anything Robustly on Degraded Images"" (CVPR 2024)
4. ""Matching Anything by Segmenting Anything"" (CVPR 2024)
5. ""FocSAM: Delving Deeply into Focused Objects in Segmenting Anything"" (CVPR 2024)
6. ""ASAM: Boosting Segment Anything Model with Adversarial Tuning"" (CVPR 2024)
7. ""BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model"" (CVPR 2024)
8. ""Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively"" (ECCV 2024)
9. ""CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model"" (ECCV 2024)
10. ""Semantic-SAM: Segment and Recognize Anything at Any Granularity"" (ECCV 2024)

These citations are suggested to provide an up-to-date review of the field and to compare the results of DarkSAM with other related works.",1,"2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024",CAT-SAM Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model
VFmLx5UgF6,"This paper introduces DarkSAM, a prompt-free universal attack framework against the Segment Anything Model (SAM) in a quasi-black-box setting. The framework consists of a semantic decoupling-based spatial attack and a texture distortion-based frequency attack. While SAM uses geometric prompt inputs to guide segmentation of critical objects within images, DarkSAM disrupts these processes by decoupling the object features of images in both spatial and frequency domains using a universal adversarial perturbation (UAP). In the spatial domain, it scrambles SAM’s decisions by destroying the features of the foreground and background of the image separately. In the frequency domain, it decomposes images into high-frequency components (HFC) and low-frequency components (LFC), increasing the dissimilarity in the HFC of adversarial and benign examples while maintaining consistency in their LFC. Experiments are conducted on four public segmentation datasets (ADE20K, MS-COCO, CITYSCAPES, and SA-1B), with 100 images used for UAP generation and 2,000 images for testing for each dataset. Victim models include the pre-trained SAM, HQ-SAM, and PerSAM with the ViT-B backbone.","1. The paper is well-written and easy to follow.
2. The specific design of the shadow target strategy is tailored to SAM for prompt-based segmentation, which is unique compared to adversary attacks against traditional segmentation pipelines.
3. The attacking results are impressive. All three models show very low segmentation performance across multiple datasets.","SAM is a milestone work, and a series of follow-up studies have been proposed recently. However, this paper does not provide an up-to-date review in Section 2.1 and lacks comparison in Section 4, weakening its significance. For example:
- SAM-based adversary attack:
[1] Practical Region-level Attack against Segment Anything Models, CVPR 2024.
- Other SAM-based models:  
[2] From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation, CVPR 2024.  
[3] RobustSAM: Segment Anything Robustly on Degraded Images, CVPR 2024.  
[4] Matching Anything by Segmenting Anything, CVPR 2024.  
[5] FocSAM: Delving Deeply into Focused Objects in Segmenting Anything, CVPR 2024.  
[6] ASAM: Boosting Segment Anything Model with Adversarial Tuning, CVPR 2024.  
[7] BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model, CVPR 2024.  
[8] Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively, ECCV 2024.  
[9] CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model, ECCV 2024.  
[10] Semantic-SAM: Segment and Recognize Anything at Any Granularity, ECCV 2024.","1. How does DarkSAM perform with variants of the SAM models?
2. Please include a comparison with [1] ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024).",The paper presents a limitation that DarkSAM is tailored to SAM and cannot operate on traditional segmentation models.,['Ethics review needed: Safety and security'],5,3,,Yes,3,3,3,1720426333142,,,NeurIPS.cc/2024/Conference,0o9E8AsFgW,"['NeurIPS.cc/2024/Conference/Submission18495/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879980408,[],1,,,['everyone'],0o9E8AsFgW,['NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H'],1720426333142,1730879980408,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission18495/Reviewer_pM4H']","Yes, the peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. ""Practical Region-level Attack against Segment Anything Models"" (CVPR 2024)
2. ""From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation"" (CVPR 2024)
3. ""RobustSAM: Segment Anything Robustly on Degraded Images"" (CVPR 2024)
4. ""Matching Anything by Segmenting Anything"" (CVPR 2024)
5. ""FocSAM: Delving Deeply into Focused Objects in Segmenting Anything"" (CVPR 2024)
6. ""ASAM: Boosting Segment Anything Model with Adversarial Tuning"" (CVPR 2024)
7. ""BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model"" (CVPR 2024)
8. ""Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively"" (ECCV 2024)
9. ""CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model"" (ECCV 2024)
10. ""Semantic-SAM: Segment and Recognize Anything at Any Granularity"" (ECCV 2024)

These citations are suggested to provide an up-to-date review of the field and to compare the results of DarkSAM with other related works.",1,"2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024",Semantic-SAM Segment and Recognize Anything at Any Granularity
1cgH9KTgYs,"This paper studies the learning of Random Utility Models (RUMs). A RUM is a probability distribution $P$ over the set of permutations over $[n]$. Fix a permutation $\pi$ and consider any subset $T \subseteq [n]$, known as a *slate*. The winner of the slate (corresponding to $\pi$) is the highest ranked element in $T$ accordint to $\pi$. We can imagine fixing a slate $T$, and consider the distribution of the winner of the slate $T$ as we draw $\pi$ from $P$. In the problem of learning RUMs, one is given a set of slates, together with the corresponding distribution of the winner of that slate. The task is to reconstruct the distribution of the winner of every possible slate.

Specifically, this paper considers the problem when the example slates given to a learning algorithm are at most a size $k$. The main result of the paper is that having access to the winning distributions of all slates of size at most $O(k)$ is necessary and sufficient for the task of learning RUMs. The same result also holds if one has only sample access to the winning distributions of all slates of this size. The authors present two algorithms that achieve the upper bound: 1) a proper algorithm, that constructs a RUM in time $n^{O(n)}$, and thereafter, given any slate, returns an approximation to the winning distribution of that slate in polynomial time 2) an improper algorithm, that does not construct a RUM, but runs in time $n^{O(\sqrt{n})}$, and thereafter, given any slate, returns an approximation to the winning distribution of that slate in time $2^{O(\sqrt{n})}$. The latter algorithm thus, in time $n^{O(\sqrt{n})}$, approximates the winning distribution of the full slate $[n]$ in $l_\infty$, which is an improvement over the previous best running time of $2^{O(n)}$ for the same task, implicit in prior work. The latter algorithm can also be adapted to yield the following guarantee: given a prespecified slate $T \subseteq [n]$, one can approximate the winning distribution of $T$ in $l_\infty$ in time polynomial in $n$, by querying slates of size at most $O(|T|/\log|T|)$. The authors also show that any algorithm that only accesses slates of size $o(\sqrt{n})$ can not successfully learn the winning distribution of the full slate. This shows that their earlier two algorithms are optimal in the maximum size of the slates they access. Finally, the authors define fractional versions of two classic problems in the intersection of combinatorics and computer science: $k$-deck and trace reconstruction. Using their techniques for learning RUMs with small slates, they are able to obtain new results for the fractional versions of both these problems (similar quantitative results would be major breakthroughs for the original problems).

The upper bounds rely crucially on results by Sherstov in 2008, and on the state-of-the-art approximation of the AND function by low degree polynomials due to Huang and Viola, 2022. The lower bound is a reduction to a lower bound on the approximation of the AND function by low-degree polynomials, due to Bogdanov et al. 2016.","This paper considers a natural constrained formulation of the problem of learning RUMs on $n$ elements: algorithms that are only given input access to slates of size at most $k$. For such algorithms, what is the smallest $k$ that is both necessary and sufficient? Satisfyingly, the authors give a compete answer to this question: $k=O(\sqrt{n})$ is necessary and sufficient. Given the pre-existing technical machinery by Sherstov, 2008, Huang and Viola, 2022 and Bogdanov et al. 2016 (albeit for problems not directly related to learning RUMs), the connections to RUMs are not too difficult to read and understand, and I found them innovative and cute. I also liked the applications of the the authors' techniques to obtain novel bounds for relaxed versions of classical hard problems in computer science. While I am not closely familiar with the literature on these problems, I imagine the fractional definitions of these problems given by the authors, together with their bounds, might be of interest to people who study these problems. Overall, I find the authors' work to be a strong and compelling study.","If I am to nitpick: while the technical narration of the problem of learning RUMs given by the authors is clear (I admit that I did not even know this problem before reading the paper, but could understand almost all of the paper), I would have liked to see a little more story-building and motivation around this problem in the introduction. I felt that the authors dived into their technical contributions rather too soon. I would also have liked to see the authors elaborate more on how their work compares to prior work by Chierichetti et al. 2021, 2023. As of now, these works, while seeming to be most relevant, are only cited in passing in the related work. Also, I feel that a few more references could be provided with respect to variations of the $k$-deck and trace reconstruction problems that have been considered in the literature.","1) The authors do show in Observation 13 that having access to slates of size exactly $k=\Theta(\sqrt{n})$ is also not sufficient for learning the RUM. Might it however be possible that such a result holds for some $k > \Theta(\sqrt{n})$? Say I am given all the slates of size exactly $\Theta(n^{0.6})$?


2) Are similar fractional versions of the $k$-deck or trace reconstruction problems known? I suggest doing a literature survey to cite some works that have considered variants of these problems -- this might make these sections more complete and situate your definitions of the problems better within the literature. For example, here are two works I found with a preliminary google search: 1) Approximate Trace Reconstruction from a Single Trace. Xi Chen, Anindya De, Chin Ho Lee, Rocco A. Servedio, Sandip Sinha, 2022 2) Approximate Trace Reconstruction. Sami Davies, Miklos Z. Racz, Cyrus Rashtchian, Benjamin G. Schiffer, 2020.",The authors have satisfactorily addressed the limitations of their work.,['No ethics review needed.'],8,3,,Yes,4,4,4,1718254632897,,,NeurIPS.cc/2024/Conference,0nSY8NiILP,"['NeurIPS.cc/2024/Conference/Submission10854/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879422037,[],1,,,['everyone'],0nSY8NiILP,['NeurIPS.cc/2024/Conference/Submission10854/Reviewer_NbMn'],1718254632897,1730879422037,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10854/Reviewer_NbMn']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two specific works:

1. ""Approximate Trace Reconstruction from a Single Trace"" by Xi Chen, Anindya De, Chin Ho Lee, Rocco A. Servedio, Sandip Sinha (2022)
2. ""Approximate Trace Reconstruction"" by Sami Davies, Miklos Z. Racz, Cyrus Rashtchian, Benjamin G. Schiffer (2020)

The reviewer suggests that citing these works could make the sections on fractional versions of the k-deck and trace reconstruction problems more complete and better situated within the literature. Additionally, the reviewer mentions that the authors should elaborate more on how their work compares to prior work by Chierichetti et al. (2021, 2023), which is currently only cited in passing in the related work section.",1,"2022, 2020, 2021, 2023",Approximate Trace Reconstruction from a Single Trace 
1cgH9KTgYs,"This paper studies the learning of Random Utility Models (RUMs). A RUM is a probability distribution $P$ over the set of permutations over $[n]$. Fix a permutation $\pi$ and consider any subset $T \subseteq [n]$, known as a *slate*. The winner of the slate (corresponding to $\pi$) is the highest ranked element in $T$ accordint to $\pi$. We can imagine fixing a slate $T$, and consider the distribution of the winner of the slate $T$ as we draw $\pi$ from $P$. In the problem of learning RUMs, one is given a set of slates, together with the corresponding distribution of the winner of that slate. The task is to reconstruct the distribution of the winner of every possible slate.

Specifically, this paper considers the problem when the example slates given to a learning algorithm are at most a size $k$. The main result of the paper is that having access to the winning distributions of all slates of size at most $O(k)$ is necessary and sufficient for the task of learning RUMs. The same result also holds if one has only sample access to the winning distributions of all slates of this size. The authors present two algorithms that achieve the upper bound: 1) a proper algorithm, that constructs a RUM in time $n^{O(n)}$, and thereafter, given any slate, returns an approximation to the winning distribution of that slate in polynomial time 2) an improper algorithm, that does not construct a RUM, but runs in time $n^{O(\sqrt{n})}$, and thereafter, given any slate, returns an approximation to the winning distribution of that slate in time $2^{O(\sqrt{n})}$. The latter algorithm thus, in time $n^{O(\sqrt{n})}$, approximates the winning distribution of the full slate $[n]$ in $l_\infty$, which is an improvement over the previous best running time of $2^{O(n)}$ for the same task, implicit in prior work. The latter algorithm can also be adapted to yield the following guarantee: given a prespecified slate $T \subseteq [n]$, one can approximate the winning distribution of $T$ in $l_\infty$ in time polynomial in $n$, by querying slates of size at most $O(|T|/\log|T|)$. The authors also show that any algorithm that only accesses slates of size $o(\sqrt{n})$ can not successfully learn the winning distribution of the full slate. This shows that their earlier two algorithms are optimal in the maximum size of the slates they access. Finally, the authors define fractional versions of two classic problems in the intersection of combinatorics and computer science: $k$-deck and trace reconstruction. Using their techniques for learning RUMs with small slates, they are able to obtain new results for the fractional versions of both these problems (similar quantitative results would be major breakthroughs for the original problems).

The upper bounds rely crucially on results by Sherstov in 2008, and on the state-of-the-art approximation of the AND function by low degree polynomials due to Huang and Viola, 2022. The lower bound is a reduction to a lower bound on the approximation of the AND function by low-degree polynomials, due to Bogdanov et al. 2016.","This paper considers a natural constrained formulation of the problem of learning RUMs on $n$ elements: algorithms that are only given input access to slates of size at most $k$. For such algorithms, what is the smallest $k$ that is both necessary and sufficient? Satisfyingly, the authors give a compete answer to this question: $k=O(\sqrt{n})$ is necessary and sufficient. Given the pre-existing technical machinery by Sherstov, 2008, Huang and Viola, 2022 and Bogdanov et al. 2016 (albeit for problems not directly related to learning RUMs), the connections to RUMs are not too difficult to read and understand, and I found them innovative and cute. I also liked the applications of the the authors' techniques to obtain novel bounds for relaxed versions of classical hard problems in computer science. While I am not closely familiar with the literature on these problems, I imagine the fractional definitions of these problems given by the authors, together with their bounds, might be of interest to people who study these problems. Overall, I find the authors' work to be a strong and compelling study.","If I am to nitpick: while the technical narration of the problem of learning RUMs given by the authors is clear (I admit that I did not even know this problem before reading the paper, but could understand almost all of the paper), I would have liked to see a little more story-building and motivation around this problem in the introduction. I felt that the authors dived into their technical contributions rather too soon. I would also have liked to see the authors elaborate more on how their work compares to prior work by Chierichetti et al. 2021, 2023. As of now, these works, while seeming to be most relevant, are only cited in passing in the related work. Also, I feel that a few more references could be provided with respect to variations of the $k$-deck and trace reconstruction problems that have been considered in the literature.","1) The authors do show in Observation 13 that having access to slates of size exactly $k=\Theta(\sqrt{n})$ is also not sufficient for learning the RUM. Might it however be possible that such a result holds for some $k > \Theta(\sqrt{n})$? Say I am given all the slates of size exactly $\Theta(n^{0.6})$?


2) Are similar fractional versions of the $k$-deck or trace reconstruction problems known? I suggest doing a literature survey to cite some works that have considered variants of these problems -- this might make these sections more complete and situate your definitions of the problems better within the literature. For example, here are two works I found with a preliminary google search: 1) Approximate Trace Reconstruction from a Single Trace. Xi Chen, Anindya De, Chin Ho Lee, Rocco A. Servedio, Sandip Sinha, 2022 2) Approximate Trace Reconstruction. Sami Davies, Miklos Z. Racz, Cyrus Rashtchian, Benjamin G. Schiffer, 2020.",The authors have satisfactorily addressed the limitations of their work.,['No ethics review needed.'],8,3,,Yes,4,4,4,1718254632897,,,NeurIPS.cc/2024/Conference,0nSY8NiILP,"['NeurIPS.cc/2024/Conference/Submission10854/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879422037,[],1,,,['everyone'],0nSY8NiILP,['NeurIPS.cc/2024/Conference/Submission10854/Reviewer_NbMn'],1718254632897,1730879422037,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10854/Reviewer_NbMn']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions two specific works:

1. ""Approximate Trace Reconstruction from a Single Trace"" by Xi Chen, Anindya De, Chin Ho Lee, Rocco A. Servedio, Sandip Sinha (2022)
2. ""Approximate Trace Reconstruction"" by Sami Davies, Miklos Z. Racz, Cyrus Rashtchian, Benjamin G. Schiffer (2020)

The reviewer suggests that citing these works could make the sections on fractional versions of the k-deck and trace reconstruction problems more complete and better situated within the literature. Additionally, the reviewer mentions that the authors should elaborate more on how their work compares to prior work by Chierichetti et al. (2021, 2023), which is currently only cited in passing in the related work section.",1,"2022, 2020, 2021, 2023",Approximate Trace Reconstruction
eSPgMZjt5m,"This paper demonstrates a quantized diffusion model called BitFusion, which successfully quantize the Stable Diffusion (SD) v1.5 to 1.99 bits with 7.9x smaller size.  They first analyse the SD model in a layer perspective and assign the optimal bit based on the analysis. Then they propose a training pipeline to perform quantization-aware training (QAT) based on the analysis result. The experiment result shows that the quantized diffusion model BitFusion outperforms the full-precision SD v1.5 model.","1. The result is significant. BitFusion successfully compressed the SD model while maintaining its performance.

2. The authors successfully combine novel quantization techniques and existing quantization techniques, showing an effective way to quantize SD model to extreme low bit.

3. The paper provides valuable observations about different layers' behaviour under quantization.","1. The analysis and experiment according to scaling factor initialization is not comprehensive. The authors propose alternating optimization for scaling factor initialization which is based on the MSE between quantized weight and full-precision weight. However, quantized weight initialization is well-studied and there are existing weight initialization technique that optimize the same objective. Nevertheless, there are some advanced initialization technique like adaround [1]. Those techniques are adapted by other Diffusion Model quantization research [2]. An experiment to compare the alternating Opt. and those initialization techniques is necessary.

2. Stable Diffusion 1.5 is no longer the SOTA in Diffusion text-to-image model. Diffusion transformer (DiT) is the new trend in diffusion model research. The conclusion on UNet-based diffusion model like SD 1.5 might not be precise for the DiT diffusion model.

3. FID is widely adapted by most of the diffusion model quantization research. Although the authors provide human evaluation and justify that FID is not accurate compared with human evaluation, the FID comparison between BitFusion and other baseline models should be included in the main body of the paper.

4. In this paper [3], the authors propose a 1.58-bit LLM quantization approach comparable to Bit Fusion at model size reduction. However, they can perform activation quantization to 8-bit while Bit Fusion doesn't. 


[1] Nagel, Markus, et al. ""Up or down? adaptive rounding for post-training quantization."" International Conference on Machine Learning. PMLR, 2020.

[2] Li, Xiuyu, et al. ""Q-diffusion: Quantizing diffusion models."" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.

[3] Ma, Shuming, et al. ""The era of 1-bit llms: All large language models are in 1.58 bits."" arXiv preprint arXiv:2402.17764 (2024).",,"The authors honestly point out their limitation: not quantizing VAE and text encoder and not quantizing activation. For the first limitation, it is quite common that diffusion model quantization research doesn't quantize VAE and text encoder according to the literature. But for the second limitation, the authors leave it for future work and doesn't address it. Activation quantization is recommended, as the fact that activation usually has higher quantization difficulty.",['No ethics review needed.'],5,5,,Yes,2,3,2,1720834575284,,,NeurIPS.cc/2024/Conference,0m19blQT6y,"['NeurIPS.cc/2024/Conference/Submission5489/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879005104,[],3,,,['everyone'],0m19blQT6y,['NeurIPS.cc/2024/Conference/Submission5489/Reviewer_tjXw'],1720834575284,1730879005104,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5489/Reviewer_tjXw']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions three specific references ([1], [2], and [3]) and encourages the authors to compare their work with these existing research, particularly in terms of quantization techniques and results. 

Reference [1] is ""Up or down? adaptive rounding for post-training quantization"" by Nagel et al., which proposes an adaptive rounding technique for post-training quantization. The reviewer suggests that the authors should experiment with this technique and compare it with their proposed alternating optimization method.

Reference [2] is ""Q-diffusion: Quantizing diffusion models"" by Li et al., which is another work on quantizing diffusion models. The reviewer mentions that this work uses advanced initialization techniques like adaround, which the authors of the paper should consider.

Reference [3] is ""The era of 1-bit llms: All large language models are in 1.58 bits"" by Ma et al., which proposes a 1.58-bit quantization approach for large language models. The reviewer points out that this work achieves comparable model size reduction to BitFusion but also performs activation quantization to 8-bit, which BitFusion does not. The reviewer implies that the authors should consider addressing this limitation in their work.",1,,Up or down adaptive rounding for post-training quantization
eSPgMZjt5m,"This paper demonstrates a quantized diffusion model called BitFusion, which successfully quantize the Stable Diffusion (SD) v1.5 to 1.99 bits with 7.9x smaller size.  They first analyse the SD model in a layer perspective and assign the optimal bit based on the analysis. Then they propose a training pipeline to perform quantization-aware training (QAT) based on the analysis result. The experiment result shows that the quantized diffusion model BitFusion outperforms the full-precision SD v1.5 model.","1. The result is significant. BitFusion successfully compressed the SD model while maintaining its performance.

2. The authors successfully combine novel quantization techniques and existing quantization techniques, showing an effective way to quantize SD model to extreme low bit.

3. The paper provides valuable observations about different layers' behaviour under quantization.","1. The analysis and experiment according to scaling factor initialization is not comprehensive. The authors propose alternating optimization for scaling factor initialization which is based on the MSE between quantized weight and full-precision weight. However, quantized weight initialization is well-studied and there are existing weight initialization technique that optimize the same objective. Nevertheless, there are some advanced initialization technique like adaround [1]. Those techniques are adapted by other Diffusion Model quantization research [2]. An experiment to compare the alternating Opt. and those initialization techniques is necessary.

2. Stable Diffusion 1.5 is no longer the SOTA in Diffusion text-to-image model. Diffusion transformer (DiT) is the new trend in diffusion model research. The conclusion on UNet-based diffusion model like SD 1.5 might not be precise for the DiT diffusion model.

3. FID is widely adapted by most of the diffusion model quantization research. Although the authors provide human evaluation and justify that FID is not accurate compared with human evaluation, the FID comparison between BitFusion and other baseline models should be included in the main body of the paper.

4. In this paper [3], the authors propose a 1.58-bit LLM quantization approach comparable to Bit Fusion at model size reduction. However, they can perform activation quantization to 8-bit while Bit Fusion doesn't. 


[1] Nagel, Markus, et al. ""Up or down? adaptive rounding for post-training quantization."" International Conference on Machine Learning. PMLR, 2020.

[2] Li, Xiuyu, et al. ""Q-diffusion: Quantizing diffusion models."" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.

[3] Ma, Shuming, et al. ""The era of 1-bit llms: All large language models are in 1.58 bits."" arXiv preprint arXiv:2402.17764 (2024).",,"The authors honestly point out their limitation: not quantizing VAE and text encoder and not quantizing activation. For the first limitation, it is quite common that diffusion model quantization research doesn't quantize VAE and text encoder according to the literature. But for the second limitation, the authors leave it for future work and doesn't address it. Activation quantization is recommended, as the fact that activation usually has higher quantization difficulty.",['No ethics review needed.'],5,5,,Yes,2,3,2,1720834575284,,,NeurIPS.cc/2024/Conference,0m19blQT6y,"['NeurIPS.cc/2024/Conference/Submission5489/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879005104,[],3,,,['everyone'],0m19blQT6y,['NeurIPS.cc/2024/Conference/Submission5489/Reviewer_tjXw'],1720834575284,1730879005104,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5489/Reviewer_tjXw']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions three specific references ([1], [2], and [3]) and encourages the authors to compare their work with these existing research, particularly in terms of quantization techniques and results. 

Reference [1] is ""Up or down? adaptive rounding for post-training quantization"" by Nagel et al., which proposes an adaptive rounding technique for post-training quantization. The reviewer suggests that the authors should experiment with this technique and compare it with their proposed alternating optimization method.

Reference [2] is ""Q-diffusion: Quantizing diffusion models"" by Li et al., which is another work on quantizing diffusion models. The reviewer mentions that this work uses advanced initialization techniques like adaround, which the authors of the paper should consider.

Reference [3] is ""The era of 1-bit llms: All large language models are in 1.58 bits"" by Ma et al., which proposes a 1.58-bit quantization approach for large language models. The reviewer points out that this work achieves comparable model size reduction to BitFusion but also performs activation quantization to 8-bit, which BitFusion does not. The reviewer implies that the authors should consider addressing this limitation in their work.",1,,Q-diffusion Quantizing diffusion models
qnqaCC2LEp,"This paper proposes a novel weight quantization method called ""BitsFusion"" for compressing the Stable Diffusion v1.5 model. The primary goal is to address the issue of large model sizes, which hinder the deployment of diffusion models on resource-constrained devices. The BitsFusion framework quantizes the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a 7.9× reduction in model size while improving image generation quality. The approach involves mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline. Extensive experiments on various benchmark datasets demonstrate that the quantized model outperforms the original full-precision model in terms of generation quality and text-image alignment. My detailed comments are as follows.","1. The BitsFusion framework is an innovative approach to compressing the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a significant reduction in model size while enhancing image quality by using mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline.
2. The paper provides a thorough analysis of quantization errors and develops a mixed-precision strategy based on this analysis, which contributes to the theoretical understanding of low-bit quantization for large-scale diffusion models.
3. The results demonstrate the effectiveness of the proposed framework. The quantized model consistently outperforms the original full-precision model across various metrics, including CLIP score, TIFA score, and GenEval score. The model's ability to achieve a 7.9× reduction in size while maintaining or improving performance highlights its practical potential for deployment on resource-constrained devices.
4. The manuscript is well-written and easy to understand, with clear explanations of the methodology and experimental procedures. Sufficient experimental details are provided, ensuring that the results can be reproduced by other researchers, which enhances the paper's credibility and utility.","1. The two-stage training pipeline, while effective, may introduce additional computational complexity and training time, which could be a drawback for some applications. However, the paper does not explicitly discuss the additional computational complexity and training time it introduces. To provide a more comprehensive evaluation of this method, it is recommended that the authors discuss the potential additional computational overhead introduced by the two-stage training pipeline and its impact on training time.
2. The study demonstrates that there is a high correlation between certain metrics, such as MSE and PSNR, and uses these correlations to validate the effectiveness of their quantization methods. However, correlation does not imply causation. The study does not delve into why these metrics are correlated or explain the intrinsic mechanisms that cause certain layers to be more sensitive to quantization (e.g., why quantization affects some layers more than others, and what intrinsic properties of these layers make them more prone to quantization-induced errors). Understanding these mechanisms is crucial for improving the quantization process, as knowing why certain layers are sensitive can lead to more targeted and effective quantization strategies.
3. The claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is a significant overgeneralization. This assertion, based on specific experimental settings and datasets, may not fully represent the diversity encountered in real-world applications. Primarily, the evaluation on the MS-COCO 2014 validation set, though extensive, does not cover a wide variety of prompts, limiting the assessment of the model's ability to handle different types of inputs (e.g., complex scenes, abstract concepts, specific artistic styles). Additionally, the tests do not include various real-world conditions such as different lighting, backgrounds, or object complexities. Therefore, the claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is premature. A more robust evaluation including varied datasets, prompts, and real-world conditions, such as [A-E],  is necessary to substantiate such a broad claim.
4. The discussion regarding model compression techniques is insufficient. It would be better for the authors to present more model quantization methods [F-J].

[A] Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations. International Journal of Computer Vision. IJCV. 2017.
[B]  Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models. ICCV. 2015.
[C]  The Open Images Dataset V4: Unified Image Classification, Object Detection, and Visual Relationship Detection at Scale. IJCV. 2020.
[D]  Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts. CVPR. 2021.
[E]  Scene Parsing through ADE20K Dataset. CVPR. 2017.
[F] Binary quantized network training with sharpness-aware minimization. Scientific Computing 2023.
[G] Network Quantization with Element-Wise Gradient Scaling. CVPR 2021.
[H] Single-path bit sharing for automatic loss-aware model compression. TPAMI 2023.
[I] Generative Data Free Model Quantization with Knowledge Matching for Classification. TCSVT 2023.",Please check the weakness section.,,['No ethics review needed.'],6,4,,Yes,3,4,3,1720884527967,,,NeurIPS.cc/2024/Conference,0m19blQT6y,"['NeurIPS.cc/2024/Conference/Submission5489/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879004998,[],4,,,['everyone'],0m19blQT6y,['NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG'],1720884527967,1730879004998,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. In the weaknesses section, the reviewer mentions several papers and datasets, including:

* Visual Genome (2017)
* Flickr30k Entities (2015)
* The Open Images Dataset V4 (2020)
* Conceptual 12M (2021)
* Scene Parsing through ADE20K Dataset (2017)
* Binary quantized network training with sharpness-aware minimization (2023)
* Network Quantization with Element-Wise Gradient Scaling (2021)
* Single-path bit sharing for automatic loss-aware model compression (2023)
* Generative Data Free Model Quantization with Knowledge Matching for Classification (2023)

The reviewer suggests that the authors should consider citing these papers and using these datasets to improve their evaluation and discussion of model compression techniques.",1,"2017, 2015, 2020, 2021, 2017, 2023, 2021, 2023, 2023",Visual Genome 
qnqaCC2LEp,"This paper proposes a novel weight quantization method called ""BitsFusion"" for compressing the Stable Diffusion v1.5 model. The primary goal is to address the issue of large model sizes, which hinder the deployment of diffusion models on resource-constrained devices. The BitsFusion framework quantizes the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a 7.9× reduction in model size while improving image generation quality. The approach involves mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline. Extensive experiments on various benchmark datasets demonstrate that the quantized model outperforms the original full-precision model in terms of generation quality and text-image alignment. My detailed comments are as follows.","1. The BitsFusion framework is an innovative approach to compressing the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a significant reduction in model size while enhancing image quality by using mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline.
2. The paper provides a thorough analysis of quantization errors and develops a mixed-precision strategy based on this analysis, which contributes to the theoretical understanding of low-bit quantization for large-scale diffusion models.
3. The results demonstrate the effectiveness of the proposed framework. The quantized model consistently outperforms the original full-precision model across various metrics, including CLIP score, TIFA score, and GenEval score. The model's ability to achieve a 7.9× reduction in size while maintaining or improving performance highlights its practical potential for deployment on resource-constrained devices.
4. The manuscript is well-written and easy to understand, with clear explanations of the methodology and experimental procedures. Sufficient experimental details are provided, ensuring that the results can be reproduced by other researchers, which enhances the paper's credibility and utility.","1. The two-stage training pipeline, while effective, may introduce additional computational complexity and training time, which could be a drawback for some applications. However, the paper does not explicitly discuss the additional computational complexity and training time it introduces. To provide a more comprehensive evaluation of this method, it is recommended that the authors discuss the potential additional computational overhead introduced by the two-stage training pipeline and its impact on training time.
2. The study demonstrates that there is a high correlation between certain metrics, such as MSE and PSNR, and uses these correlations to validate the effectiveness of their quantization methods. However, correlation does not imply causation. The study does not delve into why these metrics are correlated or explain the intrinsic mechanisms that cause certain layers to be more sensitive to quantization (e.g., why quantization affects some layers more than others, and what intrinsic properties of these layers make them more prone to quantization-induced errors). Understanding these mechanisms is crucial for improving the quantization process, as knowing why certain layers are sensitive can lead to more targeted and effective quantization strategies.
3. The claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is a significant overgeneralization. This assertion, based on specific experimental settings and datasets, may not fully represent the diversity encountered in real-world applications. Primarily, the evaluation on the MS-COCO 2014 validation set, though extensive, does not cover a wide variety of prompts, limiting the assessment of the model's ability to handle different types of inputs (e.g., complex scenes, abstract concepts, specific artistic styles). Additionally, the tests do not include various real-world conditions such as different lighting, backgrounds, or object complexities. Therefore, the claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is premature. A more robust evaluation including varied datasets, prompts, and real-world conditions, such as [A-E],  is necessary to substantiate such a broad claim.
4. The discussion regarding model compression techniques is insufficient. It would be better for the authors to present more model quantization methods [F-J].

[A] Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations. International Journal of Computer Vision. IJCV. 2017.
[B]  Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models. ICCV. 2015.
[C]  The Open Images Dataset V4: Unified Image Classification, Object Detection, and Visual Relationship Detection at Scale. IJCV. 2020.
[D]  Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts. CVPR. 2021.
[E]  Scene Parsing through ADE20K Dataset. CVPR. 2017.
[F] Binary quantized network training with sharpness-aware minimization. Scientific Computing 2023.
[G] Network Quantization with Element-Wise Gradient Scaling. CVPR 2021.
[H] Single-path bit sharing for automatic loss-aware model compression. TPAMI 2023.
[I] Generative Data Free Model Quantization with Knowledge Matching for Classification. TCSVT 2023.",Please check the weakness section.,,['No ethics review needed.'],6,4,,Yes,3,4,3,1720884527967,,,NeurIPS.cc/2024/Conference,0m19blQT6y,"['NeurIPS.cc/2024/Conference/Submission5489/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879004998,[],4,,,['everyone'],0m19blQT6y,['NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG'],1720884527967,1730879004998,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. In the weaknesses section, the reviewer mentions several papers and datasets, including:

* Visual Genome (2017)
* Flickr30k Entities (2015)
* The Open Images Dataset V4 (2020)
* Conceptual 12M (2021)
* Scene Parsing through ADE20K Dataset (2017)
* Binary quantized network training with sharpness-aware minimization (2023)
* Network Quantization with Element-Wise Gradient Scaling (2021)
* Single-path bit sharing for automatic loss-aware model compression (2023)
* Generative Data Free Model Quantization with Knowledge Matching for Classification (2023)

The reviewer suggests that the authors should consider citing these papers and using these datasets to improve their evaluation and discussion of model compression techniques.",1,"2017, 2015, 2020, 2021, 2017, 2023, 2021, 2023, 2023",Flickr30k Entities 
qnqaCC2LEp,"This paper proposes a novel weight quantization method called ""BitsFusion"" for compressing the Stable Diffusion v1.5 model. The primary goal is to address the issue of large model sizes, which hinder the deployment of diffusion models on resource-constrained devices. The BitsFusion framework quantizes the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a 7.9× reduction in model size while improving image generation quality. The approach involves mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline. Extensive experiments on various benchmark datasets demonstrate that the quantized model outperforms the original full-precision model in terms of generation quality and text-image alignment. My detailed comments are as follows.","1. The BitsFusion framework is an innovative approach to compressing the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a significant reduction in model size while enhancing image quality by using mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline.
2. The paper provides a thorough analysis of quantization errors and develops a mixed-precision strategy based on this analysis, which contributes to the theoretical understanding of low-bit quantization for large-scale diffusion models.
3. The results demonstrate the effectiveness of the proposed framework. The quantized model consistently outperforms the original full-precision model across various metrics, including CLIP score, TIFA score, and GenEval score. The model's ability to achieve a 7.9× reduction in size while maintaining or improving performance highlights its practical potential for deployment on resource-constrained devices.
4. The manuscript is well-written and easy to understand, with clear explanations of the methodology and experimental procedures. Sufficient experimental details are provided, ensuring that the results can be reproduced by other researchers, which enhances the paper's credibility and utility.","1. The two-stage training pipeline, while effective, may introduce additional computational complexity and training time, which could be a drawback for some applications. However, the paper does not explicitly discuss the additional computational complexity and training time it introduces. To provide a more comprehensive evaluation of this method, it is recommended that the authors discuss the potential additional computational overhead introduced by the two-stage training pipeline and its impact on training time.
2. The study demonstrates that there is a high correlation between certain metrics, such as MSE and PSNR, and uses these correlations to validate the effectiveness of their quantization methods. However, correlation does not imply causation. The study does not delve into why these metrics are correlated or explain the intrinsic mechanisms that cause certain layers to be more sensitive to quantization (e.g., why quantization affects some layers more than others, and what intrinsic properties of these layers make them more prone to quantization-induced errors). Understanding these mechanisms is crucial for improving the quantization process, as knowing why certain layers are sensitive can lead to more targeted and effective quantization strategies.
3. The claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is a significant overgeneralization. This assertion, based on specific experimental settings and datasets, may not fully represent the diversity encountered in real-world applications. Primarily, the evaluation on the MS-COCO 2014 validation set, though extensive, does not cover a wide variety of prompts, limiting the assessment of the model's ability to handle different types of inputs (e.g., complex scenes, abstract concepts, specific artistic styles). Additionally, the tests do not include various real-world conditions such as different lighting, backgrounds, or object complexities. Therefore, the claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is premature. A more robust evaluation including varied datasets, prompts, and real-world conditions, such as [A-E],  is necessary to substantiate such a broad claim.
4. The discussion regarding model compression techniques is insufficient. It would be better for the authors to present more model quantization methods [F-J].

[A] Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations. International Journal of Computer Vision. IJCV. 2017.
[B]  Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models. ICCV. 2015.
[C]  The Open Images Dataset V4: Unified Image Classification, Object Detection, and Visual Relationship Detection at Scale. IJCV. 2020.
[D]  Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts. CVPR. 2021.
[E]  Scene Parsing through ADE20K Dataset. CVPR. 2017.
[F] Binary quantized network training with sharpness-aware minimization. Scientific Computing 2023.
[G] Network Quantization with Element-Wise Gradient Scaling. CVPR 2021.
[H] Single-path bit sharing for automatic loss-aware model compression. TPAMI 2023.
[I] Generative Data Free Model Quantization with Knowledge Matching for Classification. TCSVT 2023.",Please check the weakness section.,,['No ethics review needed.'],6,4,,Yes,3,4,3,1720884527967,,,NeurIPS.cc/2024/Conference,0m19blQT6y,"['NeurIPS.cc/2024/Conference/Submission5489/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879004998,[],4,,,['everyone'],0m19blQT6y,['NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG'],1720884527967,1730879004998,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. In the weaknesses section, the reviewer mentions several papers and datasets, including:

* Visual Genome (2017)
* Flickr30k Entities (2015)
* The Open Images Dataset V4 (2020)
* Conceptual 12M (2021)
* Scene Parsing through ADE20K Dataset (2017)
* Binary quantized network training with sharpness-aware minimization (2023)
* Network Quantization with Element-Wise Gradient Scaling (2021)
* Single-path bit sharing for automatic loss-aware model compression (2023)
* Generative Data Free Model Quantization with Knowledge Matching for Classification (2023)

The reviewer suggests that the authors should consider citing these papers and using these datasets to improve their evaluation and discussion of model compression techniques.",1,"2017, 2015, 2020, 2021, 2017, 2023, 2021, 2023, 2023",The Open Images Dataset V4 
qnqaCC2LEp,"This paper proposes a novel weight quantization method called ""BitsFusion"" for compressing the Stable Diffusion v1.5 model. The primary goal is to address the issue of large model sizes, which hinder the deployment of diffusion models on resource-constrained devices. The BitsFusion framework quantizes the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a 7.9× reduction in model size while improving image generation quality. The approach involves mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline. Extensive experiments on various benchmark datasets demonstrate that the quantized model outperforms the original full-precision model in terms of generation quality and text-image alignment. My detailed comments are as follows.","1. The BitsFusion framework is an innovative approach to compressing the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a significant reduction in model size while enhancing image quality by using mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline.
2. The paper provides a thorough analysis of quantization errors and develops a mixed-precision strategy based on this analysis, which contributes to the theoretical understanding of low-bit quantization for large-scale diffusion models.
3. The results demonstrate the effectiveness of the proposed framework. The quantized model consistently outperforms the original full-precision model across various metrics, including CLIP score, TIFA score, and GenEval score. The model's ability to achieve a 7.9× reduction in size while maintaining or improving performance highlights its practical potential for deployment on resource-constrained devices.
4. The manuscript is well-written and easy to understand, with clear explanations of the methodology and experimental procedures. Sufficient experimental details are provided, ensuring that the results can be reproduced by other researchers, which enhances the paper's credibility and utility.","1. The two-stage training pipeline, while effective, may introduce additional computational complexity and training time, which could be a drawback for some applications. However, the paper does not explicitly discuss the additional computational complexity and training time it introduces. To provide a more comprehensive evaluation of this method, it is recommended that the authors discuss the potential additional computational overhead introduced by the two-stage training pipeline and its impact on training time.
2. The study demonstrates that there is a high correlation between certain metrics, such as MSE and PSNR, and uses these correlations to validate the effectiveness of their quantization methods. However, correlation does not imply causation. The study does not delve into why these metrics are correlated or explain the intrinsic mechanisms that cause certain layers to be more sensitive to quantization (e.g., why quantization affects some layers more than others, and what intrinsic properties of these layers make them more prone to quantization-induced errors). Understanding these mechanisms is crucial for improving the quantization process, as knowing why certain layers are sensitive can lead to more targeted and effective quantization strategies.
3. The claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is a significant overgeneralization. This assertion, based on specific experimental settings and datasets, may not fully represent the diversity encountered in real-world applications. Primarily, the evaluation on the MS-COCO 2014 validation set, though extensive, does not cover a wide variety of prompts, limiting the assessment of the model's ability to handle different types of inputs (e.g., complex scenes, abstract concepts, specific artistic styles). Additionally, the tests do not include various real-world conditions such as different lighting, backgrounds, or object complexities. Therefore, the claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is premature. A more robust evaluation including varied datasets, prompts, and real-world conditions, such as [A-E],  is necessary to substantiate such a broad claim.
4. The discussion regarding model compression techniques is insufficient. It would be better for the authors to present more model quantization methods [F-J].

[A] Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations. International Journal of Computer Vision. IJCV. 2017.
[B]  Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models. ICCV. 2015.
[C]  The Open Images Dataset V4: Unified Image Classification, Object Detection, and Visual Relationship Detection at Scale. IJCV. 2020.
[D]  Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts. CVPR. 2021.
[E]  Scene Parsing through ADE20K Dataset. CVPR. 2017.
[F] Binary quantized network training with sharpness-aware minimization. Scientific Computing 2023.
[G] Network Quantization with Element-Wise Gradient Scaling. CVPR 2021.
[H] Single-path bit sharing for automatic loss-aware model compression. TPAMI 2023.
[I] Generative Data Free Model Quantization with Knowledge Matching for Classification. TCSVT 2023.",Please check the weakness section.,,['No ethics review needed.'],6,4,,Yes,3,4,3,1720884527967,,,NeurIPS.cc/2024/Conference,0m19blQT6y,"['NeurIPS.cc/2024/Conference/Submission5489/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879004998,[],4,,,['everyone'],0m19blQT6y,['NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG'],1720884527967,1730879004998,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. In the weaknesses section, the reviewer mentions several papers and datasets, including:

* Visual Genome (2017)
* Flickr30k Entities (2015)
* The Open Images Dataset V4 (2020)
* Conceptual 12M (2021)
* Scene Parsing through ADE20K Dataset (2017)
* Binary quantized network training with sharpness-aware minimization (2023)
* Network Quantization with Element-Wise Gradient Scaling (2021)
* Single-path bit sharing for automatic loss-aware model compression (2023)
* Generative Data Free Model Quantization with Knowledge Matching for Classification (2023)

The reviewer suggests that the authors should consider citing these papers and using these datasets to improve their evaluation and discussion of model compression techniques.",1,"2017, 2015, 2020, 2021, 2017, 2023, 2021, 2023, 2023",Conceptual 12M 
qnqaCC2LEp,"This paper proposes a novel weight quantization method called ""BitsFusion"" for compressing the Stable Diffusion v1.5 model. The primary goal is to address the issue of large model sizes, which hinder the deployment of diffusion models on resource-constrained devices. The BitsFusion framework quantizes the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a 7.9× reduction in model size while improving image generation quality. The approach involves mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline. Extensive experiments on various benchmark datasets demonstrate that the quantized model outperforms the original full-precision model in terms of generation quality and text-image alignment. My detailed comments are as follows.","1. The BitsFusion framework is an innovative approach to compressing the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a significant reduction in model size while enhancing image quality by using mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline.
2. The paper provides a thorough analysis of quantization errors and develops a mixed-precision strategy based on this analysis, which contributes to the theoretical understanding of low-bit quantization for large-scale diffusion models.
3. The results demonstrate the effectiveness of the proposed framework. The quantized model consistently outperforms the original full-precision model across various metrics, including CLIP score, TIFA score, and GenEval score. The model's ability to achieve a 7.9× reduction in size while maintaining or improving performance highlights its practical potential for deployment on resource-constrained devices.
4. The manuscript is well-written and easy to understand, with clear explanations of the methodology and experimental procedures. Sufficient experimental details are provided, ensuring that the results can be reproduced by other researchers, which enhances the paper's credibility and utility.","1. The two-stage training pipeline, while effective, may introduce additional computational complexity and training time, which could be a drawback for some applications. However, the paper does not explicitly discuss the additional computational complexity and training time it introduces. To provide a more comprehensive evaluation of this method, it is recommended that the authors discuss the potential additional computational overhead introduced by the two-stage training pipeline and its impact on training time.
2. The study demonstrates that there is a high correlation between certain metrics, such as MSE and PSNR, and uses these correlations to validate the effectiveness of their quantization methods. However, correlation does not imply causation. The study does not delve into why these metrics are correlated or explain the intrinsic mechanisms that cause certain layers to be more sensitive to quantization (e.g., why quantization affects some layers more than others, and what intrinsic properties of these layers make them more prone to quantization-induced errors). Understanding these mechanisms is crucial for improving the quantization process, as knowing why certain layers are sensitive can lead to more targeted and effective quantization strategies.
3. The claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is a significant overgeneralization. This assertion, based on specific experimental settings and datasets, may not fully represent the diversity encountered in real-world applications. Primarily, the evaluation on the MS-COCO 2014 validation set, though extensive, does not cover a wide variety of prompts, limiting the assessment of the model's ability to handle different types of inputs (e.g., complex scenes, abstract concepts, specific artistic styles). Additionally, the tests do not include various real-world conditions such as different lighting, backgrounds, or object complexities. Therefore, the claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is premature. A more robust evaluation including varied datasets, prompts, and real-world conditions, such as [A-E],  is necessary to substantiate such a broad claim.
4. The discussion regarding model compression techniques is insufficient. It would be better for the authors to present more model quantization methods [F-J].

[A] Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations. International Journal of Computer Vision. IJCV. 2017.
[B]  Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models. ICCV. 2015.
[C]  The Open Images Dataset V4: Unified Image Classification, Object Detection, and Visual Relationship Detection at Scale. IJCV. 2020.
[D]  Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts. CVPR. 2021.
[E]  Scene Parsing through ADE20K Dataset. CVPR. 2017.
[F] Binary quantized network training with sharpness-aware minimization. Scientific Computing 2023.
[G] Network Quantization with Element-Wise Gradient Scaling. CVPR 2021.
[H] Single-path bit sharing for automatic loss-aware model compression. TPAMI 2023.
[I] Generative Data Free Model Quantization with Knowledge Matching for Classification. TCSVT 2023.",Please check the weakness section.,,['No ethics review needed.'],6,4,,Yes,3,4,3,1720884527967,,,NeurIPS.cc/2024/Conference,0m19blQT6y,"['NeurIPS.cc/2024/Conference/Submission5489/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879004998,[],4,,,['everyone'],0m19blQT6y,['NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG'],1720884527967,1730879004998,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. In the weaknesses section, the reviewer mentions several papers and datasets, including:

* Visual Genome (2017)
* Flickr30k Entities (2015)
* The Open Images Dataset V4 (2020)
* Conceptual 12M (2021)
* Scene Parsing through ADE20K Dataset (2017)
* Binary quantized network training with sharpness-aware minimization (2023)
* Network Quantization with Element-Wise Gradient Scaling (2021)
* Single-path bit sharing for automatic loss-aware model compression (2023)
* Generative Data Free Model Quantization with Knowledge Matching for Classification (2023)

The reviewer suggests that the authors should consider citing these papers and using these datasets to improve their evaluation and discussion of model compression techniques.",1,"2017, 2015, 2020, 2021, 2017, 2023, 2021, 2023, 2023",Scene Parsing through ADE20K Dataset 
qnqaCC2LEp,"This paper proposes a novel weight quantization method called ""BitsFusion"" for compressing the Stable Diffusion v1.5 model. The primary goal is to address the issue of large model sizes, which hinder the deployment of diffusion models on resource-constrained devices. The BitsFusion framework quantizes the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a 7.9× reduction in model size while improving image generation quality. The approach involves mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline. Extensive experiments on various benchmark datasets demonstrate that the quantized model outperforms the original full-precision model in terms of generation quality and text-image alignment. My detailed comments are as follows.","1. The BitsFusion framework is an innovative approach to compressing the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a significant reduction in model size while enhancing image quality by using mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline.
2. The paper provides a thorough analysis of quantization errors and develops a mixed-precision strategy based on this analysis, which contributes to the theoretical understanding of low-bit quantization for large-scale diffusion models.
3. The results demonstrate the effectiveness of the proposed framework. The quantized model consistently outperforms the original full-precision model across various metrics, including CLIP score, TIFA score, and GenEval score. The model's ability to achieve a 7.9× reduction in size while maintaining or improving performance highlights its practical potential for deployment on resource-constrained devices.
4. The manuscript is well-written and easy to understand, with clear explanations of the methodology and experimental procedures. Sufficient experimental details are provided, ensuring that the results can be reproduced by other researchers, which enhances the paper's credibility and utility.","1. The two-stage training pipeline, while effective, may introduce additional computational complexity and training time, which could be a drawback for some applications. However, the paper does not explicitly discuss the additional computational complexity and training time it introduces. To provide a more comprehensive evaluation of this method, it is recommended that the authors discuss the potential additional computational overhead introduced by the two-stage training pipeline and its impact on training time.
2. The study demonstrates that there is a high correlation between certain metrics, such as MSE and PSNR, and uses these correlations to validate the effectiveness of their quantization methods. However, correlation does not imply causation. The study does not delve into why these metrics are correlated or explain the intrinsic mechanisms that cause certain layers to be more sensitive to quantization (e.g., why quantization affects some layers more than others, and what intrinsic properties of these layers make them more prone to quantization-induced errors). Understanding these mechanisms is crucial for improving the quantization process, as knowing why certain layers are sensitive can lead to more targeted and effective quantization strategies.
3. The claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is a significant overgeneralization. This assertion, based on specific experimental settings and datasets, may not fully represent the diversity encountered in real-world applications. Primarily, the evaluation on the MS-COCO 2014 validation set, though extensive, does not cover a wide variety of prompts, limiting the assessment of the model's ability to handle different types of inputs (e.g., complex scenes, abstract concepts, specific artistic styles). Additionally, the tests do not include various real-world conditions such as different lighting, backgrounds, or object complexities. Therefore, the claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is premature. A more robust evaluation including varied datasets, prompts, and real-world conditions, such as [A-E],  is necessary to substantiate such a broad claim.
4. The discussion regarding model compression techniques is insufficient. It would be better for the authors to present more model quantization methods [F-J].

[A] Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations. International Journal of Computer Vision. IJCV. 2017.
[B]  Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models. ICCV. 2015.
[C]  The Open Images Dataset V4: Unified Image Classification, Object Detection, and Visual Relationship Detection at Scale. IJCV. 2020.
[D]  Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts. CVPR. 2021.
[E]  Scene Parsing through ADE20K Dataset. CVPR. 2017.
[F] Binary quantized network training with sharpness-aware minimization. Scientific Computing 2023.
[G] Network Quantization with Element-Wise Gradient Scaling. CVPR 2021.
[H] Single-path bit sharing for automatic loss-aware model compression. TPAMI 2023.
[I] Generative Data Free Model Quantization with Knowledge Matching for Classification. TCSVT 2023.",Please check the weakness section.,,['No ethics review needed.'],6,4,,Yes,3,4,3,1720884527967,,,NeurIPS.cc/2024/Conference,0m19blQT6y,"['NeurIPS.cc/2024/Conference/Submission5489/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879004998,[],4,,,['everyone'],0m19blQT6y,['NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG'],1720884527967,1730879004998,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. In the weaknesses section, the reviewer mentions several papers and datasets, including:

* Visual Genome (2017)
* Flickr30k Entities (2015)
* The Open Images Dataset V4 (2020)
* Conceptual 12M (2021)
* Scene Parsing through ADE20K Dataset (2017)
* Binary quantized network training with sharpness-aware minimization (2023)
* Network Quantization with Element-Wise Gradient Scaling (2021)
* Single-path bit sharing for automatic loss-aware model compression (2023)
* Generative Data Free Model Quantization with Knowledge Matching for Classification (2023)

The reviewer suggests that the authors should consider citing these papers and using these datasets to improve their evaluation and discussion of model compression techniques.",1,"2017, 2015, 2020, 2021, 2017, 2023, 2021, 2023, 2023",Binary quantized network training with sharpness-aware minimization 
qnqaCC2LEp,"This paper proposes a novel weight quantization method called ""BitsFusion"" for compressing the Stable Diffusion v1.5 model. The primary goal is to address the issue of large model sizes, which hinder the deployment of diffusion models on resource-constrained devices. The BitsFusion framework quantizes the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a 7.9× reduction in model size while improving image generation quality. The approach involves mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline. Extensive experiments on various benchmark datasets demonstrate that the quantized model outperforms the original full-precision model in terms of generation quality and text-image alignment. My detailed comments are as follows.","1. The BitsFusion framework is an innovative approach to compressing the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a significant reduction in model size while enhancing image quality by using mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline.
2. The paper provides a thorough analysis of quantization errors and develops a mixed-precision strategy based on this analysis, which contributes to the theoretical understanding of low-bit quantization for large-scale diffusion models.
3. The results demonstrate the effectiveness of the proposed framework. The quantized model consistently outperforms the original full-precision model across various metrics, including CLIP score, TIFA score, and GenEval score. The model's ability to achieve a 7.9× reduction in size while maintaining or improving performance highlights its practical potential for deployment on resource-constrained devices.
4. The manuscript is well-written and easy to understand, with clear explanations of the methodology and experimental procedures. Sufficient experimental details are provided, ensuring that the results can be reproduced by other researchers, which enhances the paper's credibility and utility.","1. The two-stage training pipeline, while effective, may introduce additional computational complexity and training time, which could be a drawback for some applications. However, the paper does not explicitly discuss the additional computational complexity and training time it introduces. To provide a more comprehensive evaluation of this method, it is recommended that the authors discuss the potential additional computational overhead introduced by the two-stage training pipeline and its impact on training time.
2. The study demonstrates that there is a high correlation between certain metrics, such as MSE and PSNR, and uses these correlations to validate the effectiveness of their quantization methods. However, correlation does not imply causation. The study does not delve into why these metrics are correlated or explain the intrinsic mechanisms that cause certain layers to be more sensitive to quantization (e.g., why quantization affects some layers more than others, and what intrinsic properties of these layers make them more prone to quantization-induced errors). Understanding these mechanisms is crucial for improving the quantization process, as knowing why certain layers are sensitive can lead to more targeted and effective quantization strategies.
3. The claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is a significant overgeneralization. This assertion, based on specific experimental settings and datasets, may not fully represent the diversity encountered in real-world applications. Primarily, the evaluation on the MS-COCO 2014 validation set, though extensive, does not cover a wide variety of prompts, limiting the assessment of the model's ability to handle different types of inputs (e.g., complex scenes, abstract concepts, specific artistic styles). Additionally, the tests do not include various real-world conditions such as different lighting, backgrounds, or object complexities. Therefore, the claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is premature. A more robust evaluation including varied datasets, prompts, and real-world conditions, such as [A-E],  is necessary to substantiate such a broad claim.
4. The discussion regarding model compression techniques is insufficient. It would be better for the authors to present more model quantization methods [F-J].

[A] Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations. International Journal of Computer Vision. IJCV. 2017.
[B]  Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models. ICCV. 2015.
[C]  The Open Images Dataset V4: Unified Image Classification, Object Detection, and Visual Relationship Detection at Scale. IJCV. 2020.
[D]  Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts. CVPR. 2021.
[E]  Scene Parsing through ADE20K Dataset. CVPR. 2017.
[F] Binary quantized network training with sharpness-aware minimization. Scientific Computing 2023.
[G] Network Quantization with Element-Wise Gradient Scaling. CVPR 2021.
[H] Single-path bit sharing for automatic loss-aware model compression. TPAMI 2023.
[I] Generative Data Free Model Quantization with Knowledge Matching for Classification. TCSVT 2023.",Please check the weakness section.,,['No ethics review needed.'],6,4,,Yes,3,4,3,1720884527967,,,NeurIPS.cc/2024/Conference,0m19blQT6y,"['NeurIPS.cc/2024/Conference/Submission5489/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879004998,[],4,,,['everyone'],0m19blQT6y,['NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG'],1720884527967,1730879004998,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. In the weaknesses section, the reviewer mentions several papers and datasets, including:

* Visual Genome (2017)
* Flickr30k Entities (2015)
* The Open Images Dataset V4 (2020)
* Conceptual 12M (2021)
* Scene Parsing through ADE20K Dataset (2017)
* Binary quantized network training with sharpness-aware minimization (2023)
* Network Quantization with Element-Wise Gradient Scaling (2021)
* Single-path bit sharing for automatic loss-aware model compression (2023)
* Generative Data Free Model Quantization with Knowledge Matching for Classification (2023)

The reviewer suggests that the authors should consider citing these papers and using these datasets to improve their evaluation and discussion of model compression techniques.",1,"2017, 2015, 2020, 2021, 2017, 2023, 2021, 2023, 2023",Network Quantization with Element-Wise Gradient Scaling 
qnqaCC2LEp,"This paper proposes a novel weight quantization method called ""BitsFusion"" for compressing the Stable Diffusion v1.5 model. The primary goal is to address the issue of large model sizes, which hinder the deployment of diffusion models on resource-constrained devices. The BitsFusion framework quantizes the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a 7.9× reduction in model size while improving image generation quality. The approach involves mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline. Extensive experiments on various benchmark datasets demonstrate that the quantized model outperforms the original full-precision model in terms of generation quality and text-image alignment. My detailed comments are as follows.","1. The BitsFusion framework is an innovative approach to compressing the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a significant reduction in model size while enhancing image quality by using mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline.
2. The paper provides a thorough analysis of quantization errors and develops a mixed-precision strategy based on this analysis, which contributes to the theoretical understanding of low-bit quantization for large-scale diffusion models.
3. The results demonstrate the effectiveness of the proposed framework. The quantized model consistently outperforms the original full-precision model across various metrics, including CLIP score, TIFA score, and GenEval score. The model's ability to achieve a 7.9× reduction in size while maintaining or improving performance highlights its practical potential for deployment on resource-constrained devices.
4. The manuscript is well-written and easy to understand, with clear explanations of the methodology and experimental procedures. Sufficient experimental details are provided, ensuring that the results can be reproduced by other researchers, which enhances the paper's credibility and utility.","1. The two-stage training pipeline, while effective, may introduce additional computational complexity and training time, which could be a drawback for some applications. However, the paper does not explicitly discuss the additional computational complexity and training time it introduces. To provide a more comprehensive evaluation of this method, it is recommended that the authors discuss the potential additional computational overhead introduced by the two-stage training pipeline and its impact on training time.
2. The study demonstrates that there is a high correlation between certain metrics, such as MSE and PSNR, and uses these correlations to validate the effectiveness of their quantization methods. However, correlation does not imply causation. The study does not delve into why these metrics are correlated or explain the intrinsic mechanisms that cause certain layers to be more sensitive to quantization (e.g., why quantization affects some layers more than others, and what intrinsic properties of these layers make them more prone to quantization-induced errors). Understanding these mechanisms is crucial for improving the quantization process, as knowing why certain layers are sensitive can lead to more targeted and effective quantization strategies.
3. The claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is a significant overgeneralization. This assertion, based on specific experimental settings and datasets, may not fully represent the diversity encountered in real-world applications. Primarily, the evaluation on the MS-COCO 2014 validation set, though extensive, does not cover a wide variety of prompts, limiting the assessment of the model's ability to handle different types of inputs (e.g., complex scenes, abstract concepts, specific artistic styles). Additionally, the tests do not include various real-world conditions such as different lighting, backgrounds, or object complexities. Therefore, the claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is premature. A more robust evaluation including varied datasets, prompts, and real-world conditions, such as [A-E],  is necessary to substantiate such a broad claim.
4. The discussion regarding model compression techniques is insufficient. It would be better for the authors to present more model quantization methods [F-J].

[A] Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations. International Journal of Computer Vision. IJCV. 2017.
[B]  Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models. ICCV. 2015.
[C]  The Open Images Dataset V4: Unified Image Classification, Object Detection, and Visual Relationship Detection at Scale. IJCV. 2020.
[D]  Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts. CVPR. 2021.
[E]  Scene Parsing through ADE20K Dataset. CVPR. 2017.
[F] Binary quantized network training with sharpness-aware minimization. Scientific Computing 2023.
[G] Network Quantization with Element-Wise Gradient Scaling. CVPR 2021.
[H] Single-path bit sharing for automatic loss-aware model compression. TPAMI 2023.
[I] Generative Data Free Model Quantization with Knowledge Matching for Classification. TCSVT 2023.",Please check the weakness section.,,['No ethics review needed.'],6,4,,Yes,3,4,3,1720884527967,,,NeurIPS.cc/2024/Conference,0m19blQT6y,"['NeurIPS.cc/2024/Conference/Submission5489/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879004998,[],4,,,['everyone'],0m19blQT6y,['NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG'],1720884527967,1730879004998,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. In the weaknesses section, the reviewer mentions several papers and datasets, including:

* Visual Genome (2017)
* Flickr30k Entities (2015)
* The Open Images Dataset V4 (2020)
* Conceptual 12M (2021)
* Scene Parsing through ADE20K Dataset (2017)
* Binary quantized network training with sharpness-aware minimization (2023)
* Network Quantization with Element-Wise Gradient Scaling (2021)
* Single-path bit sharing for automatic loss-aware model compression (2023)
* Generative Data Free Model Quantization with Knowledge Matching for Classification (2023)

The reviewer suggests that the authors should consider citing these papers and using these datasets to improve their evaluation and discussion of model compression techniques.",1,"2017, 2015, 2020, 2021, 2017, 2023, 2021, 2023, 2023",Single-path bit sharing for automatic loss-aware model compression 
qnqaCC2LEp,"This paper proposes a novel weight quantization method called ""BitsFusion"" for compressing the Stable Diffusion v1.5 model. The primary goal is to address the issue of large model sizes, which hinder the deployment of diffusion models on resource-constrained devices. The BitsFusion framework quantizes the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a 7.9× reduction in model size while improving image generation quality. The approach involves mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline. Extensive experiments on various benchmark datasets demonstrate that the quantized model outperforms the original full-precision model in terms of generation quality and text-image alignment. My detailed comments are as follows.","1. The BitsFusion framework is an innovative approach to compressing the UNet component of Stable Diffusion v1.5 to 1.99 bits, achieving a significant reduction in model size while enhancing image quality by using mixed-precision quantization, novel initialization techniques, and an improved two-stage training pipeline.
2. The paper provides a thorough analysis of quantization errors and develops a mixed-precision strategy based on this analysis, which contributes to the theoretical understanding of low-bit quantization for large-scale diffusion models.
3. The results demonstrate the effectiveness of the proposed framework. The quantized model consistently outperforms the original full-precision model across various metrics, including CLIP score, TIFA score, and GenEval score. The model's ability to achieve a 7.9× reduction in size while maintaining or improving performance highlights its practical potential for deployment on resource-constrained devices.
4. The manuscript is well-written and easy to understand, with clear explanations of the methodology and experimental procedures. Sufficient experimental details are provided, ensuring that the results can be reproduced by other researchers, which enhances the paper's credibility and utility.","1. The two-stage training pipeline, while effective, may introduce additional computational complexity and training time, which could be a drawback for some applications. However, the paper does not explicitly discuss the additional computational complexity and training time it introduces. To provide a more comprehensive evaluation of this method, it is recommended that the authors discuss the potential additional computational overhead introduced by the two-stage training pipeline and its impact on training time.
2. The study demonstrates that there is a high correlation between certain metrics, such as MSE and PSNR, and uses these correlations to validate the effectiveness of their quantization methods. However, correlation does not imply causation. The study does not delve into why these metrics are correlated or explain the intrinsic mechanisms that cause certain layers to be more sensitive to quantization (e.g., why quantization affects some layers more than others, and what intrinsic properties of these layers make them more prone to quantization-induced errors). Understanding these mechanisms is crucial for improving the quantization process, as knowing why certain layers are sensitive can lead to more targeted and effective quantization strategies.
3. The claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is a significant overgeneralization. This assertion, based on specific experimental settings and datasets, may not fully represent the diversity encountered in real-world applications. Primarily, the evaluation on the MS-COCO 2014 validation set, though extensive, does not cover a wide variety of prompts, limiting the assessment of the model's ability to handle different types of inputs (e.g., complex scenes, abstract concepts, specific artistic styles). Additionally, the tests do not include various real-world conditions such as different lighting, backgrounds, or object complexities. Therefore, the claim that the 1.99-bit quantized model outperforms the full-precision model in all evaluated metrics is premature. A more robust evaluation including varied datasets, prompts, and real-world conditions, such as [A-E],  is necessary to substantiate such a broad claim.
4. The discussion regarding model compression techniques is insufficient. It would be better for the authors to present more model quantization methods [F-J].

[A] Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations. International Journal of Computer Vision. IJCV. 2017.
[B]  Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models. ICCV. 2015.
[C]  The Open Images Dataset V4: Unified Image Classification, Object Detection, and Visual Relationship Detection at Scale. IJCV. 2020.
[D]  Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts. CVPR. 2021.
[E]  Scene Parsing through ADE20K Dataset. CVPR. 2017.
[F] Binary quantized network training with sharpness-aware minimization. Scientific Computing 2023.
[G] Network Quantization with Element-Wise Gradient Scaling. CVPR 2021.
[H] Single-path bit sharing for automatic loss-aware model compression. TPAMI 2023.
[I] Generative Data Free Model Quantization with Knowledge Matching for Classification. TCSVT 2023.",Please check the weakness section.,,['No ethics review needed.'],6,4,,Yes,3,4,3,1720884527967,,,NeurIPS.cc/2024/Conference,0m19blQT6y,"['NeurIPS.cc/2024/Conference/Submission5489/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879004998,[],4,,,['everyone'],0m19blQT6y,['NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG'],1720884527967,1730879004998,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5489/Reviewer_WzcG']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. In the weaknesses section, the reviewer mentions several papers and datasets, including:

* Visual Genome (2017)
* Flickr30k Entities (2015)
* The Open Images Dataset V4 (2020)
* Conceptual 12M (2021)
* Scene Parsing through ADE20K Dataset (2017)
* Binary quantized network training with sharpness-aware minimization (2023)
* Network Quantization with Element-Wise Gradient Scaling (2021)
* Single-path bit sharing for automatic loss-aware model compression (2023)
* Generative Data Free Model Quantization with Knowledge Matching for Classification (2023)

The reviewer suggests that the authors should consider citing these papers and using these datasets to improve their evaluation and discussion of model compression techniques.",1,"2017, 2015, 2020, 2021, 2017, 2023, 2021, 2023, 2023",Generative Data Free Model Quantization with Knowledge Matching for Classification
ufUB24c840,"This work focuses on improving the latency of Non-Maximum Suppression (NMS), a crucial step for nearly all object detectors.  The work analyzes NMS, as a directed acyclic graph (DAG) treating bounding boxes as nodes, and suppression relationships as arcs allowing NMS solutions based on dynamic programming. Based on this graph interpreation, the work proposes two new approximate versions of NMS, named QSI-NMS, and BOE-NMS with different precision v/s latency tradeoffs. Finally, the proposed NMS approaches are evaluated on a new benchmark NMS-bench, showing improved latency with little to no mAP loss.","1. The paper is written adequately, and offers a new graph theory perspective for non-maximum suppression, further exploring avenues for new research in the area.
2. The proposed approaches show improved latency compared to other NMS approaches including original (greedy NMS), Fast NMS and Cluster NMS, while maintaining mAP. This is achieved without fine-tuning the underlying model.","1. The paper does not compare against (or even cite) other approximations to NMS proposed in the literature such as MaxPoolNMS[1],  PSRR-MaxpoolNMS [2] or ASAP-NMS [3]. It's unclear how the contribution, and performance of proposed approximations differs from the literature. For example, the idea behind BOE-NMS, using locality b/w suppression relationships is already explored in the above works.
2. Can this approach be utilized for two-stage object detectors as well for both stages of NMS? The proposed benchmark only applies the methods this for single-stage object detectors, it's unclear how the method performs on single stage detectors. 

[1] Cai, Lile, et al. ""Maxpoolnms: getting rid of nms bottlenecks in two-stage object detectors."" _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_. 2019.
[2] Zhang, Tianyi, et al. ""Psrr-maxpoolnms: Pyramid shifted maxpoolnms with relationship recovery."" _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_. 2021.
[3] Tripathi, Rohun, et al. ""Asap-nms: Accelerating non-maximum suppression using spatially aware priors."" _arXiv preprint arXiv:2007.09785_ (2020).","1.  The worst case complexity of the proposed approaches is still O(n log n), while other approaches, stated above claim O(n) complexity. Does this imply the other approaches scale better?",The work does an adequate job of discussing the limitations of the proposed work.,['No ethics review needed.'],6,2,,Yes,2,2,3,1721335505596,,,NeurIPS.cc/2024/Conference,0lau89u4oE,"['NeurIPS.cc/2024/Conference/Submission9369/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879309270,[],4,,,['everyone'],0lau89u4oE,['NeurIPS.cc/2024/Conference/Submission9369/Reviewer_pEVt'],1721335505596,1730879309270,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9369/Reviewer_pEVt']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. MaxPoolNMS [1]
2. PSRR-MaxpoolNMS [2]
3. ASAP-NMS [3]

The reviewer mentions that the paper does not compare against or cite these other approximations to NMS proposed in the literature, and implies that the authors should do so to provide a more comprehensive understanding of the contribution and performance of the proposed approximations.",1,,MaxPoolNMS 
ufUB24c840,"This work focuses on improving the latency of Non-Maximum Suppression (NMS), a crucial step for nearly all object detectors.  The work analyzes NMS, as a directed acyclic graph (DAG) treating bounding boxes as nodes, and suppression relationships as arcs allowing NMS solutions based on dynamic programming. Based on this graph interpreation, the work proposes two new approximate versions of NMS, named QSI-NMS, and BOE-NMS with different precision v/s latency tradeoffs. Finally, the proposed NMS approaches are evaluated on a new benchmark NMS-bench, showing improved latency with little to no mAP loss.","1. The paper is written adequately, and offers a new graph theory perspective for non-maximum suppression, further exploring avenues for new research in the area.
2. The proposed approaches show improved latency compared to other NMS approaches including original (greedy NMS), Fast NMS and Cluster NMS, while maintaining mAP. This is achieved without fine-tuning the underlying model.","1. The paper does not compare against (or even cite) other approximations to NMS proposed in the literature such as MaxPoolNMS[1],  PSRR-MaxpoolNMS [2] or ASAP-NMS [3]. It's unclear how the contribution, and performance of proposed approximations differs from the literature. For example, the idea behind BOE-NMS, using locality b/w suppression relationships is already explored in the above works.
2. Can this approach be utilized for two-stage object detectors as well for both stages of NMS? The proposed benchmark only applies the methods this for single-stage object detectors, it's unclear how the method performs on single stage detectors. 

[1] Cai, Lile, et al. ""Maxpoolnms: getting rid of nms bottlenecks in two-stage object detectors."" _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_. 2019.
[2] Zhang, Tianyi, et al. ""Psrr-maxpoolnms: Pyramid shifted maxpoolnms with relationship recovery."" _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_. 2021.
[3] Tripathi, Rohun, et al. ""Asap-nms: Accelerating non-maximum suppression using spatially aware priors."" _arXiv preprint arXiv:2007.09785_ (2020).","1.  The worst case complexity of the proposed approaches is still O(n log n), while other approaches, stated above claim O(n) complexity. Does this imply the other approaches scale better?",The work does an adequate job of discussing the limitations of the proposed work.,['No ethics review needed.'],6,2,,Yes,2,2,3,1721335505596,,,NeurIPS.cc/2024/Conference,0lau89u4oE,"['NeurIPS.cc/2024/Conference/Submission9369/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879309270,[],4,,,['everyone'],0lau89u4oE,['NeurIPS.cc/2024/Conference/Submission9369/Reviewer_pEVt'],1721335505596,1730879309270,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9369/Reviewer_pEVt']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. MaxPoolNMS [1]
2. PSRR-MaxpoolNMS [2]
3. ASAP-NMS [3]

The reviewer mentions that the paper does not compare against or cite these other approximations to NMS proposed in the literature, and implies that the authors should do so to provide a more comprehensive understanding of the contribution and performance of the proposed approximations.",1,,PSRR-MaxpoolNMS 
ufUB24c840,"This work focuses on improving the latency of Non-Maximum Suppression (NMS), a crucial step for nearly all object detectors.  The work analyzes NMS, as a directed acyclic graph (DAG) treating bounding boxes as nodes, and suppression relationships as arcs allowing NMS solutions based on dynamic programming. Based on this graph interpreation, the work proposes two new approximate versions of NMS, named QSI-NMS, and BOE-NMS with different precision v/s latency tradeoffs. Finally, the proposed NMS approaches are evaluated on a new benchmark NMS-bench, showing improved latency with little to no mAP loss.","1. The paper is written adequately, and offers a new graph theory perspective for non-maximum suppression, further exploring avenues for new research in the area.
2. The proposed approaches show improved latency compared to other NMS approaches including original (greedy NMS), Fast NMS and Cluster NMS, while maintaining mAP. This is achieved without fine-tuning the underlying model.","1. The paper does not compare against (or even cite) other approximations to NMS proposed in the literature such as MaxPoolNMS[1],  PSRR-MaxpoolNMS [2] or ASAP-NMS [3]. It's unclear how the contribution, and performance of proposed approximations differs from the literature. For example, the idea behind BOE-NMS, using locality b/w suppression relationships is already explored in the above works.
2. Can this approach be utilized for two-stage object detectors as well for both stages of NMS? The proposed benchmark only applies the methods this for single-stage object detectors, it's unclear how the method performs on single stage detectors. 

[1] Cai, Lile, et al. ""Maxpoolnms: getting rid of nms bottlenecks in two-stage object detectors."" _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_. 2019.
[2] Zhang, Tianyi, et al. ""Psrr-maxpoolnms: Pyramid shifted maxpoolnms with relationship recovery."" _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_. 2021.
[3] Tripathi, Rohun, et al. ""Asap-nms: Accelerating non-maximum suppression using spatially aware priors."" _arXiv preprint arXiv:2007.09785_ (2020).","1.  The worst case complexity of the proposed approaches is still O(n log n), while other approaches, stated above claim O(n) complexity. Does this imply the other approaches scale better?",The work does an adequate job of discussing the limitations of the proposed work.,['No ethics review needed.'],6,2,,Yes,2,2,3,1721335505596,,,NeurIPS.cc/2024/Conference,0lau89u4oE,"['NeurIPS.cc/2024/Conference/Submission9369/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879309270,[],4,,,['everyone'],0lau89u4oE,['NeurIPS.cc/2024/Conference/Submission9369/Reviewer_pEVt'],1721335505596,1730879309270,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9369/Reviewer_pEVt']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. MaxPoolNMS [1]
2. PSRR-MaxpoolNMS [2]
3. ASAP-NMS [3]

The reviewer mentions that the paper does not compare against or cite these other approximations to NMS proposed in the literature, and implies that the authors should do so to provide a more comprehensive understanding of the contribution and performance of the proposed approximations.",1,,ASAP-NMS
NqMgODClOA,"The paper introduces ALPS, an optimization-based framework for one-shot pruning of large language models (LLMs). ALPS leverages an ADMM-based algorithm with operator splitting and preconditioned conjugate gradient methods to achieve improvements in sparsity and perplexity over state-of-the-art methods, particularly in high-sparsity regimes.","**S1.**
ALPS achieves substantial reductions in test perplexity and improved zero-shot benchmark performance for highly sparse models.

**S2.**
Provides theoretical convergence guarantees for $\ell_0$-constrained optimization problems with ADMM solver.

**S3.**
Implements efficient post-processing techniques via conjugate projected gradient, enhancing computational performance.","**W1.**
Important Reference Missing: The paper does not cite ""Fast and optimal weight update for pruned large language models"" by Boža, which addresses a similar problem using an ADMM-based optimization algorithm. This omission is significant as both papers share highly similar problem definitions and solutions.

**W2.**
Limited Novelty: ALPS closely resembles methods discussed in both ""Fast and optimal pruning"" and ""Progressive weight pruning of deep neural networks using ADMM."" The primary difference is ALPS's specific application to LLMs. However, this differentiation might not be substantial enough to establish ALPS as a novel contribution. Btw, the reference of ""Progressive weight pruning of deep neural networks using ADMM."" seems also missing in the paper.

**W3.**
Performance at High Sparsity: At very high sparsity levels, ALPS’s perplexity remains significantly higher than the dense model. This indicates that the pruned LLMs by ALPS may still perform poorly and being practically useless, although they are better than those pruned by comparison methods. 

**W4.**
Unfair Comparison: The comparison with methods like Wanda and DSnoT, which do not involve retraining after pruning, is solely based on perplexity. This is unfair because it overlooks the overall running time per iteration/epoch. ALPS’s performance should be compared with these methods by considering both perplexity and computational efficiency to provide a more balanced evaluation. In addition, I believe if Wanda or DSnoT is combined with some re-training techniques, they can achieve a much lower perplexity as well.

Reference:

Boža, Vladimír. ""Fast and optimal weight update for pruned large language models."" arXiv preprint arXiv:2401.02938 (2024).

Ye, Shaokai, et al. ""Progressive weight pruning of deep neural networks using ADMM."" arXiv preprint arXiv:1810.07378 (2018).","Please refer to my points listed in the weakness section. Besides those,

1. Could you provide a clearer explanation of the practical implications of your theoretical contributions?

2. I encourage the authors to report the overall running time per epoch for ALPS in comparison with Wanda and DSnoT.

3. Could you provide the perplexity of the dense models (without any pruning) in all the tables in the paper?

4. How does ALPS's speed of convergence compare with the referenced methods, and what practical benefits does the novel penalty parameter update scheme offer?",The authors have not thoroughly discussed the limitations and potential negative societal impacts. They should address the limited novelty compared to existing ADMM-based methods and discuss the risks and mitigation strategies for the misuse of more accessible powerful models.,['No ethics review needed.'],3,3,,Yes,2,2,3,1719719390897,,,NeurIPS.cc/2024/Conference,0lBx844upd,"['NeurIPS.cc/2024/Conference/Submission5378/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878996832,[],1,,,['everyone'],0lBx844upd,['NeurIPS.cc/2024/Conference/Submission5378/Reviewer_1PwE'],1719719390897,1730878996832,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5378/Reviewer_1PwE']","Yes, this peer review explicitly suggests that the authors of the paper should cite two specific pieces of literature:

1. ""Fast and optimal weight update for pruned large language models"" by Boža (arXiv preprint arXiv:2401.02938, 2024)
2. ""Progressive weight pruning of deep neural networks using ADMM"" by Ye et al. (arXiv preprint arXiv:1810.07378, 2018)

The reviewer mentions that the omission of these references is significant, as they address similar problems and solutions to the one presented in the paper.",1,"2024, 2024, 2018, 2018",Fast and optimal weight update for pruned large language models 
NqMgODClOA,"The paper introduces ALPS, an optimization-based framework for one-shot pruning of large language models (LLMs). ALPS leverages an ADMM-based algorithm with operator splitting and preconditioned conjugate gradient methods to achieve improvements in sparsity and perplexity over state-of-the-art methods, particularly in high-sparsity regimes.","**S1.**
ALPS achieves substantial reductions in test perplexity and improved zero-shot benchmark performance for highly sparse models.

**S2.**
Provides theoretical convergence guarantees for $\ell_0$-constrained optimization problems with ADMM solver.

**S3.**
Implements efficient post-processing techniques via conjugate projected gradient, enhancing computational performance.","**W1.**
Important Reference Missing: The paper does not cite ""Fast and optimal weight update for pruned large language models"" by Boža, which addresses a similar problem using an ADMM-based optimization algorithm. This omission is significant as both papers share highly similar problem definitions and solutions.

**W2.**
Limited Novelty: ALPS closely resembles methods discussed in both ""Fast and optimal pruning"" and ""Progressive weight pruning of deep neural networks using ADMM."" The primary difference is ALPS's specific application to LLMs. However, this differentiation might not be substantial enough to establish ALPS as a novel contribution. Btw, the reference of ""Progressive weight pruning of deep neural networks using ADMM."" seems also missing in the paper.

**W3.**
Performance at High Sparsity: At very high sparsity levels, ALPS’s perplexity remains significantly higher than the dense model. This indicates that the pruned LLMs by ALPS may still perform poorly and being practically useless, although they are better than those pruned by comparison methods. 

**W4.**
Unfair Comparison: The comparison with methods like Wanda and DSnoT, which do not involve retraining after pruning, is solely based on perplexity. This is unfair because it overlooks the overall running time per iteration/epoch. ALPS’s performance should be compared with these methods by considering both perplexity and computational efficiency to provide a more balanced evaluation. In addition, I believe if Wanda or DSnoT is combined with some re-training techniques, they can achieve a much lower perplexity as well.

Reference:

Boža, Vladimír. ""Fast and optimal weight update for pruned large language models."" arXiv preprint arXiv:2401.02938 (2024).

Ye, Shaokai, et al. ""Progressive weight pruning of deep neural networks using ADMM."" arXiv preprint arXiv:1810.07378 (2018).","Please refer to my points listed in the weakness section. Besides those,

1. Could you provide a clearer explanation of the practical implications of your theoretical contributions?

2. I encourage the authors to report the overall running time per epoch for ALPS in comparison with Wanda and DSnoT.

3. Could you provide the perplexity of the dense models (without any pruning) in all the tables in the paper?

4. How does ALPS's speed of convergence compare with the referenced methods, and what practical benefits does the novel penalty parameter update scheme offer?",The authors have not thoroughly discussed the limitations and potential negative societal impacts. They should address the limited novelty compared to existing ADMM-based methods and discuss the risks and mitigation strategies for the misuse of more accessible powerful models.,['No ethics review needed.'],3,3,,Yes,2,2,3,1719719390897,,,NeurIPS.cc/2024/Conference,0lBx844upd,"['NeurIPS.cc/2024/Conference/Submission5378/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878996832,[],1,,,['everyone'],0lBx844upd,['NeurIPS.cc/2024/Conference/Submission5378/Reviewer_1PwE'],1719719390897,1730878996832,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission5378/Reviewer_1PwE']","Yes, this peer review explicitly suggests that the authors of the paper should cite two specific pieces of literature:

1. ""Fast and optimal weight update for pruned large language models"" by Boža (arXiv preprint arXiv:2401.02938, 2024)
2. ""Progressive weight pruning of deep neural networks using ADMM"" by Ye et al. (arXiv preprint arXiv:1810.07378, 2018)

The reviewer mentions that the omission of these references is significant, as they address similar problems and solutions to the one presented in the paper.",1,"2024, 2024, 2018, 2018",Progressive weight pruning of deep neural networks using ADMM
trZiS7HDlt,"This paper presents a useful theoretical framework that shows that samples that exhibit spurious correlations lie on a lower rank manifold and that the depth of a network acts as an implicit regularizer for the rank of the attribute subspace. Building upon this, the paper proposes a method *DeNetDM* that creates a biased strong encoder (deep network) and a debiased weak encoder (shallow network) and then leverages this to train a final strong encoder that is debiased.","1. The theoretical characterization provided in this paper is extremely intuitive and useful. Confirming the intuitions that examples with spurious attributes lie on a lower-dimension manifold formally is the most important contribution of this paper in my opinion. Supplementing this with the explanation that the depth of the network acts as implicit regularizer makes the method of this paper theoretically sound. 

2. The confirmation of theoretical findings using synthetic experiments helps validate the theoretical claims. 

3. Putting the theoretical findings together into a method that does outperform prior work illustrates the effectivness of this approach.","1. Empirical Evaluation: The datasets chosen by the authors to evaluate their method are not standard in this literature. Common datasets such as Waterbirds [1] and CelebA [2] are missing. Moreover, including newer more challenging datasets such as UrbanCars [3], SpuCoAnimals [4] and SpuCoMNIST [4] could further improve this paper. 

2. Insufficient discussion of similarity to related work: Two related works seem very similar in method to the proposed method. 1) Overcoming simplicity bias in deep networks using a feature sieve and 2) Learning from failure: De-biasing Classifier from biased classifier. The paper would greatly benefit from discussing the similarities and differences between the proposed approach and these 2 closely related approaches. Moreover, Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias is another relevant theoretical / empirical study of spurious correlations which would be useful to compare & contrast with to better understand the contributions of the authors' work. 

[1] https://arxiv.org/abs/1911.08731
[2] https://arxiv.org/abs/1411.7766v3
[3] https://arxiv.org/abs/2212.04825
[4] https://arxiv.org/abs/2306.11957",See above in weaknesses.,Empirical evaluation of method: discussed in greater depth in weaknesses.,['No ethics review needed.'],6,4,,Yes,3,4,4,1720810384044,,,NeurIPS.cc/2024/Conference,0dtA21q83C,"['NeurIPS.cc/2024/Conference/Submission4710/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878948007,[],1,,,['everyone'],0dtA21q83C,['NeurIPS.cc/2024/Conference/Submission4710/Reviewer_Bkbf'],1720810384044,1730878948007,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4710/Reviewer_Bkbf']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several related works that are similar in method to the proposed approach, including:

1. ""Overcoming simplicity bias in deep networks using a feature sieve""
2. ""Learning from failure: De-biasing Classifier from biased classifier""
3. ""Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias""

The reviewer suggests that discussing the similarities and differences between the proposed approach and these related works would be beneficial to better understand the contributions of the authors' work.

Additionally, the reviewer mentions several datasets that are commonly used in this literature, such as Waterbirds, CelebA, UrbanCars, SpuCoAnimals, and SpuCoMNIST, and suggests that including these datasets in the empirical evaluation could improve the paper. The reviewer provides arXiv links to these datasets, which can be considered as a suggestion to cite these specific literature.",1,,Overcoming simplicity bias in deep networks using a feature sieve
trZiS7HDlt,"This paper presents a useful theoretical framework that shows that samples that exhibit spurious correlations lie on a lower rank manifold and that the depth of a network acts as an implicit regularizer for the rank of the attribute subspace. Building upon this, the paper proposes a method *DeNetDM* that creates a biased strong encoder (deep network) and a debiased weak encoder (shallow network) and then leverages this to train a final strong encoder that is debiased.","1. The theoretical characterization provided in this paper is extremely intuitive and useful. Confirming the intuitions that examples with spurious attributes lie on a lower-dimension manifold formally is the most important contribution of this paper in my opinion. Supplementing this with the explanation that the depth of the network acts as implicit regularizer makes the method of this paper theoretically sound. 

2. The confirmation of theoretical findings using synthetic experiments helps validate the theoretical claims. 

3. Putting the theoretical findings together into a method that does outperform prior work illustrates the effectivness of this approach.","1. Empirical Evaluation: The datasets chosen by the authors to evaluate their method are not standard in this literature. Common datasets such as Waterbirds [1] and CelebA [2] are missing. Moreover, including newer more challenging datasets such as UrbanCars [3], SpuCoAnimals [4] and SpuCoMNIST [4] could further improve this paper. 

2. Insufficient discussion of similarity to related work: Two related works seem very similar in method to the proposed method. 1) Overcoming simplicity bias in deep networks using a feature sieve and 2) Learning from failure: De-biasing Classifier from biased classifier. The paper would greatly benefit from discussing the similarities and differences between the proposed approach and these 2 closely related approaches. Moreover, Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias is another relevant theoretical / empirical study of spurious correlations which would be useful to compare & contrast with to better understand the contributions of the authors' work. 

[1] https://arxiv.org/abs/1911.08731
[2] https://arxiv.org/abs/1411.7766v3
[3] https://arxiv.org/abs/2212.04825
[4] https://arxiv.org/abs/2306.11957",See above in weaknesses.,Empirical evaluation of method: discussed in greater depth in weaknesses.,['No ethics review needed.'],6,4,,Yes,3,4,4,1720810384044,,,NeurIPS.cc/2024/Conference,0dtA21q83C,"['NeurIPS.cc/2024/Conference/Submission4710/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878948007,[],1,,,['everyone'],0dtA21q83C,['NeurIPS.cc/2024/Conference/Submission4710/Reviewer_Bkbf'],1720810384044,1730878948007,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4710/Reviewer_Bkbf']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several related works that are similar in method to the proposed approach, including:

1. ""Overcoming simplicity bias in deep networks using a feature sieve""
2. ""Learning from failure: De-biasing Classifier from biased classifier""
3. ""Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias""

The reviewer suggests that discussing the similarities and differences between the proposed approach and these related works would be beneficial to better understand the contributions of the authors' work.

Additionally, the reviewer mentions several datasets that are commonly used in this literature, such as Waterbirds, CelebA, UrbanCars, SpuCoAnimals, and SpuCoMNIST, and suggests that including these datasets in the empirical evaluation could improve the paper. The reviewer provides arXiv links to these datasets, which can be considered as a suggestion to cite these specific literature.",1,,Learning from failure: De-biasing Classifier from biased classifier
trZiS7HDlt,"This paper presents a useful theoretical framework that shows that samples that exhibit spurious correlations lie on a lower rank manifold and that the depth of a network acts as an implicit regularizer for the rank of the attribute subspace. Building upon this, the paper proposes a method *DeNetDM* that creates a biased strong encoder (deep network) and a debiased weak encoder (shallow network) and then leverages this to train a final strong encoder that is debiased.","1. The theoretical characterization provided in this paper is extremely intuitive and useful. Confirming the intuitions that examples with spurious attributes lie on a lower-dimension manifold formally is the most important contribution of this paper in my opinion. Supplementing this with the explanation that the depth of the network acts as implicit regularizer makes the method of this paper theoretically sound. 

2. The confirmation of theoretical findings using synthetic experiments helps validate the theoretical claims. 

3. Putting the theoretical findings together into a method that does outperform prior work illustrates the effectivness of this approach.","1. Empirical Evaluation: The datasets chosen by the authors to evaluate their method are not standard in this literature. Common datasets such as Waterbirds [1] and CelebA [2] are missing. Moreover, including newer more challenging datasets such as UrbanCars [3], SpuCoAnimals [4] and SpuCoMNIST [4] could further improve this paper. 

2. Insufficient discussion of similarity to related work: Two related works seem very similar in method to the proposed method. 1) Overcoming simplicity bias in deep networks using a feature sieve and 2) Learning from failure: De-biasing Classifier from biased classifier. The paper would greatly benefit from discussing the similarities and differences between the proposed approach and these 2 closely related approaches. Moreover, Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias is another relevant theoretical / empirical study of spurious correlations which would be useful to compare & contrast with to better understand the contributions of the authors' work. 

[1] https://arxiv.org/abs/1911.08731
[2] https://arxiv.org/abs/1411.7766v3
[3] https://arxiv.org/abs/2212.04825
[4] https://arxiv.org/abs/2306.11957",See above in weaknesses.,Empirical evaluation of method: discussed in greater depth in weaknesses.,['No ethics review needed.'],6,4,,Yes,3,4,4,1720810384044,,,NeurIPS.cc/2024/Conference,0dtA21q83C,"['NeurIPS.cc/2024/Conference/Submission4710/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878948007,[],1,,,['everyone'],0dtA21q83C,['NeurIPS.cc/2024/Conference/Submission4710/Reviewer_Bkbf'],1720810384044,1730878948007,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4710/Reviewer_Bkbf']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions several related works that are similar in method to the proposed approach, including:

1. ""Overcoming simplicity bias in deep networks using a feature sieve""
2. ""Learning from failure: De-biasing Classifier from biased classifier""
3. ""Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias""

The reviewer suggests that discussing the similarities and differences between the proposed approach and these related works would be beneficial to better understand the contributions of the authors' work.

Additionally, the reviewer mentions several datasets that are commonly used in this literature, such as Waterbirds, CelebA, UrbanCars, SpuCoAnimals, and SpuCoMNIST, and suggests that including these datasets in the empirical evaluation could improve the paper. The reviewer provides arXiv links to these datasets, which can be considered as a suggestion to cite these specific literature.",1,,Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias
VHDB6Y2lqB,"The submission proposes that deeper networks are more likely to use biased features than shallower ones. Using this idea, they develop a training algorithm to encourage reliance upon non-spurious attributes. This is done by training a deep and shallow network as a product-of-experts, then distilling the shallow network into a target network.

Analytic experiments on synthetic datasets indicate that deeper networks do tend to fixate on simpler features as training progresses. A theoretical development of the key intuitions are provided, along with experimental results suggesting that the proposed algorithm can improve over baselines.","Originality: The core idea in the submission about depth modulation is original to my knowledge. Some existing work (e.g. Gradient Starvation: A Learning Proclivity in Neural Networks) has discussed how being able to learn some target-correlating features can impede the learning of others, so it seems plausible that a network that learns a simpler feature quicker is less likely to also learn other features. 

Quality: There is a good set of comparisons to related methods, on some of the standard datasets in the literature. The ideas presented and the intuitions appear sound. Limitations such as anticipated difficulties in scaling beyond single-biases are acknowledged.

Clarity: The submission is generally intuitively clear and easy to follow.

Significance: The ML community continues to consider ways to approach bias in datasets, since specific domains that are data-scarce and unique enough that foundation models may not be available continue to motivate explorations along these lines.","One key weakness in approaches of this flavour is the reliance upon use of a “debiased’ validation set to pick crucial hyper-parameters. This presumes knowledge of the bias, and if one knows it exactly, one can likely adopt other bias-informed approaches in practice. There is some work (e.g. Systematic Generalization with Group-Invariant Predictions) that have used a differently-biased validation set to pick hyperparameters relative to the test set, which can be a slightly better alternative than use of an “oracle” validation set. 

In practice, it is unclear if a model is always going to be operating in an OOD setting. In fact, it might be the case that OOD settings arise relatively infrequently in deployment. From this perspective, it might make more sense to consider both aligned and conflicting accuracies of all baselines. A competing model that takes less of a hit in-distribution might be preferable.

The learning dynamics of decodability throughout training are interesting, but based only on the simpler datasets with a more drastic difference in the “complexity” of the core and biasing attributes. It is unclear how these trends play out for more realistic data.


Minor:

Is an equation with the full loss for training the target model missing? I’m assuming the objective used for training the target network is really L_t + \lambda*L_dist.

A related baseline might be relevant for inclusion: Simple and Fast Group Robustness by Automatic Feature Reweighting, Qiu et al., ICML 2023.

For the mathematical development, it might be better to include some of the key results from Huh et al., Wang and Jacot, etc. for sake of completeness, and also make it easier to gauge the additional contributions brought in this submission. 

Using \citep to might be better to enclose citations in parentheses/brackets.","The submission mentions use of a “small” validation set, could they clarify the exact size, relative to training and testing (I couldn’t find it easily upon a quick look)?

It would be interesting to look at the decodability dynamics on the more complex datasets such as BFFHQ and BAR. Are there technical difficulties in showcasing these trends that I missed?

Would it be possible to compare both aligned and conflicting accuracies for all methods?",The submission acknowledges limitations and broader impact in the Appendix.,['No ethics review needed.'],5,3,,Yes,2,3,3,1720817647511,,,NeurIPS.cc/2024/Conference,0dtA21q83C,"['NeurIPS.cc/2024/Conference/Submission4710/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878947760,[],3,,,['everyone'],0dtA21q83C,['NeurIPS.cc/2024/Conference/Submission4710/Reviewer_9dFt'],1720817647511,1730878947760,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4710/Reviewer_9dFt']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Huh et al.
2. Wang and Jacot
3. Qiu et al., ""Simple and Fast Group Robustness by Automatic Feature Reweighting"" (ICML 2023)
4. ""Systematic Generalization with Group-Invariant Predictions""
5. ""Gradient Starvation: A Learning Proclivity in Neural Networks""

The reviewer mentions that including key results from these works would be beneficial for the mathematical development and to gauge the additional contributions brought in this submission.",1,2023,Simple and Fast Group Robustness by Automatic Feature Reweighting 
VHDB6Y2lqB,"The submission proposes that deeper networks are more likely to use biased features than shallower ones. Using this idea, they develop a training algorithm to encourage reliance upon non-spurious attributes. This is done by training a deep and shallow network as a product-of-experts, then distilling the shallow network into a target network.

Analytic experiments on synthetic datasets indicate that deeper networks do tend to fixate on simpler features as training progresses. A theoretical development of the key intuitions are provided, along with experimental results suggesting that the proposed algorithm can improve over baselines.","Originality: The core idea in the submission about depth modulation is original to my knowledge. Some existing work (e.g. Gradient Starvation: A Learning Proclivity in Neural Networks) has discussed how being able to learn some target-correlating features can impede the learning of others, so it seems plausible that a network that learns a simpler feature quicker is less likely to also learn other features. 

Quality: There is a good set of comparisons to related methods, on some of the standard datasets in the literature. The ideas presented and the intuitions appear sound. Limitations such as anticipated difficulties in scaling beyond single-biases are acknowledged.

Clarity: The submission is generally intuitively clear and easy to follow.

Significance: The ML community continues to consider ways to approach bias in datasets, since specific domains that are data-scarce and unique enough that foundation models may not be available continue to motivate explorations along these lines.","One key weakness in approaches of this flavour is the reliance upon use of a “debiased’ validation set to pick crucial hyper-parameters. This presumes knowledge of the bias, and if one knows it exactly, one can likely adopt other bias-informed approaches in practice. There is some work (e.g. Systematic Generalization with Group-Invariant Predictions) that have used a differently-biased validation set to pick hyperparameters relative to the test set, which can be a slightly better alternative than use of an “oracle” validation set. 

In practice, it is unclear if a model is always going to be operating in an OOD setting. In fact, it might be the case that OOD settings arise relatively infrequently in deployment. From this perspective, it might make more sense to consider both aligned and conflicting accuracies of all baselines. A competing model that takes less of a hit in-distribution might be preferable.

The learning dynamics of decodability throughout training are interesting, but based only on the simpler datasets with a more drastic difference in the “complexity” of the core and biasing attributes. It is unclear how these trends play out for more realistic data.


Minor:

Is an equation with the full loss for training the target model missing? I’m assuming the objective used for training the target network is really L_t + \lambda*L_dist.

A related baseline might be relevant for inclusion: Simple and Fast Group Robustness by Automatic Feature Reweighting, Qiu et al., ICML 2023.

For the mathematical development, it might be better to include some of the key results from Huh et al., Wang and Jacot, etc. for sake of completeness, and also make it easier to gauge the additional contributions brought in this submission. 

Using \citep to might be better to enclose citations in parentheses/brackets.","The submission mentions use of a “small” validation set, could they clarify the exact size, relative to training and testing (I couldn’t find it easily upon a quick look)?

It would be interesting to look at the decodability dynamics on the more complex datasets such as BFFHQ and BAR. Are there technical difficulties in showcasing these trends that I missed?

Would it be possible to compare both aligned and conflicting accuracies for all methods?",The submission acknowledges limitations and broader impact in the Appendix.,['No ethics review needed.'],5,3,,Yes,2,3,3,1720817647511,,,NeurIPS.cc/2024/Conference,0dtA21q83C,"['NeurIPS.cc/2024/Conference/Submission4710/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878947760,[],3,,,['everyone'],0dtA21q83C,['NeurIPS.cc/2024/Conference/Submission4710/Reviewer_9dFt'],1720817647511,1730878947760,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4710/Reviewer_9dFt']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Huh et al.
2. Wang and Jacot
3. Qiu et al., ""Simple and Fast Group Robustness by Automatic Feature Reweighting"" (ICML 2023)
4. ""Systematic Generalization with Group-Invariant Predictions""
5. ""Gradient Starvation: A Learning Proclivity in Neural Networks""

The reviewer mentions that including key results from these works would be beneficial for the mathematical development and to gauge the additional contributions brought in this submission.",1,2023,Systematic Generalization with Group-Invariant Predictions 
VHDB6Y2lqB,"The submission proposes that deeper networks are more likely to use biased features than shallower ones. Using this idea, they develop a training algorithm to encourage reliance upon non-spurious attributes. This is done by training a deep and shallow network as a product-of-experts, then distilling the shallow network into a target network.

Analytic experiments on synthetic datasets indicate that deeper networks do tend to fixate on simpler features as training progresses. A theoretical development of the key intuitions are provided, along with experimental results suggesting that the proposed algorithm can improve over baselines.","Originality: The core idea in the submission about depth modulation is original to my knowledge. Some existing work (e.g. Gradient Starvation: A Learning Proclivity in Neural Networks) has discussed how being able to learn some target-correlating features can impede the learning of others, so it seems plausible that a network that learns a simpler feature quicker is less likely to also learn other features. 

Quality: There is a good set of comparisons to related methods, on some of the standard datasets in the literature. The ideas presented and the intuitions appear sound. Limitations such as anticipated difficulties in scaling beyond single-biases are acknowledged.

Clarity: The submission is generally intuitively clear and easy to follow.

Significance: The ML community continues to consider ways to approach bias in datasets, since specific domains that are data-scarce and unique enough that foundation models may not be available continue to motivate explorations along these lines.","One key weakness in approaches of this flavour is the reliance upon use of a “debiased’ validation set to pick crucial hyper-parameters. This presumes knowledge of the bias, and if one knows it exactly, one can likely adopt other bias-informed approaches in practice. There is some work (e.g. Systematic Generalization with Group-Invariant Predictions) that have used a differently-biased validation set to pick hyperparameters relative to the test set, which can be a slightly better alternative than use of an “oracle” validation set. 

In practice, it is unclear if a model is always going to be operating in an OOD setting. In fact, it might be the case that OOD settings arise relatively infrequently in deployment. From this perspective, it might make more sense to consider both aligned and conflicting accuracies of all baselines. A competing model that takes less of a hit in-distribution might be preferable.

The learning dynamics of decodability throughout training are interesting, but based only on the simpler datasets with a more drastic difference in the “complexity” of the core and biasing attributes. It is unclear how these trends play out for more realistic data.


Minor:

Is an equation with the full loss for training the target model missing? I’m assuming the objective used for training the target network is really L_t + \lambda*L_dist.

A related baseline might be relevant for inclusion: Simple and Fast Group Robustness by Automatic Feature Reweighting, Qiu et al., ICML 2023.

For the mathematical development, it might be better to include some of the key results from Huh et al., Wang and Jacot, etc. for sake of completeness, and also make it easier to gauge the additional contributions brought in this submission. 

Using \citep to might be better to enclose citations in parentheses/brackets.","The submission mentions use of a “small” validation set, could they clarify the exact size, relative to training and testing (I couldn’t find it easily upon a quick look)?

It would be interesting to look at the decodability dynamics on the more complex datasets such as BFFHQ and BAR. Are there technical difficulties in showcasing these trends that I missed?

Would it be possible to compare both aligned and conflicting accuracies for all methods?",The submission acknowledges limitations and broader impact in the Appendix.,['No ethics review needed.'],5,3,,Yes,2,3,3,1720817647511,,,NeurIPS.cc/2024/Conference,0dtA21q83C,"['NeurIPS.cc/2024/Conference/Submission4710/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878947760,[],3,,,['everyone'],0dtA21q83C,['NeurIPS.cc/2024/Conference/Submission4710/Reviewer_9dFt'],1720817647511,1730878947760,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4710/Reviewer_9dFt']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Huh et al.
2. Wang and Jacot
3. Qiu et al., ""Simple and Fast Group Robustness by Automatic Feature Reweighting"" (ICML 2023)
4. ""Systematic Generalization with Group-Invariant Predictions""
5. ""Gradient Starvation: A Learning Proclivity in Neural Networks""

The reviewer mentions that including key results from these works would be beneficial for the mathematical development and to gauge the additional contributions brought in this submission.",1,2023,Gradient Starvation A Learning Proclivity in Neural Networks
42rACQ86vI,"This paper proposes an approach to estimating a maximum-entropy source distribution (akin to a prior distribution over simulator parameters) for a given set of observations and simulation model. Their method assumes a differentiable simulator that may be deterministic or stochastic, and it uses neural samplers to approximate the prior and a variational objective that encourages proximity of both the marginal likelihood to the true data distribution and the estimated source distribution to some known prior distribution (which may be uniform, corresponding to entropy regularisation). In particular, proximity to the true data distribution is measured with a sliced Wasserstein distance, due to its fast computation and differentiability (preserving the differentiable pipeline). The authors present experiments on four benchmark tasks, before extending to higher dimensional and more complex examples such as the single-compartment Hodgkin-Huxley model.","*Originality*

The authors consider using a sample based loss to capture mismatch between the simulated and true data distributions, in contrast to using likelihood-based notions of distance. This is useful since simulation models often lack tractable likelihood functions. 

*Quality* 

The experimental section presents good and extensive empirical testing on a number of toy benchmark models, in addition to two additional more complex simulation models. Their approach is also well-motivated via Proposition 2.1.

*Clarity*

The clarity of writing is generally good. There are a few minor errors in the writing that made it not absolutely clear all the way through:
- The last sentence of the first paragraph of Section 1 isn't a full sentence (or, if it is, then it not well-written because I have read it multiple times and could not turn it into a full sentence in my head).
- There is a subscript $\phi$ missing in Equation 4. 

*Significance*

I think this paper will be of some interest to the community and the techniques presented used by practitioners.","My main concern is that the work presented looks like it is not a large or significant contribution beyond what is already present in the literature. From my perspective, it looks like someone could reasonably argue that the contribution is just to use a different sample-based loss function to capture the discrepancy between the data distribution and simulator's marginal likelihood. It also isn't quite clear to me how exactly the approach that uses the surrogate model (Sur. in Table 1) is different from what is presented in Vandegar et al. (2020).","Could the authors provide some more detail and clarification on how their approach differs/relates to/builds on previous works please? Ideally at least those papers already cited such as Vandegar et al. (2020), but I think some additional related literature is also missing, such as references [1] (relevant since it discusses variational approaches to targeting generalised Bayesian posteriors) and [2] (relevant to the problem of source estimation in complex simulation models) below. Is there anything that we lose by using something like the Sliced Wasserstein Distance instead of a likelihood-based discrepancy?

[1] _Knoblauch, J., Jewson, J., & Damoulas, T. (2022). An optimization-centric view on Bayes' rule: Reviewing and generalizing variational inference. Journal of Machine Learning Research, 23(132), 1-109._

[2] _Dyer, J., Quera-Bofarull, A., Bishop, N., Farmer, J. D., Calinescu, A., & Wooldridge, M. (2024, May). Population Synthesis as Scenario Generation for Simulation-based Planning under Uncertainty. In Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems (pp. 490-498)._","The authors provide a good discussion of the limitations towards the end of the paper. Perhaps something additional to discuss would be limitations associated with simulators that involve discrete randomness, which (as far as I can tell) aren't tested in this paper but which often appears in simulation modelling and presents an additional complication when the requirement is that sampling from the simulator is a differentiable operation (see e.g. [1] below). I also do not see any problems related to the broader social impact of this work. 

[1] _Arya, G., Schauer, M., Schäfer, F., & Rackauckas, C. (2022). Automatic differentiation of programs with discrete randomness. Advances in Neural Information Processing Systems, 35, 10435-10447._",['No ethics review needed.'],5,2,,Yes,2,3,3,1720626729489,,,NeurIPS.cc/2024/Conference,0cgDDa4OFr,"['NeurIPS.cc/2024/Conference/Submission15224/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879764079,[],3,,,['everyone'],0cgDDa4OFr,['NeurIPS.cc/2024/Conference/Submission15224/Reviewer_J2pY'],1720626729489,1730879764079,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission15224/Reviewer_J2pY']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Knoblauch, J., Jewson, J., & Damoulas, T. (2022). An optimization-centric view on Bayes' rule: Reviewing and generalizing variational inference. Journal of Machine Learning Research, 23(132), 1-109.
2. Dyer, J., Quera-Bofarull, A., Bishop, N., Farmer, J. D., Calinescu, A., & Wooldridge, M. (2024, May). Population Synthesis as Scenario Generation for Simulation-based Planning under Uncertainty. In Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems (pp. 490-498).
3. Arya, G., Schauer, M., Schäfer, F., & Rackauckas, C. (2022). Automatic differentiation of programs with discrete randomness. Advances in Neural Information Processing Systems, 35, 10435-10447.

The reviewer also mentions Vandegar et al. (2020) which is already cited in the paper, but asks the authors to provide more detail on how their approach differs/relates to/builds on this previous work.",1,"2022, 2024, 2022, 2020",An optimization-centric view on Bayes' rule: Reviewing and generalizing variational inference
42rACQ86vI,"This paper proposes an approach to estimating a maximum-entropy source distribution (akin to a prior distribution over simulator parameters) for a given set of observations and simulation model. Their method assumes a differentiable simulator that may be deterministic or stochastic, and it uses neural samplers to approximate the prior and a variational objective that encourages proximity of both the marginal likelihood to the true data distribution and the estimated source distribution to some known prior distribution (which may be uniform, corresponding to entropy regularisation). In particular, proximity to the true data distribution is measured with a sliced Wasserstein distance, due to its fast computation and differentiability (preserving the differentiable pipeline). The authors present experiments on four benchmark tasks, before extending to higher dimensional and more complex examples such as the single-compartment Hodgkin-Huxley model.","*Originality*

The authors consider using a sample based loss to capture mismatch between the simulated and true data distributions, in contrast to using likelihood-based notions of distance. This is useful since simulation models often lack tractable likelihood functions. 

*Quality* 

The experimental section presents good and extensive empirical testing on a number of toy benchmark models, in addition to two additional more complex simulation models. Their approach is also well-motivated via Proposition 2.1.

*Clarity*

The clarity of writing is generally good. There are a few minor errors in the writing that made it not absolutely clear all the way through:
- The last sentence of the first paragraph of Section 1 isn't a full sentence (or, if it is, then it not well-written because I have read it multiple times and could not turn it into a full sentence in my head).
- There is a subscript $\phi$ missing in Equation 4. 

*Significance*

I think this paper will be of some interest to the community and the techniques presented used by practitioners.","My main concern is that the work presented looks like it is not a large or significant contribution beyond what is already present in the literature. From my perspective, it looks like someone could reasonably argue that the contribution is just to use a different sample-based loss function to capture the discrepancy between the data distribution and simulator's marginal likelihood. It also isn't quite clear to me how exactly the approach that uses the surrogate model (Sur. in Table 1) is different from what is presented in Vandegar et al. (2020).","Could the authors provide some more detail and clarification on how their approach differs/relates to/builds on previous works please? Ideally at least those papers already cited such as Vandegar et al. (2020), but I think some additional related literature is also missing, such as references [1] (relevant since it discusses variational approaches to targeting generalised Bayesian posteriors) and [2] (relevant to the problem of source estimation in complex simulation models) below. Is there anything that we lose by using something like the Sliced Wasserstein Distance instead of a likelihood-based discrepancy?

[1] _Knoblauch, J., Jewson, J., & Damoulas, T. (2022). An optimization-centric view on Bayes' rule: Reviewing and generalizing variational inference. Journal of Machine Learning Research, 23(132), 1-109._

[2] _Dyer, J., Quera-Bofarull, A., Bishop, N., Farmer, J. D., Calinescu, A., & Wooldridge, M. (2024, May). Population Synthesis as Scenario Generation for Simulation-based Planning under Uncertainty. In Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems (pp. 490-498)._","The authors provide a good discussion of the limitations towards the end of the paper. Perhaps something additional to discuss would be limitations associated with simulators that involve discrete randomness, which (as far as I can tell) aren't tested in this paper but which often appears in simulation modelling and presents an additional complication when the requirement is that sampling from the simulator is a differentiable operation (see e.g. [1] below). I also do not see any problems related to the broader social impact of this work. 

[1] _Arya, G., Schauer, M., Schäfer, F., & Rackauckas, C. (2022). Automatic differentiation of programs with discrete randomness. Advances in Neural Information Processing Systems, 35, 10435-10447._",['No ethics review needed.'],5,2,,Yes,2,3,3,1720626729489,,,NeurIPS.cc/2024/Conference,0cgDDa4OFr,"['NeurIPS.cc/2024/Conference/Submission15224/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879764079,[],3,,,['everyone'],0cgDDa4OFr,['NeurIPS.cc/2024/Conference/Submission15224/Reviewer_J2pY'],1720626729489,1730879764079,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission15224/Reviewer_J2pY']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Knoblauch, J., Jewson, J., & Damoulas, T. (2022). An optimization-centric view on Bayes' rule: Reviewing and generalizing variational inference. Journal of Machine Learning Research, 23(132), 1-109.
2. Dyer, J., Quera-Bofarull, A., Bishop, N., Farmer, J. D., Calinescu, A., & Wooldridge, M. (2024, May). Population Synthesis as Scenario Generation for Simulation-based Planning under Uncertainty. In Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems (pp. 490-498).
3. Arya, G., Schauer, M., Schäfer, F., & Rackauckas, C. (2022). Automatic differentiation of programs with discrete randomness. Advances in Neural Information Processing Systems, 35, 10435-10447.

The reviewer also mentions Vandegar et al. (2020) which is already cited in the paper, but asks the authors to provide more detail on how their approach differs/relates to/builds on this previous work.",1,"2022, 2024, 2022, 2020",Population Synthesis as Scenario Generation for Simulation-based Planning under Uncertainty
42rACQ86vI,"This paper proposes an approach to estimating a maximum-entropy source distribution (akin to a prior distribution over simulator parameters) for a given set of observations and simulation model. Their method assumes a differentiable simulator that may be deterministic or stochastic, and it uses neural samplers to approximate the prior and a variational objective that encourages proximity of both the marginal likelihood to the true data distribution and the estimated source distribution to some known prior distribution (which may be uniform, corresponding to entropy regularisation). In particular, proximity to the true data distribution is measured with a sliced Wasserstein distance, due to its fast computation and differentiability (preserving the differentiable pipeline). The authors present experiments on four benchmark tasks, before extending to higher dimensional and more complex examples such as the single-compartment Hodgkin-Huxley model.","*Originality*

The authors consider using a sample based loss to capture mismatch between the simulated and true data distributions, in contrast to using likelihood-based notions of distance. This is useful since simulation models often lack tractable likelihood functions. 

*Quality* 

The experimental section presents good and extensive empirical testing on a number of toy benchmark models, in addition to two additional more complex simulation models. Their approach is also well-motivated via Proposition 2.1.

*Clarity*

The clarity of writing is generally good. There are a few minor errors in the writing that made it not absolutely clear all the way through:
- The last sentence of the first paragraph of Section 1 isn't a full sentence (or, if it is, then it not well-written because I have read it multiple times and could not turn it into a full sentence in my head).
- There is a subscript $\phi$ missing in Equation 4. 

*Significance*

I think this paper will be of some interest to the community and the techniques presented used by practitioners.","My main concern is that the work presented looks like it is not a large or significant contribution beyond what is already present in the literature. From my perspective, it looks like someone could reasonably argue that the contribution is just to use a different sample-based loss function to capture the discrepancy between the data distribution and simulator's marginal likelihood. It also isn't quite clear to me how exactly the approach that uses the surrogate model (Sur. in Table 1) is different from what is presented in Vandegar et al. (2020).","Could the authors provide some more detail and clarification on how their approach differs/relates to/builds on previous works please? Ideally at least those papers already cited such as Vandegar et al. (2020), but I think some additional related literature is also missing, such as references [1] (relevant since it discusses variational approaches to targeting generalised Bayesian posteriors) and [2] (relevant to the problem of source estimation in complex simulation models) below. Is there anything that we lose by using something like the Sliced Wasserstein Distance instead of a likelihood-based discrepancy?

[1] _Knoblauch, J., Jewson, J., & Damoulas, T. (2022). An optimization-centric view on Bayes' rule: Reviewing and generalizing variational inference. Journal of Machine Learning Research, 23(132), 1-109._

[2] _Dyer, J., Quera-Bofarull, A., Bishop, N., Farmer, J. D., Calinescu, A., & Wooldridge, M. (2024, May). Population Synthesis as Scenario Generation for Simulation-based Planning under Uncertainty. In Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems (pp. 490-498)._","The authors provide a good discussion of the limitations towards the end of the paper. Perhaps something additional to discuss would be limitations associated with simulators that involve discrete randomness, which (as far as I can tell) aren't tested in this paper but which often appears in simulation modelling and presents an additional complication when the requirement is that sampling from the simulator is a differentiable operation (see e.g. [1] below). I also do not see any problems related to the broader social impact of this work. 

[1] _Arya, G., Schauer, M., Schäfer, F., & Rackauckas, C. (2022). Automatic differentiation of programs with discrete randomness. Advances in Neural Information Processing Systems, 35, 10435-10447._",['No ethics review needed.'],5,2,,Yes,2,3,3,1720626729489,,,NeurIPS.cc/2024/Conference,0cgDDa4OFr,"['NeurIPS.cc/2024/Conference/Submission15224/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879764079,[],3,,,['everyone'],0cgDDa4OFr,['NeurIPS.cc/2024/Conference/Submission15224/Reviewer_J2pY'],1720626729489,1730879764079,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission15224/Reviewer_J2pY']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Knoblauch, J., Jewson, J., & Damoulas, T. (2022). An optimization-centric view on Bayes' rule: Reviewing and generalizing variational inference. Journal of Machine Learning Research, 23(132), 1-109.
2. Dyer, J., Quera-Bofarull, A., Bishop, N., Farmer, J. D., Calinescu, A., & Wooldridge, M. (2024, May). Population Synthesis as Scenario Generation for Simulation-based Planning under Uncertainty. In Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems (pp. 490-498).
3. Arya, G., Schauer, M., Schäfer, F., & Rackauckas, C. (2022). Automatic differentiation of programs with discrete randomness. Advances in Neural Information Processing Systems, 35, 10435-10447.

The reviewer also mentions Vandegar et al. (2020) which is already cited in the paper, but asks the authors to provide more detail on how their approach differs/relates to/builds on this previous work.",1,"2022, 2024, 2022, 2020",Automatic differentiation of programs with discrete randomness
6UQX7sPLS1,"The paper introduces novel loss functions - the Fourier Amplitude Loss (FAL), Fourier Correlation Loss (FCL) and a Regional Histogram Divergence (RHD) - to improve the realism of the predictions of precipitation nowcasting models without the use of generative models. The loss is applied to established precipitation nowcasting methods and is seen to significantly improve the sharpness and overall realism of the predictions.","The paper presents a few interesting loss functions, and in particular the RTD is an interesting approach to improving the representation of precipitation quantiles while not overly penalizing small spatial shifts. The paper also shows comparisons of various key metrics with standard model architectures trained with MSE and with the new losses, showing the advantages of the new losses with","The authors sensibly use MSE loss as a baseline when evaluating their model. However, there is quite a long history of developing new losses for making precipitation nowcasting produce sharper images and improve the representation of extreme precipitation. As such, I would have wanted to see a paper introducing a new loss function do some comparisons to earlier attempts to improve on the MSE loss if it wants to claim state-of-the-art performance. See e.g.:
https://proceedings.neurips.cc/paper/2017/hash/a6db4ed04f1621a119799fd3d7545d3d-Abstract.html
https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019EA000812
https://www.mdpi.com/2073-4433/10/5/244","You mention that you introduce FCL because the FAL doesn't fully constrain the spatial positions in the image. A seemingly simpler solution would be to use the FAL in combination with MSE. Have you tried this approach and if so, do you see advantages with using FCL instead?

Also, you are using a loss where you randomize between FAL and FCL and the probability of using FAL increases over time. You motivate this (lines 210-214) as it being tricky to find the correct weighting of FAL and FCL for a linear combination, but I don't quite understand, how is this not functionally equivalent to using a linear combination with the weight of FAL increasing over time?","The paper discusses some limitations of the approach, but one point that is not mentioned is that unlike generative approaches to producing realistic nowcasting predictions, the model trained with the new loss function cannot produce multiple outputs for the same input, and is thus unable to provide stochastic predictions where multiple outputs from the model are used to characterize the probability distribution of precipitation.",['No ethics review needed.'],6,4,,Yes,3,3,3,1720548801244,,,NeurIPS.cc/2024/Conference,0aN7VWwp4g,"['NeurIPS.cc/2024/Conference/Submission4964/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878966471,[],1,,,['everyone'],0aN7VWwp4g,['NeurIPS.cc/2024/Conference/Submission4964/Reviewer_bJuK'],1720548801244,1730878966471,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4964/Reviewer_bJuK']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions three specific references:

1. https://proceedings.neurips.cc/paper/2017/hash/a6db4ed04f1621a119799fd3d7545d3d-Abstract.html
2. https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019EA000812
3. https://www.mdpi.com/2073-4433/10/5/244

The reviewer suggests that the authors should compare their new loss functions to earlier attempts to improve on the MSE loss, as mentioned in these references, in order to claim state-of-the-art performance.",1,2017,Learning to Compare: Relation Network for Few-Shot Learning 
6UQX7sPLS1,"The paper introduces novel loss functions - the Fourier Amplitude Loss (FAL), Fourier Correlation Loss (FCL) and a Regional Histogram Divergence (RHD) - to improve the realism of the predictions of precipitation nowcasting models without the use of generative models. The loss is applied to established precipitation nowcasting methods and is seen to significantly improve the sharpness and overall realism of the predictions.","The paper presents a few interesting loss functions, and in particular the RTD is an interesting approach to improving the representation of precipitation quantiles while not overly penalizing small spatial shifts. The paper also shows comparisons of various key metrics with standard model architectures trained with MSE and with the new losses, showing the advantages of the new losses with","The authors sensibly use MSE loss as a baseline when evaluating their model. However, there is quite a long history of developing new losses for making precipitation nowcasting produce sharper images and improve the representation of extreme precipitation. As such, I would have wanted to see a paper introducing a new loss function do some comparisons to earlier attempts to improve on the MSE loss if it wants to claim state-of-the-art performance. See e.g.:
https://proceedings.neurips.cc/paper/2017/hash/a6db4ed04f1621a119799fd3d7545d3d-Abstract.html
https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019EA000812
https://www.mdpi.com/2073-4433/10/5/244","You mention that you introduce FCL because the FAL doesn't fully constrain the spatial positions in the image. A seemingly simpler solution would be to use the FAL in combination with MSE. Have you tried this approach and if so, do you see advantages with using FCL instead?

Also, you are using a loss where you randomize between FAL and FCL and the probability of using FAL increases over time. You motivate this (lines 210-214) as it being tricky to find the correct weighting of FAL and FCL for a linear combination, but I don't quite understand, how is this not functionally equivalent to using a linear combination with the weight of FAL increasing over time?","The paper discusses some limitations of the approach, but one point that is not mentioned is that unlike generative approaches to producing realistic nowcasting predictions, the model trained with the new loss function cannot produce multiple outputs for the same input, and is thus unable to provide stochastic predictions where multiple outputs from the model are used to characterize the probability distribution of precipitation.",['No ethics review needed.'],6,4,,Yes,3,3,3,1720548801244,,,NeurIPS.cc/2024/Conference,0aN7VWwp4g,"['NeurIPS.cc/2024/Conference/Submission4964/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878966471,[],1,,,['everyone'],0aN7VWwp4g,['NeurIPS.cc/2024/Conference/Submission4964/Reviewer_bJuK'],1720548801244,1730878966471,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4964/Reviewer_bJuK']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions three specific references:

1. https://proceedings.neurips.cc/paper/2017/hash/a6db4ed04f1621a119799fd3d7545d3d-Abstract.html
2. https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019EA000812
3. https://www.mdpi.com/2073-4433/10/5/244

The reviewer suggests that the authors should compare their new loss functions to earlier attempts to improve on the MSE loss, as mentioned in these references, in order to claim state-of-the-art performance.",1,2017, 
6UQX7sPLS1,"The paper introduces novel loss functions - the Fourier Amplitude Loss (FAL), Fourier Correlation Loss (FCL) and a Regional Histogram Divergence (RHD) - to improve the realism of the predictions of precipitation nowcasting models without the use of generative models. The loss is applied to established precipitation nowcasting methods and is seen to significantly improve the sharpness and overall realism of the predictions.","The paper presents a few interesting loss functions, and in particular the RTD is an interesting approach to improving the representation of precipitation quantiles while not overly penalizing small spatial shifts. The paper also shows comparisons of various key metrics with standard model architectures trained with MSE and with the new losses, showing the advantages of the new losses with","The authors sensibly use MSE loss as a baseline when evaluating their model. However, there is quite a long history of developing new losses for making precipitation nowcasting produce sharper images and improve the representation of extreme precipitation. As such, I would have wanted to see a paper introducing a new loss function do some comparisons to earlier attempts to improve on the MSE loss if it wants to claim state-of-the-art performance. See e.g.:
https://proceedings.neurips.cc/paper/2017/hash/a6db4ed04f1621a119799fd3d7545d3d-Abstract.html
https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019EA000812
https://www.mdpi.com/2073-4433/10/5/244","You mention that you introduce FCL because the FAL doesn't fully constrain the spatial positions in the image. A seemingly simpler solution would be to use the FAL in combination with MSE. Have you tried this approach and if so, do you see advantages with using FCL instead?

Also, you are using a loss where you randomize between FAL and FCL and the probability of using FAL increases over time. You motivate this (lines 210-214) as it being tricky to find the correct weighting of FAL and FCL for a linear combination, but I don't quite understand, how is this not functionally equivalent to using a linear combination with the weight of FAL increasing over time?","The paper discusses some limitations of the approach, but one point that is not mentioned is that unlike generative approaches to producing realistic nowcasting predictions, the model trained with the new loss function cannot produce multiple outputs for the same input, and is thus unable to provide stochastic predictions where multiple outputs from the model are used to characterize the probability distribution of precipitation.",['No ethics review needed.'],6,4,,Yes,3,3,3,1720548801244,,,NeurIPS.cc/2024/Conference,0aN7VWwp4g,"['NeurIPS.cc/2024/Conference/Submission4964/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878966471,[],1,,,['everyone'],0aN7VWwp4g,['NeurIPS.cc/2024/Conference/Submission4964/Reviewer_bJuK'],1720548801244,1730878966471,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4964/Reviewer_bJuK']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions three specific references:

1. https://proceedings.neurips.cc/paper/2017/hash/a6db4ed04f1621a119799fd3d7545d3d-Abstract.html
2. https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019EA000812
3. https://www.mdpi.com/2073-4433/10/5/244

The reviewer suggests that the authors should compare their new loss functions to earlier attempts to improve on the MSE loss, as mentioned in these references, in order to claim state-of-the-art performance.",1,2017,A Deep Learning Approach to Downscaling of Climate Variability and Extremes
6UQX7sPLS1,"The paper introduces novel loss functions - the Fourier Amplitude Loss (FAL), Fourier Correlation Loss (FCL) and a Regional Histogram Divergence (RHD) - to improve the realism of the predictions of precipitation nowcasting models without the use of generative models. The loss is applied to established precipitation nowcasting methods and is seen to significantly improve the sharpness and overall realism of the predictions.","The paper presents a few interesting loss functions, and in particular the RTD is an interesting approach to improving the representation of precipitation quantiles while not overly penalizing small spatial shifts. The paper also shows comparisons of various key metrics with standard model architectures trained with MSE and with the new losses, showing the advantages of the new losses with","The authors sensibly use MSE loss as a baseline when evaluating their model. However, there is quite a long history of developing new losses for making precipitation nowcasting produce sharper images and improve the representation of extreme precipitation. As such, I would have wanted to see a paper introducing a new loss function do some comparisons to earlier attempts to improve on the MSE loss if it wants to claim state-of-the-art performance. See e.g.:
https://proceedings.neurips.cc/paper/2017/hash/a6db4ed04f1621a119799fd3d7545d3d-Abstract.html
https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019EA000812
https://www.mdpi.com/2073-4433/10/5/244","You mention that you introduce FCL because the FAL doesn't fully constrain the spatial positions in the image. A seemingly simpler solution would be to use the FAL in combination with MSE. Have you tried this approach and if so, do you see advantages with using FCL instead?

Also, you are using a loss where you randomize between FAL and FCL and the probability of using FAL increases over time. You motivate this (lines 210-214) as it being tricky to find the correct weighting of FAL and FCL for a linear combination, but I don't quite understand, how is this not functionally equivalent to using a linear combination with the weight of FAL increasing over time?","The paper discusses some limitations of the approach, but one point that is not mentioned is that unlike generative approaches to producing realistic nowcasting predictions, the model trained with the new loss function cannot produce multiple outputs for the same input, and is thus unable to provide stochastic predictions where multiple outputs from the model are used to characterize the probability distribution of precipitation.",['No ethics review needed.'],6,4,,Yes,3,3,3,1720548801244,,,NeurIPS.cc/2024/Conference,0aN7VWwp4g,"['NeurIPS.cc/2024/Conference/Submission4964/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878966471,[],1,,,['everyone'],0aN7VWwp4g,['NeurIPS.cc/2024/Conference/Submission4964/Reviewer_bJuK'],1720548801244,1730878966471,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4964/Reviewer_bJuK']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions three specific references:

1. https://proceedings.neurips.cc/paper/2017/hash/a6db4ed04f1621a119799fd3d7545d3d-Abstract.html
2. https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019EA000812
3. https://www.mdpi.com/2073-4433/10/5/244

The reviewer suggests that the authors should compare their new loss functions to earlier attempts to improve on the MSE loss, as mentioned in these references, in order to claim state-of-the-art performance.",1,2017, 
6UQX7sPLS1,"The paper introduces novel loss functions - the Fourier Amplitude Loss (FAL), Fourier Correlation Loss (FCL) and a Regional Histogram Divergence (RHD) - to improve the realism of the predictions of precipitation nowcasting models without the use of generative models. The loss is applied to established precipitation nowcasting methods and is seen to significantly improve the sharpness and overall realism of the predictions.","The paper presents a few interesting loss functions, and in particular the RTD is an interesting approach to improving the representation of precipitation quantiles while not overly penalizing small spatial shifts. The paper also shows comparisons of various key metrics with standard model architectures trained with MSE and with the new losses, showing the advantages of the new losses with","The authors sensibly use MSE loss as a baseline when evaluating their model. However, there is quite a long history of developing new losses for making precipitation nowcasting produce sharper images and improve the representation of extreme precipitation. As such, I would have wanted to see a paper introducing a new loss function do some comparisons to earlier attempts to improve on the MSE loss if it wants to claim state-of-the-art performance. See e.g.:
https://proceedings.neurips.cc/paper/2017/hash/a6db4ed04f1621a119799fd3d7545d3d-Abstract.html
https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019EA000812
https://www.mdpi.com/2073-4433/10/5/244","You mention that you introduce FCL because the FAL doesn't fully constrain the spatial positions in the image. A seemingly simpler solution would be to use the FAL in combination with MSE. Have you tried this approach and if so, do you see advantages with using FCL instead?

Also, you are using a loss where you randomize between FAL and FCL and the probability of using FAL increases over time. You motivate this (lines 210-214) as it being tricky to find the correct weighting of FAL and FCL for a linear combination, but I don't quite understand, how is this not functionally equivalent to using a linear combination with the weight of FAL increasing over time?","The paper discusses some limitations of the approach, but one point that is not mentioned is that unlike generative approaches to producing realistic nowcasting predictions, the model trained with the new loss function cannot produce multiple outputs for the same input, and is thus unable to provide stochastic predictions where multiple outputs from the model are used to characterize the probability distribution of precipitation.",['No ethics review needed.'],6,4,,Yes,3,3,3,1720548801244,,,NeurIPS.cc/2024/Conference,0aN7VWwp4g,"['NeurIPS.cc/2024/Conference/Submission4964/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878966471,[],1,,,['everyone'],0aN7VWwp4g,['NeurIPS.cc/2024/Conference/Submission4964/Reviewer_bJuK'],1720548801244,1730878966471,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4964/Reviewer_bJuK']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature. The reviewer mentions three specific references:

1. https://proceedings.neurips.cc/paper/2017/hash/a6db4ed04f1621a119799fd3d7545d3d-Abstract.html
2. https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019EA000812
3. https://www.mdpi.com/2073-4433/10/5/244

The reviewer suggests that the authors should compare their new loss functions to earlier attempts to improve on the MSE loss, as mentioned in these references, in order to claim state-of-the-art performance.",1,2017,A Novel Loss Function for the Apparent and True Wind Speed Estimation Based on Machine Learning
4DH0EA0icT,This paper proposes the FACL loss function and provides theoretical and empiral proofs on how it boosts clarity and structure for images. The paper also shows how the loss behaves with generative setups and additionally proposes a new metric that is tolerant to deformations.,"- Clearly demonstrates why a naive fourier loss has no benefit over MSE
- Clearly demonstrates how FAL is translation invariant
- Clearly demonstrates why FCL provides global information to predicted pixels instead of pixel-level local information","- Instead of the stochastic modification to Moving-MNIST, [1] already introduced a chaotic yet deterministic N-Body MNIST to mimic the complexity of Earth system interactions, would have been interesting to see the performance on this dataset
- FVD and LPIPS calculated on the basis of models trained on natural images, difficult to see why it would extend to scientific data

[1] Gao, Z., Shi, X., Wang, H., Zhu, Y., Wang, Y. B., Li, M., & Yeung, D. Y. (2022). Earthformer: Exploring space-time transformers for earth system forecasting. Advances in Neural Information Processing Systems, 35, 25390-25403.","- Does the alpha parameter swing wildly between datasets? Any good strategy to figure this out?
- What are the benefits of RHD over a simple wasserstein distance between predicted and true distributions or their quantile error?",Yes,['No ethics review needed.'],7,4,,Yes,3,3,3,1720779575940,,,NeurIPS.cc/2024/Conference,0aN7VWwp4g,"['NeurIPS.cc/2024/Conference/Submission4964/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878966198,[],3,,,['everyone'],0aN7VWwp4g,['NeurIPS.cc/2024/Conference/Submission4964/Reviewer_w5PB'],1720779575940,1730878966198,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4964/Reviewer_w5PB']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

Gao, Z., Shi, X., Wang, H., Zhu, Y., Wang, Y. B., Li, M., & Yeung, D. Y. (2022). Earthformer: Exploring space-time transformers for earth system forecasting. Advances in Neural Information Processing Systems, 35, 25390-25403.

The reviewer mentions that it would have been interesting to see the performance of the proposed method on the N-Body MNIST dataset introduced in this paper, implying that the authors should be aware of and possibly cite this work.",1,2022,Earthformer Exploring space-time transformers for earth system forecasting
bMUaTgeENF,"The paper investigates the computational power of GNNs by demonstrating that the expressiveness of GNNs with different activation functions is equivalent to the capabilities of arithmetic circuits over real numbers. The authors introduce a new GNN variant called C-GNNs, which are equipped with constant-depth arithmetic circuits, and prove that these can compute the same functions as constant-depth arithmetic circuits. This result holds uniformly for all common activation functions and provides insights into the inherent computational limitations of GNNs, suggesting that enhancing GNN expressivity requires more complex functions or different architectures beyond mere scaling.","The paper offers a novel perspective on the expressiveness of GNNs, which is a valuable addition to the existing body of research on GNN expressiveness. This could potentially inspire future work in GNN design.","1. The paper's presentation may not align well with the expectations of a NeurIPS audience. Even for readers with a background in TCS and combinatorics, the contributions of the paper could be made more apparent. An improved presentation could potentially result in a higher evaluation score. (Questions 1, 2, 3)

2. The paper would benefit from a more thorough discussion and comparison with existing literature within the main body of the text. This would help to contextualize the paper's contributions within the broader field. (Questions 3, 4)","1. In Line 115-116, you mention that the results are ""not only an upper bound for neural networks."" However, existing studies often establish the *equivalence* between GNNs and classic algorithms, implying both upper and lower bounds. Moreover, the exact correspondence seems to be established only for C-GNNs and not AC-GNNs. Could you clarify this distinction?

2. You state that the ""result holds for all commonly used activation functions."" Yet, the results appear to hinge solely on the injectivity of the activation function, without more detailed results. Since commonly adopted activation functions are injective, it's challenging to discern the expressiveness of these functions. Could you provide more nuanced insights into this matter?

3. The paper does not discuss applications to deep learning, which may limit its appeal to the NeurIPS audience. 
- Could you elaborate on potential practical problems that the FAC-circuit family can solve or not solve? 
- Additionally, how do FAC-circuits relate to traditional GNN expressiveness results, such as the WL test and first-order logic? Can these classic algorithms be simulated by FAC-circuits?

4. An important related work is missed [1]. This study discusses the equivalence between GNNs and a family of distributed algorithms, as well as the impact on aggregation functions. Furthermore, VVc-GNN appears similar to the C-GNN proposed in your paper. A discussion on this would be beneficial.

[1] Sato, Ryoma, Makoto Yamada, and Hisashi Kashima. ""Approximation ratios of graph neural networks for combinatorial problems."" NeurIPS 2019.",Yes,['No ethics review needed.'],6,3,,Yes,3,3,3,1720425288977,,,NeurIPS.cc/2024/Conference,0ZeONp33f0,"['NeurIPS.cc/2024/Conference/Submission15878/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879804973,[],2,,,['everyone'],0ZeONp33f0,['NeurIPS.cc/2024/Conference/Submission15878/Reviewer_FVmx'],1720425288977,1730879804973,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission15878/Reviewer_FVmx']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, namely:

[1] Sato, Ryoma, Makoto Yamada, and Hisashi Kashima. ""Approximation ratios of graph neural networks for combinatorial problems."" NeurIPS 2019.

The reviewer mentions that this study is an ""important related work"" that is missed in the paper, and suggests that a discussion on this would be beneficial, particularly in relation to the similarity between VVc-GNN and the proposed C-GNN.",1,2019,Approximation ratios of graph neural networks for combinatorial problems
GeRxu5qd7Q,"In this article, the authors present new contributions on the understanding on the computational framework provided by GNNs.
In particular, they draw a connection between Arithmetic Circuits and GNNs. 

Based on a new definition of GNN using arithmetic circuits, they show that the function computed by a GNN on each node can be thought of a function that an (tail-symmetric) arithmetic circuit computes, by stacking the adjacency matrix of the graph and the features vector. In other words, by using arithmetic circuits as comb and aggregation functions inside a message passing framework, the overall procedure can still be thought of as an arithmetic circuit (and vice-versa).","- The paper reads well, in particular the introduction about related work is useful. (although the authors may want to include some additional references for completeness, as detailed below in the Questions section).

- The authors propose a new way to think about GNNs, as a correspondence between a given iteration number, and two family circuits (which used to be the COMB and AGG functions).

- I find the several contributions interesting.","- The main weakness that I can see, is that the definition of the C-GNNs makes the connection between AC-GNN (or close variants, which is what is implemented and used in practice) and circuits. Since the correspondence between GNNs and tail-symmetric arithmetic circuit is established in the following sense:

$$ \text{AC-GNN} \subsetneq (\text{ C-GNNs} = FAC^{0}_{\mathbb{R}^{k}}[\mathcal{A}] )$$

There is potentially a huge gap between AC-GNNs and C-GNNs, that is partially discussed in Remark 3.4. The obscure part of this correspondance seems to arise mainly because of the aggregation functions: i.e., if we have the sum, max and product as aggregation functions, what part of the C-GNNs can we simulate (with polynomial reductions)? 

- Also, although I personally find the results interesting, they are not very deep or insightful: if one provide arithmetic circuit power on each node, and arithmetic circuit power as aggregation, then we obtain at most arithmetic circuits.","- The authors emphasize (and I think it is a good thing) that the computational equivalence they obtain with Arithmetic circuits is something that applies to the message passing framework (the essence of GNNs), regardless of the computational power on the nodes. But in their work, the authors provide an arithmetic circuit as computational power to the nodes. In other words, do the authors believe there is an arithmetic circuit that cannot be computed by an AC-GNN?

- The authors define standard notations like $[n]$, notation for multisets, but not for $(\mathbb{R}^{k})^{*}$. This probably refers to all possible n-tuples of $R^{k}$ for every n. However, it becomes confusing at several locations in the paper.

- From the abstract, the authors mention that their result hold uniformly and non uniformly. This is not mentioned again nor explained in the paper (uniform vs. non uniform) (except if I missed it?)

- The definition of an AC-GNN, as an C-GNN does not coincide with the standard one: a function \sigma^{i} is applied after the combination. This does not align for instance with [2020, Barcelo & Al.]. 

- Definition 3.3, is unclear: The authors may want to elaborate why the proj_1 and proj_2 operations are made consecutively, why is proj_2 needed for $\sigma^{(i)}$ ? I suppose that this is in order to have access to two different arithmetic consecutively.
 

- The authors may want to consider in their introduction, in order to compare their result (in particular the independence w.r.t. the activation functions) the references:

- Impact of aggregation function: 		Eran Rosenbluth, Jan Tönshoff, Martin Grohe ``Some might say all you need is sum``
Martin Grohe, Eran Rosenbluth               ``Are Targeted Messages More Effective?``

- Impact of activation function on GNN expressivity: Sammy Khalife ``Graph Neural Networks with polynomial activations cannot express all GC2 queries``
						    
- Sammy Khalife, Amitabh Basu	``On the power of graph neural networks and the role of the activation function.``


- In proof of Theorem 3.11 is used Definition A.7, and mentioned (``via the injective function'', but this definition allows several functions (as long as different depth implies different values taken by the function). Can the authors confirm and/or clarify this?

- I had a look at the proof of Theorem 3.11 in details (I find this result the most interesting). Can the authors confirm: the essence of the proof is to group the input of the initial circuits (vector of reals) and the circuit as a new graph input to the C-GNN? The gates and structure of the initial circuit is then processed by the C-GNN, in order to compensate for the excess (addition and multiplication shown in Algorithm 1). The division performed in Algorithm 1 is allowed as it is the same as multiplying by the inverse of a constant (this number is indeed a constant as it relates to the structure of the circuit, not the input).",The authors are transparent in the conclusion of their work about the limitations of their work.,['No ethics review needed.'],7,5,,Yes,2,4,4,1720716440321,,,NeurIPS.cc/2024/Conference,0ZeONp33f0,"['NeurIPS.cc/2024/Conference/Submission15878/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879804834,[],3,,,['everyone'],0ZeONp33f0,['NeurIPS.cc/2024/Conference/Submission15878/Reviewer_E5Mq'],1720716440321,1730879804834,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission15878/Reviewer_E5Mq']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Eran Rosenbluth, Jan Tönshoff, Martin Grohe ""Some might say all you need is sum""
2. Martin Grohe, Eran Rosenbluth ""Are Targeted Messages More Effective?""
3. Sammy Khalife ""Graph Neural Networks with polynomial activations cannot express all GC2 queries""
4. Sammy Khalife, Amitabh Basu ""On the power of graph neural networks and the role of the activation function""
5. Barcelo & Al. (2020)

The reviewer suggests that including these references in the introduction would help to compare the authors' result with existing work, particularly regarding the independence of the activation functions and the impact of aggregation functions on GNN expressivity.",1,2020,Some might say all you need is sum
GeRxu5qd7Q,"In this article, the authors present new contributions on the understanding on the computational framework provided by GNNs.
In particular, they draw a connection between Arithmetic Circuits and GNNs. 

Based on a new definition of GNN using arithmetic circuits, they show that the function computed by a GNN on each node can be thought of a function that an (tail-symmetric) arithmetic circuit computes, by stacking the adjacency matrix of the graph and the features vector. In other words, by using arithmetic circuits as comb and aggregation functions inside a message passing framework, the overall procedure can still be thought of as an arithmetic circuit (and vice-versa).","- The paper reads well, in particular the introduction about related work is useful. (although the authors may want to include some additional references for completeness, as detailed below in the Questions section).

- The authors propose a new way to think about GNNs, as a correspondence between a given iteration number, and two family circuits (which used to be the COMB and AGG functions).

- I find the several contributions interesting.","- The main weakness that I can see, is that the definition of the C-GNNs makes the connection between AC-GNN (or close variants, which is what is implemented and used in practice) and circuits. Since the correspondence between GNNs and tail-symmetric arithmetic circuit is established in the following sense:

$$ \text{AC-GNN} \subsetneq (\text{ C-GNNs} = FAC^{0}_{\mathbb{R}^{k}}[\mathcal{A}] )$$

There is potentially a huge gap between AC-GNNs and C-GNNs, that is partially discussed in Remark 3.4. The obscure part of this correspondance seems to arise mainly because of the aggregation functions: i.e., if we have the sum, max and product as aggregation functions, what part of the C-GNNs can we simulate (with polynomial reductions)? 

- Also, although I personally find the results interesting, they are not very deep or insightful: if one provide arithmetic circuit power on each node, and arithmetic circuit power as aggregation, then we obtain at most arithmetic circuits.","- The authors emphasize (and I think it is a good thing) that the computational equivalence they obtain with Arithmetic circuits is something that applies to the message passing framework (the essence of GNNs), regardless of the computational power on the nodes. But in their work, the authors provide an arithmetic circuit as computational power to the nodes. In other words, do the authors believe there is an arithmetic circuit that cannot be computed by an AC-GNN?

- The authors define standard notations like $[n]$, notation for multisets, but not for $(\mathbb{R}^{k})^{*}$. This probably refers to all possible n-tuples of $R^{k}$ for every n. However, it becomes confusing at several locations in the paper.

- From the abstract, the authors mention that their result hold uniformly and non uniformly. This is not mentioned again nor explained in the paper (uniform vs. non uniform) (except if I missed it?)

- The definition of an AC-GNN, as an C-GNN does not coincide with the standard one: a function \sigma^{i} is applied after the combination. This does not align for instance with [2020, Barcelo & Al.]. 

- Definition 3.3, is unclear: The authors may want to elaborate why the proj_1 and proj_2 operations are made consecutively, why is proj_2 needed for $\sigma^{(i)}$ ? I suppose that this is in order to have access to two different arithmetic consecutively.
 

- The authors may want to consider in their introduction, in order to compare their result (in particular the independence w.r.t. the activation functions) the references:

- Impact of aggregation function: 		Eran Rosenbluth, Jan Tönshoff, Martin Grohe ``Some might say all you need is sum``
Martin Grohe, Eran Rosenbluth               ``Are Targeted Messages More Effective?``

- Impact of activation function on GNN expressivity: Sammy Khalife ``Graph Neural Networks with polynomial activations cannot express all GC2 queries``
						    
- Sammy Khalife, Amitabh Basu	``On the power of graph neural networks and the role of the activation function.``


- In proof of Theorem 3.11 is used Definition A.7, and mentioned (``via the injective function'', but this definition allows several functions (as long as different depth implies different values taken by the function). Can the authors confirm and/or clarify this?

- I had a look at the proof of Theorem 3.11 in details (I find this result the most interesting). Can the authors confirm: the essence of the proof is to group the input of the initial circuits (vector of reals) and the circuit as a new graph input to the C-GNN? The gates and structure of the initial circuit is then processed by the C-GNN, in order to compensate for the excess (addition and multiplication shown in Algorithm 1). The division performed in Algorithm 1 is allowed as it is the same as multiplying by the inverse of a constant (this number is indeed a constant as it relates to the structure of the circuit, not the input).",The authors are transparent in the conclusion of their work about the limitations of their work.,['No ethics review needed.'],7,5,,Yes,2,4,4,1720716440321,,,NeurIPS.cc/2024/Conference,0ZeONp33f0,"['NeurIPS.cc/2024/Conference/Submission15878/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879804834,[],3,,,['everyone'],0ZeONp33f0,['NeurIPS.cc/2024/Conference/Submission15878/Reviewer_E5Mq'],1720716440321,1730879804834,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission15878/Reviewer_E5Mq']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Eran Rosenbluth, Jan Tönshoff, Martin Grohe ""Some might say all you need is sum""
2. Martin Grohe, Eran Rosenbluth ""Are Targeted Messages More Effective?""
3. Sammy Khalife ""Graph Neural Networks with polynomial activations cannot express all GC2 queries""
4. Sammy Khalife, Amitabh Basu ""On the power of graph neural networks and the role of the activation function""
5. Barcelo & Al. (2020)

The reviewer suggests that including these references in the introduction would help to compare the authors' result with existing work, particularly regarding the independence of the activation functions and the impact of aggregation functions on GNN expressivity.",1,2020,Are Targeted Messages More Effective?
GeRxu5qd7Q,"In this article, the authors present new contributions on the understanding on the computational framework provided by GNNs.
In particular, they draw a connection between Arithmetic Circuits and GNNs. 

Based on a new definition of GNN using arithmetic circuits, they show that the function computed by a GNN on each node can be thought of a function that an (tail-symmetric) arithmetic circuit computes, by stacking the adjacency matrix of the graph and the features vector. In other words, by using arithmetic circuits as comb and aggregation functions inside a message passing framework, the overall procedure can still be thought of as an arithmetic circuit (and vice-versa).","- The paper reads well, in particular the introduction about related work is useful. (although the authors may want to include some additional references for completeness, as detailed below in the Questions section).

- The authors propose a new way to think about GNNs, as a correspondence between a given iteration number, and two family circuits (which used to be the COMB and AGG functions).

- I find the several contributions interesting.","- The main weakness that I can see, is that the definition of the C-GNNs makes the connection between AC-GNN (or close variants, which is what is implemented and used in practice) and circuits. Since the correspondence between GNNs and tail-symmetric arithmetic circuit is established in the following sense:

$$ \text{AC-GNN} \subsetneq (\text{ C-GNNs} = FAC^{0}_{\mathbb{R}^{k}}[\mathcal{A}] )$$

There is potentially a huge gap between AC-GNNs and C-GNNs, that is partially discussed in Remark 3.4. The obscure part of this correspondance seems to arise mainly because of the aggregation functions: i.e., if we have the sum, max and product as aggregation functions, what part of the C-GNNs can we simulate (with polynomial reductions)? 

- Also, although I personally find the results interesting, they are not very deep or insightful: if one provide arithmetic circuit power on each node, and arithmetic circuit power as aggregation, then we obtain at most arithmetic circuits.","- The authors emphasize (and I think it is a good thing) that the computational equivalence they obtain with Arithmetic circuits is something that applies to the message passing framework (the essence of GNNs), regardless of the computational power on the nodes. But in their work, the authors provide an arithmetic circuit as computational power to the nodes. In other words, do the authors believe there is an arithmetic circuit that cannot be computed by an AC-GNN?

- The authors define standard notations like $[n]$, notation for multisets, but not for $(\mathbb{R}^{k})^{*}$. This probably refers to all possible n-tuples of $R^{k}$ for every n. However, it becomes confusing at several locations in the paper.

- From the abstract, the authors mention that their result hold uniformly and non uniformly. This is not mentioned again nor explained in the paper (uniform vs. non uniform) (except if I missed it?)

- The definition of an AC-GNN, as an C-GNN does not coincide with the standard one: a function \sigma^{i} is applied after the combination. This does not align for instance with [2020, Barcelo & Al.]. 

- Definition 3.3, is unclear: The authors may want to elaborate why the proj_1 and proj_2 operations are made consecutively, why is proj_2 needed for $\sigma^{(i)}$ ? I suppose that this is in order to have access to two different arithmetic consecutively.
 

- The authors may want to consider in their introduction, in order to compare their result (in particular the independence w.r.t. the activation functions) the references:

- Impact of aggregation function: 		Eran Rosenbluth, Jan Tönshoff, Martin Grohe ``Some might say all you need is sum``
Martin Grohe, Eran Rosenbluth               ``Are Targeted Messages More Effective?``

- Impact of activation function on GNN expressivity: Sammy Khalife ``Graph Neural Networks with polynomial activations cannot express all GC2 queries``
						    
- Sammy Khalife, Amitabh Basu	``On the power of graph neural networks and the role of the activation function.``


- In proof of Theorem 3.11 is used Definition A.7, and mentioned (``via the injective function'', but this definition allows several functions (as long as different depth implies different values taken by the function). Can the authors confirm and/or clarify this?

- I had a look at the proof of Theorem 3.11 in details (I find this result the most interesting). Can the authors confirm: the essence of the proof is to group the input of the initial circuits (vector of reals) and the circuit as a new graph input to the C-GNN? The gates and structure of the initial circuit is then processed by the C-GNN, in order to compensate for the excess (addition and multiplication shown in Algorithm 1). The division performed in Algorithm 1 is allowed as it is the same as multiplying by the inverse of a constant (this number is indeed a constant as it relates to the structure of the circuit, not the input).",The authors are transparent in the conclusion of their work about the limitations of their work.,['No ethics review needed.'],7,5,,Yes,2,4,4,1720716440321,,,NeurIPS.cc/2024/Conference,0ZeONp33f0,"['NeurIPS.cc/2024/Conference/Submission15878/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879804834,[],3,,,['everyone'],0ZeONp33f0,['NeurIPS.cc/2024/Conference/Submission15878/Reviewer_E5Mq'],1720716440321,1730879804834,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission15878/Reviewer_E5Mq']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Eran Rosenbluth, Jan Tönshoff, Martin Grohe ""Some might say all you need is sum""
2. Martin Grohe, Eran Rosenbluth ""Are Targeted Messages More Effective?""
3. Sammy Khalife ""Graph Neural Networks with polynomial activations cannot express all GC2 queries""
4. Sammy Khalife, Amitabh Basu ""On the power of graph neural networks and the role of the activation function""
5. Barcelo & Al. (2020)

The reviewer suggests that including these references in the introduction would help to compare the authors' result with existing work, particularly regarding the independence of the activation functions and the impact of aggregation functions on GNN expressivity.",1,2020,Graph Neural Networks with polynomial activations cannot express all GC2 queries
GeRxu5qd7Q,"In this article, the authors present new contributions on the understanding on the computational framework provided by GNNs.
In particular, they draw a connection between Arithmetic Circuits and GNNs. 

Based on a new definition of GNN using arithmetic circuits, they show that the function computed by a GNN on each node can be thought of a function that an (tail-symmetric) arithmetic circuit computes, by stacking the adjacency matrix of the graph and the features vector. In other words, by using arithmetic circuits as comb and aggregation functions inside a message passing framework, the overall procedure can still be thought of as an arithmetic circuit (and vice-versa).","- The paper reads well, in particular the introduction about related work is useful. (although the authors may want to include some additional references for completeness, as detailed below in the Questions section).

- The authors propose a new way to think about GNNs, as a correspondence between a given iteration number, and two family circuits (which used to be the COMB and AGG functions).

- I find the several contributions interesting.","- The main weakness that I can see, is that the definition of the C-GNNs makes the connection between AC-GNN (or close variants, which is what is implemented and used in practice) and circuits. Since the correspondence between GNNs and tail-symmetric arithmetic circuit is established in the following sense:

$$ \text{AC-GNN} \subsetneq (\text{ C-GNNs} = FAC^{0}_{\mathbb{R}^{k}}[\mathcal{A}] )$$

There is potentially a huge gap between AC-GNNs and C-GNNs, that is partially discussed in Remark 3.4. The obscure part of this correspondance seems to arise mainly because of the aggregation functions: i.e., if we have the sum, max and product as aggregation functions, what part of the C-GNNs can we simulate (with polynomial reductions)? 

- Also, although I personally find the results interesting, they are not very deep or insightful: if one provide arithmetic circuit power on each node, and arithmetic circuit power as aggregation, then we obtain at most arithmetic circuits.","- The authors emphasize (and I think it is a good thing) that the computational equivalence they obtain with Arithmetic circuits is something that applies to the message passing framework (the essence of GNNs), regardless of the computational power on the nodes. But in their work, the authors provide an arithmetic circuit as computational power to the nodes. In other words, do the authors believe there is an arithmetic circuit that cannot be computed by an AC-GNN?

- The authors define standard notations like $[n]$, notation for multisets, but not for $(\mathbb{R}^{k})^{*}$. This probably refers to all possible n-tuples of $R^{k}$ for every n. However, it becomes confusing at several locations in the paper.

- From the abstract, the authors mention that their result hold uniformly and non uniformly. This is not mentioned again nor explained in the paper (uniform vs. non uniform) (except if I missed it?)

- The definition of an AC-GNN, as an C-GNN does not coincide with the standard one: a function \sigma^{i} is applied after the combination. This does not align for instance with [2020, Barcelo & Al.]. 

- Definition 3.3, is unclear: The authors may want to elaborate why the proj_1 and proj_2 operations are made consecutively, why is proj_2 needed for $\sigma^{(i)}$ ? I suppose that this is in order to have access to two different arithmetic consecutively.
 

- The authors may want to consider in their introduction, in order to compare their result (in particular the independence w.r.t. the activation functions) the references:

- Impact of aggregation function: 		Eran Rosenbluth, Jan Tönshoff, Martin Grohe ``Some might say all you need is sum``
Martin Grohe, Eran Rosenbluth               ``Are Targeted Messages More Effective?``

- Impact of activation function on GNN expressivity: Sammy Khalife ``Graph Neural Networks with polynomial activations cannot express all GC2 queries``
						    
- Sammy Khalife, Amitabh Basu	``On the power of graph neural networks and the role of the activation function.``


- In proof of Theorem 3.11 is used Definition A.7, and mentioned (``via the injective function'', but this definition allows several functions (as long as different depth implies different values taken by the function). Can the authors confirm and/or clarify this?

- I had a look at the proof of Theorem 3.11 in details (I find this result the most interesting). Can the authors confirm: the essence of the proof is to group the input of the initial circuits (vector of reals) and the circuit as a new graph input to the C-GNN? The gates and structure of the initial circuit is then processed by the C-GNN, in order to compensate for the excess (addition and multiplication shown in Algorithm 1). The division performed in Algorithm 1 is allowed as it is the same as multiplying by the inverse of a constant (this number is indeed a constant as it relates to the structure of the circuit, not the input).",The authors are transparent in the conclusion of their work about the limitations of their work.,['No ethics review needed.'],7,5,,Yes,2,4,4,1720716440321,,,NeurIPS.cc/2024/Conference,0ZeONp33f0,"['NeurIPS.cc/2024/Conference/Submission15878/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879804834,[],3,,,['everyone'],0ZeONp33f0,['NeurIPS.cc/2024/Conference/Submission15878/Reviewer_E5Mq'],1720716440321,1730879804834,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission15878/Reviewer_E5Mq']","Yes, this peer review explicitly suggests the authors of the paper to cite several specific literature, including:

1. Eran Rosenbluth, Jan Tönshoff, Martin Grohe ""Some might say all you need is sum""
2. Martin Grohe, Eran Rosenbluth ""Are Targeted Messages More Effective?""
3. Sammy Khalife ""Graph Neural Networks with polynomial activations cannot express all GC2 queries""
4. Sammy Khalife, Amitabh Basu ""On the power of graph neural networks and the role of the activation function""
5. Barcelo & Al. (2020)

The reviewer suggests that including these references in the introduction would help to compare the authors' result with existing work, particularly regarding the independence of the activation functions and the impact of aggregation functions on GNN expressivity.",1,2020,On the power of graph neural networks and the role of the activation function
1oyi4EACk1,"This paper ""Can LLMs Learn by Teaching? A Preliminary Study"" presents a novel approach towards LLM learning by teaching with three methods: observing student feedback, learning from student feedback, and learning iteratively. The contribute two key findings: teaching student models are an effective way to improve model performance (with fine-tuning), and student models must be diverse (teaching multiple students are better than teaching one student).","- The paper is exceedingly well-written and structured, making it easy to follow for a reader. The diagrams are informative and helpful.
- The idea is simple and brilliant -- it could be could be very effective for LLM finetuning and is executed well.
- Particularly M3 is reminiscent of ideas from OpenAI (AlphaFold). This is a very interesting exploration.
- The experiments are plentiful and convincing.","Figure 4, Table 2, Table 3, and Table 4 must include at least standard error or ideally 95% CI to prove statistical significance of the results.

With the number of acronyms in table 3 metrics, it's hard to understand what exactly numbers mean. Please find some way to include more understandable question categorizations.

The paper is missing literature from the learning sciences backing up the authors' strategy of implementing feedback and their premise of learning-by-teaching. Including a discussion on this would be important for motivating their work. Please examine literature on feedback (i.e. Power of Feedback, Hattie et al. or from the recent EDM, AIED, LAK communities) to strengthen your discussion and motivation. Additionally, it would be useful to examine ways to evaluate teaching quality also from the same communities.","What are the interpretability implications of teaching diverse students at different knowledge levels? A discussion on this might be useful in the paper.

Why choose the game theory + math reasoning datasets? The motivation for the dataset choice seems to be a bit missing in the paper. 

Can this be extended to open-ended math problems? How and what would need to change in the architecture?","The limitations are discussed mostly in terms of extensions. A discussion of bias perpetuation along the student / teacher pipeline i.e. Wambsganss et al. ""Bias at a Second Glance"" (COLING 2022) and global interpretability implications would be helpful here.",['No ethics review needed.'],7,4,,Yes,4,4,4,1721241849078,,,NeurIPS.cc/2024/Conference,0ZZMUjZJYF,"['NeurIPS.cc/2024/Conference/Submission10254/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879372305,[],4,,,['everyone'],0ZZMUjZJYF,['NeurIPS.cc/2024/Conference/Submission10254/Reviewer_UmKq'],1721241849078,1730879372305,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10254/Reviewer_UmKq']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. ""The Power of Feedback"" by Hattie et al.
2. Literature from the recent EDM (Educational Data Mining), AIED (Artificial Intelligence in Education), and LAK (Learning Analytics and Knowledge) communities, to strengthen the discussion and motivation of the paper's strategy of implementing feedback and the premise of learning-by-teaching.
3. ""Bias at a Second Glance"" by Wambsganss et al. (COLING 2022), to discuss bias perpetuation along the student/teacher pipeline.",1,2022,The Power of Feedback 
1oyi4EACk1,"This paper ""Can LLMs Learn by Teaching? A Preliminary Study"" presents a novel approach towards LLM learning by teaching with three methods: observing student feedback, learning from student feedback, and learning iteratively. The contribute two key findings: teaching student models are an effective way to improve model performance (with fine-tuning), and student models must be diverse (teaching multiple students are better than teaching one student).","- The paper is exceedingly well-written and structured, making it easy to follow for a reader. The diagrams are informative and helpful.
- The idea is simple and brilliant -- it could be could be very effective for LLM finetuning and is executed well.
- Particularly M3 is reminiscent of ideas from OpenAI (AlphaFold). This is a very interesting exploration.
- The experiments are plentiful and convincing.","Figure 4, Table 2, Table 3, and Table 4 must include at least standard error or ideally 95% CI to prove statistical significance of the results.

With the number of acronyms in table 3 metrics, it's hard to understand what exactly numbers mean. Please find some way to include more understandable question categorizations.

The paper is missing literature from the learning sciences backing up the authors' strategy of implementing feedback and their premise of learning-by-teaching. Including a discussion on this would be important for motivating their work. Please examine literature on feedback (i.e. Power of Feedback, Hattie et al. or from the recent EDM, AIED, LAK communities) to strengthen your discussion and motivation. Additionally, it would be useful to examine ways to evaluate teaching quality also from the same communities.","What are the interpretability implications of teaching diverse students at different knowledge levels? A discussion on this might be useful in the paper.

Why choose the game theory + math reasoning datasets? The motivation for the dataset choice seems to be a bit missing in the paper. 

Can this be extended to open-ended math problems? How and what would need to change in the architecture?","The limitations are discussed mostly in terms of extensions. A discussion of bias perpetuation along the student / teacher pipeline i.e. Wambsganss et al. ""Bias at a Second Glance"" (COLING 2022) and global interpretability implications would be helpful here.",['No ethics review needed.'],7,4,,Yes,4,4,4,1721241849078,,,NeurIPS.cc/2024/Conference,0ZZMUjZJYF,"['NeurIPS.cc/2024/Conference/Submission10254/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879372305,[],4,,,['everyone'],0ZZMUjZJYF,['NeurIPS.cc/2024/Conference/Submission10254/Reviewer_UmKq'],1721241849078,1730879372305,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission10254/Reviewer_UmKq']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. ""The Power of Feedback"" by Hattie et al.
2. Literature from the recent EDM (Educational Data Mining), AIED (Artificial Intelligence in Education), and LAK (Learning Analytics and Knowledge) communities, to strengthen the discussion and motivation of the paper's strategy of implementing feedback and the premise of learning-by-teaching.
3. ""Bias at a Second Glance"" by Wambsganss et al. (COLING 2022), to discuss bias perpetuation along the student/teacher pipeline.",1,2022,Bias at a Second Glance
x2glxioLED,"The authors propose a method for training neural nets without needing to know the total training time T in advance. This contrasts with a standard training setup where one chooses a learning rate schedule in advance, and the schedule must include an a priori chosen stopping time T (e.g. cosine schedule or linear decay). If the method really works as advertised it therefore simplifies practical training setups and reduces the cost of training, by avoiding the need to run multiple training runs with different values of stopping time T.

The method works by tracking two sequences: one is the ""noisy"" sequence z that integrates noisy gradient updates, the second is the ""smoothed"" sequence x that tracks a uniform average over all past noisy iterates z. Gradients are evaluated at an interpolation between the current noisy z and smoothed x sequence, and added back to the noisy z sequence which is then averaged into the smoothed x sequence.

Authors present theoretical results about their technique for convex optimisation, and evaluate the method across a set of training benchmarks, some that involve tuning and some that don't. The results look promising.","- the idea is legitimately really cool and clever and seems very original to me. People know that weight averaging on top of standard training can boost performance, so it's really cool to ask ""is there a way to fold this back into the training loop"" as the authors do. 
- my broad understanding of the technique is that it's doing noise filtering in a clever way, and I think that this idea can inspire others to explore this direction, which is great
- the paper is very clearly written and I like the mix of the intuitive description of the technique, the formal results, and then the experimental evaluation
- it's great that the authors engaged with the MLCommons Algorithmic Efficiency benchmark, and from what I understand the results are very promising.","Okay as I've mentioned, I think the idea is cool and original and can inspire followup work, which is all we really want of a paper. So I'm going to focus on giving you feedback which is intended to be constructive and I hope can help you generally improve the quality of the work or followup work that you do. I'm not going to hold the paper hostage, but if I feel like you engage meaningfully with my critiques I'm willing to upgrade my score. All of my critiques can be addressed either by making minor amendments to text or by adding a limitations section at the end of the paper *or* by running more experiments and addressing them, but I won't insist on which and leave this up to the authors.

### **Paper may be over claiming slightly on its results**

The paper makes claims to be **""one of the largest and most comprehensive machine learning optimization algorithm evaluations”**. Can you quantify in what sense this is true? To me the evaluation doesn't feel that comprehensive---for instance, there is only one plot on hyperparameter sensitivity, while a broad swathe of the community has started to explore this question as standard in evaluations papers. The authors also state their method **""has no notable memory, computation or performance limitations compared to scheduling approaches""**. In my opinion, the truth value of this statement is essentially unknowable without more thorough evaluation. It would be fine to amend the statement by saying ""WE BELIEVE THAT our method has no notable memory, computation or performance limitations compared to scheduling approaches.""

### **Hyperparameter sensitivity is not thoroughly investigated**

In my opinion, the main potential limitation of the work is that tuning hyperparameters (learning rate, weight decay, interpolation constant $\beta$) may implicitly be tuning an LR schedule. This is especially the case for this technique since the role of these hyperparameters is quite subtle given the unusual form of the update sequences. Now the authors may argue that they address this with their MLCommons Algorithmic Efficiency experiments that reportedly use the same set of hyperparameter across all tasks, but in my opinion this could be a fluke relating to all the MLCommons tasks involving similar training times for instance. What I would want to see to convince me otherwise is to see experiments that sweep across beta for different training times, and check if the optimal beta is invariant to training time, say.

### **Paper applies a potentially ill-suited theoretical framework to deep learning, and as such there are gaps**

The paper comes from a part of the community that uses convex optimization frameworks to do algorithm design, and then extends the methods to deep network training. Sometimes the extension can feel a bit forced: e.g. let's switch to Adam instead of SGD as our base optimiser because it works better, let's use learning rate warmup because it works better, etc. The paper uses theorems within this convex framework to support its significance, but as far as I can tell these theorems don't answer basic questions a practitioner would have about the technique: e.g. Theorems 1 and 2 provided no guidance on setting the interpolation parameter $\beta$ since they hold uniformly for all $\beta \in [0,1]$.

I want to point out that another part of the community is trying to build up understanding and frameworks for deep learning fundamentals that involve less of a ""jump"" from convex optimisation to deep learning. To point out two examples:
- https://arxiv.org/abs/2103.00065 ""Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability""
- https://arxiv.org/abs/2405.14813 ""Scalable Optimization in the Modular Norm"" (concurrent work)

I think it would be great to at least read these works and potentially engage with them---not in this paper, but in the future

### **Final note**

I sometimes worry about giving frank feedback as I think I can sometimes have a blunt style. I want to re-emphasise that I really like this paper. I think the idea is clever and creative, and I really encourage you to pursue these directions further. The feedback is intended constructively. I am currently giving the paper a score of 5 because a score of 6 requires ""no major concerns with respect to evaluation"" and I am not there yet. I can get there if I become confident that you've engaged with my review.","- do you know if beta is sensitive to e.g. training time? Fine if you don't know, but consider adding a limitation saying future work could investigate this closer
- which sequence is used to do inference x, or y, or z? It might be worth clearly flagging this in this paper. Sorry if I just missed it.","""Note that we excluded one benchmark problem, ResNet-50 training, as neither AdamW nor NAdamW can hit the target accuracy on that task."" ---- this feels artificial to me. I still want to know how schedule free AdamW does!",['No ethics review needed.'],5,4,,Yes,3,3,2,1720797532124,,,NeurIPS.cc/2024/Conference,0XeNkkENuI,"['NeurIPS.cc/2024/Conference/Submission14/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878618723,[],3,,,['everyone'],0XeNkkENuI,['NeurIPS.cc/2024/Conference/Submission14/Reviewer_Q984'],1720797532124,1730878618723,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission14/Reviewer_Q984']","Yes, the peer review explicitly suggests the authors of the paper to engage with and potentially cite two specific literature:

1. https://arxiv.org/abs/2103.00065 ""Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability""
2. https://arxiv.org/abs/2405.14813 ""Scalable Optimization in the Modular Norm"" (concurrent work)

The reviewer mentions that it would be great for the authors to ""at least read these works and potentially engage with them---not in this paper, but in the future"". This implies that the reviewer thinks the authors could benefit from exploring these alternative frameworks for deep learning fundamentals, but does not necessarily expect them to be cited in the current paper.",1,"2021, 2024",Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability 
x2glxioLED,"The authors propose a method for training neural nets without needing to know the total training time T in advance. This contrasts with a standard training setup where one chooses a learning rate schedule in advance, and the schedule must include an a priori chosen stopping time T (e.g. cosine schedule or linear decay). If the method really works as advertised it therefore simplifies practical training setups and reduces the cost of training, by avoiding the need to run multiple training runs with different values of stopping time T.

The method works by tracking two sequences: one is the ""noisy"" sequence z that integrates noisy gradient updates, the second is the ""smoothed"" sequence x that tracks a uniform average over all past noisy iterates z. Gradients are evaluated at an interpolation between the current noisy z and smoothed x sequence, and added back to the noisy z sequence which is then averaged into the smoothed x sequence.

Authors present theoretical results about their technique for convex optimisation, and evaluate the method across a set of training benchmarks, some that involve tuning and some that don't. The results look promising.","- the idea is legitimately really cool and clever and seems very original to me. People know that weight averaging on top of standard training can boost performance, so it's really cool to ask ""is there a way to fold this back into the training loop"" as the authors do. 
- my broad understanding of the technique is that it's doing noise filtering in a clever way, and I think that this idea can inspire others to explore this direction, which is great
- the paper is very clearly written and I like the mix of the intuitive description of the technique, the formal results, and then the experimental evaluation
- it's great that the authors engaged with the MLCommons Algorithmic Efficiency benchmark, and from what I understand the results are very promising.","Okay as I've mentioned, I think the idea is cool and original and can inspire followup work, which is all we really want of a paper. So I'm going to focus on giving you feedback which is intended to be constructive and I hope can help you generally improve the quality of the work or followup work that you do. I'm not going to hold the paper hostage, but if I feel like you engage meaningfully with my critiques I'm willing to upgrade my score. All of my critiques can be addressed either by making minor amendments to text or by adding a limitations section at the end of the paper *or* by running more experiments and addressing them, but I won't insist on which and leave this up to the authors.

### **Paper may be over claiming slightly on its results**

The paper makes claims to be **""one of the largest and most comprehensive machine learning optimization algorithm evaluations”**. Can you quantify in what sense this is true? To me the evaluation doesn't feel that comprehensive---for instance, there is only one plot on hyperparameter sensitivity, while a broad swathe of the community has started to explore this question as standard in evaluations papers. The authors also state their method **""has no notable memory, computation or performance limitations compared to scheduling approaches""**. In my opinion, the truth value of this statement is essentially unknowable without more thorough evaluation. It would be fine to amend the statement by saying ""WE BELIEVE THAT our method has no notable memory, computation or performance limitations compared to scheduling approaches.""

### **Hyperparameter sensitivity is not thoroughly investigated**

In my opinion, the main potential limitation of the work is that tuning hyperparameters (learning rate, weight decay, interpolation constant $\beta$) may implicitly be tuning an LR schedule. This is especially the case for this technique since the role of these hyperparameters is quite subtle given the unusual form of the update sequences. Now the authors may argue that they address this with their MLCommons Algorithmic Efficiency experiments that reportedly use the same set of hyperparameter across all tasks, but in my opinion this could be a fluke relating to all the MLCommons tasks involving similar training times for instance. What I would want to see to convince me otherwise is to see experiments that sweep across beta for different training times, and check if the optimal beta is invariant to training time, say.

### **Paper applies a potentially ill-suited theoretical framework to deep learning, and as such there are gaps**

The paper comes from a part of the community that uses convex optimization frameworks to do algorithm design, and then extends the methods to deep network training. Sometimes the extension can feel a bit forced: e.g. let's switch to Adam instead of SGD as our base optimiser because it works better, let's use learning rate warmup because it works better, etc. The paper uses theorems within this convex framework to support its significance, but as far as I can tell these theorems don't answer basic questions a practitioner would have about the technique: e.g. Theorems 1 and 2 provided no guidance on setting the interpolation parameter $\beta$ since they hold uniformly for all $\beta \in [0,1]$.

I want to point out that another part of the community is trying to build up understanding and frameworks for deep learning fundamentals that involve less of a ""jump"" from convex optimisation to deep learning. To point out two examples:
- https://arxiv.org/abs/2103.00065 ""Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability""
- https://arxiv.org/abs/2405.14813 ""Scalable Optimization in the Modular Norm"" (concurrent work)

I think it would be great to at least read these works and potentially engage with them---not in this paper, but in the future

### **Final note**

I sometimes worry about giving frank feedback as I think I can sometimes have a blunt style. I want to re-emphasise that I really like this paper. I think the idea is clever and creative, and I really encourage you to pursue these directions further. The feedback is intended constructively. I am currently giving the paper a score of 5 because a score of 6 requires ""no major concerns with respect to evaluation"" and I am not there yet. I can get there if I become confident that you've engaged with my review.","- do you know if beta is sensitive to e.g. training time? Fine if you don't know, but consider adding a limitation saying future work could investigate this closer
- which sequence is used to do inference x, or y, or z? It might be worth clearly flagging this in this paper. Sorry if I just missed it.","""Note that we excluded one benchmark problem, ResNet-50 training, as neither AdamW nor NAdamW can hit the target accuracy on that task."" ---- this feels artificial to me. I still want to know how schedule free AdamW does!",['No ethics review needed.'],5,4,,Yes,3,3,2,1720797532124,,,NeurIPS.cc/2024/Conference,0XeNkkENuI,"['NeurIPS.cc/2024/Conference/Submission14/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878618723,[],3,,,['everyone'],0XeNkkENuI,['NeurIPS.cc/2024/Conference/Submission14/Reviewer_Q984'],1720797532124,1730878618723,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission14/Reviewer_Q984']","Yes, the peer review explicitly suggests the authors of the paper to engage with and potentially cite two specific literature:

1. https://arxiv.org/abs/2103.00065 ""Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability""
2. https://arxiv.org/abs/2405.14813 ""Scalable Optimization in the Modular Norm"" (concurrent work)

The reviewer mentions that it would be great for the authors to ""at least read these works and potentially engage with them---not in this paper, but in the future"". This implies that the reviewer thinks the authors could benefit from exploring these alternative frameworks for deep learning fundamentals, but does not necessarily expect them to be cited in the current paper.",1,"2021, 2024",Scalable Optimization in the Modular Norm
EpCxjnpBh9,"This paper introduces a novel knowledge distillation method called ScaleKD. The method aims to leverage well pre-trained vision transformer models as teacher models for a variety of student model architectures.the authors first adopt a cross attention projector to align student features with the teacher's. Then, a dual-view feature mimicking module and a teacher parameter perception module are used to achieve better knowledge transfer. Extensive experiments demonstrate the effectiveness of ScaleKD across various tasks and model types.","1. The paper is well-written and well-structured.
2. The authors provide extensive experimental results and analyses that demonstrate the effectiveness of the proposed method.","1. The paper's motivation could be strengthened. As highlighted in previous research [1], a stronger teacher model does not always equate to a better teacher. The necessity of adapting a ViT teacher for training a CNN student needs further justification. Including a comparison between ViT teachers and CNN teachers would provide better support.
2. The teacher parameter perception (TPP) module's cross-architecture KD paradigm is similar to techniques used in existing research [2,3]. While this does not diminish the novelty of other aspects of the paper, these related works should be properly discussed.
3. The authors critique the focus on ""evaluation on small datasets with non-mainstream student models"" in existing works. Some relevant papers about these issues should also be discussed, such as [4,5].

[1] Mirzadeh, Seyed Iman, et al. ""Improved knowledge distillation via teacher assistant."" Proceedings of the AAAI conference on artificial intelligence. Vol. 34. No. 04. 2020.

[2] Wang, Jiabao, et al. ""CrossKD: Cross-head knowledge distillation for object detection."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.

[3] Bai, Haoli, et al. ""Few shot network compression via cross distillation."" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 04. 2020.

[4] Hao, Zhiwei, et al. ""Vanillakd: Revisit the power of vanilla knowledge distillation from small scale to large scale."" arXiv preprint arXiv:2305.15781 (2023).

[5] Stanton, Samuel, et al. ""Does knowledge distillation really work?."" Advances in Neural Information Processing Systems 34 (2021): 6906-6919.","In the dual-view feature mimicking module, the direct component is omitted during the alternative feature mimicking process. However, the remaining non-direct features are duplicated in the normal matching process (as shown in the upper path in Figure 2b). How does the removal of the non-direct component in the upper path affect performance?",Yes,['No ethics review needed.'],6,4,,Yes,3,3,3,1718708809957,,,NeurIPS.cc/2024/Conference,0WCFI2Qx85,"['NeurIPS.cc/2024/Conference/Submission11330/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879457437,[],1,,,['everyone'],0WCFI2Qx85,['NeurIPS.cc/2024/Conference/Submission11330/Reviewer_mfZF'],1718708809957,1730879457437,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11330/Reviewer_mfZF']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Mirzadeh, Seyed Iman, et al. ""Improved knowledge distillation via teacher assistant."" (2020)
2. Wang, Jiabao, et al. ""CrossKD: Cross-head knowledge distillation for object detection."" (2024)
3. Bai, Haoli, et al. ""Few shot network compression via cross distillation."" (2020)
4. Hao, Zhiwei, et al. ""Vanillakd: Revisit the power of vanilla knowledge distillation from small scale to large scale."" (2023)
5. Stanton, Samuel, et al. ""Does knowledge distillation really work?."" (2021)

These citations are suggested to provide better support for the paper's motivation, to discuss related works, and to address the critique of existing works.",1,"2020, 2024, 2020, 2023, 2021",Improved knowledge distillation via teacher assistant 
EpCxjnpBh9,"This paper introduces a novel knowledge distillation method called ScaleKD. The method aims to leverage well pre-trained vision transformer models as teacher models for a variety of student model architectures.the authors first adopt a cross attention projector to align student features with the teacher's. Then, a dual-view feature mimicking module and a teacher parameter perception module are used to achieve better knowledge transfer. Extensive experiments demonstrate the effectiveness of ScaleKD across various tasks and model types.","1. The paper is well-written and well-structured.
2. The authors provide extensive experimental results and analyses that demonstrate the effectiveness of the proposed method.","1. The paper's motivation could be strengthened. As highlighted in previous research [1], a stronger teacher model does not always equate to a better teacher. The necessity of adapting a ViT teacher for training a CNN student needs further justification. Including a comparison between ViT teachers and CNN teachers would provide better support.
2. The teacher parameter perception (TPP) module's cross-architecture KD paradigm is similar to techniques used in existing research [2,3]. While this does not diminish the novelty of other aspects of the paper, these related works should be properly discussed.
3. The authors critique the focus on ""evaluation on small datasets with non-mainstream student models"" in existing works. Some relevant papers about these issues should also be discussed, such as [4,5].

[1] Mirzadeh, Seyed Iman, et al. ""Improved knowledge distillation via teacher assistant."" Proceedings of the AAAI conference on artificial intelligence. Vol. 34. No. 04. 2020.

[2] Wang, Jiabao, et al. ""CrossKD: Cross-head knowledge distillation for object detection."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.

[3] Bai, Haoli, et al. ""Few shot network compression via cross distillation."" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 04. 2020.

[4] Hao, Zhiwei, et al. ""Vanillakd: Revisit the power of vanilla knowledge distillation from small scale to large scale."" arXiv preprint arXiv:2305.15781 (2023).

[5] Stanton, Samuel, et al. ""Does knowledge distillation really work?."" Advances in Neural Information Processing Systems 34 (2021): 6906-6919.","In the dual-view feature mimicking module, the direct component is omitted during the alternative feature mimicking process. However, the remaining non-direct features are duplicated in the normal matching process (as shown in the upper path in Figure 2b). How does the removal of the non-direct component in the upper path affect performance?",Yes,['No ethics review needed.'],6,4,,Yes,3,3,3,1718708809957,,,NeurIPS.cc/2024/Conference,0WCFI2Qx85,"['NeurIPS.cc/2024/Conference/Submission11330/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879457437,[],1,,,['everyone'],0WCFI2Qx85,['NeurIPS.cc/2024/Conference/Submission11330/Reviewer_mfZF'],1718708809957,1730879457437,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11330/Reviewer_mfZF']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Mirzadeh, Seyed Iman, et al. ""Improved knowledge distillation via teacher assistant."" (2020)
2. Wang, Jiabao, et al. ""CrossKD: Cross-head knowledge distillation for object detection."" (2024)
3. Bai, Haoli, et al. ""Few shot network compression via cross distillation."" (2020)
4. Hao, Zhiwei, et al. ""Vanillakd: Revisit the power of vanilla knowledge distillation from small scale to large scale."" (2023)
5. Stanton, Samuel, et al. ""Does knowledge distillation really work?."" (2021)

These citations are suggested to provide better support for the paper's motivation, to discuss related works, and to address the critique of existing works.",1,"2020, 2024, 2020, 2023, 2021",CrossKD Cross-head knowledge distillation for object detection 
EpCxjnpBh9,"This paper introduces a novel knowledge distillation method called ScaleKD. The method aims to leverage well pre-trained vision transformer models as teacher models for a variety of student model architectures.the authors first adopt a cross attention projector to align student features with the teacher's. Then, a dual-view feature mimicking module and a teacher parameter perception module are used to achieve better knowledge transfer. Extensive experiments demonstrate the effectiveness of ScaleKD across various tasks and model types.","1. The paper is well-written and well-structured.
2. The authors provide extensive experimental results and analyses that demonstrate the effectiveness of the proposed method.","1. The paper's motivation could be strengthened. As highlighted in previous research [1], a stronger teacher model does not always equate to a better teacher. The necessity of adapting a ViT teacher for training a CNN student needs further justification. Including a comparison between ViT teachers and CNN teachers would provide better support.
2. The teacher parameter perception (TPP) module's cross-architecture KD paradigm is similar to techniques used in existing research [2,3]. While this does not diminish the novelty of other aspects of the paper, these related works should be properly discussed.
3. The authors critique the focus on ""evaluation on small datasets with non-mainstream student models"" in existing works. Some relevant papers about these issues should also be discussed, such as [4,5].

[1] Mirzadeh, Seyed Iman, et al. ""Improved knowledge distillation via teacher assistant."" Proceedings of the AAAI conference on artificial intelligence. Vol. 34. No. 04. 2020.

[2] Wang, Jiabao, et al. ""CrossKD: Cross-head knowledge distillation for object detection."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.

[3] Bai, Haoli, et al. ""Few shot network compression via cross distillation."" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 04. 2020.

[4] Hao, Zhiwei, et al. ""Vanillakd: Revisit the power of vanilla knowledge distillation from small scale to large scale."" arXiv preprint arXiv:2305.15781 (2023).

[5] Stanton, Samuel, et al. ""Does knowledge distillation really work?."" Advances in Neural Information Processing Systems 34 (2021): 6906-6919.","In the dual-view feature mimicking module, the direct component is omitted during the alternative feature mimicking process. However, the remaining non-direct features are duplicated in the normal matching process (as shown in the upper path in Figure 2b). How does the removal of the non-direct component in the upper path affect performance?",Yes,['No ethics review needed.'],6,4,,Yes,3,3,3,1718708809957,,,NeurIPS.cc/2024/Conference,0WCFI2Qx85,"['NeurIPS.cc/2024/Conference/Submission11330/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879457437,[],1,,,['everyone'],0WCFI2Qx85,['NeurIPS.cc/2024/Conference/Submission11330/Reviewer_mfZF'],1718708809957,1730879457437,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11330/Reviewer_mfZF']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Mirzadeh, Seyed Iman, et al. ""Improved knowledge distillation via teacher assistant."" (2020)
2. Wang, Jiabao, et al. ""CrossKD: Cross-head knowledge distillation for object detection."" (2024)
3. Bai, Haoli, et al. ""Few shot network compression via cross distillation."" (2020)
4. Hao, Zhiwei, et al. ""Vanillakd: Revisit the power of vanilla knowledge distillation from small scale to large scale."" (2023)
5. Stanton, Samuel, et al. ""Does knowledge distillation really work?."" (2021)

These citations are suggested to provide better support for the paper's motivation, to discuss related works, and to address the critique of existing works.",1,"2020, 2024, 2020, 2023, 2021",Few shot network compression via cross distillation 
EpCxjnpBh9,"This paper introduces a novel knowledge distillation method called ScaleKD. The method aims to leverage well pre-trained vision transformer models as teacher models for a variety of student model architectures.the authors first adopt a cross attention projector to align student features with the teacher's. Then, a dual-view feature mimicking module and a teacher parameter perception module are used to achieve better knowledge transfer. Extensive experiments demonstrate the effectiveness of ScaleKD across various tasks and model types.","1. The paper is well-written and well-structured.
2. The authors provide extensive experimental results and analyses that demonstrate the effectiveness of the proposed method.","1. The paper's motivation could be strengthened. As highlighted in previous research [1], a stronger teacher model does not always equate to a better teacher. The necessity of adapting a ViT teacher for training a CNN student needs further justification. Including a comparison between ViT teachers and CNN teachers would provide better support.
2. The teacher parameter perception (TPP) module's cross-architecture KD paradigm is similar to techniques used in existing research [2,3]. While this does not diminish the novelty of other aspects of the paper, these related works should be properly discussed.
3. The authors critique the focus on ""evaluation on small datasets with non-mainstream student models"" in existing works. Some relevant papers about these issues should also be discussed, such as [4,5].

[1] Mirzadeh, Seyed Iman, et al. ""Improved knowledge distillation via teacher assistant."" Proceedings of the AAAI conference on artificial intelligence. Vol. 34. No. 04. 2020.

[2] Wang, Jiabao, et al. ""CrossKD: Cross-head knowledge distillation for object detection."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.

[3] Bai, Haoli, et al. ""Few shot network compression via cross distillation."" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 04. 2020.

[4] Hao, Zhiwei, et al. ""Vanillakd: Revisit the power of vanilla knowledge distillation from small scale to large scale."" arXiv preprint arXiv:2305.15781 (2023).

[5] Stanton, Samuel, et al. ""Does knowledge distillation really work?."" Advances in Neural Information Processing Systems 34 (2021): 6906-6919.","In the dual-view feature mimicking module, the direct component is omitted during the alternative feature mimicking process. However, the remaining non-direct features are duplicated in the normal matching process (as shown in the upper path in Figure 2b). How does the removal of the non-direct component in the upper path affect performance?",Yes,['No ethics review needed.'],6,4,,Yes,3,3,3,1718708809957,,,NeurIPS.cc/2024/Conference,0WCFI2Qx85,"['NeurIPS.cc/2024/Conference/Submission11330/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879457437,[],1,,,['everyone'],0WCFI2Qx85,['NeurIPS.cc/2024/Conference/Submission11330/Reviewer_mfZF'],1718708809957,1730879457437,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11330/Reviewer_mfZF']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Mirzadeh, Seyed Iman, et al. ""Improved knowledge distillation via teacher assistant."" (2020)
2. Wang, Jiabao, et al. ""CrossKD: Cross-head knowledge distillation for object detection."" (2024)
3. Bai, Haoli, et al. ""Few shot network compression via cross distillation."" (2020)
4. Hao, Zhiwei, et al. ""Vanillakd: Revisit the power of vanilla knowledge distillation from small scale to large scale."" (2023)
5. Stanton, Samuel, et al. ""Does knowledge distillation really work?."" (2021)

These citations are suggested to provide better support for the paper's motivation, to discuss related works, and to address the critique of existing works.",1,"2020, 2024, 2020, 2023, 2021",Vanillakd Revisit the power of vanilla knowledge distillation from small scale to large scale 
EpCxjnpBh9,"This paper introduces a novel knowledge distillation method called ScaleKD. The method aims to leverage well pre-trained vision transformer models as teacher models for a variety of student model architectures.the authors first adopt a cross attention projector to align student features with the teacher's. Then, a dual-view feature mimicking module and a teacher parameter perception module are used to achieve better knowledge transfer. Extensive experiments demonstrate the effectiveness of ScaleKD across various tasks and model types.","1. The paper is well-written and well-structured.
2. The authors provide extensive experimental results and analyses that demonstrate the effectiveness of the proposed method.","1. The paper's motivation could be strengthened. As highlighted in previous research [1], a stronger teacher model does not always equate to a better teacher. The necessity of adapting a ViT teacher for training a CNN student needs further justification. Including a comparison between ViT teachers and CNN teachers would provide better support.
2. The teacher parameter perception (TPP) module's cross-architecture KD paradigm is similar to techniques used in existing research [2,3]. While this does not diminish the novelty of other aspects of the paper, these related works should be properly discussed.
3. The authors critique the focus on ""evaluation on small datasets with non-mainstream student models"" in existing works. Some relevant papers about these issues should also be discussed, such as [4,5].

[1] Mirzadeh, Seyed Iman, et al. ""Improved knowledge distillation via teacher assistant."" Proceedings of the AAAI conference on artificial intelligence. Vol. 34. No. 04. 2020.

[2] Wang, Jiabao, et al. ""CrossKD: Cross-head knowledge distillation for object detection."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.

[3] Bai, Haoli, et al. ""Few shot network compression via cross distillation."" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 04. 2020.

[4] Hao, Zhiwei, et al. ""Vanillakd: Revisit the power of vanilla knowledge distillation from small scale to large scale."" arXiv preprint arXiv:2305.15781 (2023).

[5] Stanton, Samuel, et al. ""Does knowledge distillation really work?."" Advances in Neural Information Processing Systems 34 (2021): 6906-6919.","In the dual-view feature mimicking module, the direct component is omitted during the alternative feature mimicking process. However, the remaining non-direct features are duplicated in the normal matching process (as shown in the upper path in Figure 2b). How does the removal of the non-direct component in the upper path affect performance?",Yes,['No ethics review needed.'],6,4,,Yes,3,3,3,1718708809957,,,NeurIPS.cc/2024/Conference,0WCFI2Qx85,"['NeurIPS.cc/2024/Conference/Submission11330/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879457437,[],1,,,['everyone'],0WCFI2Qx85,['NeurIPS.cc/2024/Conference/Submission11330/Reviewer_mfZF'],1718708809957,1730879457437,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11330/Reviewer_mfZF']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Mirzadeh, Seyed Iman, et al. ""Improved knowledge distillation via teacher assistant."" (2020)
2. Wang, Jiabao, et al. ""CrossKD: Cross-head knowledge distillation for object detection."" (2024)
3. Bai, Haoli, et al. ""Few shot network compression via cross distillation."" (2020)
4. Hao, Zhiwei, et al. ""Vanillakd: Revisit the power of vanilla knowledge distillation from small scale to large scale."" (2023)
5. Stanton, Samuel, et al. ""Does knowledge distillation really work?."" (2021)

These citations are suggested to provide better support for the paper's motivation, to discuss related works, and to address the critique of existing works.",1,"2020, 2024, 2020, 2023, 2021",Does knowledge distillation really work
NbBj8onTXB,The paper introduces a novel approach to knowledge distillation for Large Language Models (LLMs) using an adversarial training method that incorporates both on and off-policy distillation. The method jointly learns a critic that estimates Q-values while updating both the Q-function and the student model to more closely match the teacher model. The authors employ a policy gradient method to update the student model.,"+ As far as I am aware, a novel approach to knowledge distillation for LLMs -- although I am not an expert.
+ A well-presented method, tying together some previous ideas on IRL into the distillation application.
+ Demonstrates a boost to accuracy.","+ Some crucial details are unclear, particularly regarding the parameterization of the Q-value function (see questions section)
+ Not very much discussion of the computational complexity or additional overhead in memory of having multiple models and requiring rollouts from the teacher and student model while training
+ Lack of ablation studies -- the method is evaluated as a single monolithic method, when there are many variants that could be applied, such as a weighted combination of the two upper bounds. In particular, I'd like to see how the method using only the on-policy upper bound and the method using only the off-policy upper bound would compare against the method using the linear combination of the on and off policy upper bounds.","+ How exactly is the Q-value function parameterized? Is it an extra head on the model, or a new model entirely?
+ Regarding the use of policy gradients for training the student function:
   a. Did you use a baseline to reduce variance?
   b. What is the variance of these policy gradients? In applications such as RL, policy gradients typically have quite high variance compared to other methods.
   c. Have you considered lightweight baseline methods, such as those presented in [1]?
+ Can you provide an ablation of the different elements of the approach, such as investigating the relative importance of the two upper bounds?
+ Can you provide an analysis -- even if it is brief -- on the computational cost and memory usage of using the additional Q-value critics while training?



[1] Ahmadian, Arash, et al. ""Back to basics: Revisiting reinforce style optimization for learning from human feedback in llms."" arXiv preprint arXiv:2402.14740 (2024).",Yes,['No ethics review needed.'],7,4,,Yes,3,3,3,1720594268852,,,NeurIPS.cc/2024/Conference,0VeSCjRDBy,"['NeurIPS.cc/2024/Conference/Submission16268/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879833617,[],3,,,['everyone'],0VeSCjRDBy,['NeurIPS.cc/2024/Conference/Submission16268/Reviewer_8hQS'],1720594268852,1730879833617,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission16268/Reviewer_8hQS']","Yes, this peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

[1] Ahmadian, Arash, et al. ""Back to basics: Revisiting reinforce style optimization for learning from human feedback in llms."" arXiv preprint arXiv:2402.14740 (2024).

The reviewer mentions this paper in the context of suggesting the use of lightweight baseline methods for reducing variance in policy gradients.",1,"2024, 2024",Back to basics Revisiting reinforce style optimization for learning from human feedback in llms
raW2IrHvhg,"Paper proposes CoFie — 3D shape representation as a set of latents arranged on a regular voxel grid. Each latent encodes an oriented local quadratic patch. This local oriented patch defines local SDF in a local coordinate frame which is decoded via conditional MLP for which the last layer is quadratic: it defines a bilnear form on input vector instead of linear mapping). SDF value for query point x is decided based on the SDF value of local implicit function belonging to the nearest voxel and transformed from local coordinate frame to global. 

Authors train proposed methods and baselines on a single random subsample of 1000 ShapeNet shapes (5 categories, 200 shapes each) and evaluate on holdout ShapeNet shapes and out-of-distribution shapes from Thingi10K. Proposed method outperforms baselines trained in the same limited data regime. The same ShapeNet model is also evaluated with the Neural Geometric Level of Detail method and DeepSDF fitted in the shape overfitting scenario.","— Proposed representation is more efficient compared to regular latent grids and is comparable to surface latent grids (3DILG) in terms of latents needed to represent shape; 
— Method figure is clear and well done and quantitative results are well formatted;
— Qualitative results look comparable to NGLOD which is a strong baseline for shape overfitting setting;
— Design choices are clearly ablated (Table 4);","— Proposed method seems to be very similar to AutoSDF and SDFusion: both methods utilize a regular latent grid that encodes local SDF that is used to infer the global SDF. Main difference seems to be in a local SDF decoder that is quadratic (last layer) for proposed method and also encodes SDF in the local coordinate frame (SDFusion and AutoSDF use global coordinates). Overall, it is fine as long as proposed method compares to these similar methods but evaluation of the paper is limited (see below). 

— Similarly to other regular latent grids methods (e.g. SDFusion, AutoSDF), this model scales cubically with respect to grid resolution and thus might not be well suited for representation of topologically challenging shapes with thin parts. 

— Evaluation of the paper is extremely limited. For point cloud reconstruction (auto-encoding), proposed methods and baselines are trained on 5 ShapeNet categories with 200 shapes per category (overall 1000 shapes). This evaluation is not enough to support the claim that CoFie “can represent arbitrary shapes that belong to any novel category” (LL52-53). These results might only indicate that CoFie might be better representation in low-data regime but in this case evaluation should be done similar to few-shot learning setting: all models should be trained on several different subsets of ShapeNet (e.g. 5) and average/std of test errors should be reported. I also want to note that 3D2VS trained on full ShapeNet is an extremely strong baseline that achieves almost perfect reconstruction quality for some categories (like airplanes). Also, the paper only uses Chamfer distance for evaluation and ignores other common measures like IoU and surface F-Score. 


— The choice of baselines is also limited. DeepSDF is a 2019 paper that uses a very simple Pointnet (not even PointNet++) encoder. DeepLS is a 2020 paper. 3D2VS seems to be the only recent baseline for 3D point cloud reconstruction. It is a very strong baseline but authors have not used pretrained models and trained their version on limited data instead. Given the fact that 3D2VS uses a very high capacity attention-based decoder, this training regime might not be a fair comparison because attention-based models often struggle in low data regimes. For the same reason, 3D2VS might not be a good baseline if the goal of the paper is to show that their representation is compact. In this case, 3DILG might be a more suitable and strong baseline (see below) because it uses a simpler local patch encoder (Pointnet), so it might work better in a limited data regime. Since the model utilizes local surface patches similarly to AtlasNet (see links below), it also can be a strong baseline, especially in low data setting. 

— Evaluation in an overfitting setting  does not seem methodologically correct. : NGLOD and DeepSDF overfit to single shapes while CoFie was pretrained trained on 1000 shapes. These are completely different settings: overfitting regime measures capability of the model to efficiently fit one shape with preservation of geometric detail, and fitting and evaluation on collection of shapes evaluates the ability of the model to generalize to unseen shapes. This experiment should either be done if fully overfitting setting (similar to NGLOD paper) or in a reconstruction setting (see concerns above). 

— Quadratic MLP contribution seems a little bit weak to me. It looks like it is basically equivalent to linear MLP being run on quadratic feature expansion and in this case commonly fourier embeddings of points can be a very strong alternative (this is not tested). 

— Paper writing can be significantly improved in clarity. For example, paper does not specify input to auto-encoder for baselines. Is it point cloud or mesh? If it is a point cloud, what is the density of sampling and what sampling was used (FPS, random, poisson disk sampling, etc). How many codes were used to train 3D2VS? 512? What were hyperparameters for baseline training? On the other hand, paper spends a lot of space describing relatively common knowledge like MLP with ReLU activations (LL172-177). Another example is equation (5). On first glance it appears as weighted average, but since authors use voxel indicator function as weight, it means that for each query point x, global implicit function is based only on implicit function of nearest voxel grid latent. 

— Some statements in the paper are not correct. For example, the paper states that 3D2VS “employs transformers to predict the shape latent code” (LL258-260) . This is not factually correct: 3D2VS does not represent shape as one vector, it uses latent code clouds (usually 512 codes per shape). 

— Representation seems to be computationally expensive. Training on 1000 shapes takes one day on 4 GPUs with 24 GB VRAM. 

— Some relevant work is missing

AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation https://arxiv.org/abs/2203.09516 

SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation
https://arxiv.org/abs/2212.04493 

4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks https://arxiv.org/abs/1904.08755 

3DILG: Irregular Latent Grids for 3D Generative Modeling https://arxiv.org/abs/2205.13914 


AtlasNet: A Papier-Mâché Approach to Learning 3D Surface Generation https://arxiv.org/abs/1802.05384","— What is the input for the model for auto-encoding settings? Is it a point cloud? Or model back propagates into learnable latent code like DeepSDF? If it is a point cloud, what encoder model is used? If model back propagates into latent code, how come it is generalizable?

— How were baselines trained? Were they trained on the same inputs as the proposed method? Did all methods use the same SDF sampling? As far as I know, 3D2VS uses occupancy as supervision. Was it trained with SDF or occupancy supervision for the paper? 

— What motivated size 1000 for a training dataset? Majority of modern shape auto-encoder train either on full ShapeNet of full ShapeNet categories (e.g. ~6000 ShapeNet chairs). If 5 different subsets of ShapeNet of size 1000 would be selected (same categories), how high would be the variance in evaluation across these subsets? I have strong suspicion that results shown int Tables 1 and Tables 2 might not generalize across training subsamples. 

— Have you tried using Fourier embeddings of input coordinates instead of quadratic layers? This might be a very strong alternative since it helps coordinate based models to encode high-frequency details very efficiently.","— Proposed method represents the shape as a set of latents arranged on a regular latent grid and thus scales cubically with latent grid resolution. This limits method’s ability to efficiently encode topologically challenging shapes. 

— Method requires a lot of compute to fit 1000 shapes (1 day on 4GPUs with 24GB VRAM). This might be due to fact that authors use 32^3 latent grid (SDFusion for example uses 8^3). This severely limits scalability of the proposed method even for training on full ShapeNet, not to mention larger datasets like Objaverse.",['No ethics review needed.'],3,4,,Yes,2,2,2,1720840324339,,,NeurIPS.cc/2024/Conference,0KseSacluJ,"['NeurIPS.cc/2024/Conference/Submission3012/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878820242,[],4,,,['everyone'],0KseSacluJ,['NeurIPS.cc/2024/Conference/Submission3012/Reviewer_V5fn'],1720840324339,1730878820242,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3012/Reviewer_V5fn']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation (https://arxiv.org/abs/2203.09516)
2. SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation (https://arxiv.org/abs/2212.04493)
3. 4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks (https://arxiv.org/abs/1904.08755)
4. 3DILG: Irregular Latent Grids for 3D Generative Modeling (https://arxiv.org/abs/2205.13914)
5. AtlasNet: A Papier-Mâché Approach to Learning 3D Surface Generation (https://arxiv.org/abs/1802.05384)

The reviewer mentions that these papers are relevant to the proposed method and should be cited.",1,"2022, 2022, 2019, 2022, 2018",AutoSDF Shape Priors for 3D Completion Reconstruction and Generation
raW2IrHvhg,"Paper proposes CoFie — 3D shape representation as a set of latents arranged on a regular voxel grid. Each latent encodes an oriented local quadratic patch. This local oriented patch defines local SDF in a local coordinate frame which is decoded via conditional MLP for which the last layer is quadratic: it defines a bilnear form on input vector instead of linear mapping). SDF value for query point x is decided based on the SDF value of local implicit function belonging to the nearest voxel and transformed from local coordinate frame to global. 

Authors train proposed methods and baselines on a single random subsample of 1000 ShapeNet shapes (5 categories, 200 shapes each) and evaluate on holdout ShapeNet shapes and out-of-distribution shapes from Thingi10K. Proposed method outperforms baselines trained in the same limited data regime. The same ShapeNet model is also evaluated with the Neural Geometric Level of Detail method and DeepSDF fitted in the shape overfitting scenario.","— Proposed representation is more efficient compared to regular latent grids and is comparable to surface latent grids (3DILG) in terms of latents needed to represent shape; 
— Method figure is clear and well done and quantitative results are well formatted;
— Qualitative results look comparable to NGLOD which is a strong baseline for shape overfitting setting;
— Design choices are clearly ablated (Table 4);","— Proposed method seems to be very similar to AutoSDF and SDFusion: both methods utilize a regular latent grid that encodes local SDF that is used to infer the global SDF. Main difference seems to be in a local SDF decoder that is quadratic (last layer) for proposed method and also encodes SDF in the local coordinate frame (SDFusion and AutoSDF use global coordinates). Overall, it is fine as long as proposed method compares to these similar methods but evaluation of the paper is limited (see below). 

— Similarly to other regular latent grids methods (e.g. SDFusion, AutoSDF), this model scales cubically with respect to grid resolution and thus might not be well suited for representation of topologically challenging shapes with thin parts. 

— Evaluation of the paper is extremely limited. For point cloud reconstruction (auto-encoding), proposed methods and baselines are trained on 5 ShapeNet categories with 200 shapes per category (overall 1000 shapes). This evaluation is not enough to support the claim that CoFie “can represent arbitrary shapes that belong to any novel category” (LL52-53). These results might only indicate that CoFie might be better representation in low-data regime but in this case evaluation should be done similar to few-shot learning setting: all models should be trained on several different subsets of ShapeNet (e.g. 5) and average/std of test errors should be reported. I also want to note that 3D2VS trained on full ShapeNet is an extremely strong baseline that achieves almost perfect reconstruction quality for some categories (like airplanes). Also, the paper only uses Chamfer distance for evaluation and ignores other common measures like IoU and surface F-Score. 


— The choice of baselines is also limited. DeepSDF is a 2019 paper that uses a very simple Pointnet (not even PointNet++) encoder. DeepLS is a 2020 paper. 3D2VS seems to be the only recent baseline for 3D point cloud reconstruction. It is a very strong baseline but authors have not used pretrained models and trained their version on limited data instead. Given the fact that 3D2VS uses a very high capacity attention-based decoder, this training regime might not be a fair comparison because attention-based models often struggle in low data regimes. For the same reason, 3D2VS might not be a good baseline if the goal of the paper is to show that their representation is compact. In this case, 3DILG might be a more suitable and strong baseline (see below) because it uses a simpler local patch encoder (Pointnet), so it might work better in a limited data regime. Since the model utilizes local surface patches similarly to AtlasNet (see links below), it also can be a strong baseline, especially in low data setting. 

— Evaluation in an overfitting setting  does not seem methodologically correct. : NGLOD and DeepSDF overfit to single shapes while CoFie was pretrained trained on 1000 shapes. These are completely different settings: overfitting regime measures capability of the model to efficiently fit one shape with preservation of geometric detail, and fitting and evaluation on collection of shapes evaluates the ability of the model to generalize to unseen shapes. This experiment should either be done if fully overfitting setting (similar to NGLOD paper) or in a reconstruction setting (see concerns above). 

— Quadratic MLP contribution seems a little bit weak to me. It looks like it is basically equivalent to linear MLP being run on quadratic feature expansion and in this case commonly fourier embeddings of points can be a very strong alternative (this is not tested). 

— Paper writing can be significantly improved in clarity. For example, paper does not specify input to auto-encoder for baselines. Is it point cloud or mesh? If it is a point cloud, what is the density of sampling and what sampling was used (FPS, random, poisson disk sampling, etc). How many codes were used to train 3D2VS? 512? What were hyperparameters for baseline training? On the other hand, paper spends a lot of space describing relatively common knowledge like MLP with ReLU activations (LL172-177). Another example is equation (5). On first glance it appears as weighted average, but since authors use voxel indicator function as weight, it means that for each query point x, global implicit function is based only on implicit function of nearest voxel grid latent. 

— Some statements in the paper are not correct. For example, the paper states that 3D2VS “employs transformers to predict the shape latent code” (LL258-260) . This is not factually correct: 3D2VS does not represent shape as one vector, it uses latent code clouds (usually 512 codes per shape). 

— Representation seems to be computationally expensive. Training on 1000 shapes takes one day on 4 GPUs with 24 GB VRAM. 

— Some relevant work is missing

AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation https://arxiv.org/abs/2203.09516 

SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation
https://arxiv.org/abs/2212.04493 

4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks https://arxiv.org/abs/1904.08755 

3DILG: Irregular Latent Grids for 3D Generative Modeling https://arxiv.org/abs/2205.13914 


AtlasNet: A Papier-Mâché Approach to Learning 3D Surface Generation https://arxiv.org/abs/1802.05384","— What is the input for the model for auto-encoding settings? Is it a point cloud? Or model back propagates into learnable latent code like DeepSDF? If it is a point cloud, what encoder model is used? If model back propagates into latent code, how come it is generalizable?

— How were baselines trained? Were they trained on the same inputs as the proposed method? Did all methods use the same SDF sampling? As far as I know, 3D2VS uses occupancy as supervision. Was it trained with SDF or occupancy supervision for the paper? 

— What motivated size 1000 for a training dataset? Majority of modern shape auto-encoder train either on full ShapeNet of full ShapeNet categories (e.g. ~6000 ShapeNet chairs). If 5 different subsets of ShapeNet of size 1000 would be selected (same categories), how high would be the variance in evaluation across these subsets? I have strong suspicion that results shown int Tables 1 and Tables 2 might not generalize across training subsamples. 

— Have you tried using Fourier embeddings of input coordinates instead of quadratic layers? This might be a very strong alternative since it helps coordinate based models to encode high-frequency details very efficiently.","— Proposed method represents the shape as a set of latents arranged on a regular latent grid and thus scales cubically with latent grid resolution. This limits method’s ability to efficiently encode topologically challenging shapes. 

— Method requires a lot of compute to fit 1000 shapes (1 day on 4GPUs with 24GB VRAM). This might be due to fact that authors use 32^3 latent grid (SDFusion for example uses 8^3). This severely limits scalability of the proposed method even for training on full ShapeNet, not to mention larger datasets like Objaverse.",['No ethics review needed.'],3,4,,Yes,2,2,2,1720840324339,,,NeurIPS.cc/2024/Conference,0KseSacluJ,"['NeurIPS.cc/2024/Conference/Submission3012/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878820242,[],4,,,['everyone'],0KseSacluJ,['NeurIPS.cc/2024/Conference/Submission3012/Reviewer_V5fn'],1720840324339,1730878820242,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3012/Reviewer_V5fn']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation (https://arxiv.org/abs/2203.09516)
2. SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation (https://arxiv.org/abs/2212.04493)
3. 4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks (https://arxiv.org/abs/1904.08755)
4. 3DILG: Irregular Latent Grids for 3D Generative Modeling (https://arxiv.org/abs/2205.13914)
5. AtlasNet: A Papier-Mâché Approach to Learning 3D Surface Generation (https://arxiv.org/abs/1802.05384)

The reviewer mentions that these papers are relevant to the proposed method and should be cited.",1,"2022, 2022, 2019, 2022, 2018",SDFusion Multimodal 3D Shape Completion Reconstruction and Generation
raW2IrHvhg,"Paper proposes CoFie — 3D shape representation as a set of latents arranged on a regular voxel grid. Each latent encodes an oriented local quadratic patch. This local oriented patch defines local SDF in a local coordinate frame which is decoded via conditional MLP for which the last layer is quadratic: it defines a bilnear form on input vector instead of linear mapping). SDF value for query point x is decided based on the SDF value of local implicit function belonging to the nearest voxel and transformed from local coordinate frame to global. 

Authors train proposed methods and baselines on a single random subsample of 1000 ShapeNet shapes (5 categories, 200 shapes each) and evaluate on holdout ShapeNet shapes and out-of-distribution shapes from Thingi10K. Proposed method outperforms baselines trained in the same limited data regime. The same ShapeNet model is also evaluated with the Neural Geometric Level of Detail method and DeepSDF fitted in the shape overfitting scenario.","— Proposed representation is more efficient compared to regular latent grids and is comparable to surface latent grids (3DILG) in terms of latents needed to represent shape; 
— Method figure is clear and well done and quantitative results are well formatted;
— Qualitative results look comparable to NGLOD which is a strong baseline for shape overfitting setting;
— Design choices are clearly ablated (Table 4);","— Proposed method seems to be very similar to AutoSDF and SDFusion: both methods utilize a regular latent grid that encodes local SDF that is used to infer the global SDF. Main difference seems to be in a local SDF decoder that is quadratic (last layer) for proposed method and also encodes SDF in the local coordinate frame (SDFusion and AutoSDF use global coordinates). Overall, it is fine as long as proposed method compares to these similar methods but evaluation of the paper is limited (see below). 

— Similarly to other regular latent grids methods (e.g. SDFusion, AutoSDF), this model scales cubically with respect to grid resolution and thus might not be well suited for representation of topologically challenging shapes with thin parts. 

— Evaluation of the paper is extremely limited. For point cloud reconstruction (auto-encoding), proposed methods and baselines are trained on 5 ShapeNet categories with 200 shapes per category (overall 1000 shapes). This evaluation is not enough to support the claim that CoFie “can represent arbitrary shapes that belong to any novel category” (LL52-53). These results might only indicate that CoFie might be better representation in low-data regime but in this case evaluation should be done similar to few-shot learning setting: all models should be trained on several different subsets of ShapeNet (e.g. 5) and average/std of test errors should be reported. I also want to note that 3D2VS trained on full ShapeNet is an extremely strong baseline that achieves almost perfect reconstruction quality for some categories (like airplanes). Also, the paper only uses Chamfer distance for evaluation and ignores other common measures like IoU and surface F-Score. 


— The choice of baselines is also limited. DeepSDF is a 2019 paper that uses a very simple Pointnet (not even PointNet++) encoder. DeepLS is a 2020 paper. 3D2VS seems to be the only recent baseline for 3D point cloud reconstruction. It is a very strong baseline but authors have not used pretrained models and trained their version on limited data instead. Given the fact that 3D2VS uses a very high capacity attention-based decoder, this training regime might not be a fair comparison because attention-based models often struggle in low data regimes. For the same reason, 3D2VS might not be a good baseline if the goal of the paper is to show that their representation is compact. In this case, 3DILG might be a more suitable and strong baseline (see below) because it uses a simpler local patch encoder (Pointnet), so it might work better in a limited data regime. Since the model utilizes local surface patches similarly to AtlasNet (see links below), it also can be a strong baseline, especially in low data setting. 

— Evaluation in an overfitting setting  does not seem methodologically correct. : NGLOD and DeepSDF overfit to single shapes while CoFie was pretrained trained on 1000 shapes. These are completely different settings: overfitting regime measures capability of the model to efficiently fit one shape with preservation of geometric detail, and fitting and evaluation on collection of shapes evaluates the ability of the model to generalize to unseen shapes. This experiment should either be done if fully overfitting setting (similar to NGLOD paper) or in a reconstruction setting (see concerns above). 

— Quadratic MLP contribution seems a little bit weak to me. It looks like it is basically equivalent to linear MLP being run on quadratic feature expansion and in this case commonly fourier embeddings of points can be a very strong alternative (this is not tested). 

— Paper writing can be significantly improved in clarity. For example, paper does not specify input to auto-encoder for baselines. Is it point cloud or mesh? If it is a point cloud, what is the density of sampling and what sampling was used (FPS, random, poisson disk sampling, etc). How many codes were used to train 3D2VS? 512? What were hyperparameters for baseline training? On the other hand, paper spends a lot of space describing relatively common knowledge like MLP with ReLU activations (LL172-177). Another example is equation (5). On first glance it appears as weighted average, but since authors use voxel indicator function as weight, it means that for each query point x, global implicit function is based only on implicit function of nearest voxel grid latent. 

— Some statements in the paper are not correct. For example, the paper states that 3D2VS “employs transformers to predict the shape latent code” (LL258-260) . This is not factually correct: 3D2VS does not represent shape as one vector, it uses latent code clouds (usually 512 codes per shape). 

— Representation seems to be computationally expensive. Training on 1000 shapes takes one day on 4 GPUs with 24 GB VRAM. 

— Some relevant work is missing

AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation https://arxiv.org/abs/2203.09516 

SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation
https://arxiv.org/abs/2212.04493 

4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks https://arxiv.org/abs/1904.08755 

3DILG: Irregular Latent Grids for 3D Generative Modeling https://arxiv.org/abs/2205.13914 


AtlasNet: A Papier-Mâché Approach to Learning 3D Surface Generation https://arxiv.org/abs/1802.05384","— What is the input for the model for auto-encoding settings? Is it a point cloud? Or model back propagates into learnable latent code like DeepSDF? If it is a point cloud, what encoder model is used? If model back propagates into latent code, how come it is generalizable?

— How were baselines trained? Were they trained on the same inputs as the proposed method? Did all methods use the same SDF sampling? As far as I know, 3D2VS uses occupancy as supervision. Was it trained with SDF or occupancy supervision for the paper? 

— What motivated size 1000 for a training dataset? Majority of modern shape auto-encoder train either on full ShapeNet of full ShapeNet categories (e.g. ~6000 ShapeNet chairs). If 5 different subsets of ShapeNet of size 1000 would be selected (same categories), how high would be the variance in evaluation across these subsets? I have strong suspicion that results shown int Tables 1 and Tables 2 might not generalize across training subsamples. 

— Have you tried using Fourier embeddings of input coordinates instead of quadratic layers? This might be a very strong alternative since it helps coordinate based models to encode high-frequency details very efficiently.","— Proposed method represents the shape as a set of latents arranged on a regular latent grid and thus scales cubically with latent grid resolution. This limits method’s ability to efficiently encode topologically challenging shapes. 

— Method requires a lot of compute to fit 1000 shapes (1 day on 4GPUs with 24GB VRAM). This might be due to fact that authors use 32^3 latent grid (SDFusion for example uses 8^3). This severely limits scalability of the proposed method even for training on full ShapeNet, not to mention larger datasets like Objaverse.",['No ethics review needed.'],3,4,,Yes,2,2,2,1720840324339,,,NeurIPS.cc/2024/Conference,0KseSacluJ,"['NeurIPS.cc/2024/Conference/Submission3012/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878820242,[],4,,,['everyone'],0KseSacluJ,['NeurIPS.cc/2024/Conference/Submission3012/Reviewer_V5fn'],1720840324339,1730878820242,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3012/Reviewer_V5fn']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation (https://arxiv.org/abs/2203.09516)
2. SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation (https://arxiv.org/abs/2212.04493)
3. 4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks (https://arxiv.org/abs/1904.08755)
4. 3DILG: Irregular Latent Grids for 3D Generative Modeling (https://arxiv.org/abs/2205.13914)
5. AtlasNet: A Papier-Mâché Approach to Learning 3D Surface Generation (https://arxiv.org/abs/1802.05384)

The reviewer mentions that these papers are relevant to the proposed method and should be cited.",1,"2022, 2022, 2019, 2022, 2018",4D Spatio-Temporal ConvNets Minkowski Convolutional Neural Networks
raW2IrHvhg,"Paper proposes CoFie — 3D shape representation as a set of latents arranged on a regular voxel grid. Each latent encodes an oriented local quadratic patch. This local oriented patch defines local SDF in a local coordinate frame which is decoded via conditional MLP for which the last layer is quadratic: it defines a bilnear form on input vector instead of linear mapping). SDF value for query point x is decided based on the SDF value of local implicit function belonging to the nearest voxel and transformed from local coordinate frame to global. 

Authors train proposed methods and baselines on a single random subsample of 1000 ShapeNet shapes (5 categories, 200 shapes each) and evaluate on holdout ShapeNet shapes and out-of-distribution shapes from Thingi10K. Proposed method outperforms baselines trained in the same limited data regime. The same ShapeNet model is also evaluated with the Neural Geometric Level of Detail method and DeepSDF fitted in the shape overfitting scenario.","— Proposed representation is more efficient compared to regular latent grids and is comparable to surface latent grids (3DILG) in terms of latents needed to represent shape; 
— Method figure is clear and well done and quantitative results are well formatted;
— Qualitative results look comparable to NGLOD which is a strong baseline for shape overfitting setting;
— Design choices are clearly ablated (Table 4);","— Proposed method seems to be very similar to AutoSDF and SDFusion: both methods utilize a regular latent grid that encodes local SDF that is used to infer the global SDF. Main difference seems to be in a local SDF decoder that is quadratic (last layer) for proposed method and also encodes SDF in the local coordinate frame (SDFusion and AutoSDF use global coordinates). Overall, it is fine as long as proposed method compares to these similar methods but evaluation of the paper is limited (see below). 

— Similarly to other regular latent grids methods (e.g. SDFusion, AutoSDF), this model scales cubically with respect to grid resolution and thus might not be well suited for representation of topologically challenging shapes with thin parts. 

— Evaluation of the paper is extremely limited. For point cloud reconstruction (auto-encoding), proposed methods and baselines are trained on 5 ShapeNet categories with 200 shapes per category (overall 1000 shapes). This evaluation is not enough to support the claim that CoFie “can represent arbitrary shapes that belong to any novel category” (LL52-53). These results might only indicate that CoFie might be better representation in low-data regime but in this case evaluation should be done similar to few-shot learning setting: all models should be trained on several different subsets of ShapeNet (e.g. 5) and average/std of test errors should be reported. I also want to note that 3D2VS trained on full ShapeNet is an extremely strong baseline that achieves almost perfect reconstruction quality for some categories (like airplanes). Also, the paper only uses Chamfer distance for evaluation and ignores other common measures like IoU and surface F-Score. 


— The choice of baselines is also limited. DeepSDF is a 2019 paper that uses a very simple Pointnet (not even PointNet++) encoder. DeepLS is a 2020 paper. 3D2VS seems to be the only recent baseline for 3D point cloud reconstruction. It is a very strong baseline but authors have not used pretrained models and trained their version on limited data instead. Given the fact that 3D2VS uses a very high capacity attention-based decoder, this training regime might not be a fair comparison because attention-based models often struggle in low data regimes. For the same reason, 3D2VS might not be a good baseline if the goal of the paper is to show that their representation is compact. In this case, 3DILG might be a more suitable and strong baseline (see below) because it uses a simpler local patch encoder (Pointnet), so it might work better in a limited data regime. Since the model utilizes local surface patches similarly to AtlasNet (see links below), it also can be a strong baseline, especially in low data setting. 

— Evaluation in an overfitting setting  does not seem methodologically correct. : NGLOD and DeepSDF overfit to single shapes while CoFie was pretrained trained on 1000 shapes. These are completely different settings: overfitting regime measures capability of the model to efficiently fit one shape with preservation of geometric detail, and fitting and evaluation on collection of shapes evaluates the ability of the model to generalize to unseen shapes. This experiment should either be done if fully overfitting setting (similar to NGLOD paper) or in a reconstruction setting (see concerns above). 

— Quadratic MLP contribution seems a little bit weak to me. It looks like it is basically equivalent to linear MLP being run on quadratic feature expansion and in this case commonly fourier embeddings of points can be a very strong alternative (this is not tested). 

— Paper writing can be significantly improved in clarity. For example, paper does not specify input to auto-encoder for baselines. Is it point cloud or mesh? If it is a point cloud, what is the density of sampling and what sampling was used (FPS, random, poisson disk sampling, etc). How many codes were used to train 3D2VS? 512? What were hyperparameters for baseline training? On the other hand, paper spends a lot of space describing relatively common knowledge like MLP with ReLU activations (LL172-177). Another example is equation (5). On first glance it appears as weighted average, but since authors use voxel indicator function as weight, it means that for each query point x, global implicit function is based only on implicit function of nearest voxel grid latent. 

— Some statements in the paper are not correct. For example, the paper states that 3D2VS “employs transformers to predict the shape latent code” (LL258-260) . This is not factually correct: 3D2VS does not represent shape as one vector, it uses latent code clouds (usually 512 codes per shape). 

— Representation seems to be computationally expensive. Training on 1000 shapes takes one day on 4 GPUs with 24 GB VRAM. 

— Some relevant work is missing

AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation https://arxiv.org/abs/2203.09516 

SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation
https://arxiv.org/abs/2212.04493 

4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks https://arxiv.org/abs/1904.08755 

3DILG: Irregular Latent Grids for 3D Generative Modeling https://arxiv.org/abs/2205.13914 


AtlasNet: A Papier-Mâché Approach to Learning 3D Surface Generation https://arxiv.org/abs/1802.05384","— What is the input for the model for auto-encoding settings? Is it a point cloud? Or model back propagates into learnable latent code like DeepSDF? If it is a point cloud, what encoder model is used? If model back propagates into latent code, how come it is generalizable?

— How were baselines trained? Were they trained on the same inputs as the proposed method? Did all methods use the same SDF sampling? As far as I know, 3D2VS uses occupancy as supervision. Was it trained with SDF or occupancy supervision for the paper? 

— What motivated size 1000 for a training dataset? Majority of modern shape auto-encoder train either on full ShapeNet of full ShapeNet categories (e.g. ~6000 ShapeNet chairs). If 5 different subsets of ShapeNet of size 1000 would be selected (same categories), how high would be the variance in evaluation across these subsets? I have strong suspicion that results shown int Tables 1 and Tables 2 might not generalize across training subsamples. 

— Have you tried using Fourier embeddings of input coordinates instead of quadratic layers? This might be a very strong alternative since it helps coordinate based models to encode high-frequency details very efficiently.","— Proposed method represents the shape as a set of latents arranged on a regular latent grid and thus scales cubically with latent grid resolution. This limits method’s ability to efficiently encode topologically challenging shapes. 

— Method requires a lot of compute to fit 1000 shapes (1 day on 4GPUs with 24GB VRAM). This might be due to fact that authors use 32^3 latent grid (SDFusion for example uses 8^3). This severely limits scalability of the proposed method even for training on full ShapeNet, not to mention larger datasets like Objaverse.",['No ethics review needed.'],3,4,,Yes,2,2,2,1720840324339,,,NeurIPS.cc/2024/Conference,0KseSacluJ,"['NeurIPS.cc/2024/Conference/Submission3012/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878820242,[],4,,,['everyone'],0KseSacluJ,['NeurIPS.cc/2024/Conference/Submission3012/Reviewer_V5fn'],1720840324339,1730878820242,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3012/Reviewer_V5fn']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation (https://arxiv.org/abs/2203.09516)
2. SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation (https://arxiv.org/abs/2212.04493)
3. 4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks (https://arxiv.org/abs/1904.08755)
4. 3DILG: Irregular Latent Grids for 3D Generative Modeling (https://arxiv.org/abs/2205.13914)
5. AtlasNet: A Papier-Mâché Approach to Learning 3D Surface Generation (https://arxiv.org/abs/1802.05384)

The reviewer mentions that these papers are relevant to the proposed method and should be cited.",1,"2022, 2022, 2019, 2022, 2018",3DILG Irregular Latent Grids for 3D Generative Modeling
raW2IrHvhg,"Paper proposes CoFie — 3D shape representation as a set of latents arranged on a regular voxel grid. Each latent encodes an oriented local quadratic patch. This local oriented patch defines local SDF in a local coordinate frame which is decoded via conditional MLP for which the last layer is quadratic: it defines a bilnear form on input vector instead of linear mapping). SDF value for query point x is decided based on the SDF value of local implicit function belonging to the nearest voxel and transformed from local coordinate frame to global. 

Authors train proposed methods and baselines on a single random subsample of 1000 ShapeNet shapes (5 categories, 200 shapes each) and evaluate on holdout ShapeNet shapes and out-of-distribution shapes from Thingi10K. Proposed method outperforms baselines trained in the same limited data regime. The same ShapeNet model is also evaluated with the Neural Geometric Level of Detail method and DeepSDF fitted in the shape overfitting scenario.","— Proposed representation is more efficient compared to regular latent grids and is comparable to surface latent grids (3DILG) in terms of latents needed to represent shape; 
— Method figure is clear and well done and quantitative results are well formatted;
— Qualitative results look comparable to NGLOD which is a strong baseline for shape overfitting setting;
— Design choices are clearly ablated (Table 4);","— Proposed method seems to be very similar to AutoSDF and SDFusion: both methods utilize a regular latent grid that encodes local SDF that is used to infer the global SDF. Main difference seems to be in a local SDF decoder that is quadratic (last layer) for proposed method and also encodes SDF in the local coordinate frame (SDFusion and AutoSDF use global coordinates). Overall, it is fine as long as proposed method compares to these similar methods but evaluation of the paper is limited (see below). 

— Similarly to other regular latent grids methods (e.g. SDFusion, AutoSDF), this model scales cubically with respect to grid resolution and thus might not be well suited for representation of topologically challenging shapes with thin parts. 

— Evaluation of the paper is extremely limited. For point cloud reconstruction (auto-encoding), proposed methods and baselines are trained on 5 ShapeNet categories with 200 shapes per category (overall 1000 shapes). This evaluation is not enough to support the claim that CoFie “can represent arbitrary shapes that belong to any novel category” (LL52-53). These results might only indicate that CoFie might be better representation in low-data regime but in this case evaluation should be done similar to few-shot learning setting: all models should be trained on several different subsets of ShapeNet (e.g. 5) and average/std of test errors should be reported. I also want to note that 3D2VS trained on full ShapeNet is an extremely strong baseline that achieves almost perfect reconstruction quality for some categories (like airplanes). Also, the paper only uses Chamfer distance for evaluation and ignores other common measures like IoU and surface F-Score. 


— The choice of baselines is also limited. DeepSDF is a 2019 paper that uses a very simple Pointnet (not even PointNet++) encoder. DeepLS is a 2020 paper. 3D2VS seems to be the only recent baseline for 3D point cloud reconstruction. It is a very strong baseline but authors have not used pretrained models and trained their version on limited data instead. Given the fact that 3D2VS uses a very high capacity attention-based decoder, this training regime might not be a fair comparison because attention-based models often struggle in low data regimes. For the same reason, 3D2VS might not be a good baseline if the goal of the paper is to show that their representation is compact. In this case, 3DILG might be a more suitable and strong baseline (see below) because it uses a simpler local patch encoder (Pointnet), so it might work better in a limited data regime. Since the model utilizes local surface patches similarly to AtlasNet (see links below), it also can be a strong baseline, especially in low data setting. 

— Evaluation in an overfitting setting  does not seem methodologically correct. : NGLOD and DeepSDF overfit to single shapes while CoFie was pretrained trained on 1000 shapes. These are completely different settings: overfitting regime measures capability of the model to efficiently fit one shape with preservation of geometric detail, and fitting and evaluation on collection of shapes evaluates the ability of the model to generalize to unseen shapes. This experiment should either be done if fully overfitting setting (similar to NGLOD paper) or in a reconstruction setting (see concerns above). 

— Quadratic MLP contribution seems a little bit weak to me. It looks like it is basically equivalent to linear MLP being run on quadratic feature expansion and in this case commonly fourier embeddings of points can be a very strong alternative (this is not tested). 

— Paper writing can be significantly improved in clarity. For example, paper does not specify input to auto-encoder for baselines. Is it point cloud or mesh? If it is a point cloud, what is the density of sampling and what sampling was used (FPS, random, poisson disk sampling, etc). How many codes were used to train 3D2VS? 512? What were hyperparameters for baseline training? On the other hand, paper spends a lot of space describing relatively common knowledge like MLP with ReLU activations (LL172-177). Another example is equation (5). On first glance it appears as weighted average, but since authors use voxel indicator function as weight, it means that for each query point x, global implicit function is based only on implicit function of nearest voxel grid latent. 

— Some statements in the paper are not correct. For example, the paper states that 3D2VS “employs transformers to predict the shape latent code” (LL258-260) . This is not factually correct: 3D2VS does not represent shape as one vector, it uses latent code clouds (usually 512 codes per shape). 

— Representation seems to be computationally expensive. Training on 1000 shapes takes one day on 4 GPUs with 24 GB VRAM. 

— Some relevant work is missing

AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation https://arxiv.org/abs/2203.09516 

SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation
https://arxiv.org/abs/2212.04493 

4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks https://arxiv.org/abs/1904.08755 

3DILG: Irregular Latent Grids for 3D Generative Modeling https://arxiv.org/abs/2205.13914 


AtlasNet: A Papier-Mâché Approach to Learning 3D Surface Generation https://arxiv.org/abs/1802.05384","— What is the input for the model for auto-encoding settings? Is it a point cloud? Or model back propagates into learnable latent code like DeepSDF? If it is a point cloud, what encoder model is used? If model back propagates into latent code, how come it is generalizable?

— How were baselines trained? Were they trained on the same inputs as the proposed method? Did all methods use the same SDF sampling? As far as I know, 3D2VS uses occupancy as supervision. Was it trained with SDF or occupancy supervision for the paper? 

— What motivated size 1000 for a training dataset? Majority of modern shape auto-encoder train either on full ShapeNet of full ShapeNet categories (e.g. ~6000 ShapeNet chairs). If 5 different subsets of ShapeNet of size 1000 would be selected (same categories), how high would be the variance in evaluation across these subsets? I have strong suspicion that results shown int Tables 1 and Tables 2 might not generalize across training subsamples. 

— Have you tried using Fourier embeddings of input coordinates instead of quadratic layers? This might be a very strong alternative since it helps coordinate based models to encode high-frequency details very efficiently.","— Proposed method represents the shape as a set of latents arranged on a regular latent grid and thus scales cubically with latent grid resolution. This limits method’s ability to efficiently encode topologically challenging shapes. 

— Method requires a lot of compute to fit 1000 shapes (1 day on 4GPUs with 24GB VRAM). This might be due to fact that authors use 32^3 latent grid (SDFusion for example uses 8^3). This severely limits scalability of the proposed method even for training on full ShapeNet, not to mention larger datasets like Objaverse.",['No ethics review needed.'],3,4,,Yes,2,2,2,1720840324339,,,NeurIPS.cc/2024/Conference,0KseSacluJ,"['NeurIPS.cc/2024/Conference/Submission3012/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878820242,[],4,,,['everyone'],0KseSacluJ,['NeurIPS.cc/2024/Conference/Submission3012/Reviewer_V5fn'],1720840324339,1730878820242,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission3012/Reviewer_V5fn']","Yes, this peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation (https://arxiv.org/abs/2203.09516)
2. SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation (https://arxiv.org/abs/2212.04493)
3. 4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks (https://arxiv.org/abs/1904.08755)
4. 3DILG: Irregular Latent Grids for 3D Generative Modeling (https://arxiv.org/abs/2205.13914)
5. AtlasNet: A Papier-Mâché Approach to Learning 3D Surface Generation (https://arxiv.org/abs/1802.05384)

The reviewer mentions that these papers are relevant to the proposed method and should be cited.",1,"2022, 2022, 2019, 2022, 2018",AtlasNet A Papier-Mâché Approach to Learning 3D Surface Generation
tcXarkC7Fo,"This paper proposes a novel time-adaptive RL method framework (TaCoS) for continuous-time systems with continuous state and action spaces. The framework shows that the settings of interactions having costs or a budget of interactions, can be formulated as extended MDPs, that can be solved with standard RL algorithms. The paper theoretically demonstrates this, and empirically verifies this. The paper also empirically demonstrates that TaCoS works across a range of interaction frequencies, and proposes OTaCoS a model-based RL approach.","* The paper is well written, and the intuitive explanations help the reader.
* The problem of time-adaptive RL for continuous-time systems with continuous state and action spaces is of high significance to the community and is well-motived throughout.
* The paper contributions are novel to the framework proposed by TaCoS and provide theoretical and empirical evidence.
* The method works surprisingly well, with the surprise that TaCoS achieves better control performance even with a small budget of interactions.","* L154: “Intuitively, the more stochastic the environment, the more interactions we would require to stabilize the system.” the argument should either have a reference or be empirically verified.
* Minor: Missing related work reference of (Nam et al. 2021).

References:

* Nam, HyunJi Alex, Scott Fleming, and Emma Brunskill. ""Reinforcement learning with state observation costs in action-contingent noiselessly observable Markov decision processes."" Advances in Neural Information Processing Systems 34 (2021): 15650-15666.",* Is the action applied from the policy kept constant until the next interaction? I presume the action is kept constant. Have you considered parameterizing the action and enabling non-constant actions or even continuous trajectories of actions between interaction times as a form of open-loop planning?,"Yes, they are discussed in Section 5.",['No ethics review needed.'],8,3,,Yes,3,3,3,1720836925509,,,NeurIPS.cc/2024/Conference,0JSKjdePGq,"['NeurIPS.cc/2024/Conference/Submission15313/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879769104,[],3,,,['everyone'],0JSKjdePGq,['NeurIPS.cc/2024/Conference/Submission15313/Reviewer_L1VF'],1720836925509,1730879769104,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission15313/Reviewer_L1VF']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

Nam, HyunJi Alex, Scott Fleming, and Emma Brunskill. ""Reinforcement learning with state observation costs in action-contingent noiselessly observable Markov decision processes."" Advances in Neural Information Processing Systems 34 (2021): 15650-15666.

This is mentioned in the ""weaknesses"" section of the review as a ""Minor"" point, stating that the related work reference of (Nam et al. 2021) is missing.",1,"2021, 2021",Reinforcement learning with state observation costs in action-contingent noiselessly observable Markov decision processes
FzlJZlNyho,"This paper aims to evaluate how well large-scale vision models encode 3D properties of the scenes depicted in images. The paper proposes a general and lightweight protocol that involves training discriminative classifiers on the features of pre-trained models to assess their encoding of several physical properties of 3D scenes. These properties include scene geometry, materials, support relations, lighting, shadow, occlusion and depth.

This protocol is applied to several large vision models, such as CLIP, DINOv1, DINOv2, VQGAN, and Stable Diffusion. The findings indicate that features from Stable Diffusion and DINOv2 are particularly adept at discriminative learning for properties like scene geometry, support relations, shadows, and depth. However, they perform less well for occlusion and material properties. The results also show that different layers and time steps of these models are good at different properties, which could have potential applications for 3D physical understanding.","1. This paper proposes a protocol to assess the 3D awareness for current large-scale vision models. The protocol considers various physical properties and is lightweight.

2. The overall structure and writing are easy to follow.

3. The problem investigated in this paper is very interesting. It provides a new perspective to interpret the features learned by large-scale models, especially their 3D awareness. This is very valuable for future studies.","1. It seems unclear to me whether the proposed probes can really reflect the 3D understanding of large vision models, due to properties to be probed and the way to probe them. For example, the material, support relation and shadow properties, from my point of view, can be well identified with 2D clues (e.g. appearance and 2D spatial location). For occlusion and depth, using linear SVM to answer binary questions may not be enough to assess these properties.

2. There is a lack of baselines for the linear probing. It is unclear how a 3D-aware model trained explicitly with 3D data will respond to probe questions (upper bound). Also, it is better to show how the models with little 3D awareness will react to the probes (lower bound). Otherwise, it is less informative just comparing between large vision models, especially when their scores are close and pretty high as shown in table 4.

3. The paper “Probing the 3d awareness of visual foundation models” [1] shares a very similar goal with this paper. It’s suggested to add comparison and discussion with that paper. 

4. It would be more comprehensive to evaluate more large vision models such as SAM [2] and MAE [3].

[1] Mohamed El Banani, Amit Raj, Kevis-Kokitsi Maninis, Abhishek Kar, Yuanzhen Li, Michael Rubinstein, Deqing Sun, Leonidas Guibas, Justin Johnson, and Varun Jampani. Probing the 3d awareness of visual foundation models. CVPR, 2024.

[2] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al. Segment anything. ICCV, 2023.

[3] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollar, and Ross Girshick. Masked autoencoders are scalable vision learners. CVPR, 2022","1. Have the large-scale models been trained on the dataset chosen in this paper? Does it have influence on the probe results?

2. In Table 4, instead of using a random classifier as the baseline, it is fairer to train a feature extractor from scratch with your probing training set.

3. Following the second point in Weakness, could you provide the upper bound and lower bound of the probe? That’s essential to justify that the probing tasks can actually reflect 3D awareness.

4. Currently, the input to the linear SVM is designed as the difference between the averaged pooled features from two patches. Will pooling and subtraction operations lead to information loss? Is there any better way to formulate the linear probing?",Yes.,['No ethics review needed.'],5,4,,Yes,4,4,3,1720599837059,,,NeurIPS.cc/2024/Conference,0HRRNEAQFp,"['NeurIPS.cc/2024/Conference/Submission17954/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879942850,[],1,,,['everyone'],0HRRNEAQFp,['NeurIPS.cc/2024/Conference/Submission17954/Reviewer_Wno9'],1720599837059,1730879942850,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17954/Reviewer_Wno9']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, namely:

1. ""Probing the 3d awareness of visual foundation models"" by Mohamed El Banani et al. (CVPR, 2024) - [1]
2. ""Segment anything"" by Alexander Kirillov et al. (ICCV, 2023) - [2]
3. ""Masked autoencoders are scalable vision learners"" by Kaiming He et al. (CVPR, 2022) - [3]

The reviewer suggests that the authors should add a comparison and discussion with the first paper, and also evaluate more large vision models such as SAM [2] and MAE [3].",1,"2024, 2023, 2022",Probing the 3d awareness of visual foundation models 
FzlJZlNyho,"This paper aims to evaluate how well large-scale vision models encode 3D properties of the scenes depicted in images. The paper proposes a general and lightweight protocol that involves training discriminative classifiers on the features of pre-trained models to assess their encoding of several physical properties of 3D scenes. These properties include scene geometry, materials, support relations, lighting, shadow, occlusion and depth.

This protocol is applied to several large vision models, such as CLIP, DINOv1, DINOv2, VQGAN, and Stable Diffusion. The findings indicate that features from Stable Diffusion and DINOv2 are particularly adept at discriminative learning for properties like scene geometry, support relations, shadows, and depth. However, they perform less well for occlusion and material properties. The results also show that different layers and time steps of these models are good at different properties, which could have potential applications for 3D physical understanding.","1. This paper proposes a protocol to assess the 3D awareness for current large-scale vision models. The protocol considers various physical properties and is lightweight.

2. The overall structure and writing are easy to follow.

3. The problem investigated in this paper is very interesting. It provides a new perspective to interpret the features learned by large-scale models, especially their 3D awareness. This is very valuable for future studies.","1. It seems unclear to me whether the proposed probes can really reflect the 3D understanding of large vision models, due to properties to be probed and the way to probe them. For example, the material, support relation and shadow properties, from my point of view, can be well identified with 2D clues (e.g. appearance and 2D spatial location). For occlusion and depth, using linear SVM to answer binary questions may not be enough to assess these properties.

2. There is a lack of baselines for the linear probing. It is unclear how a 3D-aware model trained explicitly with 3D data will respond to probe questions (upper bound). Also, it is better to show how the models with little 3D awareness will react to the probes (lower bound). Otherwise, it is less informative just comparing between large vision models, especially when their scores are close and pretty high as shown in table 4.

3. The paper “Probing the 3d awareness of visual foundation models” [1] shares a very similar goal with this paper. It’s suggested to add comparison and discussion with that paper. 

4. It would be more comprehensive to evaluate more large vision models such as SAM [2] and MAE [3].

[1] Mohamed El Banani, Amit Raj, Kevis-Kokitsi Maninis, Abhishek Kar, Yuanzhen Li, Michael Rubinstein, Deqing Sun, Leonidas Guibas, Justin Johnson, and Varun Jampani. Probing the 3d awareness of visual foundation models. CVPR, 2024.

[2] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al. Segment anything. ICCV, 2023.

[3] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollar, and Ross Girshick. Masked autoencoders are scalable vision learners. CVPR, 2022","1. Have the large-scale models been trained on the dataset chosen in this paper? Does it have influence on the probe results?

2. In Table 4, instead of using a random classifier as the baseline, it is fairer to train a feature extractor from scratch with your probing training set.

3. Following the second point in Weakness, could you provide the upper bound and lower bound of the probe? That’s essential to justify that the probing tasks can actually reflect 3D awareness.

4. Currently, the input to the linear SVM is designed as the difference between the averaged pooled features from two patches. Will pooling and subtraction operations lead to information loss? Is there any better way to formulate the linear probing?",Yes.,['No ethics review needed.'],5,4,,Yes,4,4,3,1720599837059,,,NeurIPS.cc/2024/Conference,0HRRNEAQFp,"['NeurIPS.cc/2024/Conference/Submission17954/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879942850,[],1,,,['everyone'],0HRRNEAQFp,['NeurIPS.cc/2024/Conference/Submission17954/Reviewer_Wno9'],1720599837059,1730879942850,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17954/Reviewer_Wno9']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, namely:

1. ""Probing the 3d awareness of visual foundation models"" by Mohamed El Banani et al. (CVPR, 2024) - [1]
2. ""Segment anything"" by Alexander Kirillov et al. (ICCV, 2023) - [2]
3. ""Masked autoencoders are scalable vision learners"" by Kaiming He et al. (CVPR, 2022) - [3]

The reviewer suggests that the authors should add a comparison and discussion with the first paper, and also evaluate more large vision models such as SAM [2] and MAE [3].",1,"2024, 2023, 2022",Segment anything 
FzlJZlNyho,"This paper aims to evaluate how well large-scale vision models encode 3D properties of the scenes depicted in images. The paper proposes a general and lightweight protocol that involves training discriminative classifiers on the features of pre-trained models to assess their encoding of several physical properties of 3D scenes. These properties include scene geometry, materials, support relations, lighting, shadow, occlusion and depth.

This protocol is applied to several large vision models, such as CLIP, DINOv1, DINOv2, VQGAN, and Stable Diffusion. The findings indicate that features from Stable Diffusion and DINOv2 are particularly adept at discriminative learning for properties like scene geometry, support relations, shadows, and depth. However, they perform less well for occlusion and material properties. The results also show that different layers and time steps of these models are good at different properties, which could have potential applications for 3D physical understanding.","1. This paper proposes a protocol to assess the 3D awareness for current large-scale vision models. The protocol considers various physical properties and is lightweight.

2. The overall structure and writing are easy to follow.

3. The problem investigated in this paper is very interesting. It provides a new perspective to interpret the features learned by large-scale models, especially their 3D awareness. This is very valuable for future studies.","1. It seems unclear to me whether the proposed probes can really reflect the 3D understanding of large vision models, due to properties to be probed and the way to probe them. For example, the material, support relation and shadow properties, from my point of view, can be well identified with 2D clues (e.g. appearance and 2D spatial location). For occlusion and depth, using linear SVM to answer binary questions may not be enough to assess these properties.

2. There is a lack of baselines for the linear probing. It is unclear how a 3D-aware model trained explicitly with 3D data will respond to probe questions (upper bound). Also, it is better to show how the models with little 3D awareness will react to the probes (lower bound). Otherwise, it is less informative just comparing between large vision models, especially when their scores are close and pretty high as shown in table 4.

3. The paper “Probing the 3d awareness of visual foundation models” [1] shares a very similar goal with this paper. It’s suggested to add comparison and discussion with that paper. 

4. It would be more comprehensive to evaluate more large vision models such as SAM [2] and MAE [3].

[1] Mohamed El Banani, Amit Raj, Kevis-Kokitsi Maninis, Abhishek Kar, Yuanzhen Li, Michael Rubinstein, Deqing Sun, Leonidas Guibas, Justin Johnson, and Varun Jampani. Probing the 3d awareness of visual foundation models. CVPR, 2024.

[2] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al. Segment anything. ICCV, 2023.

[3] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollar, and Ross Girshick. Masked autoencoders are scalable vision learners. CVPR, 2022","1. Have the large-scale models been trained on the dataset chosen in this paper? Does it have influence on the probe results?

2. In Table 4, instead of using a random classifier as the baseline, it is fairer to train a feature extractor from scratch with your probing training set.

3. Following the second point in Weakness, could you provide the upper bound and lower bound of the probe? That’s essential to justify that the probing tasks can actually reflect 3D awareness.

4. Currently, the input to the linear SVM is designed as the difference between the averaged pooled features from two patches. Will pooling and subtraction operations lead to information loss? Is there any better way to formulate the linear probing?",Yes.,['No ethics review needed.'],5,4,,Yes,4,4,3,1720599837059,,,NeurIPS.cc/2024/Conference,0HRRNEAQFp,"['NeurIPS.cc/2024/Conference/Submission17954/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879942850,[],1,,,['everyone'],0HRRNEAQFp,['NeurIPS.cc/2024/Conference/Submission17954/Reviewer_Wno9'],1720599837059,1730879942850,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission17954/Reviewer_Wno9']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, namely:

1. ""Probing the 3d awareness of visual foundation models"" by Mohamed El Banani et al. (CVPR, 2024) - [1]
2. ""Segment anything"" by Alexander Kirillov et al. (ICCV, 2023) - [2]
3. ""Masked autoencoders are scalable vision learners"" by Kaiming He et al. (CVPR, 2022) - [3]

The reviewer suggests that the authors should add a comparison and discussion with the first paper, and also evaluate more large vision models such as SAM [2] and MAE [3].",1,"2024, 2023, 2022",Masked autoencoders are scalable vision learners
WqCsdlFzAL,"In this paper the authors present a way to adapt a Vision and Language model to perform action execution tasks in embodied environments. Specifically, systematically evaluate different ways of predicting actions both on task having both discrete and continuous action spaces. Thanks to this evaluation, it is possible to assess which are the most performant action prediction losses to use for different use cases. According to the authors' results, approaches based on VQ-VAEs are able to obtain the best performance in many tasks.","1. One of the first papers that finally sheds light on the different approaches to performing action prediction in embodied environments. This is the most important contribution of this paper and I believe it will be really useful to refer to this set of experiments for future research. 

2. They propose a VQ-VAE variant to generate latent codes for encoding actions. These codes can be intended as a way to learn ""latent bins"" to cluster the action space. Additionally, they propose a variant of this model based on the RVQ-VAE architecture to model a set of codebooks that are used to generate more precise actions.","1. The VQ-VAE variants are indeed really interesting and novel. However, I find the description of this method a bit unsatisfactory because it omits some details regarding ""how"" you train these models. See my question below for details. 

2. The authors chose a good set of tasks for their evaluation however I believe that a benchmark that would have been perfect for this work is VIMA-Bench because of its focus on systematic generalisation. CALVIN somehow offers this but I don't think it's as systematic as VIMA-Bench.

3. For discrete action spaces they use BabyAI however they only test with a very limited size of the grids and with few tasks. Please see my questions related to this point as well. 

4. Some related work missing: 

- Team, Octo Model, et al. ""Octo: An open-source generalist robot policy."" arXiv preprint arXiv:2405.12213 (2024).
- Pantazopoulos, G., Nikandrou, M., Parekh, A., Hemanthage, B., Eshghi, A., Konstas, I., ... & Suglia, A. (2023, December). Multitask Multimodal Prompted Training for Interactive Embodied Task Completion. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (pp. 768-789).","1. I believe that a reader would appreciate the details of how you have arranged the dataset to train the VQ-VAE variants. The appendix contains some information but it doesn't fully address the nature of the data (e.g., ""What is each example?"").

2. Why did you decide to follow the work from Carta et al. considering that it uses only a subset of the trajectory instead of the BabyAI benchmark which contains a range of different tasks of different complexity? Additionally, when you evaluate, are you sure that 100 episodes are enough to experience different configurations from the ones you used at training time?

3. Could you please clarify what is the language instructions for environments that do not have one such as Meta-World?","The authors acknowledge the limitations of their experimental setup rather than the limitations of their work more broadly. Specifically, I would recommend the authors consider the societal impact of developing embodied AI models. For instance, it would be important to acknowledge that these models are still far from being deployed in real-world scenarios considering that their performance, even on simple grid-world-like environments, is barely over the 30% success rate bar.",['No ethics review needed.'],7,5,,Yes,3,3,3,1720531741213,,,NeurIPS.cc/2024/Conference,0Gl5WxY6es,"['NeurIPS.cc/2024/Conference/Submission19642/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880057657,[],2,,,['everyone'],0Gl5WxY6es,['NeurIPS.cc/2024/Conference/Submission19642/Reviewer_YrxP'],1720531741213,1730880057657,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission19642/Reviewer_YrxP']","Yes, the peer review explicitly suggests the authors of the paper to cite two specific literature:

1. ""Octo: An open-source generalist robot policy"" by Team, Octo Model, et al. (arXiv preprint arXiv:2405.12213, 2024)
2. ""Multitask Multimodal Prompted Training for Interactive Embodied Task Completion"" by Pantazopoulos, G., Nikandrou, M., Parekh, A., Hemanthage, B., Eshghi, A., Konstas, I., ... & Suglia, A. (Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 768-789)",1,"2024, 2024, 2023",Octo An open-source generalist robot policy 
WqCsdlFzAL,"In this paper the authors present a way to adapt a Vision and Language model to perform action execution tasks in embodied environments. Specifically, systematically evaluate different ways of predicting actions both on task having both discrete and continuous action spaces. Thanks to this evaluation, it is possible to assess which are the most performant action prediction losses to use for different use cases. According to the authors' results, approaches based on VQ-VAEs are able to obtain the best performance in many tasks.","1. One of the first papers that finally sheds light on the different approaches to performing action prediction in embodied environments. This is the most important contribution of this paper and I believe it will be really useful to refer to this set of experiments for future research. 

2. They propose a VQ-VAE variant to generate latent codes for encoding actions. These codes can be intended as a way to learn ""latent bins"" to cluster the action space. Additionally, they propose a variant of this model based on the RVQ-VAE architecture to model a set of codebooks that are used to generate more precise actions.","1. The VQ-VAE variants are indeed really interesting and novel. However, I find the description of this method a bit unsatisfactory because it omits some details regarding ""how"" you train these models. See my question below for details. 

2. The authors chose a good set of tasks for their evaluation however I believe that a benchmark that would have been perfect for this work is VIMA-Bench because of its focus on systematic generalisation. CALVIN somehow offers this but I don't think it's as systematic as VIMA-Bench.

3. For discrete action spaces they use BabyAI however they only test with a very limited size of the grids and with few tasks. Please see my questions related to this point as well. 

4. Some related work missing: 

- Team, Octo Model, et al. ""Octo: An open-source generalist robot policy."" arXiv preprint arXiv:2405.12213 (2024).
- Pantazopoulos, G., Nikandrou, M., Parekh, A., Hemanthage, B., Eshghi, A., Konstas, I., ... & Suglia, A. (2023, December). Multitask Multimodal Prompted Training for Interactive Embodied Task Completion. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (pp. 768-789).","1. I believe that a reader would appreciate the details of how you have arranged the dataset to train the VQ-VAE variants. The appendix contains some information but it doesn't fully address the nature of the data (e.g., ""What is each example?"").

2. Why did you decide to follow the work from Carta et al. considering that it uses only a subset of the trajectory instead of the BabyAI benchmark which contains a range of different tasks of different complexity? Additionally, when you evaluate, are you sure that 100 episodes are enough to experience different configurations from the ones you used at training time?

3. Could you please clarify what is the language instructions for environments that do not have one such as Meta-World?","The authors acknowledge the limitations of their experimental setup rather than the limitations of their work more broadly. Specifically, I would recommend the authors consider the societal impact of developing embodied AI models. For instance, it would be important to acknowledge that these models are still far from being deployed in real-world scenarios considering that their performance, even on simple grid-world-like environments, is barely over the 30% success rate bar.",['No ethics review needed.'],7,5,,Yes,3,3,3,1720531741213,,,NeurIPS.cc/2024/Conference,0Gl5WxY6es,"['NeurIPS.cc/2024/Conference/Submission19642/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730880057657,[],2,,,['everyone'],0Gl5WxY6es,['NeurIPS.cc/2024/Conference/Submission19642/Reviewer_YrxP'],1720531741213,1730880057657,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission19642/Reviewer_YrxP']","Yes, the peer review explicitly suggests the authors of the paper to cite two specific literature:

1. ""Octo: An open-source generalist robot policy"" by Team, Octo Model, et al. (arXiv preprint arXiv:2405.12213, 2024)
2. ""Multitask Multimodal Prompted Training for Interactive Embodied Task Completion"" by Pantazopoulos, G., Nikandrou, M., Parekh, A., Hemanthage, B., Eshghi, A., Konstas, I., ... & Suglia, A. (Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 768-789)",1,"2024, 2024, 2023",Multitask Multimodal Prompted Training for Interactive Embodied Task Completion
jzW81U4Zvk,"This paper designs an evaluation protocol and surveys a number of video generation papers published over the last few years.  The authors point out shortcomings of evaluation protocols in these priors works (e.g. they often limit studies to video quality comparisons with no clear definitions of video quality, small number of videos, annotators etc).  The authors promise to publish their trainings for annotators along with an interface.  They show that these trainings help significantly to improve reliability of annotator scores.

Another contribution is a method that doesn’t require all pairs of models to be compared and dynamically is able to select pairs to be compared and show experimentally that this scales better than the naive quadratic approach. 

Finally the authors use their methodology to compare 5 recent models and show among other things that Runway and Pika outperform their open source competitors.","Overall the list of surveyed papers in this paper is quite impressive and comprehensive. Moreover, having an evaluation method that can be used without all-pairs of comparisons to be run is clearly important particularly as the number of video generation models increases.  I also absolutely agree with the weaknesses of other video evaluations and agree that human evals are the golden standard and so making a public one available would be very beneficial for the community.","Weaknesses include the following:
* The authors cite works like Evalcrafter/Vbench but are vague about what value this current submission brings over these prior approaches. Specifically they claim that these approaches “may lack diversity to cover all real-world scenarios” but there are no details given.  As I’ve started to see a number of papers published using the Evalcrafter methodology, I would like to see a clear explanation of the pros and cons.
* Moreover the number of models actually evaluated in this paper is fairly small (only 5) — given that this is an evaluation methodology paper, it would be much stronger to include more models and perhaps even to show clearly that these human evaluations do not correlate well with things like FID or FVD.
* I recommend citing and considering using ELO scores which similarly allow for us to score and rank models based on not-all-pairs comparisons and also allow for dynamic selection of model pairs to be compared side by side.  See e.g., https://lmsys.org/blog/2023-05-03-arena/ for a recent example using ELO to rank LLMs by quality as perceived by humans.  Related is the Microsoft TrueSkill work which has also been used widely.
* Though the authors make a big deal of the fact that few prior works reveal the details of their interface and how the videos are displayed, I found very few details actually revealed in this paper.  The one clear detail I can see is that the authors mention standardizing the height of the video across models.  But this may not be the right thing to do!  Consider the VideoPoet work which generate videos in portrait aspect ratios — resizing so that heights are fixed would be unfair to these vertical videos.  Other details that are important are how to best show videos that are generated at different framerates and even different lengths (for example, how does one compare a 5 second clip from e.g. VideoCrafter to a 1 minute clip from Sora?).
* Finally some things that are marked as objective clearly are not objective like aesthetic quality.  It would be helpful / more convincing to explain clearly what the training looks like for such a dimension.  I would presume that one example showing what aesthetic quality means is not nearly enough…


Minor quibbles:
* I recommend being clear that “higher is better” in many plots
* The authors also use a lot of acronyms which impedes readability in various parts of the paper (e.g. last subsection of 4.3)
* I somewhat disagree with the characterization of FVD being about temporal consistency… even though this is part of it, the statements about the other metrics also apply — it compares feature representations from real and generated images and assesses diversity and clarity…
* I recommend seeing/citing the Videopoet paper that had very similar comparisons.",See weaknesses above.,yes,['No ethics review needed.'],3,5,,Yes,2,4,3,1720800830784,,,NeurIPS.cc/2024/Conference,0AwMciNShl,"['NeurIPS.cc/2024/Conference/Submission4622/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878939792,[],4,,,['everyone'],0AwMciNShl,['NeurIPS.cc/2024/Conference/Submission4622/Reviewer_2pJH'],1720800830784,1730878939792,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4622/Reviewer_2pJH']","Yes, the peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. Evalcrafter/Vbench: The reviewer asks the authors to provide a clear explanation of the pros and cons of their approach compared to Evalcrafter/Vbench.
2. ELO scores: The reviewer recommends citing and considering using ELO scores, which allow for scoring and ranking models based on not-all-pairs comparisons, and provides a link to a recent example using ELO to rank LLMs by quality as perceived by humans.
3. Microsoft TrueSkill work: The reviewer mentions this work as related to ELO scores and suggests considering it.
4. VideoPoet paper: The reviewer recommends citing and considering the Videopoet paper, which had similar comparisons to the current paper.",1,,Evalcrafter/Vbench 
jzW81U4Zvk,"This paper designs an evaluation protocol and surveys a number of video generation papers published over the last few years.  The authors point out shortcomings of evaluation protocols in these priors works (e.g. they often limit studies to video quality comparisons with no clear definitions of video quality, small number of videos, annotators etc).  The authors promise to publish their trainings for annotators along with an interface.  They show that these trainings help significantly to improve reliability of annotator scores.

Another contribution is a method that doesn’t require all pairs of models to be compared and dynamically is able to select pairs to be compared and show experimentally that this scales better than the naive quadratic approach. 

Finally the authors use their methodology to compare 5 recent models and show among other things that Runway and Pika outperform their open source competitors.","Overall the list of surveyed papers in this paper is quite impressive and comprehensive. Moreover, having an evaluation method that can be used without all-pairs of comparisons to be run is clearly important particularly as the number of video generation models increases.  I also absolutely agree with the weaknesses of other video evaluations and agree that human evals are the golden standard and so making a public one available would be very beneficial for the community.","Weaknesses include the following:
* The authors cite works like Evalcrafter/Vbench but are vague about what value this current submission brings over these prior approaches. Specifically they claim that these approaches “may lack diversity to cover all real-world scenarios” but there are no details given.  As I’ve started to see a number of papers published using the Evalcrafter methodology, I would like to see a clear explanation of the pros and cons.
* Moreover the number of models actually evaluated in this paper is fairly small (only 5) — given that this is an evaluation methodology paper, it would be much stronger to include more models and perhaps even to show clearly that these human evaluations do not correlate well with things like FID or FVD.
* I recommend citing and considering using ELO scores which similarly allow for us to score and rank models based on not-all-pairs comparisons and also allow for dynamic selection of model pairs to be compared side by side.  See e.g., https://lmsys.org/blog/2023-05-03-arena/ for a recent example using ELO to rank LLMs by quality as perceived by humans.  Related is the Microsoft TrueSkill work which has also been used widely.
* Though the authors make a big deal of the fact that few prior works reveal the details of their interface and how the videos are displayed, I found very few details actually revealed in this paper.  The one clear detail I can see is that the authors mention standardizing the height of the video across models.  But this may not be the right thing to do!  Consider the VideoPoet work which generate videos in portrait aspect ratios — resizing so that heights are fixed would be unfair to these vertical videos.  Other details that are important are how to best show videos that are generated at different framerates and even different lengths (for example, how does one compare a 5 second clip from e.g. VideoCrafter to a 1 minute clip from Sora?).
* Finally some things that are marked as objective clearly are not objective like aesthetic quality.  It would be helpful / more convincing to explain clearly what the training looks like for such a dimension.  I would presume that one example showing what aesthetic quality means is not nearly enough…


Minor quibbles:
* I recommend being clear that “higher is better” in many plots
* The authors also use a lot of acronyms which impedes readability in various parts of the paper (e.g. last subsection of 4.3)
* I somewhat disagree with the characterization of FVD being about temporal consistency… even though this is part of it, the statements about the other metrics also apply — it compares feature representations from real and generated images and assesses diversity and clarity…
* I recommend seeing/citing the Videopoet paper that had very similar comparisons.",See weaknesses above.,yes,['No ethics review needed.'],3,5,,Yes,2,4,3,1720800830784,,,NeurIPS.cc/2024/Conference,0AwMciNShl,"['NeurIPS.cc/2024/Conference/Submission4622/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878939792,[],4,,,['everyone'],0AwMciNShl,['NeurIPS.cc/2024/Conference/Submission4622/Reviewer_2pJH'],1720800830784,1730878939792,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4622/Reviewer_2pJH']","Yes, the peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. Evalcrafter/Vbench: The reviewer asks the authors to provide a clear explanation of the pros and cons of their approach compared to Evalcrafter/Vbench.
2. ELO scores: The reviewer recommends citing and considering using ELO scores, which allow for scoring and ranking models based on not-all-pairs comparisons, and provides a link to a recent example using ELO to rank LLMs by quality as perceived by humans.
3. Microsoft TrueSkill work: The reviewer mentions this work as related to ELO scores and suggests considering it.
4. VideoPoet paper: The reviewer recommends citing and considering the Videopoet paper, which had similar comparisons to the current paper.",1,,ELO scores 
jzW81U4Zvk,"This paper designs an evaluation protocol and surveys a number of video generation papers published over the last few years.  The authors point out shortcomings of evaluation protocols in these priors works (e.g. they often limit studies to video quality comparisons with no clear definitions of video quality, small number of videos, annotators etc).  The authors promise to publish their trainings for annotators along with an interface.  They show that these trainings help significantly to improve reliability of annotator scores.

Another contribution is a method that doesn’t require all pairs of models to be compared and dynamically is able to select pairs to be compared and show experimentally that this scales better than the naive quadratic approach. 

Finally the authors use their methodology to compare 5 recent models and show among other things that Runway and Pika outperform their open source competitors.","Overall the list of surveyed papers in this paper is quite impressive and comprehensive. Moreover, having an evaluation method that can be used without all-pairs of comparisons to be run is clearly important particularly as the number of video generation models increases.  I also absolutely agree with the weaknesses of other video evaluations and agree that human evals are the golden standard and so making a public one available would be very beneficial for the community.","Weaknesses include the following:
* The authors cite works like Evalcrafter/Vbench but are vague about what value this current submission brings over these prior approaches. Specifically they claim that these approaches “may lack diversity to cover all real-world scenarios” but there are no details given.  As I’ve started to see a number of papers published using the Evalcrafter methodology, I would like to see a clear explanation of the pros and cons.
* Moreover the number of models actually evaluated in this paper is fairly small (only 5) — given that this is an evaluation methodology paper, it would be much stronger to include more models and perhaps even to show clearly that these human evaluations do not correlate well with things like FID or FVD.
* I recommend citing and considering using ELO scores which similarly allow for us to score and rank models based on not-all-pairs comparisons and also allow for dynamic selection of model pairs to be compared side by side.  See e.g., https://lmsys.org/blog/2023-05-03-arena/ for a recent example using ELO to rank LLMs by quality as perceived by humans.  Related is the Microsoft TrueSkill work which has also been used widely.
* Though the authors make a big deal of the fact that few prior works reveal the details of their interface and how the videos are displayed, I found very few details actually revealed in this paper.  The one clear detail I can see is that the authors mention standardizing the height of the video across models.  But this may not be the right thing to do!  Consider the VideoPoet work which generate videos in portrait aspect ratios — resizing so that heights are fixed would be unfair to these vertical videos.  Other details that are important are how to best show videos that are generated at different framerates and even different lengths (for example, how does one compare a 5 second clip from e.g. VideoCrafter to a 1 minute clip from Sora?).
* Finally some things that are marked as objective clearly are not objective like aesthetic quality.  It would be helpful / more convincing to explain clearly what the training looks like for such a dimension.  I would presume that one example showing what aesthetic quality means is not nearly enough…


Minor quibbles:
* I recommend being clear that “higher is better” in many plots
* The authors also use a lot of acronyms which impedes readability in various parts of the paper (e.g. last subsection of 4.3)
* I somewhat disagree with the characterization of FVD being about temporal consistency… even though this is part of it, the statements about the other metrics also apply — it compares feature representations from real and generated images and assesses diversity and clarity…
* I recommend seeing/citing the Videopoet paper that had very similar comparisons.",See weaknesses above.,yes,['No ethics review needed.'],3,5,,Yes,2,4,3,1720800830784,,,NeurIPS.cc/2024/Conference,0AwMciNShl,"['NeurIPS.cc/2024/Conference/Submission4622/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878939792,[],4,,,['everyone'],0AwMciNShl,['NeurIPS.cc/2024/Conference/Submission4622/Reviewer_2pJH'],1720800830784,1730878939792,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4622/Reviewer_2pJH']","Yes, the peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. Evalcrafter/Vbench: The reviewer asks the authors to provide a clear explanation of the pros and cons of their approach compared to Evalcrafter/Vbench.
2. ELO scores: The reviewer recommends citing and considering using ELO scores, which allow for scoring and ranking models based on not-all-pairs comparisons, and provides a link to a recent example using ELO to rank LLMs by quality as perceived by humans.
3. Microsoft TrueSkill work: The reviewer mentions this work as related to ELO scores and suggests considering it.
4. VideoPoet paper: The reviewer recommends citing and considering the Videopoet paper, which had similar comparisons to the current paper.",1,,Microsoft TrueSkill 
jzW81U4Zvk,"This paper designs an evaluation protocol and surveys a number of video generation papers published over the last few years.  The authors point out shortcomings of evaluation protocols in these priors works (e.g. they often limit studies to video quality comparisons with no clear definitions of video quality, small number of videos, annotators etc).  The authors promise to publish their trainings for annotators along with an interface.  They show that these trainings help significantly to improve reliability of annotator scores.

Another contribution is a method that doesn’t require all pairs of models to be compared and dynamically is able to select pairs to be compared and show experimentally that this scales better than the naive quadratic approach. 

Finally the authors use their methodology to compare 5 recent models and show among other things that Runway and Pika outperform their open source competitors.","Overall the list of surveyed papers in this paper is quite impressive and comprehensive. Moreover, having an evaluation method that can be used without all-pairs of comparisons to be run is clearly important particularly as the number of video generation models increases.  I also absolutely agree with the weaknesses of other video evaluations and agree that human evals are the golden standard and so making a public one available would be very beneficial for the community.","Weaknesses include the following:
* The authors cite works like Evalcrafter/Vbench but are vague about what value this current submission brings over these prior approaches. Specifically they claim that these approaches “may lack diversity to cover all real-world scenarios” but there are no details given.  As I’ve started to see a number of papers published using the Evalcrafter methodology, I would like to see a clear explanation of the pros and cons.
* Moreover the number of models actually evaluated in this paper is fairly small (only 5) — given that this is an evaluation methodology paper, it would be much stronger to include more models and perhaps even to show clearly that these human evaluations do not correlate well with things like FID or FVD.
* I recommend citing and considering using ELO scores which similarly allow for us to score and rank models based on not-all-pairs comparisons and also allow for dynamic selection of model pairs to be compared side by side.  See e.g., https://lmsys.org/blog/2023-05-03-arena/ for a recent example using ELO to rank LLMs by quality as perceived by humans.  Related is the Microsoft TrueSkill work which has also been used widely.
* Though the authors make a big deal of the fact that few prior works reveal the details of their interface and how the videos are displayed, I found very few details actually revealed in this paper.  The one clear detail I can see is that the authors mention standardizing the height of the video across models.  But this may not be the right thing to do!  Consider the VideoPoet work which generate videos in portrait aspect ratios — resizing so that heights are fixed would be unfair to these vertical videos.  Other details that are important are how to best show videos that are generated at different framerates and even different lengths (for example, how does one compare a 5 second clip from e.g. VideoCrafter to a 1 minute clip from Sora?).
* Finally some things that are marked as objective clearly are not objective like aesthetic quality.  It would be helpful / more convincing to explain clearly what the training looks like for such a dimension.  I would presume that one example showing what aesthetic quality means is not nearly enough…


Minor quibbles:
* I recommend being clear that “higher is better” in many plots
* The authors also use a lot of acronyms which impedes readability in various parts of the paper (e.g. last subsection of 4.3)
* I somewhat disagree with the characterization of FVD being about temporal consistency… even though this is part of it, the statements about the other metrics also apply — it compares feature representations from real and generated images and assesses diversity and clarity…
* I recommend seeing/citing the Videopoet paper that had very similar comparisons.",See weaknesses above.,yes,['No ethics review needed.'],3,5,,Yes,2,4,3,1720800830784,,,NeurIPS.cc/2024/Conference,0AwMciNShl,"['NeurIPS.cc/2024/Conference/Submission4622/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878939792,[],4,,,['everyone'],0AwMciNShl,['NeurIPS.cc/2024/Conference/Submission4622/Reviewer_2pJH'],1720800830784,1730878939792,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4622/Reviewer_2pJH']","Yes, the peer review explicitly suggests the authors of the paper to cite the following specific literature:

1. Evalcrafter/Vbench: The reviewer asks the authors to provide a clear explanation of the pros and cons of their approach compared to Evalcrafter/Vbench.
2. ELO scores: The reviewer recommends citing and considering using ELO scores, which allow for scoring and ranking models based on not-all-pairs comparisons, and provides a link to a recent example using ELO to rank LLMs by quality as perceived by humans.
3. Microsoft TrueSkill work: The reviewer mentions this work as related to ELO scores and suggests considering it.
4. VideoPoet paper: The reviewer recommends citing and considering the Videopoet paper, which had similar comparisons to the current paper.",1,,VideoPoet
n46v7AMxgY,"This paper proposes two simple, yet crucial modifications to the Generalization in the Visual RL pipeline where during the test time, the visual observation consists of various degrees of dynamically varying backgrounds.

Concretely, the authors identify two issues that inhibit RL agents from generalization: (i) imbalanced saliency and (ii) observational overfitting. To overcome these issues they propose two simple, yet effective solutions -- (a) Feature level frame stack where instead of stacking frames at the observation level, they stack at a feature level after obtaining spatial features of the images and (b) Shifted Random Overlay Augmentation where instead of applying data augmentation to the stack of frames, a shifted version of the data augmentation is applied to simulate the dynamically moving background effect which in turn helps learn more generalizable policy.

Through their experiments on the DM-Control (and robotic manipulation in the appendix) with varying backgrounds, the authors show the generalization capability of their proposed SimGRL (Simple framework for Generalization in visual RL) framework.  

Additionally, the authors also propose Task-Identification (TID) Metrics to evaluate how much of the policy can capture the task-relevant objects in each stacked frame.","1. A key strength of this paper is the simplicity of the proposed solutions to address the generalization issue and these simple changes are quite effective as shown in the experiments.

2. The intuition behind both the proposed solutions is clear and straightforward.","1. I do find myself in confusion with respect to the Attribution masking argument. I believe that the proposed solutions of Feature-level frame stack and Shifted Random overlay augmentation are both valid solutions to a generalizable policy irrespective of the authors inclusion of Attribution masking. My specific concern is as follows: 

    What is the guarantee that a clear thresholded gradient masking of the critic wrt the input, which consists of the complete segmentation of the relevant objects and agent in the mask will lead to a better generalizable policy? It can be possible that a generalizable policy would care about only a few key points that are predictive of the reward -- and hence be able to accurately predict the Value of a state, and in that sense, an accurate segmentation of the attribution mask need not be necessary. To give an example, in the robotic manipulation task of reach -- the reward function is typically shaped as some function of the Euclidean distance between the robot's end-effector and the goal position. In such a situation, the Value function shouldn't really be bothered about where the other parts of the robot are.

2. The weakness in (1) ties into my second concern where if only a few parts of the agent are responsible for achieving (and predicting) reward, then I don't see the value of the proposed TID metric. This assumes that my entire object and agent in the scene is responsible for the policy, which as argued in (1) is not the case in most scenarios.

3. [Relatively minor concern, not taken into account for the final scoring] It would be beneficial to the reader if the proposed components in Figure 4 could be highlighted with say a different color and a distinction between the existing pipeline of SVEA be made.

4. On the experimentation end, I feel that the evaluation is very limited to DM-control tasks. While SimGRL performs quite well on Video-Easy and Video-Hard settings of DM-Control, and 2 other tasks of Robotic manipulation, I would have liked to see a more comprehensive evaluation of various visual RL environments. Specifically, I'd recommend performing evaluation on RL-ViGen [1] (https://gemcollector.github.io/RL-ViGen/)  which consists of a collection of diverse visual RL tasks. This would further strengthen this work's results.

5. On L263, where authors say: 
> SimGRL demonstrates state-of-the-art performance in 4 out of 6 tasks in the Video Easy benchmark

    One has to be careful while making such claims especially when the difference on one such task is +1 -- which in DM-Control doesn't really mean anything. I would ask the authors to look at IQM and Probability of Improvement metrics to compare SimGRL to other methods from [2] which has shown to be more reliable than taking an average over seeds. This does not involve re-running the experiments, the existing checkpoints and returns can be directly used over their wrapper.","6.  Observational Overfitting: For this, one of the core arguments that authors provide is that because the same augmentation is applied uniformly to all frames the agent can tend to still focus on the background. I'm wondering how a baseline for this where you have different data augmentations for every frame in the history of stacked frames(say jittering, slight rotation, blur, overlay, random convolution, random shift) performs?

7. In the Robotic manipulation results what does Test {1, 2, 3} mean? Does it mean running an evaluation on a _single episode_ for 5 seeds?

----
**References**

[1] RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization, Zhecheng Yuan et al., NeurIPS 2023.	

[2] Deep Reinforcement Learning at the Edge of the Statistical Precipice, Rishabh Agarwal et al., NeurIPS 2021.

----
**Reason for current rating**: Because of my two major concerns around Attribute masking (and TID metrics), as well as lack of extensive experimentation on diverse RL environments, I am leaning towards a weak reject. However, my final decision would be based on authors' rebuttal, other reviewers comments and the discussion with authors during the rebuttal period. I'd encourage the authors to ask me any clarification questions for any of the experiments if they have any during the rebuttal/discussion period.

-----

**Post rebuttal update** -- As the authors have addressed all my major concerns, I have decided to increase my score to **Weak Accept**.","The authors don't mention any limitations of their work. It would be good to have a couple of lines highlighting where their method may fail. For instance, potentially large changes in background can lead to failure or their Feature stacking would work only in situations where Frame stacking is used -- model-based works like Dreamer do not use any frame stacking because of a recurrent network (such as GRU) that handles the history of states.",['No ethics review needed.'],6,5,,Yes,3,3,3,1720505611094,,,NeurIPS.cc/2024/Conference,0AumdfLzpK,"['NeurIPS.cc/2024/Conference/Submission12849/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879585168,[],2,,,['everyone'],0AumdfLzpK,['NeurIPS.cc/2024/Conference/Submission12849/Reviewer_wvnF'],1720505611094,1730879585168,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission12849/Reviewer_wvnF']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization, Zhecheng Yuan et al., NeurIPS 2023.
2. Deep Reinforcement Learning at the Edge of the Statistical Precipice, Rishabh Agarwal et al., NeurIPS 2021.

The reviewer mentions these references in the context of suggesting additional experiments and evaluation metrics to strengthen the paper's results.",1,"2023, 2021",RL-ViGen A Reinforcement Learning Benchmark for Visual Generalization 
n46v7AMxgY,"This paper proposes two simple, yet crucial modifications to the Generalization in the Visual RL pipeline where during the test time, the visual observation consists of various degrees of dynamically varying backgrounds.

Concretely, the authors identify two issues that inhibit RL agents from generalization: (i) imbalanced saliency and (ii) observational overfitting. To overcome these issues they propose two simple, yet effective solutions -- (a) Feature level frame stack where instead of stacking frames at the observation level, they stack at a feature level after obtaining spatial features of the images and (b) Shifted Random Overlay Augmentation where instead of applying data augmentation to the stack of frames, a shifted version of the data augmentation is applied to simulate the dynamically moving background effect which in turn helps learn more generalizable policy.

Through their experiments on the DM-Control (and robotic manipulation in the appendix) with varying backgrounds, the authors show the generalization capability of their proposed SimGRL (Simple framework for Generalization in visual RL) framework.  

Additionally, the authors also propose Task-Identification (TID) Metrics to evaluate how much of the policy can capture the task-relevant objects in each stacked frame.","1. A key strength of this paper is the simplicity of the proposed solutions to address the generalization issue and these simple changes are quite effective as shown in the experiments.

2. The intuition behind both the proposed solutions is clear and straightforward.","1. I do find myself in confusion with respect to the Attribution masking argument. I believe that the proposed solutions of Feature-level frame stack and Shifted Random overlay augmentation are both valid solutions to a generalizable policy irrespective of the authors inclusion of Attribution masking. My specific concern is as follows: 

    What is the guarantee that a clear thresholded gradient masking of the critic wrt the input, which consists of the complete segmentation of the relevant objects and agent in the mask will lead to a better generalizable policy? It can be possible that a generalizable policy would care about only a few key points that are predictive of the reward -- and hence be able to accurately predict the Value of a state, and in that sense, an accurate segmentation of the attribution mask need not be necessary. To give an example, in the robotic manipulation task of reach -- the reward function is typically shaped as some function of the Euclidean distance between the robot's end-effector and the goal position. In such a situation, the Value function shouldn't really be bothered about where the other parts of the robot are.

2. The weakness in (1) ties into my second concern where if only a few parts of the agent are responsible for achieving (and predicting) reward, then I don't see the value of the proposed TID metric. This assumes that my entire object and agent in the scene is responsible for the policy, which as argued in (1) is not the case in most scenarios.

3. [Relatively minor concern, not taken into account for the final scoring] It would be beneficial to the reader if the proposed components in Figure 4 could be highlighted with say a different color and a distinction between the existing pipeline of SVEA be made.

4. On the experimentation end, I feel that the evaluation is very limited to DM-control tasks. While SimGRL performs quite well on Video-Easy and Video-Hard settings of DM-Control, and 2 other tasks of Robotic manipulation, I would have liked to see a more comprehensive evaluation of various visual RL environments. Specifically, I'd recommend performing evaluation on RL-ViGen [1] (https://gemcollector.github.io/RL-ViGen/)  which consists of a collection of diverse visual RL tasks. This would further strengthen this work's results.

5. On L263, where authors say: 
> SimGRL demonstrates state-of-the-art performance in 4 out of 6 tasks in the Video Easy benchmark

    One has to be careful while making such claims especially when the difference on one such task is +1 -- which in DM-Control doesn't really mean anything. I would ask the authors to look at IQM and Probability of Improvement metrics to compare SimGRL to other methods from [2] which has shown to be more reliable than taking an average over seeds. This does not involve re-running the experiments, the existing checkpoints and returns can be directly used over their wrapper.","6.  Observational Overfitting: For this, one of the core arguments that authors provide is that because the same augmentation is applied uniformly to all frames the agent can tend to still focus on the background. I'm wondering how a baseline for this where you have different data augmentations for every frame in the history of stacked frames(say jittering, slight rotation, blur, overlay, random convolution, random shift) performs?

7. In the Robotic manipulation results what does Test {1, 2, 3} mean? Does it mean running an evaluation on a _single episode_ for 5 seeds?

----
**References**

[1] RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization, Zhecheng Yuan et al., NeurIPS 2023.	

[2] Deep Reinforcement Learning at the Edge of the Statistical Precipice, Rishabh Agarwal et al., NeurIPS 2021.

----
**Reason for current rating**: Because of my two major concerns around Attribute masking (and TID metrics), as well as lack of extensive experimentation on diverse RL environments, I am leaning towards a weak reject. However, my final decision would be based on authors' rebuttal, other reviewers comments and the discussion with authors during the rebuttal period. I'd encourage the authors to ask me any clarification questions for any of the experiments if they have any during the rebuttal/discussion period.

-----

**Post rebuttal update** -- As the authors have addressed all my major concerns, I have decided to increase my score to **Weak Accept**.","The authors don't mention any limitations of their work. It would be good to have a couple of lines highlighting where their method may fail. For instance, potentially large changes in background can lead to failure or their Feature stacking would work only in situations where Frame stacking is used -- model-based works like Dreamer do not use any frame stacking because of a recurrent network (such as GRU) that handles the history of states.",['No ethics review needed.'],6,5,,Yes,3,3,3,1720505611094,,,NeurIPS.cc/2024/Conference,0AumdfLzpK,"['NeurIPS.cc/2024/Conference/Submission12849/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879585168,[],2,,,['everyone'],0AumdfLzpK,['NeurIPS.cc/2024/Conference/Submission12849/Reviewer_wvnF'],1720505611094,1730879585168,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission12849/Reviewer_wvnF']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization, Zhecheng Yuan et al., NeurIPS 2023.
2. Deep Reinforcement Learning at the Edge of the Statistical Precipice, Rishabh Agarwal et al., NeurIPS 2021.

The reviewer mentions these references in the context of suggesting additional experiments and evaluation metrics to strengthen the paper's results.",1,"2023, 2021",Deep Reinforcement Learning at the Edge of the Statistical Precipice
EhYydZVArW,"This paper proposes Meta Deep Kernel Learning (MDKL), a new surrogate for SAEAs. MDKL consists of a deep kernel with meta-learning. Empirical studies demonstrate its effectiveness in expensive multi-objective optimization and constrained optimization.","1. This paper is well-written and easy to follow. The technical details are well presented.
2. This paper extends deep kernel and meta-learning-based surrogates into evolutionary algorithms.
3. This paper investigated multi-objective optimization and constrained optimization.","Meta-learned deep kernel surrogates have already been well-studied in Bayesian Optimization [1]. The authors are also aware of this as they mentioned in Related Work. I think this paper does not present significant new advancements based on the previous work.

First, the authors claim that MDKL is specially designed for optimization, while the previous work is not. In this regard, I do not see many differences between MDKL and previous meta-learned deep kernels. The authors claim that the advantage of MDKL lies in continuous adaptation; however, most models support parameter updates or fine-tuning. The authors also did not sufficiently explain the relationship between continuous adaptation and optimization problems, or what significance it has for optimization problems.

Second, the authors propose that one of the novelties of this paper is taking expensive multi-objective optimization problems (EMOPs) and expensive constrained optimization problems (ECOPs) into account. MDKL, as a surrogate, can be integrated into almost any expensive optimization algorithm. It seems to be able to cooperate with Bayesian optimization as well. The authors simply replaced the surrogate in a multi-objective optimization algorithm with MDKL and conducted some experiments, without providing any new analysis, insights, or proposing any new methods specifically for MOPs or COPs. Therefore, I believe this paper does not make a significant contribution to solving EMOPs and ECOPs.

[1] Martin Wistuba and Josif Grabocka. Few-shot Bayesian optimization with deep kernel surrogates. ICLR 2021.","1. Regarding MOPs, this paper only includes results on synthetic problems. I recommend using some real-world instances, such as NAS and Hyperparameter tuning.
2. Table 14 and Fig. 9. The HV values are all 0, indicating that the reference point is set too low.
3. P2, Line 64. MOPs and COPs can also be global optimization problems.
4. P5, Algorithm 3, Line 3. How are the increments initialized?",No concerns.,['No ethics review needed.'],4,4,,Yes,1,3,2,1720447750676,,,NeurIPS.cc/2024/Conference,08oUnmtj8Q,"['NeurIPS.cc/2024/Conference/Submission12733/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879575186,[],2,,,['everyone'],08oUnmtj8Q,['NeurIPS.cc/2024/Conference/Submission12733/Reviewer_rKvd'],1720447750676,1730879575186,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission12733/Reviewer_rKvd']","Yes, the peer review explicitly suggests the authors of the paper to cite a specific literature, which is:

[1] Martin Wistuba and Josif Grabocka. Few-shot Bayesian optimization with deep kernel surrogates. ICLR 2021.

This paper is mentioned as a previous work that has already studied meta-learned deep kernel surrogates in Bayesian Optimization, and the reviewer thinks that the current paper does not present significant new advancements based on this previous work.",1,2021,Few-shot Bayesian optimization with deep kernel surrogates
PgDKzzw8M1,"This paper presents Director3D, a novel text-to-3D generation framework designed to generate both real-world 3D scenes and adaptive camera trajectories. Specifically, the authors propose the Traj-DiT to generate adaptive camera trajectories, which treats camera parameters as temporal tokens and performs conditional denoising using a transformer model. The authors propose the GM-LDM and SDS++ Loss to generate robust 3D scenes by leveraging the 2D diffusion prior. Extensive experiments demonstrate the effectiveness of Director3D.","1. This paper is written clearly and easy to read. 
2. The idea of treating camera parameters as temporal tokens for denoising generation is novel and effective. 
3. The GM-LDM and SDS++ loss functions achieve a fairly high level of realistic scene synthesis. The generated scenarios conform to the textual input as well as being reasonably realistic and consistent. 
4. The proposed Director3D achieves impressive results on both quantitative and qualitative results.","1.	It would be more convincing to include more text-to-3D scene generation methods in the Quantitative Comparison in the Qualitative Comparison.
2.	For ablation experiments of SDS++ Loss, please use more detailed evaluation metrics and experimental results to illustrate the effects.
3.	Further implementation of conditionally controllable camera view generation would be helpful for the application of this technology. 
4.  Some important work in this area such as 3D-SceneDreamer should be discussed if they are not suitable for the experimental comparison.
5. The visual quality of the results seems acceptable compared to existing methods like 3D-scene-dreamer, the limitation of the method, including not allowing a large range of the camera movement, should be discussed.",No additional questions.,"1. The baseline methods like Fantasia3D and DreamFusion are mainly for object-level generation, not focusing on scene generation.
2. The result visualization can be improved, e.g., the imges are quite small for the reviewer to check the visual quality.",['No ethics review needed.'],7,4,,Yes,4,3,3,1720879020019,,,NeurIPS.cc/2024/Conference,08A6X7FSTs,"['NeurIPS.cc/2024/Conference/Submission6747/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879102858,[],3,,,['everyone'],08A6X7FSTs,['NeurIPS.cc/2024/Conference/Submission6747/Reviewer_Lv1o'],1720879020019,1730879102858,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission6747/Reviewer_Lv1o']","Yes, this peer review explicitly suggests the authors of the paper to discuss a specific literature, ""3D-SceneDreamer"", if it is not suitable for the experimental comparison. This implies that the reviewer thinks the authors should at least be aware of and acknowledge the existence of this work in the field of text-to-3D scene generation.",1,,3D-SceneDreamer
ZdCnVNUdvI,"This paper investigates content generation within a target space using pretrained diffusion models operating in projected subspaces. The authors analyze five variants of the DDIM procedure, performed separately in each subspace and aggregated in the target space using known projection and unprojection operators. They explore different sequences of projection and aggregation, concluding that the optimal approach is to aggregate each subspace's ""estimated x0 from xt"" (the output of Tweedie's formula).

The method is evaluated through texturing tasks involving depth, mesh, and 3DGS, each representing distinct projection and unprojection scenarios. The ablation study and comparisons against baselines demonstrate the robustness of the proposed aggregation stage.","+ The paper effectively breaks down the multi-DDIM process, clearly delineating distinct alternatives that differ in the sequencing of the projection and aggregation operations.  
+ The identification of three different tasks, which span a range of projection and un-projection operations, enriches the analysis and allows for a clear identification of the strengths and weaknesses of each aggregation strategy. I also appreciated the toy experiments, which effectively mimic the 3D effect in a simpler 2D setup.  
+ The final strategy advocated for in this work aligns with the standard DDIM, is straightforward to implement, requires no additional tuning, and does not incur extra computational costs.","- Missing Explanations: The figures are difficult to understand due to missing information. For example, Figure 3 does not explicitly state the experimental setup, including the definitions of the canonical space and the subspaces.
- The formulation of cases 1-3 that operate in the subspace does not explain how the recovered signal in z is finally returned. This is related to my previous comment, where it seems Figure 3 shows individual subspace generations rather than the end goal/task.
- The initialization process is not discussed in the main paper. It is unclear whether the subspaces share the same initial noise. If they do, how is noise being generated in z? This is particularly challenging when z is 3DGS.
- In the appendix, it states that the 3DGS are optimized towards the predicted clean images. Is this optimization considered the unprojection operation ""g""? If so, this should be explicitly stated and moved to the main paper. More details on this optimization process are needed, including whether it is performed until convergence at each denoising time during generation.
- In lines 129-130, phi and psi are used in the target domain. Please explain how this is done properly, given that noise is not injected in that space. Why would the coefficients in eq (3) and (4) hold true?

- The caption of Figure 1, “Diverse visual content generated by SyncTweedies,” and the abstract phrase ""generating diverse visual content"" are misleading. They suggest the generation of general 3D content, while the method, as mentioned in the limitations, relies on known mappings between the subspaces and the target space, limiting it to texturing tasks. The authors should tone down these statements.
- If the mapping from the canonical space to the instance spaces is simple (say, linear or even the Idnetity mapping), it seems all ""cases"" perform similarly both quantitatively and qualitatively. Do these methods mathematically converge to the same method, or are there still differences? In the 1-1 projection example in Figure 3, it appears all methods produce the same result. Is this correct? Table 10A shows almost identical results for different methods, and in Table 1, the scores for the 1-1 cases are very similar.
- The claim of being the first to propose this method and that it was previously ""overlooked"" is too bold. Guidance literature shows that guidance in ""\hat{x_0}"" offers more stable optimization and results. While guidance differs from multi-diffusion, it is similar enough to make the analogy. The authors should discuss similarities and differences, referencing papers like ""Universal Guidance for Diffusion Models"" and motion diffusion papers such as MDM and Trace&Pace. Further, if in degenerate cases of f and g maps (e.g. if they are the identity function) some ""cases"" are indistinguishable, be mindful when attributing aggregation choices to these methods (e.g., MultiDiffusion). Methods requiring tuning, like DiffCollage, should not be dismissed as baselines. The main contribution of this paper is identifying the best ""place"" to aggregate, and tuning is somewhat orthogonal. If ""Case 2"" improves DiffCollage, this should be demonstrated.
- The term ""1:1 case"" is confusing and suggests disjoint individual subspaces.
- The integration process of 1:n should also be better explained. It may also be useful to add illustration figures. 
- Improve Figure 2 for clarity with a more detailed caption. Connecting the diagram to the notations introduced in the paper would also help readability.",please see weaknesses.,See weaknesses -- the work in it sucrrent form is limited to known geometry,['No ethics review needed.'],7,4,,Yes,3,3,3,1720724001442,,,NeurIPS.cc/2024/Conference,06Vt6f2js7,"['NeurIPS.cc/2024/Conference/Submission370/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878639039,[],3,,,['everyone'],06Vt6f2js7,['NeurIPS.cc/2024/Conference/Submission370/Reviewer_KJxR'],1720724001442,1730878639039,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission370/Reviewer_KJxR']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. ""Universal Guidance for Diffusion Models""
2. Motion diffusion papers such as MDM and Trace&Pace
3. DiffCollage (and potentially other methods that require tuning)

The reviewer recommends that the authors discuss the similarities and differences between their proposed method and these existing works, in order to provide a more accurate and nuanced understanding of the contributions and limitations of their paper.",1,,Universal Guidance for Diffusion Models 
ZdCnVNUdvI,"This paper investigates content generation within a target space using pretrained diffusion models operating in projected subspaces. The authors analyze five variants of the DDIM procedure, performed separately in each subspace and aggregated in the target space using known projection and unprojection operators. They explore different sequences of projection and aggregation, concluding that the optimal approach is to aggregate each subspace's ""estimated x0 from xt"" (the output of Tweedie's formula).

The method is evaluated through texturing tasks involving depth, mesh, and 3DGS, each representing distinct projection and unprojection scenarios. The ablation study and comparisons against baselines demonstrate the robustness of the proposed aggregation stage.","+ The paper effectively breaks down the multi-DDIM process, clearly delineating distinct alternatives that differ in the sequencing of the projection and aggregation operations.  
+ The identification of three different tasks, which span a range of projection and un-projection operations, enriches the analysis and allows for a clear identification of the strengths and weaknesses of each aggregation strategy. I also appreciated the toy experiments, which effectively mimic the 3D effect in a simpler 2D setup.  
+ The final strategy advocated for in this work aligns with the standard DDIM, is straightforward to implement, requires no additional tuning, and does not incur extra computational costs.","- Missing Explanations: The figures are difficult to understand due to missing information. For example, Figure 3 does not explicitly state the experimental setup, including the definitions of the canonical space and the subspaces.
- The formulation of cases 1-3 that operate in the subspace does not explain how the recovered signal in z is finally returned. This is related to my previous comment, where it seems Figure 3 shows individual subspace generations rather than the end goal/task.
- The initialization process is not discussed in the main paper. It is unclear whether the subspaces share the same initial noise. If they do, how is noise being generated in z? This is particularly challenging when z is 3DGS.
- In the appendix, it states that the 3DGS are optimized towards the predicted clean images. Is this optimization considered the unprojection operation ""g""? If so, this should be explicitly stated and moved to the main paper. More details on this optimization process are needed, including whether it is performed until convergence at each denoising time during generation.
- In lines 129-130, phi and psi are used in the target domain. Please explain how this is done properly, given that noise is not injected in that space. Why would the coefficients in eq (3) and (4) hold true?

- The caption of Figure 1, “Diverse visual content generated by SyncTweedies,” and the abstract phrase ""generating diverse visual content"" are misleading. They suggest the generation of general 3D content, while the method, as mentioned in the limitations, relies on known mappings between the subspaces and the target space, limiting it to texturing tasks. The authors should tone down these statements.
- If the mapping from the canonical space to the instance spaces is simple (say, linear or even the Idnetity mapping), it seems all ""cases"" perform similarly both quantitatively and qualitatively. Do these methods mathematically converge to the same method, or are there still differences? In the 1-1 projection example in Figure 3, it appears all methods produce the same result. Is this correct? Table 10A shows almost identical results for different methods, and in Table 1, the scores for the 1-1 cases are very similar.
- The claim of being the first to propose this method and that it was previously ""overlooked"" is too bold. Guidance literature shows that guidance in ""\hat{x_0}"" offers more stable optimization and results. While guidance differs from multi-diffusion, it is similar enough to make the analogy. The authors should discuss similarities and differences, referencing papers like ""Universal Guidance for Diffusion Models"" and motion diffusion papers such as MDM and Trace&Pace. Further, if in degenerate cases of f and g maps (e.g. if they are the identity function) some ""cases"" are indistinguishable, be mindful when attributing aggregation choices to these methods (e.g., MultiDiffusion). Methods requiring tuning, like DiffCollage, should not be dismissed as baselines. The main contribution of this paper is identifying the best ""place"" to aggregate, and tuning is somewhat orthogonal. If ""Case 2"" improves DiffCollage, this should be demonstrated.
- The term ""1:1 case"" is confusing and suggests disjoint individual subspaces.
- The integration process of 1:n should also be better explained. It may also be useful to add illustration figures. 
- Improve Figure 2 for clarity with a more detailed caption. Connecting the diagram to the notations introduced in the paper would also help readability.",please see weaknesses.,See weaknesses -- the work in it sucrrent form is limited to known geometry,['No ethics review needed.'],7,4,,Yes,3,3,3,1720724001442,,,NeurIPS.cc/2024/Conference,06Vt6f2js7,"['NeurIPS.cc/2024/Conference/Submission370/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878639039,[],3,,,['everyone'],06Vt6f2js7,['NeurIPS.cc/2024/Conference/Submission370/Reviewer_KJxR'],1720724001442,1730878639039,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission370/Reviewer_KJxR']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. ""Universal Guidance for Diffusion Models""
2. Motion diffusion papers such as MDM and Trace&Pace
3. DiffCollage (and potentially other methods that require tuning)

The reviewer recommends that the authors discuss the similarities and differences between their proposed method and these existing works, in order to provide a more accurate and nuanced understanding of the contributions and limitations of their paper.",1,,MDM 
ZdCnVNUdvI,"This paper investigates content generation within a target space using pretrained diffusion models operating in projected subspaces. The authors analyze five variants of the DDIM procedure, performed separately in each subspace and aggregated in the target space using known projection and unprojection operators. They explore different sequences of projection and aggregation, concluding that the optimal approach is to aggregate each subspace's ""estimated x0 from xt"" (the output of Tweedie's formula).

The method is evaluated through texturing tasks involving depth, mesh, and 3DGS, each representing distinct projection and unprojection scenarios. The ablation study and comparisons against baselines demonstrate the robustness of the proposed aggregation stage.","+ The paper effectively breaks down the multi-DDIM process, clearly delineating distinct alternatives that differ in the sequencing of the projection and aggregation operations.  
+ The identification of three different tasks, which span a range of projection and un-projection operations, enriches the analysis and allows for a clear identification of the strengths and weaknesses of each aggregation strategy. I also appreciated the toy experiments, which effectively mimic the 3D effect in a simpler 2D setup.  
+ The final strategy advocated for in this work aligns with the standard DDIM, is straightforward to implement, requires no additional tuning, and does not incur extra computational costs.","- Missing Explanations: The figures are difficult to understand due to missing information. For example, Figure 3 does not explicitly state the experimental setup, including the definitions of the canonical space and the subspaces.
- The formulation of cases 1-3 that operate in the subspace does not explain how the recovered signal in z is finally returned. This is related to my previous comment, where it seems Figure 3 shows individual subspace generations rather than the end goal/task.
- The initialization process is not discussed in the main paper. It is unclear whether the subspaces share the same initial noise. If they do, how is noise being generated in z? This is particularly challenging when z is 3DGS.
- In the appendix, it states that the 3DGS are optimized towards the predicted clean images. Is this optimization considered the unprojection operation ""g""? If so, this should be explicitly stated and moved to the main paper. More details on this optimization process are needed, including whether it is performed until convergence at each denoising time during generation.
- In lines 129-130, phi and psi are used in the target domain. Please explain how this is done properly, given that noise is not injected in that space. Why would the coefficients in eq (3) and (4) hold true?

- The caption of Figure 1, “Diverse visual content generated by SyncTweedies,” and the abstract phrase ""generating diverse visual content"" are misleading. They suggest the generation of general 3D content, while the method, as mentioned in the limitations, relies on known mappings between the subspaces and the target space, limiting it to texturing tasks. The authors should tone down these statements.
- If the mapping from the canonical space to the instance spaces is simple (say, linear or even the Idnetity mapping), it seems all ""cases"" perform similarly both quantitatively and qualitatively. Do these methods mathematically converge to the same method, or are there still differences? In the 1-1 projection example in Figure 3, it appears all methods produce the same result. Is this correct? Table 10A shows almost identical results for different methods, and in Table 1, the scores for the 1-1 cases are very similar.
- The claim of being the first to propose this method and that it was previously ""overlooked"" is too bold. Guidance literature shows that guidance in ""\hat{x_0}"" offers more stable optimization and results. While guidance differs from multi-diffusion, it is similar enough to make the analogy. The authors should discuss similarities and differences, referencing papers like ""Universal Guidance for Diffusion Models"" and motion diffusion papers such as MDM and Trace&Pace. Further, if in degenerate cases of f and g maps (e.g. if they are the identity function) some ""cases"" are indistinguishable, be mindful when attributing aggregation choices to these methods (e.g., MultiDiffusion). Methods requiring tuning, like DiffCollage, should not be dismissed as baselines. The main contribution of this paper is identifying the best ""place"" to aggregate, and tuning is somewhat orthogonal. If ""Case 2"" improves DiffCollage, this should be demonstrated.
- The term ""1:1 case"" is confusing and suggests disjoint individual subspaces.
- The integration process of 1:n should also be better explained. It may also be useful to add illustration figures. 
- Improve Figure 2 for clarity with a more detailed caption. Connecting the diagram to the notations introduced in the paper would also help readability.",please see weaknesses.,See weaknesses -- the work in it sucrrent form is limited to known geometry,['No ethics review needed.'],7,4,,Yes,3,3,3,1720724001442,,,NeurIPS.cc/2024/Conference,06Vt6f2js7,"['NeurIPS.cc/2024/Conference/Submission370/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878639039,[],3,,,['everyone'],06Vt6f2js7,['NeurIPS.cc/2024/Conference/Submission370/Reviewer_KJxR'],1720724001442,1730878639039,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission370/Reviewer_KJxR']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. ""Universal Guidance for Diffusion Models""
2. Motion diffusion papers such as MDM and Trace&Pace
3. DiffCollage (and potentially other methods that require tuning)

The reviewer recommends that the authors discuss the similarities and differences between their proposed method and these existing works, in order to provide a more accurate and nuanced understanding of the contributions and limitations of their paper.",1,,Trace&Pace 
ZdCnVNUdvI,"This paper investigates content generation within a target space using pretrained diffusion models operating in projected subspaces. The authors analyze five variants of the DDIM procedure, performed separately in each subspace and aggregated in the target space using known projection and unprojection operators. They explore different sequences of projection and aggregation, concluding that the optimal approach is to aggregate each subspace's ""estimated x0 from xt"" (the output of Tweedie's formula).

The method is evaluated through texturing tasks involving depth, mesh, and 3DGS, each representing distinct projection and unprojection scenarios. The ablation study and comparisons against baselines demonstrate the robustness of the proposed aggregation stage.","+ The paper effectively breaks down the multi-DDIM process, clearly delineating distinct alternatives that differ in the sequencing of the projection and aggregation operations.  
+ The identification of three different tasks, which span a range of projection and un-projection operations, enriches the analysis and allows for a clear identification of the strengths and weaknesses of each aggregation strategy. I also appreciated the toy experiments, which effectively mimic the 3D effect in a simpler 2D setup.  
+ The final strategy advocated for in this work aligns with the standard DDIM, is straightforward to implement, requires no additional tuning, and does not incur extra computational costs.","- Missing Explanations: The figures are difficult to understand due to missing information. For example, Figure 3 does not explicitly state the experimental setup, including the definitions of the canonical space and the subspaces.
- The formulation of cases 1-3 that operate in the subspace does not explain how the recovered signal in z is finally returned. This is related to my previous comment, where it seems Figure 3 shows individual subspace generations rather than the end goal/task.
- The initialization process is not discussed in the main paper. It is unclear whether the subspaces share the same initial noise. If they do, how is noise being generated in z? This is particularly challenging when z is 3DGS.
- In the appendix, it states that the 3DGS are optimized towards the predicted clean images. Is this optimization considered the unprojection operation ""g""? If so, this should be explicitly stated and moved to the main paper. More details on this optimization process are needed, including whether it is performed until convergence at each denoising time during generation.
- In lines 129-130, phi and psi are used in the target domain. Please explain how this is done properly, given that noise is not injected in that space. Why would the coefficients in eq (3) and (4) hold true?

- The caption of Figure 1, “Diverse visual content generated by SyncTweedies,” and the abstract phrase ""generating diverse visual content"" are misleading. They suggest the generation of general 3D content, while the method, as mentioned in the limitations, relies on known mappings between the subspaces and the target space, limiting it to texturing tasks. The authors should tone down these statements.
- If the mapping from the canonical space to the instance spaces is simple (say, linear or even the Idnetity mapping), it seems all ""cases"" perform similarly both quantitatively and qualitatively. Do these methods mathematically converge to the same method, or are there still differences? In the 1-1 projection example in Figure 3, it appears all methods produce the same result. Is this correct? Table 10A shows almost identical results for different methods, and in Table 1, the scores for the 1-1 cases are very similar.
- The claim of being the first to propose this method and that it was previously ""overlooked"" is too bold. Guidance literature shows that guidance in ""\hat{x_0}"" offers more stable optimization and results. While guidance differs from multi-diffusion, it is similar enough to make the analogy. The authors should discuss similarities and differences, referencing papers like ""Universal Guidance for Diffusion Models"" and motion diffusion papers such as MDM and Trace&Pace. Further, if in degenerate cases of f and g maps (e.g. if they are the identity function) some ""cases"" are indistinguishable, be mindful when attributing aggregation choices to these methods (e.g., MultiDiffusion). Methods requiring tuning, like DiffCollage, should not be dismissed as baselines. The main contribution of this paper is identifying the best ""place"" to aggregate, and tuning is somewhat orthogonal. If ""Case 2"" improves DiffCollage, this should be demonstrated.
- The term ""1:1 case"" is confusing and suggests disjoint individual subspaces.
- The integration process of 1:n should also be better explained. It may also be useful to add illustration figures. 
- Improve Figure 2 for clarity with a more detailed caption. Connecting the diagram to the notations introduced in the paper would also help readability.",please see weaknesses.,See weaknesses -- the work in it sucrrent form is limited to known geometry,['No ethics review needed.'],7,4,,Yes,3,3,3,1720724001442,,,NeurIPS.cc/2024/Conference,06Vt6f2js7,"['NeurIPS.cc/2024/Conference/Submission370/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878639039,[],3,,,['everyone'],06Vt6f2js7,['NeurIPS.cc/2024/Conference/Submission370/Reviewer_KJxR'],1720724001442,1730878639039,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission370/Reviewer_KJxR']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. ""Universal Guidance for Diffusion Models""
2. Motion diffusion papers such as MDM and Trace&Pace
3. DiffCollage (and potentially other methods that require tuning)

The reviewer recommends that the authors discuss the similarities and differences between their proposed method and these existing works, in order to provide a more accurate and nuanced understanding of the contributions and limitations of their paper.",1,,DiffCollage
LvgBVJYE40,"The author introduced the Voxel Proposal Network (VPNet), a dual-branch semantic scene completion method with two key innovations.
First, the Confident Voxel Proposal (CVP) module, which includes offset learning and voxel proposal, generates a confident feature map based on the semantics-embedded feature map, enabling completion in the 3D branch. Second, the Multi-Frame Knowledge Distillation (MFKD) module distills semantic knowledge from each augmented feature map of the multi-frame network into the branches of the single-frame network in two stages, enhancing completion performance.","This manuscript has clear structure, well-benchmarked qualitative and quantitative results.","1. Lack of Comparison with State-of-the-Art Methods: The performance of VPNet is not compared with current state-of-the-art methods such as SCPNet. Specifically, (mIoU) achieved by VPNet is far lower than that of SCPNet. Or authors can argue and clarify clearly the protocol differences that render the comparison invalid.

2. SCPNet has already implemented multi-frame distillation to enhance performance. Thus, VPNet's use of Multi-Frame Knowledge Distillation (MFKD) is not readily qualified as a core contribution in the title. Or authors can dig into the effects of multi-frame distillation in different frameworks like SCPNet and [A].

[A] MonoOcc: Digging into Monocular Semantic Occupancy Prediction, ICRA 2024",It is recommended to answer questions whether there is a protocol compatibility with SCPNet and whether there are unique insights about multi-frame distillation in this study over SCPNet and MonoOcc.,No social impact limitations to be addressed.,['No ethics review needed.'],5,5,,Yes,2,3,2,1720788323521,,,NeurIPS.cc/2024/Conference,02HWT9c4Lp,"['NeurIPS.cc/2024/Conference/Submission4361/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878921446,[],3,,,['everyone'],02HWT9c4Lp,['NeurIPS.cc/2024/Conference/Submission4361/Reviewer_Rcs7'],1720788323521,1730878921446,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4361/Reviewer_Rcs7']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. SCPNet (a state-of-the-art method for comparison)
2. MonoOcc: Digging into Monocular Semantic Occupancy Prediction, ICRA 2024 (for comparison and to discuss the effects of multi-frame distillation in different frameworks)",1,2024,SCPNet 
LvgBVJYE40,"The author introduced the Voxel Proposal Network (VPNet), a dual-branch semantic scene completion method with two key innovations.
First, the Confident Voxel Proposal (CVP) module, which includes offset learning and voxel proposal, generates a confident feature map based on the semantics-embedded feature map, enabling completion in the 3D branch. Second, the Multi-Frame Knowledge Distillation (MFKD) module distills semantic knowledge from each augmented feature map of the multi-frame network into the branches of the single-frame network in two stages, enhancing completion performance.","This manuscript has clear structure, well-benchmarked qualitative and quantitative results.","1. Lack of Comparison with State-of-the-Art Methods: The performance of VPNet is not compared with current state-of-the-art methods such as SCPNet. Specifically, (mIoU) achieved by VPNet is far lower than that of SCPNet. Or authors can argue and clarify clearly the protocol differences that render the comparison invalid.

2. SCPNet has already implemented multi-frame distillation to enhance performance. Thus, VPNet's use of Multi-Frame Knowledge Distillation (MFKD) is not readily qualified as a core contribution in the title. Or authors can dig into the effects of multi-frame distillation in different frameworks like SCPNet and [A].

[A] MonoOcc: Digging into Monocular Semantic Occupancy Prediction, ICRA 2024",It is recommended to answer questions whether there is a protocol compatibility with SCPNet and whether there are unique insights about multi-frame distillation in this study over SCPNet and MonoOcc.,No social impact limitations to be addressed.,['No ethics review needed.'],5,5,,Yes,2,3,2,1720788323521,,,NeurIPS.cc/2024/Conference,02HWT9c4Lp,"['NeurIPS.cc/2024/Conference/Submission4361/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730878921446,[],3,,,['everyone'],02HWT9c4Lp,['NeurIPS.cc/2024/Conference/Submission4361/Reviewer_Rcs7'],1720788323521,1730878921446,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission4361/Reviewer_Rcs7']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, namely:

1. SCPNet (a state-of-the-art method for comparison)
2. MonoOcc: Digging into Monocular Semantic Occupancy Prediction, ICRA 2024 (for comparison and to discuss the effects of multi-frame distillation in different frameworks)",1,2024,MonoOcc Digging into Monocular Semantic Occupancy Prediction
mfUyrocIiX,"The paper introduces PointAD, the first approach to explore the domain of zero-shot 3D anomaly detection, leveraging CLIP's strong generalization to identify anomalies in previously unseen objects. It offers a unified framework that integrates 3D point clouds with 2D renderings, employing hybrid representation learning to capture the semantics of anomalies. PointAD's key contributions are its pioneering exploration of the ZS 3D anomaly detection domain, its ability to seamlessly integrate multimodal data like RGB information for enhanced detection, and its superior performance over existing methods. The robustness of the framework is confirmed through extensive experiments.","Originality: The paper introduces PointAD, a novel method in 3D anomaly detection that leverages CLIP for 3D analysis, uniquely combining point clouds and pixel data. It expands the application of vision-language models into new domains, showcasing versatility in 3D point cloud analysis.
Soundness: The paper exhibits methodological soundness through its rigorous experimental setup, including the use of diverse datasets and a thorough ablation study that substantiates the design decisions and effectiveness of the proposed PointAD framework. The state-of-the-art experiments performance confirms the model's outperforming ability.  
Clarity: The paper stands out for its clarity, guiding readers smoothly from the problem statement to the final results. It skillfully explains complex concepts in an accessible way, ensuring that a wider audience can follow along. The paper also benefits from helpful visual aids that clearly demonstrate the model's effectiveness.","1.	There’s some zero-shot anomaly detection methods with clip on 2D images, so this paper should compare with them, especially, from the view of techniques’ differences, not only the used data differences. For example, those zero-shot methods (WinCLIP, VAND and AnomalyCLIP) mentioned in [R1] and [R2].
[R1] Cao, Y., Xu, X., Zhang, J., Cheng, Y., Huang, X., Pang, G., & Shen, W. (2024). A survey on visual anomaly detection: Challenge, approach, and prospect. arxiv preprint arxiv:2401.16402.
[R2] Li, X., Huang, Z., Xue, F., & Zhou, Y. (2024). Musc: Zero-shot industrial anomaly classification and segmentation with mutual scoring of the unlabeled images. arxiv preprint arxiv:2401.16753.

2.	I also wonder if the new methods of 3D anomaly detection can also be used to deal with this zero-shot task. For example, [R3] and [R4]. 
[R3] Zuo, Z., Dong, J., Wu, Y., Qu, Y., & Wu, Z. (2024). CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation. arxiv preprint arxiv:2406.18941.
[R4] Li, W., Xu, X., Gu, Y., Zheng, B., Gao, S., & Wu, Y. (2024). Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 22207-22216).
3.	More importantly, there’s some very similar studies with this work and task. Authors should mention and compare them within this study. For example, [R5].
[R5] Li, Y., Goodge, A., Liu, F., & Foo, C. S. (2024). Promptad: Zero-shot anomaly detection using text prompts. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1093-1102).
[R6] X. Chen, J. Zhang, G. Tian, H. He, W. Zhang, Y. Wang, C. Wang,Y. Wu, and Y. Liu, “Clip-ad: A language-guided staged dual-
path model for zero-shot anomaly detection,” arXiv preprint
arXiv:2311.00453, 2023.
[R7] Wang, C., Zhu, H., Peng, J., Wang, Y., Yi, R., Wu, Y., ... & Zhang, J. (2024). M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising. arxiv preprint arxiv:2406.02263.
4.	Computational Efficiency: Although the authors have commendably addressed computational challenges, the overall computational cost associated with rendering multi-view images and processing them through the vision encoder is still substantial. Since this field is still developing with few comparable studies, it is recommended that the authors provide a broader comparison about the computational cost with existing anomaly detection techniques, including those like Cheraghian, CPFM and 3DSR that are not strictly within the zero-shot category. This expanded comparison will help to show that the computational demands of PointAD are reasonable and suitable for practical use cases.
5.	Clarity and Completeness of Presentation: The paper's writing is generally clear and free of errors, yet minor aspects of the presentation could be polished for better reader comprehension. For instance, the figure overlays, specifically in Figure 1, currently only elucidate part (a), leaving explanations for parts (b) and (c) to be found in the main text. This separation can disrupt the reader's flow and understanding. Enhancing the figure overlays to include all relevant parts and ensuring that each component of the figure is self-explanatory will make the paper more accessible and its findings easier to grasp.","1.	Please answer the main differences with these mentioned methods in Weaknesses and compare with part of them on experiments.
2.	Given the concerns raised in the Weaknesses section 1, does PointAD still hold the merit of computational efficiency when compared to other methods such as AnomalyCLIP and Cheraghian?
3.	Could you elaborate on the multi-view rendering process of point clouds (as described from line 134 to line 140), particularly how the color of the rendered images is determined? Furthermore, at line 254, it's stated that additional RGB information is utilized only in the test dataset. Given the description at line 564, which refers to 2D RGB information, how is this 2D data integrated with the rendered multi-view images? Are there any strategies which are employed to bridge the gap between the rendered training data and the RGB information used in testing?","The authors have discussed the limitations of their model, and there are no potential negative societal impacts associated with their work.",['No ethics review needed.'],6,5,,Yes,3,3,3,1720922193100,,,NeurIPS.cc/2024/Conference,02CIZ8qeDc,"['NeurIPS.cc/2024/Conference/Submission11298/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879455150,[],2,,,['everyone'],02CIZ8qeDc,['NeurIPS.cc/2024/Conference/Submission11298/Reviewer_GgEU'],1720922193100,1730879455150,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11298/Reviewer_GgEU']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Cao, Y., Xu, X., Zhang, J., Cheng, Y., Huang, X., Pang, G., & Shen, W. (2024). A survey on visual anomaly detection: Challenge, approach, and prospect. arxiv preprint arxiv:2401.16402.
2. Li, X., Huang, Z., Xue, F., & Zhou, Y. (2024). Musc: Zero-shot industrial anomaly classification and segmentation with mutual scoring of the unlabeled images. arxiv preprint arxiv:2401.16753.
3. Zuo, Z., Dong, J., Wu, Y., Qu, Y., & Wu, Z. (2024). CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation. arxiv preprint arxiv:2406.18941.
4. Li, W., Xu, X., Gu, Y., Zheng, B., Gao, S., & Wu, Y. (2024). Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 22207-22216).
5. Li, Y., Goodge, A., Liu, F., & Foo, C. S. (2024). Promptad: Zero-shot anomaly detection using text prompts. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1093-1102).
6. X. Chen, J. Zhang, G. Tian, H. He, W. Zhang, Y. Wang, C. Wang,Y. Wu, and Y. Liu, “Clip-ad: A language-guided staged dual-path model for zero-shot anomaly detection,” arXiv preprint arXiv:2311.00453, 2023.
7. Wang, C., Zhu, H., Peng, J., Wang, Y., Yi, R., Wu, Y., ... & Zhang, J. (2024). M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising. arxiv preprint arxiv:240",1,"2024, 2024, 2024, 2024, 2024, 2023, 2023, 2024",A survey on visual anomaly detection 
mfUyrocIiX,"The paper introduces PointAD, the first approach to explore the domain of zero-shot 3D anomaly detection, leveraging CLIP's strong generalization to identify anomalies in previously unseen objects. It offers a unified framework that integrates 3D point clouds with 2D renderings, employing hybrid representation learning to capture the semantics of anomalies. PointAD's key contributions are its pioneering exploration of the ZS 3D anomaly detection domain, its ability to seamlessly integrate multimodal data like RGB information for enhanced detection, and its superior performance over existing methods. The robustness of the framework is confirmed through extensive experiments.","Originality: The paper introduces PointAD, a novel method in 3D anomaly detection that leverages CLIP for 3D analysis, uniquely combining point clouds and pixel data. It expands the application of vision-language models into new domains, showcasing versatility in 3D point cloud analysis.
Soundness: The paper exhibits methodological soundness through its rigorous experimental setup, including the use of diverse datasets and a thorough ablation study that substantiates the design decisions and effectiveness of the proposed PointAD framework. The state-of-the-art experiments performance confirms the model's outperforming ability.  
Clarity: The paper stands out for its clarity, guiding readers smoothly from the problem statement to the final results. It skillfully explains complex concepts in an accessible way, ensuring that a wider audience can follow along. The paper also benefits from helpful visual aids that clearly demonstrate the model's effectiveness.","1.	There’s some zero-shot anomaly detection methods with clip on 2D images, so this paper should compare with them, especially, from the view of techniques’ differences, not only the used data differences. For example, those zero-shot methods (WinCLIP, VAND and AnomalyCLIP) mentioned in [R1] and [R2].
[R1] Cao, Y., Xu, X., Zhang, J., Cheng, Y., Huang, X., Pang, G., & Shen, W. (2024). A survey on visual anomaly detection: Challenge, approach, and prospect. arxiv preprint arxiv:2401.16402.
[R2] Li, X., Huang, Z., Xue, F., & Zhou, Y. (2024). Musc: Zero-shot industrial anomaly classification and segmentation with mutual scoring of the unlabeled images. arxiv preprint arxiv:2401.16753.

2.	I also wonder if the new methods of 3D anomaly detection can also be used to deal with this zero-shot task. For example, [R3] and [R4]. 
[R3] Zuo, Z., Dong, J., Wu, Y., Qu, Y., & Wu, Z. (2024). CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation. arxiv preprint arxiv:2406.18941.
[R4] Li, W., Xu, X., Gu, Y., Zheng, B., Gao, S., & Wu, Y. (2024). Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 22207-22216).
3.	More importantly, there’s some very similar studies with this work and task. Authors should mention and compare them within this study. For example, [R5].
[R5] Li, Y., Goodge, A., Liu, F., & Foo, C. S. (2024). Promptad: Zero-shot anomaly detection using text prompts. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1093-1102).
[R6] X. Chen, J. Zhang, G. Tian, H. He, W. Zhang, Y. Wang, C. Wang,Y. Wu, and Y. Liu, “Clip-ad: A language-guided staged dual-
path model for zero-shot anomaly detection,” arXiv preprint
arXiv:2311.00453, 2023.
[R7] Wang, C., Zhu, H., Peng, J., Wang, Y., Yi, R., Wu, Y., ... & Zhang, J. (2024). M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising. arxiv preprint arxiv:2406.02263.
4.	Computational Efficiency: Although the authors have commendably addressed computational challenges, the overall computational cost associated with rendering multi-view images and processing them through the vision encoder is still substantial. Since this field is still developing with few comparable studies, it is recommended that the authors provide a broader comparison about the computational cost with existing anomaly detection techniques, including those like Cheraghian, CPFM and 3DSR that are not strictly within the zero-shot category. This expanded comparison will help to show that the computational demands of PointAD are reasonable and suitable for practical use cases.
5.	Clarity and Completeness of Presentation: The paper's writing is generally clear and free of errors, yet minor aspects of the presentation could be polished for better reader comprehension. For instance, the figure overlays, specifically in Figure 1, currently only elucidate part (a), leaving explanations for parts (b) and (c) to be found in the main text. This separation can disrupt the reader's flow and understanding. Enhancing the figure overlays to include all relevant parts and ensuring that each component of the figure is self-explanatory will make the paper more accessible and its findings easier to grasp.","1.	Please answer the main differences with these mentioned methods in Weaknesses and compare with part of them on experiments.
2.	Given the concerns raised in the Weaknesses section 1, does PointAD still hold the merit of computational efficiency when compared to other methods such as AnomalyCLIP and Cheraghian?
3.	Could you elaborate on the multi-view rendering process of point clouds (as described from line 134 to line 140), particularly how the color of the rendered images is determined? Furthermore, at line 254, it's stated that additional RGB information is utilized only in the test dataset. Given the description at line 564, which refers to 2D RGB information, how is this 2D data integrated with the rendered multi-view images? Are there any strategies which are employed to bridge the gap between the rendered training data and the RGB information used in testing?","The authors have discussed the limitations of their model, and there are no potential negative societal impacts associated with their work.",['No ethics review needed.'],6,5,,Yes,3,3,3,1720922193100,,,NeurIPS.cc/2024/Conference,02CIZ8qeDc,"['NeurIPS.cc/2024/Conference/Submission11298/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879455150,[],2,,,['everyone'],02CIZ8qeDc,['NeurIPS.cc/2024/Conference/Submission11298/Reviewer_GgEU'],1720922193100,1730879455150,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11298/Reviewer_GgEU']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Cao, Y., Xu, X., Zhang, J., Cheng, Y., Huang, X., Pang, G., & Shen, W. (2024). A survey on visual anomaly detection: Challenge, approach, and prospect. arxiv preprint arxiv:2401.16402.
2. Li, X., Huang, Z., Xue, F., & Zhou, Y. (2024). Musc: Zero-shot industrial anomaly classification and segmentation with mutual scoring of the unlabeled images. arxiv preprint arxiv:2401.16753.
3. Zuo, Z., Dong, J., Wu, Y., Qu, Y., & Wu, Z. (2024). CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation. arxiv preprint arxiv:2406.18941.
4. Li, W., Xu, X., Gu, Y., Zheng, B., Gao, S., & Wu, Y. (2024). Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 22207-22216).
5. Li, Y., Goodge, A., Liu, F., & Foo, C. S. (2024). Promptad: Zero-shot anomaly detection using text prompts. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1093-1102).
6. X. Chen, J. Zhang, G. Tian, H. He, W. Zhang, Y. Wang, C. Wang,Y. Wu, and Y. Liu, “Clip-ad: A language-guided staged dual-path model for zero-shot anomaly detection,” arXiv preprint arXiv:2311.00453, 2023.
7. Wang, C., Zhu, H., Peng, J., Wang, Y., Yi, R., Wu, Y., ... & Zhang, J. (2024). M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising. arxiv preprint arxiv:240",1,"2024, 2024, 2024, 2024, 2024, 2023, 2023, 2024",MusC 
mfUyrocIiX,"The paper introduces PointAD, the first approach to explore the domain of zero-shot 3D anomaly detection, leveraging CLIP's strong generalization to identify anomalies in previously unseen objects. It offers a unified framework that integrates 3D point clouds with 2D renderings, employing hybrid representation learning to capture the semantics of anomalies. PointAD's key contributions are its pioneering exploration of the ZS 3D anomaly detection domain, its ability to seamlessly integrate multimodal data like RGB information for enhanced detection, and its superior performance over existing methods. The robustness of the framework is confirmed through extensive experiments.","Originality: The paper introduces PointAD, a novel method in 3D anomaly detection that leverages CLIP for 3D analysis, uniquely combining point clouds and pixel data. It expands the application of vision-language models into new domains, showcasing versatility in 3D point cloud analysis.
Soundness: The paper exhibits methodological soundness through its rigorous experimental setup, including the use of diverse datasets and a thorough ablation study that substantiates the design decisions and effectiveness of the proposed PointAD framework. The state-of-the-art experiments performance confirms the model's outperforming ability.  
Clarity: The paper stands out for its clarity, guiding readers smoothly from the problem statement to the final results. It skillfully explains complex concepts in an accessible way, ensuring that a wider audience can follow along. The paper also benefits from helpful visual aids that clearly demonstrate the model's effectiveness.","1.	There’s some zero-shot anomaly detection methods with clip on 2D images, so this paper should compare with them, especially, from the view of techniques’ differences, not only the used data differences. For example, those zero-shot methods (WinCLIP, VAND and AnomalyCLIP) mentioned in [R1] and [R2].
[R1] Cao, Y., Xu, X., Zhang, J., Cheng, Y., Huang, X., Pang, G., & Shen, W. (2024). A survey on visual anomaly detection: Challenge, approach, and prospect. arxiv preprint arxiv:2401.16402.
[R2] Li, X., Huang, Z., Xue, F., & Zhou, Y. (2024). Musc: Zero-shot industrial anomaly classification and segmentation with mutual scoring of the unlabeled images. arxiv preprint arxiv:2401.16753.

2.	I also wonder if the new methods of 3D anomaly detection can also be used to deal with this zero-shot task. For example, [R3] and [R4]. 
[R3] Zuo, Z., Dong, J., Wu, Y., Qu, Y., & Wu, Z. (2024). CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation. arxiv preprint arxiv:2406.18941.
[R4] Li, W., Xu, X., Gu, Y., Zheng, B., Gao, S., & Wu, Y. (2024). Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 22207-22216).
3.	More importantly, there’s some very similar studies with this work and task. Authors should mention and compare them within this study. For example, [R5].
[R5] Li, Y., Goodge, A., Liu, F., & Foo, C. S. (2024). Promptad: Zero-shot anomaly detection using text prompts. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1093-1102).
[R6] X. Chen, J. Zhang, G. Tian, H. He, W. Zhang, Y. Wang, C. Wang,Y. Wu, and Y. Liu, “Clip-ad: A language-guided staged dual-
path model for zero-shot anomaly detection,” arXiv preprint
arXiv:2311.00453, 2023.
[R7] Wang, C., Zhu, H., Peng, J., Wang, Y., Yi, R., Wu, Y., ... & Zhang, J. (2024). M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising. arxiv preprint arxiv:2406.02263.
4.	Computational Efficiency: Although the authors have commendably addressed computational challenges, the overall computational cost associated with rendering multi-view images and processing them through the vision encoder is still substantial. Since this field is still developing with few comparable studies, it is recommended that the authors provide a broader comparison about the computational cost with existing anomaly detection techniques, including those like Cheraghian, CPFM and 3DSR that are not strictly within the zero-shot category. This expanded comparison will help to show that the computational demands of PointAD are reasonable and suitable for practical use cases.
5.	Clarity and Completeness of Presentation: The paper's writing is generally clear and free of errors, yet minor aspects of the presentation could be polished for better reader comprehension. For instance, the figure overlays, specifically in Figure 1, currently only elucidate part (a), leaving explanations for parts (b) and (c) to be found in the main text. This separation can disrupt the reader's flow and understanding. Enhancing the figure overlays to include all relevant parts and ensuring that each component of the figure is self-explanatory will make the paper more accessible and its findings easier to grasp.","1.	Please answer the main differences with these mentioned methods in Weaknesses and compare with part of them on experiments.
2.	Given the concerns raised in the Weaknesses section 1, does PointAD still hold the merit of computational efficiency when compared to other methods such as AnomalyCLIP and Cheraghian?
3.	Could you elaborate on the multi-view rendering process of point clouds (as described from line 134 to line 140), particularly how the color of the rendered images is determined? Furthermore, at line 254, it's stated that additional RGB information is utilized only in the test dataset. Given the description at line 564, which refers to 2D RGB information, how is this 2D data integrated with the rendered multi-view images? Are there any strategies which are employed to bridge the gap between the rendered training data and the RGB information used in testing?","The authors have discussed the limitations of their model, and there are no potential negative societal impacts associated with their work.",['No ethics review needed.'],6,5,,Yes,3,3,3,1720922193100,,,NeurIPS.cc/2024/Conference,02CIZ8qeDc,"['NeurIPS.cc/2024/Conference/Submission11298/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879455150,[],2,,,['everyone'],02CIZ8qeDc,['NeurIPS.cc/2024/Conference/Submission11298/Reviewer_GgEU'],1720922193100,1730879455150,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11298/Reviewer_GgEU']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Cao, Y., Xu, X., Zhang, J., Cheng, Y., Huang, X., Pang, G., & Shen, W. (2024). A survey on visual anomaly detection: Challenge, approach, and prospect. arxiv preprint arxiv:2401.16402.
2. Li, X., Huang, Z., Xue, F., & Zhou, Y. (2024). Musc: Zero-shot industrial anomaly classification and segmentation with mutual scoring of the unlabeled images. arxiv preprint arxiv:2401.16753.
3. Zuo, Z., Dong, J., Wu, Y., Qu, Y., & Wu, Z. (2024). CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation. arxiv preprint arxiv:2406.18941.
4. Li, W., Xu, X., Gu, Y., Zheng, B., Gao, S., & Wu, Y. (2024). Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 22207-22216).
5. Li, Y., Goodge, A., Liu, F., & Foo, C. S. (2024). Promptad: Zero-shot anomaly detection using text prompts. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1093-1102).
6. X. Chen, J. Zhang, G. Tian, H. He, W. Zhang, Y. Wang, C. Wang,Y. Wu, and Y. Liu, “Clip-ad: A language-guided staged dual-path model for zero-shot anomaly detection,” arXiv preprint arXiv:2311.00453, 2023.
7. Wang, C., Zhu, H., Peng, J., Wang, Y., Yi, R., Wu, Y., ... & Zhang, J. (2024). M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising. arxiv preprint arxiv:240",1,"2024, 2024, 2024, 2024, 2024, 2023, 2023, 2024",CLIP3D-AD 
mfUyrocIiX,"The paper introduces PointAD, the first approach to explore the domain of zero-shot 3D anomaly detection, leveraging CLIP's strong generalization to identify anomalies in previously unseen objects. It offers a unified framework that integrates 3D point clouds with 2D renderings, employing hybrid representation learning to capture the semantics of anomalies. PointAD's key contributions are its pioneering exploration of the ZS 3D anomaly detection domain, its ability to seamlessly integrate multimodal data like RGB information for enhanced detection, and its superior performance over existing methods. The robustness of the framework is confirmed through extensive experiments.","Originality: The paper introduces PointAD, a novel method in 3D anomaly detection that leverages CLIP for 3D analysis, uniquely combining point clouds and pixel data. It expands the application of vision-language models into new domains, showcasing versatility in 3D point cloud analysis.
Soundness: The paper exhibits methodological soundness through its rigorous experimental setup, including the use of diverse datasets and a thorough ablation study that substantiates the design decisions and effectiveness of the proposed PointAD framework. The state-of-the-art experiments performance confirms the model's outperforming ability.  
Clarity: The paper stands out for its clarity, guiding readers smoothly from the problem statement to the final results. It skillfully explains complex concepts in an accessible way, ensuring that a wider audience can follow along. The paper also benefits from helpful visual aids that clearly demonstrate the model's effectiveness.","1.	There’s some zero-shot anomaly detection methods with clip on 2D images, so this paper should compare with them, especially, from the view of techniques’ differences, not only the used data differences. For example, those zero-shot methods (WinCLIP, VAND and AnomalyCLIP) mentioned in [R1] and [R2].
[R1] Cao, Y., Xu, X., Zhang, J., Cheng, Y., Huang, X., Pang, G., & Shen, W. (2024). A survey on visual anomaly detection: Challenge, approach, and prospect. arxiv preprint arxiv:2401.16402.
[R2] Li, X., Huang, Z., Xue, F., & Zhou, Y. (2024). Musc: Zero-shot industrial anomaly classification and segmentation with mutual scoring of the unlabeled images. arxiv preprint arxiv:2401.16753.

2.	I also wonder if the new methods of 3D anomaly detection can also be used to deal with this zero-shot task. For example, [R3] and [R4]. 
[R3] Zuo, Z., Dong, J., Wu, Y., Qu, Y., & Wu, Z. (2024). CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation. arxiv preprint arxiv:2406.18941.
[R4] Li, W., Xu, X., Gu, Y., Zheng, B., Gao, S., & Wu, Y. (2024). Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 22207-22216).
3.	More importantly, there’s some very similar studies with this work and task. Authors should mention and compare them within this study. For example, [R5].
[R5] Li, Y., Goodge, A., Liu, F., & Foo, C. S. (2024). Promptad: Zero-shot anomaly detection using text prompts. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1093-1102).
[R6] X. Chen, J. Zhang, G. Tian, H. He, W. Zhang, Y. Wang, C. Wang,Y. Wu, and Y. Liu, “Clip-ad: A language-guided staged dual-
path model for zero-shot anomaly detection,” arXiv preprint
arXiv:2311.00453, 2023.
[R7] Wang, C., Zhu, H., Peng, J., Wang, Y., Yi, R., Wu, Y., ... & Zhang, J. (2024). M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising. arxiv preprint arxiv:2406.02263.
4.	Computational Efficiency: Although the authors have commendably addressed computational challenges, the overall computational cost associated with rendering multi-view images and processing them through the vision encoder is still substantial. Since this field is still developing with few comparable studies, it is recommended that the authors provide a broader comparison about the computational cost with existing anomaly detection techniques, including those like Cheraghian, CPFM and 3DSR that are not strictly within the zero-shot category. This expanded comparison will help to show that the computational demands of PointAD are reasonable and suitable for practical use cases.
5.	Clarity and Completeness of Presentation: The paper's writing is generally clear and free of errors, yet minor aspects of the presentation could be polished for better reader comprehension. For instance, the figure overlays, specifically in Figure 1, currently only elucidate part (a), leaving explanations for parts (b) and (c) to be found in the main text. This separation can disrupt the reader's flow and understanding. Enhancing the figure overlays to include all relevant parts and ensuring that each component of the figure is self-explanatory will make the paper more accessible and its findings easier to grasp.","1.	Please answer the main differences with these mentioned methods in Weaknesses and compare with part of them on experiments.
2.	Given the concerns raised in the Weaknesses section 1, does PointAD still hold the merit of computational efficiency when compared to other methods such as AnomalyCLIP and Cheraghian?
3.	Could you elaborate on the multi-view rendering process of point clouds (as described from line 134 to line 140), particularly how the color of the rendered images is determined? Furthermore, at line 254, it's stated that additional RGB information is utilized only in the test dataset. Given the description at line 564, which refers to 2D RGB information, how is this 2D data integrated with the rendered multi-view images? Are there any strategies which are employed to bridge the gap between the rendered training data and the RGB information used in testing?","The authors have discussed the limitations of their model, and there are no potential negative societal impacts associated with their work.",['No ethics review needed.'],6,5,,Yes,3,3,3,1720922193100,,,NeurIPS.cc/2024/Conference,02CIZ8qeDc,"['NeurIPS.cc/2024/Conference/Submission11298/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879455150,[],2,,,['everyone'],02CIZ8qeDc,['NeurIPS.cc/2024/Conference/Submission11298/Reviewer_GgEU'],1720922193100,1730879455150,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11298/Reviewer_GgEU']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Cao, Y., Xu, X., Zhang, J., Cheng, Y., Huang, X., Pang, G., & Shen, W. (2024). A survey on visual anomaly detection: Challenge, approach, and prospect. arxiv preprint arxiv:2401.16402.
2. Li, X., Huang, Z., Xue, F., & Zhou, Y. (2024). Musc: Zero-shot industrial anomaly classification and segmentation with mutual scoring of the unlabeled images. arxiv preprint arxiv:2401.16753.
3. Zuo, Z., Dong, J., Wu, Y., Qu, Y., & Wu, Z. (2024). CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation. arxiv preprint arxiv:2406.18941.
4. Li, W., Xu, X., Gu, Y., Zheng, B., Gao, S., & Wu, Y. (2024). Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 22207-22216).
5. Li, Y., Goodge, A., Liu, F., & Foo, C. S. (2024). Promptad: Zero-shot anomaly detection using text prompts. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1093-1102).
6. X. Chen, J. Zhang, G. Tian, H. He, W. Zhang, Y. Wang, C. Wang,Y. Wu, and Y. Liu, “Clip-ad: A language-guided staged dual-path model for zero-shot anomaly detection,” arXiv preprint arXiv:2311.00453, 2023.
7. Wang, C., Zhu, H., Peng, J., Wang, Y., Yi, R., Wu, Y., ... & Zhang, J. (2024). M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising. arxiv preprint arxiv:240",1,"2024, 2024, 2024, 2024, 2024, 2023, 2023, 2024",Towards Scalable 3D Anomaly Detection and Localization 
mfUyrocIiX,"The paper introduces PointAD, the first approach to explore the domain of zero-shot 3D anomaly detection, leveraging CLIP's strong generalization to identify anomalies in previously unseen objects. It offers a unified framework that integrates 3D point clouds with 2D renderings, employing hybrid representation learning to capture the semantics of anomalies. PointAD's key contributions are its pioneering exploration of the ZS 3D anomaly detection domain, its ability to seamlessly integrate multimodal data like RGB information for enhanced detection, and its superior performance over existing methods. The robustness of the framework is confirmed through extensive experiments.","Originality: The paper introduces PointAD, a novel method in 3D anomaly detection that leverages CLIP for 3D analysis, uniquely combining point clouds and pixel data. It expands the application of vision-language models into new domains, showcasing versatility in 3D point cloud analysis.
Soundness: The paper exhibits methodological soundness through its rigorous experimental setup, including the use of diverse datasets and a thorough ablation study that substantiates the design decisions and effectiveness of the proposed PointAD framework. The state-of-the-art experiments performance confirms the model's outperforming ability.  
Clarity: The paper stands out for its clarity, guiding readers smoothly from the problem statement to the final results. It skillfully explains complex concepts in an accessible way, ensuring that a wider audience can follow along. The paper also benefits from helpful visual aids that clearly demonstrate the model's effectiveness.","1.	There’s some zero-shot anomaly detection methods with clip on 2D images, so this paper should compare with them, especially, from the view of techniques’ differences, not only the used data differences. For example, those zero-shot methods (WinCLIP, VAND and AnomalyCLIP) mentioned in [R1] and [R2].
[R1] Cao, Y., Xu, X., Zhang, J., Cheng, Y., Huang, X., Pang, G., & Shen, W. (2024). A survey on visual anomaly detection: Challenge, approach, and prospect. arxiv preprint arxiv:2401.16402.
[R2] Li, X., Huang, Z., Xue, F., & Zhou, Y. (2024). Musc: Zero-shot industrial anomaly classification and segmentation with mutual scoring of the unlabeled images. arxiv preprint arxiv:2401.16753.

2.	I also wonder if the new methods of 3D anomaly detection can also be used to deal with this zero-shot task. For example, [R3] and [R4]. 
[R3] Zuo, Z., Dong, J., Wu, Y., Qu, Y., & Wu, Z. (2024). CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation. arxiv preprint arxiv:2406.18941.
[R4] Li, W., Xu, X., Gu, Y., Zheng, B., Gao, S., & Wu, Y. (2024). Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 22207-22216).
3.	More importantly, there’s some very similar studies with this work and task. Authors should mention and compare them within this study. For example, [R5].
[R5] Li, Y., Goodge, A., Liu, F., & Foo, C. S. (2024). Promptad: Zero-shot anomaly detection using text prompts. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1093-1102).
[R6] X. Chen, J. Zhang, G. Tian, H. He, W. Zhang, Y. Wang, C. Wang,Y. Wu, and Y. Liu, “Clip-ad: A language-guided staged dual-
path model for zero-shot anomaly detection,” arXiv preprint
arXiv:2311.00453, 2023.
[R7] Wang, C., Zhu, H., Peng, J., Wang, Y., Yi, R., Wu, Y., ... & Zhang, J. (2024). M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising. arxiv preprint arxiv:2406.02263.
4.	Computational Efficiency: Although the authors have commendably addressed computational challenges, the overall computational cost associated with rendering multi-view images and processing them through the vision encoder is still substantial. Since this field is still developing with few comparable studies, it is recommended that the authors provide a broader comparison about the computational cost with existing anomaly detection techniques, including those like Cheraghian, CPFM and 3DSR that are not strictly within the zero-shot category. This expanded comparison will help to show that the computational demands of PointAD are reasonable and suitable for practical use cases.
5.	Clarity and Completeness of Presentation: The paper's writing is generally clear and free of errors, yet minor aspects of the presentation could be polished for better reader comprehension. For instance, the figure overlays, specifically in Figure 1, currently only elucidate part (a), leaving explanations for parts (b) and (c) to be found in the main text. This separation can disrupt the reader's flow and understanding. Enhancing the figure overlays to include all relevant parts and ensuring that each component of the figure is self-explanatory will make the paper more accessible and its findings easier to grasp.","1.	Please answer the main differences with these mentioned methods in Weaknesses and compare with part of them on experiments.
2.	Given the concerns raised in the Weaknesses section 1, does PointAD still hold the merit of computational efficiency when compared to other methods such as AnomalyCLIP and Cheraghian?
3.	Could you elaborate on the multi-view rendering process of point clouds (as described from line 134 to line 140), particularly how the color of the rendered images is determined? Furthermore, at line 254, it's stated that additional RGB information is utilized only in the test dataset. Given the description at line 564, which refers to 2D RGB information, how is this 2D data integrated with the rendered multi-view images? Are there any strategies which are employed to bridge the gap between the rendered training data and the RGB information used in testing?","The authors have discussed the limitations of their model, and there are no potential negative societal impacts associated with their work.",['No ethics review needed.'],6,5,,Yes,3,3,3,1720922193100,,,NeurIPS.cc/2024/Conference,02CIZ8qeDc,"['NeurIPS.cc/2024/Conference/Submission11298/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879455150,[],2,,,['everyone'],02CIZ8qeDc,['NeurIPS.cc/2024/Conference/Submission11298/Reviewer_GgEU'],1720922193100,1730879455150,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11298/Reviewer_GgEU']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Cao, Y., Xu, X., Zhang, J., Cheng, Y., Huang, X., Pang, G., & Shen, W. (2024). A survey on visual anomaly detection: Challenge, approach, and prospect. arxiv preprint arxiv:2401.16402.
2. Li, X., Huang, Z., Xue, F., & Zhou, Y. (2024). Musc: Zero-shot industrial anomaly classification and segmentation with mutual scoring of the unlabeled images. arxiv preprint arxiv:2401.16753.
3. Zuo, Z., Dong, J., Wu, Y., Qu, Y., & Wu, Z. (2024). CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation. arxiv preprint arxiv:2406.18941.
4. Li, W., Xu, X., Gu, Y., Zheng, B., Gao, S., & Wu, Y. (2024). Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 22207-22216).
5. Li, Y., Goodge, A., Liu, F., & Foo, C. S. (2024). Promptad: Zero-shot anomaly detection using text prompts. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1093-1102).
6. X. Chen, J. Zhang, G. Tian, H. He, W. Zhang, Y. Wang, C. Wang,Y. Wu, and Y. Liu, “Clip-ad: A language-guided staged dual-path model for zero-shot anomaly detection,” arXiv preprint arXiv:2311.00453, 2023.
7. Wang, C., Zhu, H., Peng, J., Wang, Y., Yi, R., Wu, Y., ... & Zhang, J. (2024). M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising. arxiv preprint arxiv:240",1,"2024, 2024, 2024, 2024, 2024, 2023, 2023, 2024",PromptAD 
mfUyrocIiX,"The paper introduces PointAD, the first approach to explore the domain of zero-shot 3D anomaly detection, leveraging CLIP's strong generalization to identify anomalies in previously unseen objects. It offers a unified framework that integrates 3D point clouds with 2D renderings, employing hybrid representation learning to capture the semantics of anomalies. PointAD's key contributions are its pioneering exploration of the ZS 3D anomaly detection domain, its ability to seamlessly integrate multimodal data like RGB information for enhanced detection, and its superior performance over existing methods. The robustness of the framework is confirmed through extensive experiments.","Originality: The paper introduces PointAD, a novel method in 3D anomaly detection that leverages CLIP for 3D analysis, uniquely combining point clouds and pixel data. It expands the application of vision-language models into new domains, showcasing versatility in 3D point cloud analysis.
Soundness: The paper exhibits methodological soundness through its rigorous experimental setup, including the use of diverse datasets and a thorough ablation study that substantiates the design decisions and effectiveness of the proposed PointAD framework. The state-of-the-art experiments performance confirms the model's outperforming ability.  
Clarity: The paper stands out for its clarity, guiding readers smoothly from the problem statement to the final results. It skillfully explains complex concepts in an accessible way, ensuring that a wider audience can follow along. The paper also benefits from helpful visual aids that clearly demonstrate the model's effectiveness.","1.	There’s some zero-shot anomaly detection methods with clip on 2D images, so this paper should compare with them, especially, from the view of techniques’ differences, not only the used data differences. For example, those zero-shot methods (WinCLIP, VAND and AnomalyCLIP) mentioned in [R1] and [R2].
[R1] Cao, Y., Xu, X., Zhang, J., Cheng, Y., Huang, X., Pang, G., & Shen, W. (2024). A survey on visual anomaly detection: Challenge, approach, and prospect. arxiv preprint arxiv:2401.16402.
[R2] Li, X., Huang, Z., Xue, F., & Zhou, Y. (2024). Musc: Zero-shot industrial anomaly classification and segmentation with mutual scoring of the unlabeled images. arxiv preprint arxiv:2401.16753.

2.	I also wonder if the new methods of 3D anomaly detection can also be used to deal with this zero-shot task. For example, [R3] and [R4]. 
[R3] Zuo, Z., Dong, J., Wu, Y., Qu, Y., & Wu, Z. (2024). CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation. arxiv preprint arxiv:2406.18941.
[R4] Li, W., Xu, X., Gu, Y., Zheng, B., Gao, S., & Wu, Y. (2024). Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 22207-22216).
3.	More importantly, there’s some very similar studies with this work and task. Authors should mention and compare them within this study. For example, [R5].
[R5] Li, Y., Goodge, A., Liu, F., & Foo, C. S. (2024). Promptad: Zero-shot anomaly detection using text prompts. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1093-1102).
[R6] X. Chen, J. Zhang, G. Tian, H. He, W. Zhang, Y. Wang, C. Wang,Y. Wu, and Y. Liu, “Clip-ad: A language-guided staged dual-
path model for zero-shot anomaly detection,” arXiv preprint
arXiv:2311.00453, 2023.
[R7] Wang, C., Zhu, H., Peng, J., Wang, Y., Yi, R., Wu, Y., ... & Zhang, J. (2024). M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising. arxiv preprint arxiv:2406.02263.
4.	Computational Efficiency: Although the authors have commendably addressed computational challenges, the overall computational cost associated with rendering multi-view images and processing them through the vision encoder is still substantial. Since this field is still developing with few comparable studies, it is recommended that the authors provide a broader comparison about the computational cost with existing anomaly detection techniques, including those like Cheraghian, CPFM and 3DSR that are not strictly within the zero-shot category. This expanded comparison will help to show that the computational demands of PointAD are reasonable and suitable for practical use cases.
5.	Clarity and Completeness of Presentation: The paper's writing is generally clear and free of errors, yet minor aspects of the presentation could be polished for better reader comprehension. For instance, the figure overlays, specifically in Figure 1, currently only elucidate part (a), leaving explanations for parts (b) and (c) to be found in the main text. This separation can disrupt the reader's flow and understanding. Enhancing the figure overlays to include all relevant parts and ensuring that each component of the figure is self-explanatory will make the paper more accessible and its findings easier to grasp.","1.	Please answer the main differences with these mentioned methods in Weaknesses and compare with part of them on experiments.
2.	Given the concerns raised in the Weaknesses section 1, does PointAD still hold the merit of computational efficiency when compared to other methods such as AnomalyCLIP and Cheraghian?
3.	Could you elaborate on the multi-view rendering process of point clouds (as described from line 134 to line 140), particularly how the color of the rendered images is determined? Furthermore, at line 254, it's stated that additional RGB information is utilized only in the test dataset. Given the description at line 564, which refers to 2D RGB information, how is this 2D data integrated with the rendered multi-view images? Are there any strategies which are employed to bridge the gap between the rendered training data and the RGB information used in testing?","The authors have discussed the limitations of their model, and there are no potential negative societal impacts associated with their work.",['No ethics review needed.'],6,5,,Yes,3,3,3,1720922193100,,,NeurIPS.cc/2024/Conference,02CIZ8qeDc,"['NeurIPS.cc/2024/Conference/Submission11298/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879455150,[],2,,,['everyone'],02CIZ8qeDc,['NeurIPS.cc/2024/Conference/Submission11298/Reviewer_GgEU'],1720922193100,1730879455150,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11298/Reviewer_GgEU']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Cao, Y., Xu, X., Zhang, J., Cheng, Y., Huang, X., Pang, G., & Shen, W. (2024). A survey on visual anomaly detection: Challenge, approach, and prospect. arxiv preprint arxiv:2401.16402.
2. Li, X., Huang, Z., Xue, F., & Zhou, Y. (2024). Musc: Zero-shot industrial anomaly classification and segmentation with mutual scoring of the unlabeled images. arxiv preprint arxiv:2401.16753.
3. Zuo, Z., Dong, J., Wu, Y., Qu, Y., & Wu, Z. (2024). CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation. arxiv preprint arxiv:2406.18941.
4. Li, W., Xu, X., Gu, Y., Zheng, B., Gao, S., & Wu, Y. (2024). Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 22207-22216).
5. Li, Y., Goodge, A., Liu, F., & Foo, C. S. (2024). Promptad: Zero-shot anomaly detection using text prompts. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1093-1102).
6. X. Chen, J. Zhang, G. Tian, H. He, W. Zhang, Y. Wang, C. Wang,Y. Wu, and Y. Liu, “Clip-ad: A language-guided staged dual-path model for zero-shot anomaly detection,” arXiv preprint arXiv:2311.00453, 2023.
7. Wang, C., Zhu, H., Peng, J., Wang, Y., Yi, R., Wu, Y., ... & Zhang, J. (2024). M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising. arxiv preprint arxiv:240",1,"2024, 2024, 2024, 2024, 2024, 2023, 2023, 2024",Clip-ad 
mfUyrocIiX,"The paper introduces PointAD, the first approach to explore the domain of zero-shot 3D anomaly detection, leveraging CLIP's strong generalization to identify anomalies in previously unseen objects. It offers a unified framework that integrates 3D point clouds with 2D renderings, employing hybrid representation learning to capture the semantics of anomalies. PointAD's key contributions are its pioneering exploration of the ZS 3D anomaly detection domain, its ability to seamlessly integrate multimodal data like RGB information for enhanced detection, and its superior performance over existing methods. The robustness of the framework is confirmed through extensive experiments.","Originality: The paper introduces PointAD, a novel method in 3D anomaly detection that leverages CLIP for 3D analysis, uniquely combining point clouds and pixel data. It expands the application of vision-language models into new domains, showcasing versatility in 3D point cloud analysis.
Soundness: The paper exhibits methodological soundness through its rigorous experimental setup, including the use of diverse datasets and a thorough ablation study that substantiates the design decisions and effectiveness of the proposed PointAD framework. The state-of-the-art experiments performance confirms the model's outperforming ability.  
Clarity: The paper stands out for its clarity, guiding readers smoothly from the problem statement to the final results. It skillfully explains complex concepts in an accessible way, ensuring that a wider audience can follow along. The paper also benefits from helpful visual aids that clearly demonstrate the model's effectiveness.","1.	There’s some zero-shot anomaly detection methods with clip on 2D images, so this paper should compare with them, especially, from the view of techniques’ differences, not only the used data differences. For example, those zero-shot methods (WinCLIP, VAND and AnomalyCLIP) mentioned in [R1] and [R2].
[R1] Cao, Y., Xu, X., Zhang, J., Cheng, Y., Huang, X., Pang, G., & Shen, W. (2024). A survey on visual anomaly detection: Challenge, approach, and prospect. arxiv preprint arxiv:2401.16402.
[R2] Li, X., Huang, Z., Xue, F., & Zhou, Y. (2024). Musc: Zero-shot industrial anomaly classification and segmentation with mutual scoring of the unlabeled images. arxiv preprint arxiv:2401.16753.

2.	I also wonder if the new methods of 3D anomaly detection can also be used to deal with this zero-shot task. For example, [R3] and [R4]. 
[R3] Zuo, Z., Dong, J., Wu, Y., Qu, Y., & Wu, Z. (2024). CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation. arxiv preprint arxiv:2406.18941.
[R4] Li, W., Xu, X., Gu, Y., Zheng, B., Gao, S., & Wu, Y. (2024). Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 22207-22216).
3.	More importantly, there’s some very similar studies with this work and task. Authors should mention and compare them within this study. For example, [R5].
[R5] Li, Y., Goodge, A., Liu, F., & Foo, C. S. (2024). Promptad: Zero-shot anomaly detection using text prompts. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1093-1102).
[R6] X. Chen, J. Zhang, G. Tian, H. He, W. Zhang, Y. Wang, C. Wang,Y. Wu, and Y. Liu, “Clip-ad: A language-guided staged dual-
path model for zero-shot anomaly detection,” arXiv preprint
arXiv:2311.00453, 2023.
[R7] Wang, C., Zhu, H., Peng, J., Wang, Y., Yi, R., Wu, Y., ... & Zhang, J. (2024). M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising. arxiv preprint arxiv:2406.02263.
4.	Computational Efficiency: Although the authors have commendably addressed computational challenges, the overall computational cost associated with rendering multi-view images and processing them through the vision encoder is still substantial. Since this field is still developing with few comparable studies, it is recommended that the authors provide a broader comparison about the computational cost with existing anomaly detection techniques, including those like Cheraghian, CPFM and 3DSR that are not strictly within the zero-shot category. This expanded comparison will help to show that the computational demands of PointAD are reasonable and suitable for practical use cases.
5.	Clarity and Completeness of Presentation: The paper's writing is generally clear and free of errors, yet minor aspects of the presentation could be polished for better reader comprehension. For instance, the figure overlays, specifically in Figure 1, currently only elucidate part (a), leaving explanations for parts (b) and (c) to be found in the main text. This separation can disrupt the reader's flow and understanding. Enhancing the figure overlays to include all relevant parts and ensuring that each component of the figure is self-explanatory will make the paper more accessible and its findings easier to grasp.","1.	Please answer the main differences with these mentioned methods in Weaknesses and compare with part of them on experiments.
2.	Given the concerns raised in the Weaknesses section 1, does PointAD still hold the merit of computational efficiency when compared to other methods such as AnomalyCLIP and Cheraghian?
3.	Could you elaborate on the multi-view rendering process of point clouds (as described from line 134 to line 140), particularly how the color of the rendered images is determined? Furthermore, at line 254, it's stated that additional RGB information is utilized only in the test dataset. Given the description at line 564, which refers to 2D RGB information, how is this 2D data integrated with the rendered multi-view images? Are there any strategies which are employed to bridge the gap between the rendered training data and the RGB information used in testing?","The authors have discussed the limitations of their model, and there are no potential negative societal impacts associated with their work.",['No ethics review needed.'],6,5,,Yes,3,3,3,1720922193100,,,NeurIPS.cc/2024/Conference,02CIZ8qeDc,"['NeurIPS.cc/2024/Conference/Submission11298/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879455150,[],2,,,['everyone'],02CIZ8qeDc,['NeurIPS.cc/2024/Conference/Submission11298/Reviewer_GgEU'],1720922193100,1730879455150,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission11298/Reviewer_GgEU']","Yes, this peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. Cao, Y., Xu, X., Zhang, J., Cheng, Y., Huang, X., Pang, G., & Shen, W. (2024). A survey on visual anomaly detection: Challenge, approach, and prospect. arxiv preprint arxiv:2401.16402.
2. Li, X., Huang, Z., Xue, F., & Zhou, Y. (2024). Musc: Zero-shot industrial anomaly classification and segmentation with mutual scoring of the unlabeled images. arxiv preprint arxiv:2401.16753.
3. Zuo, Z., Dong, J., Wu, Y., Qu, Y., & Wu, Z. (2024). CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation. arxiv preprint arxiv:2406.18941.
4. Li, W., Xu, X., Gu, Y., Zheng, B., Gao, S., & Wu, Y. (2024). Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 22207-22216).
5. Li, Y., Goodge, A., Liu, F., & Foo, C. S. (2024). Promptad: Zero-shot anomaly detection using text prompts. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1093-1102).
6. X. Chen, J. Zhang, G. Tian, H. He, W. Zhang, Y. Wang, C. Wang,Y. Wu, and Y. Liu, “Clip-ad: A language-guided staged dual-path model for zero-shot anomaly detection,” arXiv preprint arXiv:2311.00453, 2023.
7. Wang, C., Zhu, H., Peng, J., Wang, Y., Yi, R., Wu, Y., ... & Zhang, J. (2024). M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising. arxiv preprint arxiv:240",1,"2024, 2024, 2024, 2024, 2024, 2023, 2023, 2024",M3DM-NR
8M0EygXYhY,"The authors propose a new post-processing watermark for imagery, FreqMark. The FreqMark embeds a binary message into the frequency domain of a VAE-encoded image via a small perturbation, and then following IFFT + decompression, utilizes a pre-trained image encoder to extract the message. A PSNR + LPIPS metric is used to protect mage quality against the message embedding. The dual approach of VAE encoding + Gaussian noise makes the mark resilient against regeneration and Gaussian noise attacks. The method demonstrates high bit accuracy and good image quality when compared against DwtDct, SSL, Stable Signature on watermarked DiffusionDB & Imagenet images.","-Easy-to-follow narrative and nice motivation in the age of generative imagery. 

The intuition behind the FreqMark algorithm is sound, easy to follow, and presumably simple to implement. 

-Method demonstrates robustness against regeneration, which is a very potent attack.","This work is missing two critical competitor baselines which must be addressed. 

-In my opinion, the FreqMark is an incremental variant of the StegaStamp [1]. Surprisingly, the authors did not compare against this method even though it is well-known in existing literature that the StegaStamp is robust against many attacks, including regeneration [2]. Like FreqMark, the StegaStamp increases resilience against attacks by incorporating them into the training pipeline and uses a critic loss to preserve image quality (LPIPS + L2, versus LPIPS + PSNR for FreqMark). The resemblance of equation (10) in this manuscript to the loss function equation (2) in [1] begs the question of novelty. It is also incorrectly stated in line 71 that the StegaStamp only relies on differential image perturbations for the training pipelines -- in fact, any attack can be added, as the decoder is trained after image manipulation. 

-Again, if the spirit of the paper is to increase resilience against regenerations, the authors also needed to compare against the state-of-the-art Tree-Ring watermark [4], which was noted to be incredibly resilient against regenerations by the authors of the regeneration attack [2]. As the Tree-Ring is an in-processing technique that embeds a message within a diffusion process, one way to set up a comparison is to post-process a collection of Tree-Ring watermarked images via FreqMark, and then independently extract both watermarks. 

-As noted in [3], there is no single perceptual metric that is an objective measure of image quality, thus low PSNR or LPIPS distance does not necessarily indicate the method is not introducing artifacts. The authors need to add 1-2 more metrics (maybe L2 and FID, for example) for a more convincing argument. 

-500 images is too small a sample size for the tested FPR thresholds. Modern literature in this field such as [3,4,5] are using several thousand images. 

-VAE regenerations are far weaker compared to diffusion regenerations. Readers will want to see how the FreqMark holds up against longer, deeper regenerations (>= 100 steps) to see how the decoding accuracy is affected.

-As observed in [3], the use of publicly available VAEs to encode/decode watermarks is easily defeated if the attacker uses a regeneration leveraging encoders/decoders with the same architecture. 


[1] Tancik, M., Mildenhall, B., & Ng, R. (2020). Stegastamp: Invisible hyperlinks in physical photographs. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 2117-2126).

[2] Zhao, X., Zhang, K., Su, Z., Vasan, S., Grishchenko, I., Kruegel, C., ... & Li, L. (2023). Invisible image watermarks are provably removable using generative ai. arXiv preprint arXiv:2306.01953.

[3] An, B., Ding, M., Rabbani, T., Agrawal, A., Xu, Y., Deng, C., ... & Huang, F. (2024). Benchmarking the robustness of image watermarks. arXiv preprint arXiv:2401.08573.

[4] Wen, Y., Kirchenbauer, J., Geiping, J., & Goldstein, T. (2023). Tree-ring watermarks: Fingerprints for diffusion images that are invisible and robust. arXiv preprint arXiv:2305.20030.

[5] Saberi, M., Sadasivan, V. S., Rezaei, K., Kumar, A., Chegini, A., Wang, W., & Feizi, S. (2023). Robustness of ai-image detectors: Fundamental limits and practical attacks. arXiv preprint arXiv:2310.00076.","1. See weaknesses.

2. Which version of Stable Diffusion was used for the regeneration attack?",Adequately discussed.,['No ethics review needed.'],6,4,,Yes,1,3,3,1721081558290,,,NeurIPS.cc/2024/Conference,01s5ODIHKd,"['NeurIPS.cc/2024/Conference/Submission9375/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879310073,[],4,,,['everyone'],01s5ODIHKd,['NeurIPS.cc/2024/Conference/Submission9375/Reviewer_BZ7h'],1721081558290,1730879310073,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9375/Reviewer_BZ7h']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. StegaStamp [1]
2. Invisible image watermarks are provably removable using generative ai [2]
3. Benchmarking the robustness of image watermarks [3]
4. Tree-ring watermarks: Fingerprints for diffusion images that are invisible and robust [4]
5. Robustness of ai-image detectors: Fundamental limits and practical attacks [5]

These citations are mentioned in the weaknesses section of the review, where the reviewer points out that the authors should have compared their method to these existing works and cited them in their paper.",1,,StegaStamp 
8M0EygXYhY,"The authors propose a new post-processing watermark for imagery, FreqMark. The FreqMark embeds a binary message into the frequency domain of a VAE-encoded image via a small perturbation, and then following IFFT + decompression, utilizes a pre-trained image encoder to extract the message. A PSNR + LPIPS metric is used to protect mage quality against the message embedding. The dual approach of VAE encoding + Gaussian noise makes the mark resilient against regeneration and Gaussian noise attacks. The method demonstrates high bit accuracy and good image quality when compared against DwtDct, SSL, Stable Signature on watermarked DiffusionDB & Imagenet images.","-Easy-to-follow narrative and nice motivation in the age of generative imagery. 

The intuition behind the FreqMark algorithm is sound, easy to follow, and presumably simple to implement. 

-Method demonstrates robustness against regeneration, which is a very potent attack.","This work is missing two critical competitor baselines which must be addressed. 

-In my opinion, the FreqMark is an incremental variant of the StegaStamp [1]. Surprisingly, the authors did not compare against this method even though it is well-known in existing literature that the StegaStamp is robust against many attacks, including regeneration [2]. Like FreqMark, the StegaStamp increases resilience against attacks by incorporating them into the training pipeline and uses a critic loss to preserve image quality (LPIPS + L2, versus LPIPS + PSNR for FreqMark). The resemblance of equation (10) in this manuscript to the loss function equation (2) in [1] begs the question of novelty. It is also incorrectly stated in line 71 that the StegaStamp only relies on differential image perturbations for the training pipelines -- in fact, any attack can be added, as the decoder is trained after image manipulation. 

-Again, if the spirit of the paper is to increase resilience against regenerations, the authors also needed to compare against the state-of-the-art Tree-Ring watermark [4], which was noted to be incredibly resilient against regenerations by the authors of the regeneration attack [2]. As the Tree-Ring is an in-processing technique that embeds a message within a diffusion process, one way to set up a comparison is to post-process a collection of Tree-Ring watermarked images via FreqMark, and then independently extract both watermarks. 

-As noted in [3], there is no single perceptual metric that is an objective measure of image quality, thus low PSNR or LPIPS distance does not necessarily indicate the method is not introducing artifacts. The authors need to add 1-2 more metrics (maybe L2 and FID, for example) for a more convincing argument. 

-500 images is too small a sample size for the tested FPR thresholds. Modern literature in this field such as [3,4,5] are using several thousand images. 

-VAE regenerations are far weaker compared to diffusion regenerations. Readers will want to see how the FreqMark holds up against longer, deeper regenerations (>= 100 steps) to see how the decoding accuracy is affected.

-As observed in [3], the use of publicly available VAEs to encode/decode watermarks is easily defeated if the attacker uses a regeneration leveraging encoders/decoders with the same architecture. 


[1] Tancik, M., Mildenhall, B., & Ng, R. (2020). Stegastamp: Invisible hyperlinks in physical photographs. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 2117-2126).

[2] Zhao, X., Zhang, K., Su, Z., Vasan, S., Grishchenko, I., Kruegel, C., ... & Li, L. (2023). Invisible image watermarks are provably removable using generative ai. arXiv preprint arXiv:2306.01953.

[3] An, B., Ding, M., Rabbani, T., Agrawal, A., Xu, Y., Deng, C., ... & Huang, F. (2024). Benchmarking the robustness of image watermarks. arXiv preprint arXiv:2401.08573.

[4] Wen, Y., Kirchenbauer, J., Geiping, J., & Goldstein, T. (2023). Tree-ring watermarks: Fingerprints for diffusion images that are invisible and robust. arXiv preprint arXiv:2305.20030.

[5] Saberi, M., Sadasivan, V. S., Rezaei, K., Kumar, A., Chegini, A., Wang, W., & Feizi, S. (2023). Robustness of ai-image detectors: Fundamental limits and practical attacks. arXiv preprint arXiv:2310.00076.","1. See weaknesses.

2. Which version of Stable Diffusion was used for the regeneration attack?",Adequately discussed.,['No ethics review needed.'],6,4,,Yes,1,3,3,1721081558290,,,NeurIPS.cc/2024/Conference,01s5ODIHKd,"['NeurIPS.cc/2024/Conference/Submission9375/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879310073,[],4,,,['everyone'],01s5ODIHKd,['NeurIPS.cc/2024/Conference/Submission9375/Reviewer_BZ7h'],1721081558290,1730879310073,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9375/Reviewer_BZ7h']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. StegaStamp [1]
2. Invisible image watermarks are provably removable using generative ai [2]
3. Benchmarking the robustness of image watermarks [3]
4. Tree-ring watermarks: Fingerprints for diffusion images that are invisible and robust [4]
5. Robustness of ai-image detectors: Fundamental limits and practical attacks [5]

These citations are mentioned in the weaknesses section of the review, where the reviewer points out that the authors should have compared their method to these existing works and cited them in their paper.",1,,Invisible image watermarks are provably removable using generative ai 
8M0EygXYhY,"The authors propose a new post-processing watermark for imagery, FreqMark. The FreqMark embeds a binary message into the frequency domain of a VAE-encoded image via a small perturbation, and then following IFFT + decompression, utilizes a pre-trained image encoder to extract the message. A PSNR + LPIPS metric is used to protect mage quality against the message embedding. The dual approach of VAE encoding + Gaussian noise makes the mark resilient against regeneration and Gaussian noise attacks. The method demonstrates high bit accuracy and good image quality when compared against DwtDct, SSL, Stable Signature on watermarked DiffusionDB & Imagenet images.","-Easy-to-follow narrative and nice motivation in the age of generative imagery. 

The intuition behind the FreqMark algorithm is sound, easy to follow, and presumably simple to implement. 

-Method demonstrates robustness against regeneration, which is a very potent attack.","This work is missing two critical competitor baselines which must be addressed. 

-In my opinion, the FreqMark is an incremental variant of the StegaStamp [1]. Surprisingly, the authors did not compare against this method even though it is well-known in existing literature that the StegaStamp is robust against many attacks, including regeneration [2]. Like FreqMark, the StegaStamp increases resilience against attacks by incorporating them into the training pipeline and uses a critic loss to preserve image quality (LPIPS + L2, versus LPIPS + PSNR for FreqMark). The resemblance of equation (10) in this manuscript to the loss function equation (2) in [1] begs the question of novelty. It is also incorrectly stated in line 71 that the StegaStamp only relies on differential image perturbations for the training pipelines -- in fact, any attack can be added, as the decoder is trained after image manipulation. 

-Again, if the spirit of the paper is to increase resilience against regenerations, the authors also needed to compare against the state-of-the-art Tree-Ring watermark [4], which was noted to be incredibly resilient against regenerations by the authors of the regeneration attack [2]. As the Tree-Ring is an in-processing technique that embeds a message within a diffusion process, one way to set up a comparison is to post-process a collection of Tree-Ring watermarked images via FreqMark, and then independently extract both watermarks. 

-As noted in [3], there is no single perceptual metric that is an objective measure of image quality, thus low PSNR or LPIPS distance does not necessarily indicate the method is not introducing artifacts. The authors need to add 1-2 more metrics (maybe L2 and FID, for example) for a more convincing argument. 

-500 images is too small a sample size for the tested FPR thresholds. Modern literature in this field such as [3,4,5] are using several thousand images. 

-VAE regenerations are far weaker compared to diffusion regenerations. Readers will want to see how the FreqMark holds up against longer, deeper regenerations (>= 100 steps) to see how the decoding accuracy is affected.

-As observed in [3], the use of publicly available VAEs to encode/decode watermarks is easily defeated if the attacker uses a regeneration leveraging encoders/decoders with the same architecture. 


[1] Tancik, M., Mildenhall, B., & Ng, R. (2020). Stegastamp: Invisible hyperlinks in physical photographs. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 2117-2126).

[2] Zhao, X., Zhang, K., Su, Z., Vasan, S., Grishchenko, I., Kruegel, C., ... & Li, L. (2023). Invisible image watermarks are provably removable using generative ai. arXiv preprint arXiv:2306.01953.

[3] An, B., Ding, M., Rabbani, T., Agrawal, A., Xu, Y., Deng, C., ... & Huang, F. (2024). Benchmarking the robustness of image watermarks. arXiv preprint arXiv:2401.08573.

[4] Wen, Y., Kirchenbauer, J., Geiping, J., & Goldstein, T. (2023). Tree-ring watermarks: Fingerprints for diffusion images that are invisible and robust. arXiv preprint arXiv:2305.20030.

[5] Saberi, M., Sadasivan, V. S., Rezaei, K., Kumar, A., Chegini, A., Wang, W., & Feizi, S. (2023). Robustness of ai-image detectors: Fundamental limits and practical attacks. arXiv preprint arXiv:2310.00076.","1. See weaknesses.

2. Which version of Stable Diffusion was used for the regeneration attack?",Adequately discussed.,['No ethics review needed.'],6,4,,Yes,1,3,3,1721081558290,,,NeurIPS.cc/2024/Conference,01s5ODIHKd,"['NeurIPS.cc/2024/Conference/Submission9375/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879310073,[],4,,,['everyone'],01s5ODIHKd,['NeurIPS.cc/2024/Conference/Submission9375/Reviewer_BZ7h'],1721081558290,1730879310073,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9375/Reviewer_BZ7h']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. StegaStamp [1]
2. Invisible image watermarks are provably removable using generative ai [2]
3. Benchmarking the robustness of image watermarks [3]
4. Tree-ring watermarks: Fingerprints for diffusion images that are invisible and robust [4]
5. Robustness of ai-image detectors: Fundamental limits and practical attacks [5]

These citations are mentioned in the weaknesses section of the review, where the reviewer points out that the authors should have compared their method to these existing works and cited them in their paper.",1,,Benchmarking the robustness of image watermarks 
8M0EygXYhY,"The authors propose a new post-processing watermark for imagery, FreqMark. The FreqMark embeds a binary message into the frequency domain of a VAE-encoded image via a small perturbation, and then following IFFT + decompression, utilizes a pre-trained image encoder to extract the message. A PSNR + LPIPS metric is used to protect mage quality against the message embedding. The dual approach of VAE encoding + Gaussian noise makes the mark resilient against regeneration and Gaussian noise attacks. The method demonstrates high bit accuracy and good image quality when compared against DwtDct, SSL, Stable Signature on watermarked DiffusionDB & Imagenet images.","-Easy-to-follow narrative and nice motivation in the age of generative imagery. 

The intuition behind the FreqMark algorithm is sound, easy to follow, and presumably simple to implement. 

-Method demonstrates robustness against regeneration, which is a very potent attack.","This work is missing two critical competitor baselines which must be addressed. 

-In my opinion, the FreqMark is an incremental variant of the StegaStamp [1]. Surprisingly, the authors did not compare against this method even though it is well-known in existing literature that the StegaStamp is robust against many attacks, including regeneration [2]. Like FreqMark, the StegaStamp increases resilience against attacks by incorporating them into the training pipeline and uses a critic loss to preserve image quality (LPIPS + L2, versus LPIPS + PSNR for FreqMark). The resemblance of equation (10) in this manuscript to the loss function equation (2) in [1] begs the question of novelty. It is also incorrectly stated in line 71 that the StegaStamp only relies on differential image perturbations for the training pipelines -- in fact, any attack can be added, as the decoder is trained after image manipulation. 

-Again, if the spirit of the paper is to increase resilience against regenerations, the authors also needed to compare against the state-of-the-art Tree-Ring watermark [4], which was noted to be incredibly resilient against regenerations by the authors of the regeneration attack [2]. As the Tree-Ring is an in-processing technique that embeds a message within a diffusion process, one way to set up a comparison is to post-process a collection of Tree-Ring watermarked images via FreqMark, and then independently extract both watermarks. 

-As noted in [3], there is no single perceptual metric that is an objective measure of image quality, thus low PSNR or LPIPS distance does not necessarily indicate the method is not introducing artifacts. The authors need to add 1-2 more metrics (maybe L2 and FID, for example) for a more convincing argument. 

-500 images is too small a sample size for the tested FPR thresholds. Modern literature in this field such as [3,4,5] are using several thousand images. 

-VAE regenerations are far weaker compared to diffusion regenerations. Readers will want to see how the FreqMark holds up against longer, deeper regenerations (>= 100 steps) to see how the decoding accuracy is affected.

-As observed in [3], the use of publicly available VAEs to encode/decode watermarks is easily defeated if the attacker uses a regeneration leveraging encoders/decoders with the same architecture. 


[1] Tancik, M., Mildenhall, B., & Ng, R. (2020). Stegastamp: Invisible hyperlinks in physical photographs. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 2117-2126).

[2] Zhao, X., Zhang, K., Su, Z., Vasan, S., Grishchenko, I., Kruegel, C., ... & Li, L. (2023). Invisible image watermarks are provably removable using generative ai. arXiv preprint arXiv:2306.01953.

[3] An, B., Ding, M., Rabbani, T., Agrawal, A., Xu, Y., Deng, C., ... & Huang, F. (2024). Benchmarking the robustness of image watermarks. arXiv preprint arXiv:2401.08573.

[4] Wen, Y., Kirchenbauer, J., Geiping, J., & Goldstein, T. (2023). Tree-ring watermarks: Fingerprints for diffusion images that are invisible and robust. arXiv preprint arXiv:2305.20030.

[5] Saberi, M., Sadasivan, V. S., Rezaei, K., Kumar, A., Chegini, A., Wang, W., & Feizi, S. (2023). Robustness of ai-image detectors: Fundamental limits and practical attacks. arXiv preprint arXiv:2310.00076.","1. See weaknesses.

2. Which version of Stable Diffusion was used for the regeneration attack?",Adequately discussed.,['No ethics review needed.'],6,4,,Yes,1,3,3,1721081558290,,,NeurIPS.cc/2024/Conference,01s5ODIHKd,"['NeurIPS.cc/2024/Conference/Submission9375/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879310073,[],4,,,['everyone'],01s5ODIHKd,['NeurIPS.cc/2024/Conference/Submission9375/Reviewer_BZ7h'],1721081558290,1730879310073,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9375/Reviewer_BZ7h']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. StegaStamp [1]
2. Invisible image watermarks are provably removable using generative ai [2]
3. Benchmarking the robustness of image watermarks [3]
4. Tree-ring watermarks: Fingerprints for diffusion images that are invisible and robust [4]
5. Robustness of ai-image detectors: Fundamental limits and practical attacks [5]

These citations are mentioned in the weaknesses section of the review, where the reviewer points out that the authors should have compared their method to these existing works and cited them in their paper.",1,,Tree-ring watermarks Fingerprints for diffusion images that are invisible and robust 
8M0EygXYhY,"The authors propose a new post-processing watermark for imagery, FreqMark. The FreqMark embeds a binary message into the frequency domain of a VAE-encoded image via a small perturbation, and then following IFFT + decompression, utilizes a pre-trained image encoder to extract the message. A PSNR + LPIPS metric is used to protect mage quality against the message embedding. The dual approach of VAE encoding + Gaussian noise makes the mark resilient against regeneration and Gaussian noise attacks. The method demonstrates high bit accuracy and good image quality when compared against DwtDct, SSL, Stable Signature on watermarked DiffusionDB & Imagenet images.","-Easy-to-follow narrative and nice motivation in the age of generative imagery. 

The intuition behind the FreqMark algorithm is sound, easy to follow, and presumably simple to implement. 

-Method demonstrates robustness against regeneration, which is a very potent attack.","This work is missing two critical competitor baselines which must be addressed. 

-In my opinion, the FreqMark is an incremental variant of the StegaStamp [1]. Surprisingly, the authors did not compare against this method even though it is well-known in existing literature that the StegaStamp is robust against many attacks, including regeneration [2]. Like FreqMark, the StegaStamp increases resilience against attacks by incorporating them into the training pipeline and uses a critic loss to preserve image quality (LPIPS + L2, versus LPIPS + PSNR for FreqMark). The resemblance of equation (10) in this manuscript to the loss function equation (2) in [1] begs the question of novelty. It is also incorrectly stated in line 71 that the StegaStamp only relies on differential image perturbations for the training pipelines -- in fact, any attack can be added, as the decoder is trained after image manipulation. 

-Again, if the spirit of the paper is to increase resilience against regenerations, the authors also needed to compare against the state-of-the-art Tree-Ring watermark [4], which was noted to be incredibly resilient against regenerations by the authors of the regeneration attack [2]. As the Tree-Ring is an in-processing technique that embeds a message within a diffusion process, one way to set up a comparison is to post-process a collection of Tree-Ring watermarked images via FreqMark, and then independently extract both watermarks. 

-As noted in [3], there is no single perceptual metric that is an objective measure of image quality, thus low PSNR or LPIPS distance does not necessarily indicate the method is not introducing artifacts. The authors need to add 1-2 more metrics (maybe L2 and FID, for example) for a more convincing argument. 

-500 images is too small a sample size for the tested FPR thresholds. Modern literature in this field such as [3,4,5] are using several thousand images. 

-VAE regenerations are far weaker compared to diffusion regenerations. Readers will want to see how the FreqMark holds up against longer, deeper regenerations (>= 100 steps) to see how the decoding accuracy is affected.

-As observed in [3], the use of publicly available VAEs to encode/decode watermarks is easily defeated if the attacker uses a regeneration leveraging encoders/decoders with the same architecture. 


[1] Tancik, M., Mildenhall, B., & Ng, R. (2020). Stegastamp: Invisible hyperlinks in physical photographs. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 2117-2126).

[2] Zhao, X., Zhang, K., Su, Z., Vasan, S., Grishchenko, I., Kruegel, C., ... & Li, L. (2023). Invisible image watermarks are provably removable using generative ai. arXiv preprint arXiv:2306.01953.

[3] An, B., Ding, M., Rabbani, T., Agrawal, A., Xu, Y., Deng, C., ... & Huang, F. (2024). Benchmarking the robustness of image watermarks. arXiv preprint arXiv:2401.08573.

[4] Wen, Y., Kirchenbauer, J., Geiping, J., & Goldstein, T. (2023). Tree-ring watermarks: Fingerprints for diffusion images that are invisible and robust. arXiv preprint arXiv:2305.20030.

[5] Saberi, M., Sadasivan, V. S., Rezaei, K., Kumar, A., Chegini, A., Wang, W., & Feizi, S. (2023). Robustness of ai-image detectors: Fundamental limits and practical attacks. arXiv preprint arXiv:2310.00076.","1. See weaknesses.

2. Which version of Stable Diffusion was used for the regeneration attack?",Adequately discussed.,['No ethics review needed.'],6,4,,Yes,1,3,3,1721081558290,,,NeurIPS.cc/2024/Conference,01s5ODIHKd,"['NeurIPS.cc/2024/Conference/Submission9375/-/Official_Review', 'NeurIPS.cc/2024/Conference/-/Edit']",CC BY 4.0,1730879310073,[],4,,,['everyone'],01s5ODIHKd,['NeurIPS.cc/2024/Conference/Submission9375/Reviewer_BZ7h'],1721081558290,1730879310073,"['NeurIPS.cc/2024/Conference', 'NeurIPS.cc/2024/Conference/Submission9375/Reviewer_BZ7h']","Yes, the peer review explicitly suggests the authors of the paper to cite specific literature, including:

1. StegaStamp [1]
2. Invisible image watermarks are provably removable using generative ai [2]
3. Benchmarking the robustness of image watermarks [3]
4. Tree-ring watermarks: Fingerprints for diffusion images that are invisible and robust [4]
5. Robustness of ai-image detectors: Fundamental limits and practical attacks [5]

These citations are mentioned in the weaknesses section of the review, where the reviewer points out that the authors should have compared their method to these existing works and cited them in their paper.",1,,Robustness of ai-image detectors Fundamental limits and practical attacks
